{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ›¡ï¸ ç¬¬äºŒç«  ç»ƒä¹  3: åŒé‡ç¨³å¥ä¼°è®¡ (Doubly Robust Estimation)\n",
    "\n",
    "---\n",
    "\n",
    "## ã€ŒåŒä¿é™©ã€çš„æ™ºæ…§\n",
    "\n",
    "åœ¨å‰ä¸¤ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†ï¼š\n",
    "- **PSM/IPW**: ä¾èµ–å€¾å‘å¾—åˆ†æ¨¡å‹ $e(X) = P(T=1|X)$\n",
    "- **å›å½’è°ƒæ•´**: ä¾èµ–ç»“æœæ¨¡å‹ $\\mu(X) = E[Y|X, T]$\n",
    "\n",
    "ä½†ç°å®ä¸­ï¼Œæˆ‘ä»¬æ€ä¹ˆçŸ¥é“æ¨¡å‹æ˜¯å¦æ­£ç¡®å‘¢ï¼Ÿ\n",
    "\n",
    "> ã€Œå¦‚æœå€¾å‘å¾—åˆ†æ¨¡å‹é”™äº†ï¼ŒIPW å°±å®Œè›‹äº†...ã€\n",
    "> \n",
    "> ã€Œå¦‚æœç»“æœæ¨¡å‹é”™äº†ï¼Œå›å½’è°ƒæ•´ä¹Ÿå®Œè›‹äº†...ã€\n",
    "\n",
    "æœ‰æ²¡æœ‰ä¸€ç§æ–¹æ³•ï¼Œå¯ä»¥åƒä¹°ä¿é™©ä¸€æ ·ï¼Œå³ä½¿ä¸€ä¸ªæ¨¡å‹é”™äº†ä¹Ÿæ²¡å…³ç³»ï¼Ÿ\n",
    "\n",
    "**æœ‰çš„ï¼è¿™å°±æ˜¯åŒé‡ç¨³å¥ (Doubly Robust) ä¼°è®¡ï¼**\n",
    "\n",
    "### åŒé‡ç¨³å¥çš„é­”åŠ› âœ¨\n",
    "\n",
    "åŒé‡ç¨³å¥ä¼°è®¡å™¨æœ‰ä¸€ä¸ªç¥å¥‡çš„æ€§è´¨ï¼š\n",
    "\n",
    "> **åªè¦å€¾å‘å¾—åˆ†æ¨¡å‹æˆ–ç»“æœæ¨¡å‹ä¹‹ä¸€æ­£ç¡®ï¼Œä¼°è®¡å°±æ˜¯æ— åçš„ï¼**\n",
    "\n",
    "è¿™å°±åƒä¹°äº†ã€ŒåŒä¿é™©ã€â€”â€”ä¸¤é“é˜²çº¿ï¼Œä»»ä¸€é“æœ‰æ•ˆå°±è¡Œï¼\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š æœ¬èŠ‚å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "1. ç†è§£åŒé‡ç¨³å¥æ€§çš„æ ¸å¿ƒæ¦‚å¿µ\n",
    "2. å®ç° AIPW (Augmented IPW) ä¼°è®¡å™¨\n",
    "3. éªŒè¯åŒé‡ç¨³å¥æ€§è´¨\n",
    "4. å¯¹æ¯”ä¸åŒå› æœæ¨æ–­æ–¹æ³•\n",
    "5. ç†è§£äº¤å‰æ‹Ÿåˆ (Cross-fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "# è®¾ç½®\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæ¯•ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## ğŸŒŸ Part 1: AIPW çš„æ ¸å¿ƒæ€æƒ³\n\n### å›é¡¾ï¼šä¸¤ç§åŸºæœ¬æ–¹æ³•\n\n**æ–¹æ³• 1: å›å½’è°ƒæ•´ï¼ˆç»“æœæ¨¡å‹ï¼‰**\n\n$$\\hat{ATE}_{\\text{reg}} = \\frac{1}{n}\\sum_{i=1}^{n}[\\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i)]$$\n\nå…¶ä¸­ $\\hat{\\mu}_1(X) = \\hat{E}[Y|X, T=1]$ï¼Œ$\\hat{\\mu}_0(X) = \\hat{E}[Y|X, T=0]$\n\n**æ–¹æ³• 2: IPWï¼ˆå€¾å‘å¾—åˆ†æ¨¡å‹ï¼‰**\n\n$$\\hat{ATE}_{\\text{IPW}} = \\frac{1}{n}\\sum_{i=1}^{n}\\left[\\frac{T_i Y_i}{\\hat{e}(X_i)} - \\frac{(1-T_i) Y_i}{1-\\hat{e}(X_i)}\\right]$$\n\n### AIPWï¼šä¸¤å…¨å…¶ç¾\n\nAIPW (Augmented IPW) å·§å¦™åœ°ç»“åˆäº†ä¸¤ç§æ–¹æ³•ï¼š\n\n$$\\hat{ATE}_{\\text{AIPW}} = \\frac{1}{n}\\sum_{i=1}^{n}\\left[\\underbrace{\\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i)}_{\\text{å›å½’è°ƒæ•´}} + \\underbrace{\\frac{T_i(Y_i - \\hat{\\mu}_1(X_i))}{\\hat{e}(X_i)}}_{\\text{å¤„ç†ç»„ IPW ä¿®æ­£}} - \\underbrace{\\frac{(1-T_i)(Y_i - \\hat{\\mu}_0(X_i))}{1-\\hat{e}(X_i)}}_{\\text{æ§åˆ¶ç»„ IPW ä¿®æ­£}}\\right]$$\n\n### ç›´è§‰ç†è§£\n\nAIPW çš„ä¸‰é¡¹åˆ†åˆ«æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ\n\n| é¡¹ | å…¬å¼ | å«ä¹‰ |\n|---|------|------|\n| ç¬¬ä¸€é¡¹ | $\\hat{\\mu}_1(X) - \\hat{\\mu}_0(X)$ | ç»“æœæ¨¡å‹é¢„æµ‹çš„æ•ˆåº” |\n| ç¬¬äºŒé¡¹ | $\\frac{T(Y - \\hat{\\mu}_1(X))}{e(X)}$ | å¯¹å¤„ç†ç»„é¢„æµ‹è¯¯å·®çš„ IPW ä¿®æ­£ |\n| ç¬¬ä¸‰é¡¹ | $\\frac{(1-T)(Y - \\hat{\\mu}_0(X))}{1-e(X)}$ | å¯¹æ§åˆ¶ç»„é¢„æµ‹è¯¯å·®çš„ IPW ä¿®æ­£ |\n\n**å…³é”®æ´å¯Ÿ**ï¼š\n- å¦‚æœç»“æœæ¨¡å‹å®Œç¾ï¼ˆ$Y = \\hat{\\mu}$ï¼‰ï¼Œé‚£ç¬¬äºŒã€ä¸‰é¡¹ä¸º 0ï¼Œåªå‰©ç¬¬ä¸€é¡¹\n- å¦‚æœç»“æœæ¨¡å‹ä¸å®Œç¾ä½†å€¾å‘å¾—åˆ†æ­£ç¡®ï¼ŒIPW ä¿®æ­£ä¼šçº æ­£åå·®\n- æ‰€ä»¥åªè¦ä¸€ä¸ªæ¨¡å‹æ­£ç¡®ï¼Œä¼°è®¡å°±æ˜¯æ— åçš„ï¼\n\n---\n\n## ğŸ“ AIPW åŒé‡ç¨³å¥æ€§è¯æ˜\n\n**å®šç†**: å¦‚æœå€¾å‘å¾—åˆ†æ¨¡å‹æˆ–ç»“æœæ¨¡å‹ä¹‹ä¸€æ­£ç¡®ï¼ŒAIPW ä¼°è®¡é‡æ˜¯ ATE çš„ä¸€è‡´ä¼°è®¡ã€‚\n\n**è¯æ˜æ€è·¯**:\n\nAIPW ä¼°è®¡ $E[Y(1)]$ çš„éƒ¨åˆ†ä¸ºï¼š\n\n$$\\hat{\\mu}_{AIPW,1} = \\frac{1}{n}\\sum_{i=1}^{n}\\left[\\hat{\\mu}_1(X_i) + \\frac{T_i(Y_i - \\hat{\\mu}_1(X_i))}{\\hat{e}(X_i)}\\right]$$\n\næˆ‘ä»¬éœ€è¦è¯æ˜ï¼š**åªè¦ $\\hat{e}$ æˆ– $\\hat{\\mu}_1$ ä¹‹ä¸€æ­£ç¡®ï¼Œ$E[\\hat{\\mu}_{AIPW,1}] = E[Y(1)]$**\n\n---\n\n### æƒ…å†µ 1: å€¾å‘å¾—åˆ†æ¨¡å‹æ­£ç¡® ($\\hat{e} = e$)\n\n$$E\\left[\\hat{\\mu}_1(X) + \\frac{T(Y - \\hat{\\mu}_1(X))}{e(X)}\\right]$$\n\nå¯¹ X æ¡ä»¶åŒ–ï¼š\n\n$$= E\\left[E\\left[\\hat{\\mu}_1(X) + \\frac{T(Y - \\hat{\\mu}_1(X))}{e(X)} \\Big| X\\right]\\right]$$\n\n$$= E\\left[\\hat{\\mu}_1(X) + \\frac{E[T(Y - \\hat{\\mu}_1(X))|X]}{e(X)}\\right]$$\n\n$$= E\\left[\\hat{\\mu}_1(X) + \\frac{e(X) \\cdot E[Y - \\hat{\\mu}_1(X)|X,T=1]}{e(X)}\\right]$$\n\n$$= E\\left[\\hat{\\mu}_1(X) + E[Y|X,T=1] - \\hat{\\mu}_1(X)\\right]$$\n\n$$= E[E[Y|X,T=1]]$$\n\nåº”ç”¨æ— æ··æ·†å‡è®¾ï¼š\n\n$$= E[Y(1)]$$ âœ“\n\n**å…³é”®**ï¼šå³ä½¿ $\\hat{\\mu}_1(X) \\neq E[Y|X,T=1]$ï¼ˆç»“æœæ¨¡å‹é”™äº†ï¼‰ï¼Œåªè¦å€¾å‘å¾—åˆ†æ­£ç¡®ï¼ŒIPW ä¿®æ­£é¡¹ä¼šå®Œç¾æŠµæ¶ˆåå·®ï¼\n\n---\n\n### æƒ…å†µ 2: ç»“æœæ¨¡å‹æ­£ç¡® ($\\hat{\\mu}_1 = \\mu_1$)\n\n$$E\\left[\\mu_1(X) + \\frac{T(Y - \\mu_1(X))}{e(X)}\\right]$$\n\nå¯¹ X, T æ¡ä»¶åŒ–ï¼š\n\n$$= E\\left[\\mu_1(X)\\right] + E\\left[\\frac{T(Y - \\mu_1(X))}{e(X)}\\right]$$\n\nå¯¹äºç¬¬äºŒé¡¹ï¼š\n\n$$E\\left[\\frac{T(Y - \\mu_1(X))}{e(X)}\\right] = E\\left[E\\left[\\frac{T(Y - \\mu_1(X))}{e(X)} \\Big| X\\right]\\right]$$\n\nç”±äº $\\mu_1(X) = E[Y|X,T=1]$ï¼š\n\n$$E[Y - \\mu_1(X)|X,T=1] = 0$$\n\nå› æ­¤ç¬¬äºŒé¡¹ä¸º 0ï¼š\n\n$$E\\left[\\mu_1(X) + \\frac{T(Y - \\mu_1(X))}{e(X)}\\right] = E[\\mu_1(X)] = E[E[Y|X,T=1]] = E[Y(1)]$$ âœ“\n\n**å…³é”®**ï¼šå³ä½¿å€¾å‘å¾—åˆ†æ¨¡å‹ $\\hat{e}$ é”™äº†ï¼Œåªè¦ç»“æœæ¨¡å‹æ­£ç¡®ï¼Œæ®‹å·®çš„æœŸæœ›ä¸º 0ï¼ŒIPW ä¿®æ­£é¡¹ä¸äº§ç”Ÿé¢å¤–åå·®ï¼\n\n---\n\n### åŒé‡ä¿é™©çš„é­”åŠ›\n\n| å€¾å‘å¾—åˆ† $\\hat{e}$ | ç»“æœæ¨¡å‹ $\\hat{\\mu}$ | AIPW ä¼°è®¡ |\n|---------|---------|------|\n| âœ… æ­£ç¡® | âœ… æ­£ç¡® | âœ… æ— åï¼Œæ•ˆç‡æœ€é«˜ |\n| âœ… æ­£ç¡® | âŒ é”™è¯¯ | âœ… æ— åï¼ˆIPW ä¿®æ­£æ•‘åœºï¼‰ |\n| âŒ é”™è¯¯ | âœ… æ­£ç¡® | âœ… æ— åï¼ˆæ®‹å·®ä¸º 0ï¼‰ |\n| âŒ é”™è¯¯ | âŒ é”™è¯¯ | âŒ æœ‰å |\n\nè¿™å°±æ˜¯\"åŒé‡ç¨³å¥\"çš„å«ä¹‰ï¼š**ä¸¤é“é˜²çº¿ï¼Œä»»ä¸€é“æœ‰æ•ˆå°±å¤Ÿï¼**\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”¬ Part 2: å®ç° AIPW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def estimate_outcome_models(\n    X: np.ndarray,\n    T: np.ndarray,\n    Y: np.ndarray\n) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    ä¼°è®¡ç»“æœæ¨¡å‹\n    \n    mu_1(X) = E[Y|X, T=1]\n    mu_0(X) = E[Y|X, T=0]\n    \n    åˆ†åˆ«ä¸ºå¤„ç†ç»„å’Œæ§åˆ¶ç»„è®­ç»ƒæ¨¡å‹ï¼Œç„¶åå¯¹æ‰€æœ‰æ ·æœ¬é¢„æµ‹\n    \"\"\"\n    treated_mask = T == 1\n    control_mask = T == 0\n    \n    # TODO: è®­ç»ƒå¤„ç†ç»„çš„ç»“æœæ¨¡å‹ mu_1(X)\n    model_1 = Ridge(alpha=1.0)\n    pass  # ğŸ‘ˆ ä½ çš„ä»£ç \n    \n    # å¯¹æ‰€æœ‰æ ·æœ¬é¢„æµ‹\n    mu_1 = None  # ğŸ‘ˆ ä½ çš„ä»£ç \n    \n    # TODO: è®­ç»ƒæ§åˆ¶ç»„çš„ç»“æœæ¨¡å‹ mu_0(X)\n    model_0 = Ridge(alpha=1.0)\n    pass  # ğŸ‘ˆ ä½ çš„ä»£ç \n    \n    mu_0 = None  # ğŸ‘ˆ ä½ çš„ä»£ç \n    \n    return mu_1, mu_0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>ğŸ’¡ ç‚¹å‡»æŸ¥çœ‹å‚è€ƒç­”æ¡ˆ</summary>\n",
    "\n",
    "```python\n",
    "def estimate_outcome_models(\n",
    "    X: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    Y: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    ä¼°è®¡ç»“æœæ¨¡å‹\n",
    "    \n",
    "    mu_1(X) = E[Y|X, T=1]\n",
    "    mu_0(X) = E[Y|X, T=0]\n",
    "    \n",
    "    åˆ†åˆ«ä¸ºå¤„ç†ç»„å’Œæ§åˆ¶ç»„è®­ç»ƒæ¨¡å‹ï¼Œç„¶åå¯¹æ‰€æœ‰æ ·æœ¬é¢„æµ‹\n",
    "    \"\"\"\n",
    "    treated_mask = T == 1\n",
    "    control_mask = T == 0\n",
    "    \n",
    "    # è®­ç»ƒå¤„ç†ç»„çš„ç»“æœæ¨¡å‹ mu_1(X)\n",
    "    model_1 = Ridge(alpha=1.0)\n",
    "    model_1.fit(X[treated_mask], Y[treated_mask])\n",
    "    \n",
    "    # å¯¹æ‰€æœ‰æ ·æœ¬é¢„æµ‹\n",
    "    mu_1 = model_1.predict(X)\n",
    "    \n",
    "    # è®­ç»ƒæ§åˆ¶ç»„çš„ç»“æœæ¨¡å‹ mu_0(X)\n",
    "    model_0 = Ridge(alpha=1.0)\n",
    "    model_0.fit(X[control_mask], Y[control_mask])\n",
    "    \n",
    "    mu_0 = model_0.predict(X)\n",
    "    \n",
    "    return mu_1, mu_0\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_ate_aipw(\n",
    "    X: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    propensity: np.ndarray,\n",
    "    mu_1: np.ndarray,\n",
    "    mu_0: np.ndarray\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ AIPW ä¼°è®¡ ATE\n",
    "    \n",
    "    AIPW = E[(mu_1 - mu_0) + T*(Y - mu_1)/e - (1-T)*(Y - mu_0)/(1-e)]\n",
    "    \"\"\"\n",
    "    # è£å‰ªå€¾å‘å¾—åˆ†\n",
    "    propensity_clipped = np.clip(propensity, 0.01, 0.99)\n",
    "    \n",
    "    # TODO: è®¡ç®— AIPW çš„ä¸‰é¡¹\n",
    "    \n",
    "    # ç¬¬ä¸€é¡¹ï¼šç»“æœæ¨¡å‹é¢„æµ‹çš„å·®å¼‚\n",
    "    term1 = None  # ğŸ‘ˆ ä½ çš„ä»£ç : mu_1 - mu_0\n",
    "    \n",
    "    # ç¬¬äºŒé¡¹ï¼šå¤„ç†ç»„çš„ IPW ä¿®æ­£\n",
    "    term2 = None  # ğŸ‘ˆ ä½ çš„ä»£ç : T * (Y - mu_1) / propensity_clipped\n",
    "    \n",
    "    # ç¬¬ä¸‰é¡¹ï¼šæ§åˆ¶ç»„çš„ IPW ä¿®æ­£\n",
    "    term3 = None  # ğŸ‘ˆ ä½ çš„ä»£ç : (1 - T) * (Y - mu_0) / (1 - propensity_clipped)\n",
    "    \n",
    "    # TODO: AIPW å¾—åˆ†\n",
    "    aipw_scores = None  # ğŸ‘ˆ ä½ çš„ä»£ç : term1 + term2 - term3\n",
    "    \n",
    "    if aipw_scores is None:\n",
    "        return None, None\n",
    "    \n",
    "    # ATE ä¼°è®¡\n",
    "    ate = aipw_scores.mean()\n",
    "    \n",
    "    # æ ‡å‡†è¯¯\n",
    "    se = aipw_scores.std() / np.sqrt(len(Y))\n",
    "    \n",
    "    return ate, se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>ğŸ’¡ ç‚¹å‡»æŸ¥çœ‹å‚è€ƒç­”æ¡ˆ</summary>\n",
    "\n",
    "```python\n",
    "def estimate_ate_aipw(\n",
    "    X: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    propensity: np.ndarray,\n",
    "    mu_1: np.ndarray,\n",
    "    mu_0: np.ndarray\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ AIPW ä¼°è®¡ ATE\n",
    "    \n",
    "    AIPW = E[(mu_1 - mu_0) + T*(Y - mu_1)/e - (1-T)*(Y - mu_0)/(1-e)]\n",
    "    \"\"\"\n",
    "    # è£å‰ªå€¾å‘å¾—åˆ†\n",
    "    propensity_clipped = np.clip(propensity, 0.01, 0.99)\n",
    "    \n",
    "    # è®¡ç®— AIPW çš„ä¸‰é¡¹\n",
    "    \n",
    "    # ç¬¬ä¸€é¡¹ï¼šç»“æœæ¨¡å‹é¢„æµ‹çš„å·®å¼‚\n",
    "    term1 = mu_1 - mu_0\n",
    "    \n",
    "    # ç¬¬äºŒé¡¹ï¼šå¤„ç†ç»„çš„ IPW ä¿®æ­£\n",
    "    term2 = T * (Y - mu_1) / propensity_clipped\n",
    "    \n",
    "    # ç¬¬ä¸‰é¡¹ï¼šæ§åˆ¶ç»„çš„ IPW ä¿®æ­£\n",
    "    term3 = (1 - T) * (Y - mu_0) / (1 - propensity_clipped)\n",
    "    \n",
    "    # AIPW å¾—åˆ†\n",
    "    aipw_scores = term1 + term2 - term3\n",
    "    \n",
    "    # ATE ä¼°è®¡\n",
    "    ate = aipw_scores.mean()\n",
    "    \n",
    "    # æ ‡å‡†è¯¯\n",
    "    se = aipw_scores.std() / np.sqrt(len(Y))\n",
    "    \n",
    "    return ate, se\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯• AIPW\n",
    "np.random.seed(42)\n",
    "n = 2000\n",
    "\n",
    "# ç”Ÿæˆæ•°æ®\n",
    "X = np.random.randn(n, 3)\n",
    "propensity_logit = 1.5 * (X[:, 0] + 0.5 * X[:, 1])\n",
    "propensity_true = 1 / (1 + np.exp(-propensity_logit))\n",
    "T = np.random.binomial(1, propensity_true)\n",
    "true_ate = 2.0\n",
    "Y = 5 + true_ate * T + 1.5 * X[:, 0] + X[:, 1] + np.random.randn(n) * 0.5\n",
    "\n",
    "print(f\"ğŸ“Š æ•°æ®æ¦‚è§ˆ:\")\n",
    "print(f\"   æ ·æœ¬é‡: {n}\")\n",
    "print(f\"   çœŸå® ATE: {true_ate}\")\n",
    "print(f\"   å¤„ç†ç»„: {T.sum()} ({T.mean()*100:.1f}%)\")\n",
    "\n",
    "# æœ´ç´ ä¼°è®¡\n",
    "naive_ate = Y[T==1].mean() - Y[T==0].mean()\n",
    "print(f\"   æœ´ç´  ATE: {naive_ate:.4f} (åå·®: {naive_ate - true_ate:+.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¼°è®¡å€¾å‘å¾—åˆ†\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X, T)\n",
    "propensity = lr.predict_proba(X)[:, 1]\n",
    "\n",
    "print(f\"å€¾å‘å¾—åˆ†èŒƒå›´: [{propensity.min():.4f}, {propensity.max():.4f}]\")\n",
    "\n",
    "# ä¼°è®¡ç»“æœæ¨¡å‹\n",
    "mu_1, mu_0 = estimate_outcome_models(X, T, Y)\n",
    "\n",
    "if mu_1 is not None and mu_0 is not None:\n",
    "    print(f\"\\nç»“æœæ¨¡å‹:\")\n",
    "    print(f\"   mu_1 èŒƒå›´: [{mu_1.min():.2f}, {mu_1.max():.2f}]\")\n",
    "    print(f\"   mu_0 èŒƒå›´: [{mu_0.min():.2f}, {mu_0.max():.2f}]\")\n",
    "    print(f\"   é¢„æµ‹çš„å¹³å‡æ•ˆåº”: {(mu_1 - mu_0).mean():.4f}\")\n",
    "    \n",
    "    # AIPW ä¼°è®¡\n",
    "    aipw_ate, aipw_se = estimate_ate_aipw(X, T, Y, propensity, mu_1, mu_0)\n",
    "    \n",
    "    if aipw_ate is not None:\n",
    "        print(f\"\\nğŸ“ˆ AIPW ä¼°è®¡:\")\n",
    "        print(f\"   AIPW ATE: {aipw_ate:.4f} Â± {aipw_se:.4f}\")\n",
    "        print(f\"   95% CI: [{aipw_ate - 1.96*aipw_se:.4f}, {aipw_ate + 1.96*aipw_se:.4f}]\")\n",
    "        print(f\"   åå·®: {aipw_ate - true_ate:+.4f}\")\n",
    "    else:\n",
    "        print(\"âŒ è¯·å®Œæˆ estimate_ate_aipw å‡½æ•°ï¼\")\n",
    "else:\n",
    "    print(\"âŒ è¯·å®Œæˆ estimate_outcome_models å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§ª Part 3: éªŒè¯åŒé‡ç¨³å¥æ€§\n",
    "\n",
    "è¿™æ˜¯æœ¬èŠ‚æœ€é‡è¦çš„å®éªŒï¼æˆ‘ä»¬è¦éªŒè¯ AIPW çš„ã€ŒåŒä¿é™©ã€æ€§è´¨ã€‚\n",
    "\n",
    "### å®éªŒè®¾è®¡\n",
    "\n",
    "| åœºæ™¯ | å€¾å‘å¾—åˆ†æ¨¡å‹ | ç»“æœæ¨¡å‹ | é¢„æœŸ |\n",
    "|-----|-------------|---------|------|\n",
    "| 1 | âœ… æ­£ç¡® | âœ… æ­£ç¡® | æ— å |\n",
    "| 2 | âœ… æ­£ç¡® | âŒ é”™è¯¯ | æ— å |\n",
    "| 3 | âŒ é”™è¯¯ | âœ… æ­£ç¡® | æ— å |\n",
    "| 4 | âŒ é”™è¯¯ | âŒ é”™è¯¯ | æœ‰å |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_with_misspecification(\n",
    "    n: int = 3000,\n",
    "    propensity_correct: bool = True,\n",
    "    outcome_correct: bool = True,\n",
    "    seed: int = 42\n",
    "):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆæ•°æ®ï¼Œå¯ä»¥äººä¸ºå¼•å…¥æ¨¡å‹è¯¯è®¾å®š\n",
    "    \n",
    "    çœŸå® DGP åŒ…å«éçº¿æ€§é¡¹ï¼š\n",
    "    - logit(e) = 1.5 * (X1 + 0.5*X2 + 0.3*X1^2)\n",
    "    - Y = 5 + 2*T + 1.5*X1 + X2 + 0.5*X1^2 + noise\n",
    "    \n",
    "    å¦‚æœåªç”¨çº¿æ€§æ¨¡å‹ï¼ˆä¸åŒ…å« X1^2ï¼‰ï¼Œå°±æ˜¯è¯¯è®¾å®š\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # ç”ŸæˆåŸºç¡€ç‰¹å¾\n",
    "    X1 = np.random.randn(n)\n",
    "    X2 = np.random.randn(n)\n",
    "    X3 = np.random.randn(n)\n",
    "    \n",
    "    # çœŸå®å€¾å‘å¾—åˆ†ï¼ˆåŒ…å«éçº¿æ€§ï¼‰\n",
    "    propensity_logit = 1.5 * (X1 + 0.5*X2 + 0.3*X1**2)\n",
    "    propensity_true = 1 / (1 + np.exp(-propensity_logit))\n",
    "    T = np.random.binomial(1, propensity_true)\n",
    "    \n",
    "    # çœŸå®ç»“æœï¼ˆåŒ…å«éçº¿æ€§ï¼‰\n",
    "    true_ate = 2.0\n",
    "    Y = 5 + true_ate*T + 1.5*X1 + X2 + 0.5*X1**2 + np.random.randn(n)*0.5\n",
    "    \n",
    "    # æ ¹æ®æ­£ç¡®æ€§è¿”å›ä¸åŒçš„ç‰¹å¾\n",
    "    if propensity_correct and outcome_correct:\n",
    "        # ä¸¤ä¸ªéƒ½æ­£ç¡®ï¼šåŒ…å«éçº¿æ€§ç‰¹å¾\n",
    "        X = np.column_stack([X1, X2, X3, X1**2])\n",
    "    elif propensity_correct and not outcome_correct:\n",
    "        # åªæœ‰å€¾å‘å¾—åˆ†æ­£ç¡®\n",
    "        X_prop = np.column_stack([X1, X2, X3, X1**2])\n",
    "        X_outcome = np.column_stack([X1, X2, X3])  # ç¼ºå°‘ X1^2\n",
    "        return X_prop, X_outcome, T, Y, true_ate\n",
    "    elif not propensity_correct and outcome_correct:\n",
    "        # åªæœ‰ç»“æœæ¨¡å‹æ­£ç¡®\n",
    "        X_prop = np.column_stack([X1, X2, X3])  # ç¼ºå°‘ X1^2\n",
    "        X_outcome = np.column_stack([X1, X2, X3, X1**2])\n",
    "        return X_prop, X_outcome, T, Y, true_ate\n",
    "    else:\n",
    "        # ä¸¤ä¸ªéƒ½é”™è¯¯ï¼šç¼ºå°‘éçº¿æ€§ç‰¹å¾\n",
    "        X = np.column_stack([X1, X2, X3])\n",
    "    \n",
    "    return X, X, T, Y, true_ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_double_robustness(n: int = 3000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    æµ‹è¯•åŒé‡ç¨³å¥æ€§è´¨\n",
    "    \n",
    "    å››ç§åœºæ™¯çš„å®Œæ•´æµ‹è¯•\n",
    "    \"\"\"\n",
    "    scenarios = [\n",
    "        ('ä¸¤æ¨¡å‹éƒ½æ­£ç¡®', True, True),\n",
    "        ('åªæœ‰å€¾å‘å¾—åˆ†æ­£ç¡®', True, False),\n",
    "        ('åªæœ‰ç»“æœæ¨¡å‹æ­£ç¡®', False, True),\n",
    "        ('ä¸¤æ¨¡å‹éƒ½é”™è¯¯', False, False)\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, prop_correct, outcome_correct in scenarios:\n",
    "        # ç”Ÿæˆæ•°æ®\n",
    "        data = simulate_with_misspecification(n, prop_correct, outcome_correct)\n",
    "        \n",
    "        if len(data) == 5:\n",
    "            X_prop, X_outcome, T, Y, true_ate = data\n",
    "        else:\n",
    "            X, _, T, Y, true_ate = data\n",
    "            X_prop = X_outcome = X\n",
    "        \n",
    "        # ä¼°è®¡å€¾å‘å¾—åˆ†\n",
    "        lr = LogisticRegression(max_iter=1000)\n",
    "        lr.fit(X_prop, T)\n",
    "        propensity = lr.predict_proba(X_prop)[:, 1]\n",
    "        \n",
    "        # ä¼°è®¡ç»“æœæ¨¡å‹\n",
    "        mu_1, mu_0 = estimate_outcome_models(X_outcome, T, Y)\n",
    "        \n",
    "        if mu_1 is None or mu_0 is None:\n",
    "            continue\n",
    "        \n",
    "        # AIPW ä¼°è®¡\n",
    "        aipw_ate, aipw_se = estimate_ate_aipw(X_prop, T, Y, propensity, mu_1, mu_0)\n",
    "        \n",
    "        if aipw_ate is None:\n",
    "            continue\n",
    "        \n",
    "        bias = aipw_ate - true_ate\n",
    "        \n",
    "        results.append({\n",
    "            'åœºæ™¯': name,\n",
    "            'å€¾å‘å¾—åˆ†æ­£ç¡®': 'âœ…' if prop_correct else 'âŒ',\n",
    "            'ç»“æœæ¨¡å‹æ­£ç¡®': 'âœ…' if outcome_correct else 'âŒ',\n",
    "            'AIPW ATE': aipw_ate,\n",
    "            'SE': aipw_se,\n",
    "            'åå·®': bias,\n",
    "            '|åå·®|': abs(bias)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡ŒåŒé‡ç¨³å¥æ€§æµ‹è¯•\n",
    "dr_results = test_double_robustness(n=3000)\n",
    "\n",
    "if not dr_results.empty:\n",
    "    print(\"ğŸ›¡ï¸ åŒé‡ç¨³å¥æ€§éªŒè¯:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"çœŸå® ATE = 2.0\")\n",
    "    print()\n",
    "    display(dr_results)\n",
    "    \n",
    "    print(\"\\nğŸ’¡ å…³é”®å‘ç°:\")\n",
    "    print(\"   1. ä¸¤æ¨¡å‹éƒ½æ­£ç¡®æ—¶ï¼šåå·®æœ€å°\")\n",
    "    print(\"   2. åªæœ‰ä¸€ä¸ªæ¨¡å‹æ­£ç¡®æ—¶ï¼šåå·®ä»ç„¶å¾ˆå°ï¼ˆåŒé‡ç¨³å¥æ€§ï¼ï¼‰\")\n",
    "    print(\"   3. ä¸¤æ¨¡å‹éƒ½é”™è¯¯æ—¶ï¼šåå·®æ˜æ˜¾å¢å¤§\")\n",
    "    \n",
    "    # å¯è§†åŒ–\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    colors = ['green', 'orange', 'orange', 'red']\n",
    "    bars = ax.barh(dr_results['åœºæ™¯'], dr_results['|åå·®|'], color=colors, alpha=0.7)\n",
    "    ax.axvline(0.1, color='gray', linestyle='--', label='|åå·®| = 0.1')\n",
    "    ax.set_xlabel('|åå·®|', fontsize=12)\n",
    "    ax.set_title('åŒé‡ç¨³å¥æ€§éªŒè¯: ä¸åŒåœºæ™¯ä¸‹çš„åå·®', fontsize=14)\n",
    "    \n",
    "    for bar, bias in zip(bars, dr_results['åå·®']):\n",
    "        ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n",
    "               f'{bias:+.4f}', va='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"è¯·å…ˆå®Œæˆå‰é¢çš„ TODO éƒ¨åˆ†ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Part 4: æ–¹æ³•å¯¹æ¯”\n",
    "\n",
    "è®©æˆ‘ä»¬ç³»ç»Ÿåœ°æ¯”è¾ƒå››ç§å› æœæ¨æ–­æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_causal_methods(\n",
    "    X: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    true_ate: float\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    å¯¹æ¯”ä¸åŒçš„å› æœæ¨æ–­æ–¹æ³•\n",
    "    \n",
    "    1. æœ´ç´ ä¼°è®¡\n",
    "    2. å›å½’è°ƒæ•´\n",
    "    3. IPW\n",
    "    4. AIPW\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # 1. æœ´ç´ ä¼°è®¡\n",
    "    naive_ate = Y[T==1].mean() - Y[T==0].mean()\n",
    "    results.append({\n",
    "        'æ–¹æ³•': 'æœ´ç´ ä¼°è®¡',\n",
    "        'ATE': naive_ate,\n",
    "        'åå·®': naive_ate - true_ate,\n",
    "        'SE': None,\n",
    "        'ä¾èµ–': 'æ— '\n",
    "    })\n",
    "    \n",
    "    # 2. å›å½’è°ƒæ•´\n",
    "    X_with_T = np.column_stack([T, X])\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_with_T, Y)\n",
    "    reg_ate = reg.coef_[0]\n",
    "    results.append({\n",
    "        'æ–¹æ³•': 'å›å½’è°ƒæ•´',\n",
    "        'ATE': reg_ate,\n",
    "        'åå·®': reg_ate - true_ate,\n",
    "        'SE': None,\n",
    "        'ä¾èµ–': 'ç»“æœæ¨¡å‹'\n",
    "    })\n",
    "    \n",
    "    # 3. IPW\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    lr.fit(X, T)\n",
    "    propensity = lr.predict_proba(X)[:, 1]\n",
    "    propensity_clipped = np.clip(propensity, 0.01, 0.99)\n",
    "    \n",
    "    weights = T / propensity_clipped + (1-T) / (1 - propensity_clipped)\n",
    "    y1_ipw = (Y * weights * T).sum() / (weights * T).sum()\n",
    "    y0_ipw = (Y * weights * (1-T)).sum() / (weights * (1-T)).sum()\n",
    "    ipw_ate = y1_ipw - y0_ipw\n",
    "    \n",
    "    results.append({\n",
    "        'æ–¹æ³•': 'IPW',\n",
    "        'ATE': ipw_ate,\n",
    "        'åå·®': ipw_ate - true_ate,\n",
    "        'SE': None,\n",
    "        'ä¾èµ–': 'å€¾å‘å¾—åˆ†æ¨¡å‹'\n",
    "    })\n",
    "    \n",
    "    # 4. AIPW\n",
    "    mu_1, mu_0 = estimate_outcome_models(X, T, Y)\n",
    "    if mu_1 is not None and mu_0 is not None:\n",
    "        aipw_ate, aipw_se = estimate_ate_aipw(X, T, Y, propensity, mu_1, mu_0)\n",
    "        if aipw_ate is not None:\n",
    "            results.append({\n",
    "                'æ–¹æ³•': 'AIPW',\n",
    "                'ATE': aipw_ate,\n",
    "                'åå·®': aipw_ate - true_ate,\n",
    "                'SE': aipw_se,\n",
    "                'ä¾èµ–': 'åŒé‡ç¨³å¥'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œæ–¹æ³•å¯¹æ¯”\n",
    "comparison = compare_causal_methods(X, T, Y, true_ate)\n",
    "\n",
    "if not comparison.empty:\n",
    "    print(\"ğŸ“Š å› æœæ¨æ–­æ–¹æ³•å¯¹æ¯”:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"çœŸå® ATE = {true_ate}\")\n",
    "    print()\n",
    "    display(comparison)\n",
    "    \n",
    "    # å¯è§†åŒ–\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    methods = comparison['æ–¹æ³•']\n",
    "    ates = comparison['ATE']\n",
    "    colors = ['red', 'orange', 'blue', 'green']\n",
    "    \n",
    "    bars = ax.bar(methods, ates, color=colors, alpha=0.7)\n",
    "    ax.axhline(true_ate, color='black', linestyle='--', linewidth=2, label=f'çœŸå® ATE = {true_ate}')\n",
    "    ax.set_ylabel('ATE ä¼°è®¡', fontsize=12)\n",
    "    ax.set_title('ä¸åŒå› æœæ¨æ–­æ–¹æ³•çš„ ATE ä¼°è®¡', fontsize=14)\n",
    "    ax.legend()\n",
    "    \n",
    "    for bar, ate, bias in zip(bars, ates, comparison['åå·®']):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,\n",
    "               f'åå·®: {bias:+.3f}', ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”„ Part 5: äº¤å‰æ‹Ÿåˆ (Cross-fitting)\n",
    "\n",
    "### ä¸ºä»€ä¹ˆéœ€è¦äº¤å‰æ‹Ÿåˆï¼Ÿ\n",
    "\n",
    "å½“æˆ‘ä»¬ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚éšæœºæ£®æ—ã€ç¥ç»ç½‘ç»œï¼‰æ—¶ï¼Œå®¹æ˜“å‡ºç°**è¿‡æ‹Ÿåˆåå·®**ï¼š\n",
    "- æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°å¤ªå¥½\n",
    "- å¯¼è‡´ $Y - \\hat{\\mu}(X)$ çš„æ®‹å·®è¢«ä½ä¼°\n",
    "- IPW ä¿®æ­£é¡¹å¤±æ•ˆ\n",
    "\n",
    "### äº¤å‰æ‹Ÿåˆçš„è§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "1. æŠŠæ•°æ®åˆ†æˆ K æŠ˜\n",
    "2. å¯¹æ¯ä¸€æŠ˜ï¼š\n",
    "   - ç”¨å…¶ä»– K-1 æŠ˜è®­ç»ƒæ¨¡å‹\n",
    "   - ç”¨å½“å‰æŠ˜åšé¢„æµ‹\n",
    "3. æ±‡æ€»æ‰€æœ‰æŠ˜çš„ AIPW å¾—åˆ†\n",
    "\n",
    "è¿™æ ·æ¨¡å‹çš„è®­ç»ƒå’Œé¢„æµ‹æ˜¯åœ¨ä¸åŒæ•°æ®ä¸Šè¿›è¡Œçš„ï¼Œé¿å…äº†è¿‡æ‹Ÿåˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_fitting_aipw(\n",
    "    X: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    n_folds: int = 5\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨äº¤å‰æ‹Ÿåˆçš„ AIPW\n",
    "    \"\"\"\n",
    "    n = len(Y)\n",
    "    aipw_scores = np.zeros(n)\n",
    "    \n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        # TODO: åˆ†å‰²æ•°æ®\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        T_train, T_test = T[train_idx], T[test_idx]\n",
    "        Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "        \n",
    "        # TODO: åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒå€¾å‘å¾—åˆ†æ¨¡å‹\n",
    "        lr = LogisticRegression(max_iter=1000)\n",
    "        lr.fit(X_train, T_train)\n",
    "        propensity_test = lr.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # TODO: åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒç»“æœæ¨¡å‹\n",
    "        treated_train = T_train == 1\n",
    "        control_train = T_train == 0\n",
    "        \n",
    "        model_1 = Ridge(alpha=1.0)\n",
    "        model_1.fit(X_train[treated_train], Y_train[treated_train])\n",
    "        mu_1_test = model_1.predict(X_test)\n",
    "        \n",
    "        model_0 = Ridge(alpha=1.0)\n",
    "        model_0.fit(X_train[control_train], Y_train[control_train])\n",
    "        mu_0_test = model_0.predict(X_test)\n",
    "        \n",
    "        # è®¡ç®—æµ‹è¯•é›†ä¸Šçš„ AIPW å¾—åˆ†\n",
    "        propensity_clipped = np.clip(propensity_test, 0.01, 0.99)\n",
    "        \n",
    "        term1 = mu_1_test - mu_0_test\n",
    "        term2 = T_test * (Y_test - mu_1_test) / propensity_clipped\n",
    "        term3 = (1 - T_test) * (Y_test - mu_0_test) / (1 - propensity_clipped)\n",
    "        \n",
    "        aipw_scores[test_idx] = term1 + term2 - term3\n",
    "    \n",
    "    # è®¡ç®— ATE å’Œæ ‡å‡†è¯¯\n",
    "    ate = aipw_scores.mean()\n",
    "    se = aipw_scores.std() / np.sqrt(n)\n",
    "    \n",
    "    return ate, se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹æ¯”æ ‡å‡† AIPW å’Œäº¤å‰æ‹Ÿåˆ AIPW\n",
    "if mu_1 is not None:\n",
    "    # äº¤å‰æ‹Ÿåˆ\n",
    "    cf_ate, cf_se = cross_fitting_aipw(X, T, Y, n_folds=5)\n",
    "    \n",
    "    print(\"ğŸ”„ äº¤å‰æ‹Ÿåˆ vs æ ‡å‡† AIPW:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"çœŸå® ATE: {true_ate}\")\n",
    "    print(f\"\\næ ‡å‡† AIPW:\")\n",
    "    print(f\"   ATE: {aipw_ate:.4f} Â± {aipw_se:.4f}\")\n",
    "    print(f\"   åå·®: {aipw_ate - true_ate:+.4f}\")\n",
    "    print(f\"\\näº¤å‰æ‹Ÿåˆ AIPW:\")\n",
    "    print(f\"   ATE: {cf_ate:.4f} Â± {cf_se:.4f}\")\n",
    "    print(f\"   åå·®: {cf_ate - true_ate:+.4f}\")\n",
    "    \n",
    "    print(\"\\nğŸ’¡ è¯´æ˜:\")\n",
    "    print(\"   åœ¨ä½¿ç”¨çº¿æ€§æ¨¡å‹æ—¶ï¼Œä¸¤è€…å·®å¼‚ä¸å¤§\")\n",
    "    print(\"   ä½†åœ¨ä½¿ç”¨å¤æ‚æœºå™¨å­¦ä¹ æ¨¡å‹æ—¶ï¼Œäº¤å‰æ‹Ÿåˆæ›´ç¨³å¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Part 6: æ€è€ƒé¢˜\n",
    "\n",
    "### é—®é¢˜ 1: ä»€ä¹ˆæ˜¯åŒé‡ç¨³å¥æ€§ï¼Ÿä¸ºä»€ä¹ˆ AIPW å…·æœ‰è¿™ä¸ªæ€§è´¨ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 2: AIPW ä¼°è®¡å™¨çš„ä¸‰é¡¹åˆ†åˆ«ä»£è¡¨ä»€ä¹ˆå«ä¹‰ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 3: å¦‚æœä¸¤ä¸ªæ¨¡å‹éƒ½é”™è¯¯ï¼ŒAIPW è¿˜ä¼šæœ‰åå—ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 4: ä»€ä¹ˆæ˜¯äº¤å‰æ‹Ÿåˆï¼Ÿä¸ºä»€ä¹ˆåœ¨ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹æ—¶éœ€è¦äº¤å‰æ‹Ÿåˆï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 5: åŒé‡ç¨³å¥ä¼°è®¡æ˜¯ã€Œé“¶å¼¹ã€å—ï¼Ÿæœ‰ä»€ä¹ˆå±€é™æ€§ï¼Ÿ\n",
    "\n",
    "**æç¤º:** æƒ³æƒ³æœªè§‚æµ‹æ··æ·†ã€æ¨¡å‹é€‰æ‹©ã€æ ·æœ¬é‡...\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "source": "class MyAIPWEstimator:\n    \"\"\"\n    ä»é›¶å®ç°çš„ AIPW (Augmented IPW) ä¼°è®¡å™¨\n    \n    å®ç°äº†å®Œæ•´çš„åŒé‡ç¨³å¥ä¼°è®¡æµç¨‹\n    \"\"\"\n    \n    def __init__(self, \n                 propensity_model=None,\n                 outcome_model=None,\n                 trim_propensity: Tuple[float, float] = (0.01, 0.99)):\n        \"\"\"\n        Args:\n            propensity_model: å€¾å‘å¾—åˆ†æ¨¡å‹ï¼ˆé»˜è®¤ LogisticRegressionï¼‰\n            outcome_model: ç»“æœæ¨¡å‹ï¼ˆé»˜è®¤ Ridgeï¼‰\n            trim_propensity: å€¾å‘å¾—åˆ†è£å‰ªèŒƒå›´\n        \"\"\"\n        self.propensity_model = propensity_model or LogisticRegression(max_iter=1000)\n        self.outcome_model = outcome_model or Ridge(alpha=1.0)\n        self.trim_propensity = trim_propensity\n        \n    def fit(self, X: np.ndarray, T: np.ndarray, Y: np.ndarray):\n        \"\"\"æ‹Ÿåˆå€¾å‘å¾—åˆ†æ¨¡å‹å’Œç»“æœæ¨¡å‹\"\"\"\n        self.X_ = X\n        self.T_ = T\n        self.Y_ = Y\n        \n        # Step 1: ä¼°è®¡å€¾å‘å¾—åˆ†\n        self.propensity_model.fit(X, T)\n        self.propensity_ = self.propensity_model.predict_proba(X)[:, 1]\n        self.propensity_ = np.clip(self.propensity_, \n                                   self.trim_propensity[0],\n                                   self.trim_propensity[1])\n        \n        # Step 2: ä¼°è®¡ç»“æœæ¨¡å‹\n        treated_mask = T == 1\n        control_mask = T == 0\n        \n        # mu_1(X) = E[Y|X,T=1]\n        self.outcome_model_1_ = Ridge(alpha=1.0)\n        self.outcome_model_1_.fit(X[treated_mask], Y[treated_mask])\n        self.mu_1_ = self.outcome_model_1_.predict(X)\n        \n        # mu_0(X) = E[Y|X,T=0]\n        self.outcome_model_0_ = Ridge(alpha=1.0)\n        self.outcome_model_0_.fit(X[control_mask], Y[control_mask])\n        self.mu_0_ = self.outcome_model_0_.predict(X)\n        \n        return self\n    \n    def estimate_ate(self) -> Tuple[float, float]:\n        \"\"\"ä¼°è®¡ ATE å’Œæ ‡å‡†è¯¯\"\"\"\n        if not hasattr(self, 'propensity_'):\n            raise ValueError(\"Must fit before estimating ATE\")\n        \n        # AIPW å¾—åˆ†\n        aipw_scores = self._compute_aipw_scores()\n        \n        # ATE ä¼°è®¡\n        ate = aipw_scores.mean()\n        \n        # æ ‡å‡†è¯¯\n        se = aipw_scores.std() / np.sqrt(len(self.Y_))\n        \n        return ate, se\n    \n    def _compute_aipw_scores(self) -> np.ndarray:\n        \"\"\"\n        è®¡ç®— AIPW å¾—åˆ†\n        \n        AIPW = (mu_1 - mu_0) + T*(Y - mu_1)/e - (1-T)*(Y - mu_0)/(1-e)\n        \"\"\"\n        # ç¬¬ä¸€é¡¹ï¼šå›å½’è°ƒæ•´\n        term1 = self.mu_1_ - self.mu_0_\n        \n        # ç¬¬äºŒé¡¹ï¼šå¤„ç†ç»„ IPW ä¿®æ­£\n        term2 = self.T_ * (self.Y_ - self.mu_1_) / self.propensity_\n        \n        # ç¬¬ä¸‰é¡¹ï¼šæ§åˆ¶ç»„ IPW ä¿®æ­£\n        term3 = (1 - self.T_) * (self.Y_ - self.mu_0_) / (1 - self.propensity_)\n        \n        aipw_scores = term1 + term2 - term3\n        \n        return aipw_scores\n    \n    def decompose_components(self) -> Dict[str, float]:\n        \"\"\"åˆ†è§£ AIPW çš„ä¸‰ä¸ªç»„æˆéƒ¨åˆ†\"\"\"\n        term1 = (self.mu_1_ - self.mu_0_).mean()\n        term2 = (self.T_ * (self.Y_ - self.mu_1_) / self.propensity_).mean()\n        term3 = ((1 - self.T_) * (self.Y_ - self.mu_0_) / (1 - self.propensity_)).mean()\n        \n        return {\n            'regression_component': term1,\n            'treated_ipw_correction': term2,\n            'control_ipw_correction': -term3,\n            'total_ate': term1 + term2 - term3\n        }\n    \n    def summary(self):\n        \"\"\"æ‰“å°ä¼°è®¡ç»“æœæ‘˜è¦\"\"\"\n        ate, se = self.estimate_ate()\n        components = self.decompose_components()\n        \n        print(\"=\" * 70)\n        print(\"AIPW ä¼°è®¡ç»“æœ\")\n        print(\"=\" * 70)\n        print(f\"ATE ä¼°è®¡: {ate:.4f} Â± {se:.4f}\")\n        print(f\"95% CI: [{ate - 1.96*se:.4f}, {ate + 1.96*se:.4f}]\")\n        print()\n        print(\"ç»„æˆéƒ¨åˆ†åˆ†è§£:\")\n        print(f\"  1. å›å½’è°ƒæ•´é¡¹:        {components['regression_component']:8.4f}\")\n        print(f\"  2. å¤„ç†ç»„ IPW ä¿®æ­£:   {components['treated_ipw_correction']:+8.4f}\")\n        print(f\"  3. æ§åˆ¶ç»„ IPW ä¿®æ­£:   {components['control_ipw_correction']:+8.4f}\")\n        print(f\"  {'='*30}\")\n        print(f\"  æ€» ATE:              {components['total_ate']:8.4f}\")\n        print(\"=\" * 70)\n\n\n# æµ‹è¯•æˆ‘ä»¬çš„å®ç°\nprint(\"ğŸ§ª æµ‹è¯•è‡ªå·±å®ç°çš„ AIPW ä¼°è®¡å™¨\\n\")\n\n# ç”Ÿæˆæ•°æ®ï¼ˆåŒ…å«éçº¿æ€§ï¼‰\nnp.random.seed(42)\nn = 2000\nX_test = np.random.randn(n, 3)\n\n# çœŸå® DGPï¼ˆå¸¦éçº¿æ€§ï¼‰\npropensity_logit = 1.5 * (X_test[:, 0] + 0.5 * X_test[:, 1] + 0.2 * X_test[:, 0]**2)\npropensity_true = 1 / (1 + np.exp(-propensity_logit))\nT_test = np.random.binomial(1, propensity_true)\nY_test = 2.0 * T_test + 1.5 * X_test[:, 0] + X_test[:, 1] + 0.3 * X_test[:, 0]**2 + np.random.randn(n) * 0.5\n\nprint(f\"çœŸå® ATE = 2.0\")\nprint(f\"æ•°æ®ç‰¹ç‚¹: åŒ…å«éçº¿æ€§é¡¹ X1^2\\n\")\n\n# æµ‹è¯•æˆ‘ä»¬çš„ AIPW\nmy_aipw = MyAIPWEstimator()\nmy_aipw.fit(X_test, T_test, Y_test)\nmy_aipw.summary()\n\n# å¯¹æ¯”å…¶ä»–æ–¹æ³•\nprint(\"\\n\\nå¯¹æ¯”å…¶ä»–æ–¹æ³•:\")\nprint(\"=\" * 70)\n\n# æœ´ç´ ä¼°è®¡\nnaive = Y_test[T_test==1].mean() - Y_test[T_test==0].mean()\nprint(f\"æœ´ç´ ä¼°è®¡:     {naive:.4f}  (åå·®: {naive - 2.0:+.4f})\")\n\n# çº¯å›å½’è°ƒæ•´ï¼ˆä¼šå› éçº¿æ€§è€Œæœ‰åï¼‰\nreg_component = my_aipw.decompose_components()['regression_component']\nprint(f\"å›å½’è°ƒæ•´:     {reg_component:.4f}  (åå·®: {reg_component - 2.0:+.4f})\")\n\n# AIPW\naipw_ate, _ = my_aipw.estimate_ate()\nprint(f\"AIPW:        {aipw_ate:.4f}  (åå·®: {aipw_ate - 2.0:+.4f}) âœ…\")\n\nprint(\"\\nğŸ’¡ è§‚å¯Ÿ: AIPW é€šè¿‡ IPW ä¿®æ­£é¡¹çº æ­£äº†å›å½’è°ƒæ•´çš„åå·®ï¼\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## ğŸ’» ä»é›¶å®ç° AIPW\n\nè®©æˆ‘ä»¬å®ç°ä¸€ä¸ªå®Œæ•´çš„ AIPW ä¼°è®¡å™¨ç±»ï¼",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## ğŸ¤ é«˜é¢‘é¢è¯•é¢˜\n\n### é¢è¯•é¢˜ 1: ä»€ä¹ˆæ˜¯åŒé‡ç¨³å¥æ€§ï¼Ÿä¸ºä»€ä¹ˆ AIPW å…·æœ‰è¿™ä¸ªæ€§è´¨ï¼Ÿ\n\n**å‚è€ƒå›ç­”**:\n\nåŒé‡ç¨³å¥æ€§(Double Robustness)æ˜¯æŒ‡ï¼š**åªè¦å€¾å‘å¾—åˆ†æ¨¡å‹æˆ–ç»“æœæ¨¡å‹ä¹‹ä¸€æ­£ç¡®ï¼Œä¼°è®¡é‡å°±æ˜¯ä¸€è‡´çš„ã€‚**\n\n**AIPW çš„å…¬å¼**:\n$$\\hat{\\tau} = \\frac{1}{n}\\sum_i \\left[(\\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i)) + \\frac{T_i(Y_i - \\hat{\\mu}_1(X_i))}{\\hat{e}(X_i)} - \\frac{(1-T_i)(Y_i - \\hat{\\mu}_0(X_i))}{1-\\hat{e}(X_i)}\\right]$$\n\n**ä¸ºä»€ä¹ˆå…·æœ‰åŒé‡ç¨³å¥æ€§**:\n\n1. **å¦‚æœå€¾å‘å¾—åˆ†æ­£ç¡®**: IPW ä¿®æ­£é¡¹ä¼šå®Œç¾æŠµæ¶ˆç»“æœæ¨¡å‹çš„è¯¯å·®\n2. **å¦‚æœç»“æœæ¨¡å‹æ­£ç¡®**: æ®‹å·® $Y - \\hat{\\mu}(X)$ çš„æœŸæœ›ä¸º 0ï¼ŒIPW ä¿®æ­£é¡¹ä¸å¼•å…¥åå·®\n\n**ç›´è§‚ç†è§£**: AIPW å°±åƒä¹°äº†ä¸¤ä»½ä¿é™©ï¼š\n- ç¬¬ä¸€ä»½é™©ï¼šç»“æœæ¨¡å‹é¢„æµ‹æ•ˆåº”\n- ç¬¬äºŒä»½é™©ï¼šIPW ä¿®æ­£ä»»ä½•é¢„æµ‹è¯¯å·®\n- åªè¦ä¸€ä»½é™©æœ‰æ•ˆï¼Œå°±èƒ½å¾—åˆ°æ­£ç¡®ç­”æ¡ˆï¼\n\n---\n\n### é¢è¯•é¢˜ 2: AIPW ä¼°è®¡å™¨çš„ä¸‰é¡¹åˆ†åˆ«ä»£è¡¨ä»€ä¹ˆå«ä¹‰ï¼Ÿ\n\n**å‚è€ƒå›ç­”**:\n\n| é¡¹ | å…¬å¼ | ç»Ÿè®¡å«ä¹‰ | å› æœå«ä¹‰ |\n|---|------|----------|----------|\n| **ç¬¬ä¸€é¡¹** | $\\hat{\\mu}_1(X) - \\hat{\\mu}_0(X)$ | ä¸¤ä¸ªå›å½’æ¨¡å‹é¢„æµ‹çš„å·®å¼‚ | åŸºäºåå˜é‡é¢„æµ‹çš„ä¸ªä½“æ•ˆåº” |\n| **ç¬¬äºŒé¡¹** | $\\frac{T(Y - \\hat{\\mu}_1(X))}{e(X)}$ | å¤„ç†ç»„çš„åŠ æƒæ®‹å·® | ä¿®æ­£å¤„ç†ç»„é¢„æµ‹è¯¯å·® |\n| **ç¬¬ä¸‰é¡¹** | $-\\frac{(1-T)(Y - \\hat{\\mu}_0(X))}{1-e(X)}$ | æ§åˆ¶ç»„çš„åŠ æƒæ®‹å·® | ä¿®æ­£æ§åˆ¶ç»„é¢„æµ‹è¯¯å·® |\n\n**å·¥ä½œåŸç†**:\n1. ç¬¬ä¸€é¡¹ç»™å‡º\"åˆæ­¥ä¼°è®¡\"ï¼ˆåŸºäºç»“æœæ¨¡å‹ï¼‰\n2. ç¬¬äºŒã€ä¸‰é¡¹å¯¹\"è§‚æµ‹åˆ°çš„æ ·æœ¬\"çš„é¢„æµ‹è¯¯å·®è¿›è¡ŒåŠ æƒä¿®æ­£\n3. æƒé‡ $\\frac{1}{e(X)}$ ç¡®ä¿ä¿®æ­£æ˜¯æ— åçš„\n\n**ç‰¹æ®Šæƒ…å†µ**:\n- å¦‚æœ $\\hat{\\mu}$ å®Œç¾ï¼Œç¬¬äºŒä¸‰é¡¹ = 0ï¼Œåªç”¨ç¬¬ä¸€é¡¹\n- å¦‚æœ $\\hat{\\mu}$ å¾ˆå·®ä½† $\\hat{e}$ å¯¹ï¼Œç¬¬äºŒä¸‰é¡¹ä¼šå®Œå…¨ä¿®æ­£ç¬¬ä¸€é¡¹çš„è¯¯å·®\n\n---\n\n### é¢è¯•é¢˜ 3: å¦‚æœä¸¤ä¸ªæ¨¡å‹éƒ½é”™è¯¯ï¼ŒAIPW è¿˜ä¼šæœ‰åå—ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n\n**å‚è€ƒå›ç­”**:\n\n**æ˜¯çš„ï¼ŒAIPW ä»ä¼šæœ‰åã€‚**\n\nåŒé‡ç¨³å¥æ€§ä¸æ˜¯\"æ— æ•Œ\"çš„ï¼Œå®ƒçš„ä¿è¯æ˜¯ï¼š\n- **è‡³å°‘ä¸€ä¸ªæ¨¡å‹æ­£ç¡® â†’ æ— å**\n- **ä¸¤ä¸ªæ¨¡å‹éƒ½é”™ â†’ ä¸€èˆ¬æƒ…å†µä¸‹æœ‰å**\n\n**ä¸ºä»€ä¹ˆï¼Ÿ**\n\nAIPW çš„æœŸæœ›ä¸ºï¼š\n$$E[\\hat{\\tau}_{AIPW}] = \\tau + \\underbrace{E\\left[\\frac{T(\\hat{\\mu}_1(X) - \\mu_1(X))}{e(X)} \\cdot \\frac{e(X) - \\hat{e}(X)}{e(X)}\\right]}_{\\text{ä¸¤ä¸ªæ¨¡å‹è¯¯å·®çš„äº¤äº’é¡¹}}$$\n\nå½“ä¸¤ä¸ªæ¨¡å‹éƒ½é”™æ—¶ï¼Œäº¤äº’é¡¹ä¸€èˆ¬ä¸ä¸º 0ï¼Œå¯¼è‡´åå·®ã€‚\n\n**ä½†æ˜¯**ï¼Œå³ä½¿ä¸¤ä¸ªæ¨¡å‹éƒ½æœ‰å°è¯¯å·®ï¼ŒAIPW çš„åå·®é€šå¸¸ä¹Ÿæ¯”å•ç‹¬ä½¿ç”¨ä»»ä¸€æ¨¡å‹è¦å°ï¼è¿™å°±æ˜¯å®ƒçš„ä¼˜åŠ¿ã€‚\n\n**å®è·µå»ºè®®**:\n1. å°½é‡ç”¨çµæ´»çš„æ¨¡å‹ï¼ˆå¦‚éšæœºæ£®æ—ã€XGBoostï¼‰\n2. ä¸¤ä¸ªæ¨¡å‹ç”¨ä¸åŒçš„æ¨¡å‹æ—ï¼ˆé™ä½åŒæ—¶é”™çš„æ¦‚ç‡ï¼‰\n3. ä½¿ç”¨äº¤å‰æ‹Ÿåˆé¿å…è¿‡æ‹Ÿåˆåå·®\n\n---\n\n### é¢è¯•é¢˜ 4: AIPW å’Œæ™®é€šçš„å›å½’è°ƒæ•´æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ\n\n**å‚è€ƒå›ç­”**:\n\n| ç‰¹æ€§ | å›å½’è°ƒæ•´ | AIPW |\n|------|---------|------|\n| **å…¬å¼** | $\\hat{\\mu}_1(X) - \\hat{\\mu}_0(X)$ | $(\\hat{\\mu}_1 - \\hat{\\mu}_0) + \\text{IPW ä¿®æ­£}$ |\n| **ä¾èµ–** | åªä¾èµ–ç»“æœæ¨¡å‹ | ä¾èµ–ä¸¤ä¸ªæ¨¡å‹ |\n| **ç¨³å¥æ€§** | æ¨¡å‹é”™äº†å°±å®Œè›‹ | åŒé‡ç¨³å¥ âœ… |\n| **æ•ˆç‡** | é€šå¸¸æ•ˆç‡è¾ƒé«˜ | ä¸¤æ¨¡å‹éƒ½å¯¹æ—¶æœ€ä¼˜ï¼Œä¸€ä¸ªé”™æ—¶ä»åˆç† |\n| **æ–¹å·®** | è¾ƒå° | å¯èƒ½ç¨å¤§ï¼ˆå› ä¸ºæœ‰ IPW é¡¹ï¼‰ |\n\n**å…³é”®åŒºåˆ«**ï¼š\n- å›å½’è°ƒæ•´å‡è®¾ $\\hat{\\mu}$ æ­£ç¡®ï¼Œç›´æ¥ç”¨å®ƒä¼°è®¡\n- AIPW è¯´\"æˆ‘ä¸å®Œå…¨ä¿¡ä»» $\\hat{\\mu}$ï¼Œç”¨ IPW æ£€æŸ¥å’Œä¿®æ­£å®ƒ\"\n\n**æ¯”å–»**ï¼š\n- å›å½’è°ƒæ•´ï¼šå®Œå…¨ç›¸ä¿¡å¯¼èˆª\n- AIPWï¼šç›¸ä¿¡å¯¼èˆªï¼Œä½†åŒæ—¶çœ‹è·¯æ ‡ç¡®è®¤ï¼ˆåŒä¿é™©ï¼‰\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ‰ æ€»ç»“\n",
    "\n",
    "### æ ¸å¿ƒå…¬å¼\n",
    "\n",
    "AIPW ä¼°è®¡å™¨ï¼š\n",
    "\n",
    "$$\\hat{\\tau}_{AIPW} = \\frac{1}{n}\\sum_{i=1}^{n}\\left[(\\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i)) + \\frac{T_i(Y_i - \\hat{\\mu}_1(X_i))}{\\hat{e}(X_i)} - \\frac{(1-T_i)(Y_i - \\hat{\\mu}_0(X_i))}{1-\\hat{e}(X_i)}\\right]$$\n",
    "\n",
    "### åŒé‡ç¨³å¥æ€§\n",
    "\n",
    "| å€¾å‘å¾—åˆ† | ç»“æœæ¨¡å‹ | AIPW |\n",
    "|---------|---------|------|\n",
    "| âœ… æ­£ç¡® | âœ… æ­£ç¡® | âœ… æ— å |\n",
    "| âœ… æ­£ç¡® | âŒ é”™è¯¯ | âœ… æ— å |\n",
    "| âŒ é”™è¯¯ | âœ… æ­£ç¡® | âœ… æ— å |\n",
    "| âŒ é”™è¯¯ | âŒ é”™è¯¯ | âŒ æœ‰å |\n",
    "\n",
    "### æ–¹æ³•é€‰æ‹©æŒ‡å—\n",
    "\n",
    "| æ–¹æ³• | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |\n",
    "|-----|------|------|----------|\n",
    "| PSM | ç›´è§‚ã€å¯æ£€æŸ¥å¹³è¡¡ | ä¸¢å¼ƒæ ·æœ¬ | å°æ•°æ®ã€éœ€è¦å¯è§£é‡Šæ€§ |\n",
    "| IPW | ä½¿ç”¨å…¨éƒ¨æ ·æœ¬ | æç«¯æƒé‡ | ä¸­ç­‰æ··æ·† |\n",
    "| AIPW | åŒé‡ç¨³å¥ã€æ•ˆç‡é«˜ | è®¡ç®—å¤æ‚ | **æ¨èä½¿ç”¨** |\n",
    "\n",
    "### ç¬¬äºŒç« å®Œç»“ï¼\n",
    "\n",
    "æ­å–œä½ å®Œæˆäº†å¤„ç†æ•ˆåº”ä¼°è®¡çš„æ‰€æœ‰ç»ƒä¹ ï¼ä½ å·²ç»æŒæ¡äº†å› æœæ¨æ–­çš„æ ¸å¿ƒæ–¹æ³•ï¼š\n",
    "\n",
    "- âœ… å€¾å‘å¾—åˆ†åŒ¹é… (PSM)\n",
    "- âœ… é€†æ¦‚ç‡åŠ æƒ (IPW)\n",
    "- âœ… åŒé‡ç¨³å¥ä¼°è®¡ (AIPW)\n",
    "\n",
    "ä¸‹ä¸€ç« æˆ‘ä»¬å°†å­¦ä¹ **å¼‚è´¨å¤„ç†æ•ˆåº”**â€”â€”ä¸ä»…ä¼°è®¡å¹³å‡æ•ˆåº”ï¼Œè¿˜è¦è¯†åˆ«ã€Œè°å—ç›Šæœ€å¤šã€ï¼\n",
    "\n",
    "---\n",
    "\n",
    "**ã€ŒåŒé‡ä¿é™©ï¼Œä¸€ä¸ªæ­£ç¡®å°±å¤Ÿã€‚ã€â€”â€”è¿™å°±æ˜¯åŒé‡ç¨³å¥çš„æ™ºæ…§ã€‚**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}