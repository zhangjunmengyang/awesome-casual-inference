{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dive 03: Causal Forest åˆ†è£‚å‡†åˆ™æ·±åº¦è§£æ\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "å®Œæˆæœ¬ notebook åï¼Œä½ å°†èƒ½å¤Ÿï¼š\n",
    "\n",
    "1. **æ·±å…¥ç†è§£** Causal Forest ä¸æ™®é€šéšæœºæ£®æ—çš„æœ¬è´¨åŒºåˆ«\n",
    "2. **æŒæ¡** åŸºäº CATE æ–¹å·®æœ€å¤§åŒ–çš„åˆ†è£‚å‡†åˆ™\n",
    "3. **å®ç°** ä»é›¶å¼€å§‹æ„å»º Causal Treeï¼ˆä¸ç”¨ econml/grfï¼‰\n",
    "4. **ç†è§£** Honest Splitting å’Œç½®ä¿¡åŒºé—´ä¼°è®¡\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“– èƒŒæ™¯æ•…äº‹\n",
    "\n",
    "> **åœºæ™¯ï¼šè§£é‡Šæ¨¡å‹ä¸ºä»€ä¹ˆè¿™æ ·åˆ†è£‚**\n",
    ">\n",
    "> é¢è¯•å®˜é—®ï¼š\"ä½ ç”¨è¿‡ Causal Forestï¼Œèƒ½å‘Šè¯‰æˆ‘å®ƒçš„åˆ†è£‚å‡†åˆ™å’Œ CART æœ‰ä»€ä¹ˆä¸åŒå—ï¼Ÿ\"\n",
    ">\n",
    "> ä½ å›ç­”ï¼š\"å—¯... å®ƒæ˜¯ç”¨æ¥ä¼°è®¡å¼‚è´¨æ€§æ•ˆåº”çš„...\"\n",
    ">\n",
    "> é¢è¯•å®˜è¿½é—®ï¼š\"å…·ä½“æ€ä¹ˆåˆ†è£‚ï¼Ÿç›®æ ‡å‡½æ•°æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆè¦ç”¨ Honest Splittingï¼Ÿ\"\n",
    ">\n",
    "> ä½ ï¼š\"...\"  ğŸ˜°\n",
    ">\n",
    "> **æœ¬ notebook å°†å¸¦ä½ å½»åº•ç†è§£ Causal Forest çš„æ ¸å¿ƒåŸç†ï¼**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: ä» CART åˆ° Causal Tree\n",
    "\n",
    "### 1.1 æ™®é€š CART çš„åˆ†è£‚å‡†åˆ™\n",
    "\n",
    "CARTï¼ˆClassification and Regression Treeï¼‰çš„åˆ†è£‚ç›®æ ‡æ˜¯**æœ€å°åŒ–å­èŠ‚ç‚¹çš„ä¸çº¯åº¦**ï¼š\n",
    "\n",
    "**å›å½’æ ‘**ï¼š\n",
    "$$\\text{Impurity}(S) = \\frac{1}{|S|} \\sum_{i \\in S} (Y_i - \\bar{Y}_S)^2$$\n",
    "\n",
    "åˆ†è£‚å¢ç›Šï¼š\n",
    "$$\\text{Gain} = \\text{Impurity}(S) - \\left( \\frac{|S_L|}{|S|} \\text{Impurity}(S_L) + \\frac{|S_R|}{|S|} \\text{Impurity}(S_R) \\right)$$\n",
    "\n",
    "### 1.2 ä¸ºä»€ä¹ˆ CART ä¸é€‚åˆä¼°è®¡ CATEï¼Ÿ\n",
    "\n",
    "**é—®é¢˜**ï¼šCART ä¼˜åŒ–çš„æ˜¯ $Y$ çš„é¢„æµ‹å‡†ç¡®æ€§ï¼Œè€Œä¸æ˜¯å¤„ç†æ•ˆåº”çš„å¼‚è´¨æ€§ï¼\n",
    "\n",
    "è€ƒè™‘ä¸¤ç§æƒ…å†µï¼š\n",
    "\n",
    "| åœºæ™¯ | ç»“æœ $Y$ çš„æ–¹å·® | CATE çš„å¼‚è´¨æ€§ | CART ä¼šé€‰æ‹©ï¼Ÿ |\n",
    "|------|---------------|--------------|-------------|\n",
    "| A | é«˜ | ä½ | âœ… ä¼šé€‰æ‹©ï¼ˆå‡å°‘ Y æ–¹å·®ï¼‰ |\n",
    "| B | ä½ | é«˜ | âŒ ä¸ä¼šé€‰æ‹© |\n",
    "\n",
    "**æ ¸å¿ƒé—®é¢˜**ï¼šæˆ‘ä»¬éœ€è¦çš„åˆ†è£‚åº”è¯¥æœ€å¤§åŒ– CATE çš„å¼‚è´¨æ€§ï¼Œè€Œä¸æ˜¯ Y çš„æ–¹å·®ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯å¢ƒå‡†å¤‡\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# è®¾ç½®ç»˜å›¾é£æ ¼\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['font.family'] = ['Arial Unicode MS', 'SimHei', 'sans-serif']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Causal Tree çš„åˆ†è£‚å‡†åˆ™\n",
    "\n",
    "Causal Tree (Athey & Imbens, 2016) çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**æœ€å¤§åŒ–å­èŠ‚ç‚¹é—´ CATE çš„å·®å¼‚**\n",
    "\n",
    "$$\\text{CATE Gain} = \\frac{|S_L||S_R|}{|S|^2} (\\hat{\\tau}(S_L) - \\hat{\\tau}(S_R))^2$$\n",
    "\n",
    "å…¶ä¸­ $\\hat{\\tau}(S)$ æ˜¯èŠ‚ç‚¹ $S$ ä¸­çš„ CATE ä¼°è®¡ï¼š\n",
    "\n",
    "$$\\hat{\\tau}(S) = \\bar{Y}_{S,T=1} - \\bar{Y}_{S,T=0}$$\n",
    "\n",
    "**ç›´è§‰**ï¼šæˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°ä¸€ä¸ªåˆ†è£‚ï¼Œä½¿å¾—å·¦å³å­èŠ‚ç‚¹çš„å¤„ç†æ•ˆåº”å·®å¼‚æœ€å¤§åŒ–ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– CART vs Causal Tree åˆ†è£‚çš„åŒºåˆ«\n",
    "\n",
    "def generate_example_data(n=1000):\n",
    "    \"\"\"ç”Ÿæˆå±•ç¤ºä¸¤ç§åˆ†è£‚å·®å¼‚çš„æ•°æ®\"\"\"\n",
    "    # X1: å½±å“ Y çš„åŸºç¡€æ°´å¹³ï¼ˆCART ä¼šå…³æ³¨ï¼‰\n",
    "    # X2: å½±å“å¤„ç†æ•ˆåº”ï¼ˆCausal Tree åº”è¯¥å…³æ³¨ï¼‰\n",
    "    X1 = np.random.randn(n)\n",
    "    X2 = np.random.randn(n)\n",
    "    T = np.random.binomial(1, 0.5, n)\n",
    "    \n",
    "    # Y çš„åŸºç¡€å€¼ä¸»è¦ç”± X1 å†³å®š\n",
    "    Y_base = 10 + 5 * X1  # X1 å½±å“åŸºç¡€æ°´å¹³\n",
    "    \n",
    "    # å¤„ç†æ•ˆåº”ä¸»è¦ç”± X2 å†³å®š\n",
    "    tau = 3 + 4 * X2  # X2 å½±å“å¤„ç†æ•ˆåº”\n",
    "    \n",
    "    # è§‚æµ‹ç»“æœ\n",
    "    Y = Y_base + T * tau + np.random.randn(n) * 2\n",
    "    \n",
    "    return X1, X2, T, Y, tau\n",
    "\n",
    "X1, X2, T, Y, true_tau = generate_example_data(2000)\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# X1 ä¸ Y çš„å…³ç³»ï¼ˆé«˜æ–¹å·®ï¼‰\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(X1[T==0], Y[T==0], alpha=0.3, label='æ§åˆ¶ç»„', c='#3498db', s=20)\n",
    "ax1.scatter(X1[T==1], Y[T==1], alpha=0.3, label='å®éªŒç»„', c='#e74c3c', s=20)\n",
    "ax1.set_xlabel('X1')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_title('X1 å½±å“ Y çš„åŸºç¡€æ°´å¹³ï¼ˆé«˜æ–¹å·®ï¼‰\\nCART ä¼šä¼˜å…ˆé€‰æ‹©è¿™ä¸ªå˜é‡')\n",
    "ax1.legend()\n",
    "\n",
    "# X2 ä¸ CATE çš„å…³ç³»\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(X2, true_tau, alpha=0.5, c='#2ecc71', s=20)\n",
    "ax2.set_xlabel('X2')\n",
    "ax2.set_ylabel('CATE')\n",
    "ax2.set_title('X2 å½±å“å¤„ç†æ•ˆåº”ï¼ˆCATE å¼‚è´¨æ€§ï¼‰\\nCausal Tree åº”è¯¥é€‰æ‹©è¿™ä¸ªå˜é‡')\n",
    "\n",
    "# ä¸¤ç§åˆ†è£‚çš„å¯¹æ¯”\n",
    "ax3 = axes[2]\n",
    "# æŒ‰ X1 åˆ†è£‚\n",
    "mask_x1_low = X1 < np.median(X1)\n",
    "tau_x1_left = Y[mask_x1_low & (T==1)].mean() - Y[mask_x1_low & (T==0)].mean()\n",
    "tau_x1_right = Y[~mask_x1_low & (T==1)].mean() - Y[~mask_x1_low & (T==0)].mean()\n",
    "\n",
    "# æŒ‰ X2 åˆ†è£‚\n",
    "mask_x2_low = X2 < np.median(X2)\n",
    "tau_x2_left = Y[mask_x2_low & (T==1)].mean() - Y[mask_x2_low & (T==0)].mean()\n",
    "tau_x2_right = Y[~mask_x2_low & (T==1)].mean() - Y[~mask_x2_low & (T==0)].mean()\n",
    "\n",
    "x_pos = [0, 1]\n",
    "width = 0.35\n",
    "\n",
    "ax3.bar([p - width/2 for p in x_pos], [tau_x1_left, tau_x2_left], width, label='å·¦å­èŠ‚ç‚¹ CATE', color='#3498db')\n",
    "ax3.bar([p + width/2 for p in x_pos], [tau_x1_right, tau_x2_right], width, label='å³å­èŠ‚ç‚¹ CATE', color='#e74c3c')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels(['æŒ‰ X1 åˆ†è£‚', 'æŒ‰ X2 åˆ†è£‚'])\n",
    "ax3.set_ylabel('CATE')\n",
    "ax3.set_title('ä¸¤ç§åˆ†è£‚çš„ CATE å·®å¼‚')\n",
    "ax3.legend()\n",
    "\n",
    "# æ ‡æ³¨ CATE å·®å¼‚\n",
    "diff_x1 = abs(tau_x1_right - tau_x1_left)\n",
    "diff_x2 = abs(tau_x2_right - tau_x2_left)\n",
    "ax3.text(-0.15, max(tau_x1_left, tau_x1_right) + 0.5, f'å·®å¼‚: {diff_x1:.2f}', fontsize=10)\n",
    "ax3.text(0.85, max(tau_x2_left, tau_x2_right) + 0.5, f'å·®å¼‚: {diff_x2:.2f}', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nå…³é”®å‘ç°ï¼š\")\n",
    "print(f\"  æŒ‰ X1 åˆ†è£‚çš„ CATE å·®å¼‚: {diff_x1:.3f}\")\n",
    "print(f\"  æŒ‰ X2 åˆ†è£‚çš„ CATE å·®å¼‚: {diff_x2:.3f}\")\n",
    "print(f\"  âœ… Causal Tree åº”è¯¥é€‰æ‹© X2ï¼Œå› ä¸ºå®ƒæœ€å¤§åŒ–äº† CATE å·®å¼‚ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: ä»é›¶å®ç° Causal Tree åˆ†è£‚å‡†åˆ™\n",
    "\n",
    "### ğŸ§ª TODO ç»ƒä¹  1: å®ç° CATE å¢ç›Šè®¡ç®—\n",
    "\n",
    "è¯·å®ç° Causal Tree çš„åˆ†è£‚å¢ç›Šè®¡ç®—å‡½æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def calculate_cate_gain(Y_left, T_left, Y_right, T_right, min_samples=10):\n    \"\"\"\n    è®¡ç®— Causal Tree åˆ†è£‚å¢ç›Š\n    \n    CATE Gain = (n_L * n_R / n^2) * (tau_L - tau_R)^2\n    \n    Args:\n        Y_left: å·¦å­èŠ‚ç‚¹çš„ç»“æœ\n        T_left: å·¦å­èŠ‚ç‚¹çš„å¤„ç†\n        Y_right: å³å­èŠ‚ç‚¹çš„ç»“æœ\n        T_right: å³å­èŠ‚ç‚¹çš„å¤„ç†\n        min_samples: æœ€å°æ ·æœ¬é‡é˜ˆå€¼\n        \n    Returns:\n        gain: CATE åˆ†è£‚å¢ç›Š\n        tau_left: å·¦å­èŠ‚ç‚¹ CATE\n        tau_right: å³å­èŠ‚ç‚¹ CATE\n    \"\"\"\n    # å®ç° CATE å¢ç›Šè®¡ç®—\n    n_left = len(Y_left)\n    n_right = len(Y_right)\n    n_total = n_left + n_right\n    \n    # æ£€æŸ¥æ¯ä¸ªå­èŠ‚ç‚¹çš„å¤„ç†ç»„å’Œæ§åˆ¶ç»„æ ·æœ¬é‡\n    n_treat_left = (T_left == 1).sum()\n    n_ctrl_left = (T_left == 0).sum()\n    n_treat_right = (T_right == 1).sum()\n    n_ctrl_right = (T_right == 0).sum()\n    \n    # ç¡®ä¿æ¯ä¸ªå­èŠ‚ç‚¹æœ‰è¶³å¤Ÿçš„å¤„ç†ç»„å’Œæ§åˆ¶ç»„æ ·æœ¬\n    if (n_treat_left < min_samples or n_ctrl_left < min_samples or\n        n_treat_right < min_samples or n_ctrl_right < min_samples):\n        return 0, np.nan, np.nan\n    \n    # 1. è®¡ç®—å·¦å­èŠ‚ç‚¹çš„ CATE: tau_left = mean(Y|T=1, left) - mean(Y|T=0, left)\n    tau_left = Y_left[T_left == 1].mean() - Y_left[T_left == 0].mean()\n    \n    # 2. è®¡ç®—å³å­èŠ‚ç‚¹çš„ CATE: tau_right = mean(Y|T=1, right) - mean(Y|T=0, right)\n    tau_right = Y_right[T_right == 1].mean() - Y_right[T_right == 0].mean()\n    \n    # 3. è®¡ç®—å¢ç›Š: gain = (n_L * n_R / n^2) * (tau_left - tau_right)^2\n    gain = (n_left * n_right / (n_total ** 2)) * (tau_left - tau_right) ** 2\n    \n    return gain, tau_left, tau_right\n\nprint(\"âœ… calculate_cate_gain å‡½æ•°å®šä¹‰å®Œæˆï¼ˆå·²å®Œæˆ TODO éƒ¨åˆ†ï¼‰\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ å‚è€ƒç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# å‚è€ƒç­”æ¡ˆï¼šCATE å¢ç›Šè®¡ç®—\n",
    "# ============================================================\n",
    "\n",
    "def calculate_cate_gain(Y_left, T_left, Y_right, T_right, min_samples=10):\n",
    "    \"\"\"\n",
    "    è®¡ç®— Causal Tree åˆ†è£‚å¢ç›Š - å®Œæ•´å®ç°\n",
    "    \"\"\"\n",
    "    n_left = len(Y_left)\n",
    "    n_right = len(Y_right)\n",
    "    n_total = n_left + n_right\n",
    "    \n",
    "    # æ£€æŸ¥æ¯ä¸ªå­èŠ‚ç‚¹çš„å¤„ç†ç»„å’Œæ§åˆ¶ç»„æ ·æœ¬é‡\n",
    "    n_treat_left = (T_left == 1).sum()\n",
    "    n_ctrl_left = (T_left == 0).sum()\n",
    "    n_treat_right = (T_right == 1).sum()\n",
    "    n_ctrl_right = (T_right == 0).sum()\n",
    "    \n",
    "    # ç¡®ä¿æ¯ä¸ªå­èŠ‚ç‚¹æœ‰è¶³å¤Ÿçš„å¤„ç†ç»„å’Œæ§åˆ¶ç»„æ ·æœ¬\n",
    "    if (n_treat_left < min_samples or n_ctrl_left < min_samples or\n",
    "        n_treat_right < min_samples or n_ctrl_right < min_samples):\n",
    "        return 0, np.nan, np.nan\n",
    "    \n",
    "    # è®¡ç®—å·¦å­èŠ‚ç‚¹ CATE\n",
    "    tau_left = Y_left[T_left == 1].mean() - Y_left[T_left == 0].mean()\n",
    "    \n",
    "    # è®¡ç®—å³å­èŠ‚ç‚¹ CATE\n",
    "    tau_right = Y_right[T_right == 1].mean() - Y_right[T_right == 0].mean()\n",
    "    \n",
    "    # è®¡ç®—å¢ç›Š\n",
    "    gain = (n_left * n_right / (n_total ** 2)) * (tau_left - tau_right) ** 2\n",
    "    \n",
    "    return gain, tau_left, tau_right\n",
    "\n",
    "# æµ‹è¯•\n",
    "np.random.seed(42)\n",
    "n_test = 500\n",
    "Y_test = np.random.randn(n_test) + 10\n",
    "T_test = np.random.binomial(1, 0.5, n_test)\n",
    "\n",
    "# äººä¸ºæ„é€ å·¦å³å­èŠ‚ç‚¹\n",
    "Y_left = Y_test[:n_test//2]\n",
    "T_left = T_test[:n_test//2]\n",
    "Y_right = Y_test[n_test//2:] + 3 * T_test[n_test//2:]  # å³è¾¹åŠ å…¥å¤„ç†æ•ˆåº”\n",
    "T_right = T_test[n_test//2:]\n",
    "\n",
    "gain, tau_l, tau_r = calculate_cate_gain(Y_left, T_left, Y_right, T_right)\n",
    "print(f\"âœ… CATE å¢ç›Šè®¡ç®—æµ‹è¯•:\")\n",
    "print(f\"   å·¦å­èŠ‚ç‚¹ CATE: {tau_l:.3f}\")\n",
    "print(f\"   å³å­èŠ‚ç‚¹ CATE: {tau_r:.3f}\")\n",
    "print(f\"   åˆ†è£‚å¢ç›Š: {gain:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 å®ç°å®Œæ•´çš„ Causal Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalTree:\n",
    "    \"\"\"\n",
    "    ä»é›¶å®ç°çš„ Causal Tree\n",
    "    åˆ†è£‚å‡†åˆ™ï¼šæœ€å¤§åŒ–å­èŠ‚ç‚¹é—´çš„ CATE å·®å¼‚\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth=5, min_samples_leaf=20, min_samples_treatment=10):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_samples_treatment = min_samples_treatment\n",
    "        self.tree = None\n",
    "    \n",
    "    def _calculate_cate(self, Y, T):\n",
    "        \"\"\"è®¡ç®—èŠ‚ç‚¹çš„ CATE\"\"\"\n",
    "        if (T == 1).sum() == 0 or (T == 0).sum() == 0:\n",
    "            return np.nan\n",
    "        return Y[T == 1].mean() - Y[T == 0].mean()\n",
    "    \n",
    "    def _find_best_split(self, X, Y, T):\n",
    "        \"\"\"\n",
    "        æ‰¾åˆ°æœ€ä½³åˆ†è£‚ç‚¹\n",
    "        éå†æ‰€æœ‰ç‰¹å¾å’Œæ‰€æœ‰åˆ†è£‚ç‚¹ï¼Œé€‰æ‹© CATE å¢ç›Šæœ€å¤§çš„\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        best_gain = 0\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        \n",
    "        for feature_idx in range(n_features):\n",
    "            # è·å–æ‰€æœ‰å¯èƒ½çš„åˆ†è£‚ç‚¹\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            \n",
    "            for threshold in thresholds[:-1]:  # æ’é™¤æœ€å¤§å€¼\n",
    "                # åˆ†è£‚\n",
    "                left_mask = X[:, feature_idx] <= threshold\n",
    "                right_mask = ~left_mask\n",
    "                \n",
    "                # æ£€æŸ¥æ ·æœ¬é‡\n",
    "                if left_mask.sum() < self.min_samples_leaf or right_mask.sum() < self.min_samples_leaf:\n",
    "                    continue\n",
    "                \n",
    "                # è®¡ç®— CATE å¢ç›Š\n",
    "                gain, _, _ = calculate_cate_gain(\n",
    "                    Y[left_mask], T[left_mask],\n",
    "                    Y[right_mask], T[right_mask],\n",
    "                    min_samples=self.min_samples_treatment\n",
    "                )\n",
    "                \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature_idx\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold, best_gain\n",
    "    \n",
    "    def _build_tree(self, X, Y, T, depth=0):\n",
    "        \"\"\"\n",
    "        é€’å½’æ„å»ºæ ‘\n",
    "        \"\"\"\n",
    "        n_samples = len(Y)\n",
    "        node_cate = self._calculate_cate(Y, T)\n",
    "        \n",
    "        node = {\n",
    "            'cate': node_cate,\n",
    "            'n_samples': n_samples,\n",
    "            'n_treated': (T == 1).sum(),\n",
    "            'n_control': (T == 0).sum()\n",
    "        }\n",
    "        \n",
    "        # åœæ­¢æ¡ä»¶\n",
    "        if (depth >= self.max_depth or \n",
    "            n_samples < 2 * self.min_samples_leaf or\n",
    "            (T == 1).sum() < 2 * self.min_samples_treatment or\n",
    "            (T == 0).sum() < 2 * self.min_samples_treatment):\n",
    "            return node\n",
    "        \n",
    "        # æ‰¾æœ€ä½³åˆ†è£‚\n",
    "        best_feature, best_threshold, best_gain = self._find_best_split(X, Y, T)\n",
    "        \n",
    "        if best_feature is None or best_gain == 0:\n",
    "            return node\n",
    "        \n",
    "        # æ‰§è¡Œåˆ†è£‚\n",
    "        left_mask = X[:, best_feature] <= best_threshold\n",
    "        right_mask = ~left_mask\n",
    "        \n",
    "        node['feature'] = best_feature\n",
    "        node['threshold'] = best_threshold\n",
    "        node['gain'] = best_gain\n",
    "        node['left'] = self._build_tree(X[left_mask], Y[left_mask], T[left_mask], depth + 1)\n",
    "        node['right'] = self._build_tree(X[right_mask], Y[right_mask], T[right_mask], depth + 1)\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def fit(self, X, Y, T):\n",
    "        \"\"\"è®­ç»ƒ Causal Tree\"\"\"\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        T = np.array(T)\n",
    "        self.tree = self._build_tree(X, Y, T)\n",
    "        return self\n",
    "    \n",
    "    def _predict_single(self, x, node):\n",
    "        \"\"\"é¢„æµ‹å•ä¸ªæ ·æœ¬çš„ CATE\"\"\"\n",
    "        if 'feature' not in node:\n",
    "            return node['cate']\n",
    "        \n",
    "        if x[node['feature']] <= node['threshold']:\n",
    "            return self._predict_single(x, node['left'])\n",
    "        else:\n",
    "            return self._predict_single(x, node['right'])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"é¢„æµ‹ CATE\"\"\"\n",
    "        X = np.array(X)\n",
    "        return np.array([self._predict_single(x, self.tree) for x in X])\n",
    "    \n",
    "    def print_tree(self, node=None, depth=0, prefix=\"\"):\n",
    "        \"\"\"æ‰“å°æ ‘ç»“æ„\"\"\"\n",
    "        if node is None:\n",
    "            node = self.tree\n",
    "        \n",
    "        if 'feature' not in node:\n",
    "            print(f\"{prefix}Leaf: CATE={node['cate']:.3f}, n={node['n_samples']}\")\n",
    "        else:\n",
    "            print(f\"{prefix}X[{node['feature']}] <= {node['threshold']:.3f} (gain={node['gain']:.4f})\")\n",
    "            self.print_tree(node['left'], depth + 1, prefix + \"  L: \")\n",
    "            self.print_tree(node['right'], depth + 1, prefix + \"  R: \")\n",
    "\n",
    "print(\"âœ… CausalTree ç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒå’Œæµ‹è¯• Causal Tree\n",
    "\n",
    "def generate_causal_data(n=2000, seed=42):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆå¸¦æœ‰å¼‚è´¨æ€§å¤„ç†æ•ˆåº”çš„æ•°æ®\n",
    "    \n",
    "    çœŸå® CATE = 2 + 3*X1 + 4*X2 + 2*X1*X2\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    X = np.random.randn(n, 5)  # 5 ä¸ªç‰¹å¾\n",
    "    T = np.random.binomial(1, 0.5, n)  # éšæœºå¤„ç†åˆ†é…\n",
    "    \n",
    "    # çœŸå® CATEï¼ˆåªä¾èµ– X0 å’Œ X1ï¼‰\n",
    "    true_cate = 2 + 3 * X[:, 0] + 4 * X[:, 1] + 2 * X[:, 0] * X[:, 1]\n",
    "    \n",
    "    # åŸºç¡€ç»“æœï¼ˆä¾èµ–æ‰€æœ‰ç‰¹å¾ï¼‰\n",
    "    Y_base = 10 + 2*X[:, 0] + 1*X[:, 1] + 0.5*X[:, 2] + 0.3*X[:, 3] + 0.2*X[:, 4]\n",
    "    \n",
    "    # è§‚æµ‹ç»“æœ\n",
    "    noise = np.random.randn(n) * 2\n",
    "    Y = Y_base + T * true_cate + noise\n",
    "    \n",
    "    return X, T, Y, true_cate\n",
    "\n",
    "# ç”Ÿæˆæ•°æ®\n",
    "X, T, Y, true_cate = generate_causal_data(n=2000)\n",
    "\n",
    "print(f\"æ•°æ®ç”Ÿæˆå®Œæˆï¼š\")\n",
    "print(f\"  æ ·æœ¬æ•°: {len(Y)}\")\n",
    "print(f\"  ç‰¹å¾æ•°: {X.shape[1]}\")\n",
    "print(f\"  å¤„ç†ç»„: {(T==1).sum()}\")\n",
    "print(f\"  çœŸå® CATE èŒƒå›´: [{true_cate.min():.2f}, {true_cate.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒ Causal Tree\n",
    "ct = CausalTree(max_depth=3, min_samples_leaf=50, min_samples_treatment=20)\n",
    "ct.fit(X, Y, T)\n",
    "\n",
    "print(\"Causal Tree ç»“æ„ï¼š\")\n",
    "print(\"=\" * 50)\n",
    "ct.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯„ä¼° CATE é¢„æµ‹\n",
    "pred_cate = ct.predict(X)\n",
    "\n",
    "# è®¡ç®—ç›¸å…³æ€§\n",
    "corr = np.corrcoef(pred_cate, true_cate)[0, 1]\n",
    "rmse = np.sqrt(np.mean((pred_cate - true_cate) ** 2))\n",
    "\n",
    "print(f\"\\nCausal Tree è¯„ä¼°ç»“æœï¼š\")\n",
    "print(f\"  ç›¸å…³ç³»æ•°: {corr:.3f}\")\n",
    "print(f\"  RMSE: {rmse:.3f}\")\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# é¢„æµ‹ vs çœŸå®\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(true_cate, pred_cate, alpha=0.3, s=20)\n",
    "ax1.plot([true_cate.min(), true_cate.max()], [true_cate.min(), true_cate.max()], \n",
    "         'r--', label='å®Œç¾é¢„æµ‹')\n",
    "ax1.set_xlabel('çœŸå® CATE')\n",
    "ax1.set_ylabel('é¢„æµ‹ CATE')\n",
    "ax1.set_title(f'Causal Tree CATE é¢„æµ‹\\nCorr={corr:.3f}, RMSE={rmse:.3f}')\n",
    "ax1.legend()\n",
    "\n",
    "# æŒ‰ X0 åˆ†ç»„çœ‹ CATE\n",
    "ax2 = axes[1]\n",
    "x0_bins = pd.qcut(X[:, 0], q=5, labels=['Q1', 'Q2', 'Q3', 'Q4', 'Q5'])\n",
    "df = pd.DataFrame({'X0_bin': x0_bins, 'true_cate': true_cate, 'pred_cate': pred_cate})\n",
    "df_grouped = df.groupby('X0_bin').agg({'true_cate': 'mean', 'pred_cate': 'mean'}).reset_index()\n",
    "\n",
    "x_pos = np.arange(5)\n",
    "width = 0.35\n",
    "ax2.bar(x_pos - width/2, df_grouped['true_cate'], width, label='çœŸå® CATE', color='#3498db')\n",
    "ax2.bar(x_pos + width/2, df_grouped['pred_cate'], width, label='é¢„æµ‹ CATE', color='#e74c3c')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(df_grouped['X0_bin'])\n",
    "ax2.set_xlabel('X0 åˆ†ä½æ•°')\n",
    "ax2.set_ylabel('å¹³å‡ CATE')\n",
    "ax2.set_title('æŒ‰ X0 åˆ†ç»„çš„ CATE å¯¹æ¯”')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Honest Splitting è¯¦è§£\n",
    "\n",
    "### 3.1 ä¸ºä»€ä¹ˆéœ€è¦ Honest Splittingï¼Ÿ\n",
    "\n",
    "**é—®é¢˜**ï¼šå¦‚æœç”¨åŒä¸€ä»½æ•°æ®æ—¢é€‰æ‹©åˆ†è£‚ç‚¹åˆä¼°è®¡ CATEï¼Œä¼šå¯¼è‡´**è¿‡æ‹Ÿåˆ**ï¼\n",
    "\n",
    "| é—®é¢˜ | æè¿° |\n",
    "|------|------|\n",
    "| é€‰æ‹©åå·® | åˆ†è£‚ç‚¹æ˜¯æ ¹æ®æ•°æ®\"ä¼˜åŒ–\"å‡ºæ¥çš„ï¼Œä¼šè¿‡æ‹Ÿåˆå™ªå£° |\n",
    "| ä¼°è®¡åå·® | å¶èŠ‚ç‚¹çš„ CATE ä¼°è®¡ä½¿ç”¨äº†å‚ä¸åˆ†è£‚å†³ç­–çš„æ ·æœ¬ |\n",
    "| ç½®ä¿¡åŒºé—´å¤±æ•ˆ | æ— æ³•æ­£ç¡®è®¡ç®—æ ‡å‡†è¯¯ |\n",
    "\n",
    "### 3.2 Honest Splitting æ–¹æ¡ˆ\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³**ï¼šå°†æ•°æ®åˆ†æˆä¸¤éƒ¨åˆ†\n",
    "1. **Splitting Sample**: ç”¨äºå†³å®šåˆ†è£‚ç‚¹\n",
    "2. **Estimation Sample**: ç”¨äºä¼°è®¡å¶èŠ‚ç‚¹çš„ CATE\n",
    "\n",
    "```\n",
    "æ•°æ® D\n",
    "   â”‚\n",
    "   â”œâ”€â”€ Splitting Sample (D_s) â”€â”€â†’ å†³å®šæ ‘ç»“æ„\n",
    "   â”‚\n",
    "   â””â”€â”€ Estimation Sample (D_e) â”€â”€â†’ ä¼°è®¡å¶èŠ‚ç‚¹ CATE + ç½®ä¿¡åŒºé—´\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HonestCausalTree:\n",
    "    \"\"\"\n",
    "    Honest Causal Tree\n",
    "    åˆ†è£‚å’Œä¼°è®¡ä½¿ç”¨ä¸åŒçš„æ ·æœ¬\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth=5, min_samples_leaf=20, min_samples_treatment=10, \n",
    "                 honest_fraction=0.5):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_samples_treatment = min_samples_treatment\n",
    "        self.honest_fraction = honest_fraction\n",
    "        self.tree = None\n",
    "        self.estimation_indices = None\n",
    "    \n",
    "    def _calculate_cate_with_se(self, Y, T):\n",
    "        \"\"\"\n",
    "        è®¡ç®— CATE å’Œæ ‡å‡†è¯¯\n",
    "        \"\"\"\n",
    "        n_t = (T == 1).sum()\n",
    "        n_c = (T == 0).sum()\n",
    "        \n",
    "        if n_t < 2 or n_c < 2:\n",
    "            return np.nan, np.nan\n",
    "        \n",
    "        Y_t = Y[T == 1]\n",
    "        Y_c = Y[T == 0]\n",
    "        \n",
    "        tau = Y_t.mean() - Y_c.mean()\n",
    "        se = np.sqrt(np.var(Y_t, ddof=1)/n_t + np.var(Y_c, ddof=1)/n_c)\n",
    "        \n",
    "        return tau, se\n",
    "    \n",
    "    def fit(self, X, Y, T):\n",
    "        \"\"\"\n",
    "        è®­ç»ƒ Honest Causal Tree\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        T = np.array(T)\n",
    "        n = len(Y)\n",
    "        \n",
    "        # åˆ†å‰² Splitting å’Œ Estimation æ ·æœ¬\n",
    "        indices = np.random.permutation(n)\n",
    "        n_split = int(n * (1 - self.honest_fraction))\n",
    "        \n",
    "        split_idx = indices[:n_split]\n",
    "        est_idx = indices[n_split:]\n",
    "        \n",
    "        X_split, Y_split, T_split = X[split_idx], Y[split_idx], T[split_idx]\n",
    "        self.X_est, self.Y_est, self.T_est = X[est_idx], Y[est_idx], T[est_idx]\n",
    "        \n",
    "        # ç”¨ Splitting Sample æ„å»ºæ ‘ç»“æ„\n",
    "        base_tree = CausalTree(\n",
    "            max_depth=self.max_depth,\n",
    "            min_samples_leaf=self.min_samples_leaf,\n",
    "            min_samples_treatment=self.min_samples_treatment\n",
    "        )\n",
    "        base_tree.fit(X_split, Y_split, T_split)\n",
    "        self.tree = base_tree.tree\n",
    "        \n",
    "        # ç”¨ Estimation Sample é‡æ–°ä¼°è®¡å¶èŠ‚ç‚¹\n",
    "        self._update_leaf_estimates()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _get_leaf_mask(self, X, node):\n",
    "        \"\"\"\n",
    "        è·å–å±äºæŸä¸ªå¶èŠ‚ç‚¹çš„æ ·æœ¬ mask\n",
    "        \"\"\"\n",
    "        if 'feature' not in node:\n",
    "            return np.ones(len(X), dtype=bool)\n",
    "        \n",
    "        left_mask = X[:, node['feature']] <= node['threshold']\n",
    "        \n",
    "        left_child_mask = self._get_leaf_mask(X[left_mask], node['left'])\n",
    "        right_child_mask = self._get_leaf_mask(X[~left_mask], node['right'])\n",
    "        \n",
    "        result = np.zeros(len(X), dtype=bool)\n",
    "        result[np.where(left_mask)[0][left_child_mask]] = True\n",
    "        result[np.where(~left_mask)[0][right_child_mask]] = True\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _update_leaf_node(self, node, X, Y, T):\n",
    "        \"\"\"\n",
    "        é€’å½’æ›´æ–°å¶èŠ‚ç‚¹çš„ CATE å’Œæ ‡å‡†è¯¯\n",
    "        \"\"\"\n",
    "        if 'feature' not in node:\n",
    "            # å¶èŠ‚ç‚¹ï¼šä½¿ç”¨ Estimation Sample é‡æ–°ä¼°è®¡\n",
    "            tau, se = self._calculate_cate_with_se(Y, T)\n",
    "            node['cate'] = tau\n",
    "            node['se'] = se\n",
    "            node['n_samples'] = len(Y)\n",
    "            node['n_treated'] = (T == 1).sum()\n",
    "            node['n_control'] = (T == 0).sum()\n",
    "            return\n",
    "        \n",
    "        # å†…éƒ¨èŠ‚ç‚¹ï¼šé€’å½’æ›´æ–°å­èŠ‚ç‚¹\n",
    "        left_mask = X[:, node['feature']] <= node['threshold']\n",
    "        self._update_leaf_node(node['left'], X[left_mask], Y[left_mask], T[left_mask])\n",
    "        self._update_leaf_node(node['right'], X[~left_mask], Y[~left_mask], T[~left_mask])\n",
    "    \n",
    "    def _update_leaf_estimates(self):\n",
    "        \"\"\"ä½¿ç”¨ Estimation Sample æ›´æ–°æ‰€æœ‰å¶èŠ‚ç‚¹\"\"\"\n",
    "        self._update_leaf_node(self.tree, self.X_est, self.Y_est, self.T_est)\n",
    "    \n",
    "    def _predict_single(self, x, node):\n",
    "        \"\"\"é¢„æµ‹å•ä¸ªæ ·æœ¬\"\"\"\n",
    "        if 'feature' not in node:\n",
    "            return node['cate'], node['se']\n",
    "        \n",
    "        if x[node['feature']] <= node['threshold']:\n",
    "            return self._predict_single(x, node['left'])\n",
    "        else:\n",
    "            return self._predict_single(x, node['right'])\n",
    "    \n",
    "    def predict(self, X, return_ci=False, alpha=0.05):\n",
    "        \"\"\"\n",
    "        é¢„æµ‹ CATEï¼Œå¯é€‰è¿”å›ç½®ä¿¡åŒºé—´\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        predictions = np.array([self._predict_single(x, self.tree) for x in X])\n",
    "        \n",
    "        cate = predictions[:, 0]\n",
    "        se = predictions[:, 1]\n",
    "        \n",
    "        if return_ci:\n",
    "            z = stats.norm.ppf(1 - alpha/2)\n",
    "            ci_lower = cate - z * se\n",
    "            ci_upper = cate + z * se\n",
    "            return cate, ci_lower, ci_upper\n",
    "        \n",
    "        return cate\n",
    "\n",
    "print(\"âœ… HonestCausalTree ç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒ Honest Causal Tree\n",
    "hct = HonestCausalTree(max_depth=3, min_samples_leaf=50, honest_fraction=0.5)\n",
    "hct.fit(X, Y, T)\n",
    "\n",
    "# é¢„æµ‹ï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰\n",
    "pred_cate_honest, ci_lower, ci_upper = hct.predict(X, return_ci=True)\n",
    "\n",
    "# è¯„ä¼°\n",
    "corr_honest = np.corrcoef(pred_cate_honest, true_cate)[0, 1]\n",
    "rmse_honest = np.sqrt(np.mean((pred_cate_honest - true_cate) ** 2))\n",
    "\n",
    "# ç½®ä¿¡åŒºé—´è¦†ç›–ç‡\n",
    "coverage = np.mean((true_cate >= ci_lower) & (true_cate <= ci_upper))\n",
    "\n",
    "print(f\"\\nHonest Causal Tree è¯„ä¼°ç»“æœï¼š\")\n",
    "print(f\"  ç›¸å…³ç³»æ•°: {corr_honest:.3f}\")\n",
    "print(f\"  RMSE: {rmse_honest:.3f}\")\n",
    "print(f\"  95% CI è¦†ç›–ç‡: {coverage:.1%} (ç›®æ ‡: 95%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– Honest vs Non-Honest å¯¹æ¯”\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# é¢„æµ‹å¯¹æ¯”\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(true_cate, pred_cate, alpha=0.3, label='æ™®é€š Causal Tree', s=20)\n",
    "ax1.scatter(true_cate, pred_cate_honest, alpha=0.3, label='Honest Causal Tree', s=20)\n",
    "ax1.plot([true_cate.min(), true_cate.max()], [true_cate.min(), true_cate.max()], 'k--')\n",
    "ax1.set_xlabel('çœŸå® CATE')\n",
    "ax1.set_ylabel('é¢„æµ‹ CATE')\n",
    "ax1.set_title('CATE é¢„æµ‹å¯¹æ¯”')\n",
    "ax1.legend()\n",
    "\n",
    "# ç½®ä¿¡åŒºé—´å¯è§†åŒ–\n",
    "ax2 = axes[1]\n",
    "# é€‰å–éƒ¨åˆ†æ ·æœ¬å±•ç¤º\n",
    "idx_sample = np.random.choice(len(X), 50, replace=False)\n",
    "idx_sorted = idx_sample[np.argsort(true_cate[idx_sample])]\n",
    "\n",
    "ax2.errorbar(range(50), pred_cate_honest[idx_sorted], \n",
    "            yerr=[pred_cate_honest[idx_sorted] - ci_lower[idx_sorted],\n",
    "                  ci_upper[idx_sorted] - pred_cate_honest[idx_sorted]],\n",
    "            fmt='o', capsize=3, alpha=0.6, label='é¢„æµ‹ Â± 95% CI')\n",
    "ax2.scatter(range(50), true_cate[idx_sorted], color='red', s=30, zorder=5, label='çœŸå® CATE')\n",
    "ax2.set_xlabel('æ ·æœ¬ï¼ˆæŒ‰çœŸå® CATE æ’åºï¼‰')\n",
    "ax2.set_ylabel('CATE')\n",
    "ax2.set_title('ç½®ä¿¡åŒºé—´è¦†ç›–ç¤ºæ„')\n",
    "ax2.legend()\n",
    "\n",
    "# è¦†ç›–ç‡æ£€éªŒ\n",
    "ax3 = axes[2]\n",
    "# æ¨¡æ‹Ÿå¤šæ¬¡æ£€éªŒè¦†ç›–ç‡\n",
    "coverages = []\n",
    "for _ in range(100):\n",
    "    hct_temp = HonestCausalTree(max_depth=3, min_samples_leaf=50, honest_fraction=0.5)\n",
    "    hct_temp.fit(X, Y, T)\n",
    "    _, ci_l, ci_u = hct_temp.predict(X, return_ci=True)\n",
    "    cov = np.mean((true_cate >= ci_l) & (true_cate <= ci_u))\n",
    "    coverages.append(cov)\n",
    "\n",
    "ax3.hist(coverages, bins=15, alpha=0.7, color='#3498db', edgecolor='black')\n",
    "ax3.axvline(x=0.95, color='red', linestyle='--', linewidth=2, label='ç›®æ ‡ 95%')\n",
    "ax3.axvline(x=np.mean(coverages), color='green', linestyle='-', linewidth=2, \n",
    "           label=f'å¹³å‡ {np.mean(coverages):.1%}')\n",
    "ax3.set_xlabel('95% CI è¦†ç›–ç‡')\n",
    "ax3.set_ylabel('é¢‘æ•°')\n",
    "ax3.set_title('100 æ¬¡æ¨¡æ‹Ÿçš„è¦†ç›–ç‡åˆ†å¸ƒ')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Causal Forest å®ç°\n",
    "\n",
    "### 4.1 ä» Causal Tree åˆ° Causal Forest\n",
    "\n",
    "Causal Forest æ˜¯ Causal Tree çš„é›†æˆç‰ˆæœ¬ï¼Œé€šè¿‡ Bootstrap èšåˆæé«˜ç¨³å®šæ€§ã€‚\n",
    "\n",
    "**å…³é”®ç‰¹ç‚¹**ï¼š\n",
    "1. æ¯æ£µæ ‘ä½¿ç”¨ Bootstrap æ ·æœ¬\n",
    "2. æ¯æ¬¡åˆ†è£‚éšæœºé€‰æ‹©ç‰¹å¾å­é›†\n",
    "3. ä½¿ç”¨ Honest Splitting\n",
    "4. æœ€ç»ˆé¢„æµ‹æ˜¯æ‰€æœ‰æ ‘çš„å¹³å‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCausalForest:\n",
    "    \"\"\"\n",
    "    ç®€åŒ–ç‰ˆ Causal Forest\n",
    "    \"\"\"\n",
    "    def __init__(self, n_trees=100, max_depth=5, min_samples_leaf=20,\n",
    "                 honest_fraction=0.5, max_features='sqrt'):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.honest_fraction = honest_fraction\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X, Y, T):\n",
    "        \"\"\"\n",
    "        è®­ç»ƒ Causal Forest\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        T = np.array(T)\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # ç¡®å®šæ¯æ¬¡åˆ†è£‚çš„ç‰¹å¾æ•°\n",
    "        if self.max_features == 'sqrt':\n",
    "            self.n_features_split = int(np.sqrt(n_features))\n",
    "        elif self.max_features == 'log2':\n",
    "            self.n_features_split = int(np.log2(n_features))\n",
    "        else:\n",
    "            self.n_features_split = n_features\n",
    "        \n",
    "        self.trees = []\n",
    "        \n",
    "        for i in range(self.n_trees):\n",
    "            # Bootstrap é‡‡æ ·\n",
    "            boot_idx = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            X_boot = X[boot_idx]\n",
    "            Y_boot = Y[boot_idx]\n",
    "            T_boot = T[boot_idx]\n",
    "            \n",
    "            # éšæœºé€‰æ‹©ç‰¹å¾å­é›†\n",
    "            feature_idx = np.random.choice(n_features, self.n_features_split, replace=False)\n",
    "            X_subset = X_boot[:, feature_idx]\n",
    "            \n",
    "            # è®­ç»ƒ Honest Causal Tree\n",
    "            tree = HonestCausalTree(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_leaf=self.min_samples_leaf,\n",
    "                honest_fraction=self.honest_fraction\n",
    "            )\n",
    "            tree.fit(X_subset, Y_boot, T_boot)\n",
    "            \n",
    "            self.trees.append((tree, feature_idx))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, return_ci=False, alpha=0.05):\n",
    "        \"\"\"\n",
    "        é¢„æµ‹ CATE\n",
    "        \n",
    "        ä½¿ç”¨æ‰€æœ‰æ ‘é¢„æµ‹çš„å¹³å‡å€¼å’Œæ ‡å‡†å·®æ¥ä¼°è®¡ç½®ä¿¡åŒºé—´\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        all_predictions = []\n",
    "        \n",
    "        for tree, feature_idx in self.trees:\n",
    "            X_subset = X[:, feature_idx]\n",
    "            pred = tree.predict(X_subset)\n",
    "            all_predictions.append(pred)\n",
    "        \n",
    "        all_predictions = np.array(all_predictions)\n",
    "        \n",
    "        # å¹³å‡é¢„æµ‹\n",
    "        cate_mean = np.mean(all_predictions, axis=0)\n",
    "        \n",
    "        if return_ci:\n",
    "            # ä½¿ç”¨æ ‘ä¹‹é—´çš„æ–¹å·®ä¼°è®¡ç½®ä¿¡åŒºé—´\n",
    "            cate_se = np.std(all_predictions, axis=0) / np.sqrt(self.n_trees)\n",
    "            z = stats.norm.ppf(1 - alpha/2)\n",
    "            ci_lower = cate_mean - z * cate_se\n",
    "            ci_upper = cate_mean + z * cate_se\n",
    "            return cate_mean, ci_lower, ci_upper\n",
    "        \n",
    "        return cate_mean\n",
    "\n",
    "print(\"âœ… SimpleCausalForest ç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒ Causal Forest\n",
    "print(\"è®­ç»ƒ Causal Forest (è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´)...\")\n",
    "cf = SimpleCausalForest(n_trees=50, max_depth=4, min_samples_leaf=30)\n",
    "cf.fit(X, Y, T)\n",
    "print(\"âœ… è®­ç»ƒå®Œæˆ\")\n",
    "\n",
    "# é¢„æµ‹\n",
    "pred_cate_cf, ci_lower_cf, ci_upper_cf = cf.predict(X, return_ci=True)\n",
    "\n",
    "# è¯„ä¼°\n",
    "corr_cf = np.corrcoef(pred_cate_cf, true_cate)[0, 1]\n",
    "rmse_cf = np.sqrt(np.mean((pred_cate_cf - true_cate) ** 2))\n",
    "coverage_cf = np.mean((true_cate >= ci_lower_cf) & (true_cate <= ci_upper_cf))\n",
    "\n",
    "print(f\"\\nCausal Forest è¯„ä¼°ç»“æœï¼š\")\n",
    "print(f\"  ç›¸å…³ç³»æ•°: {corr_cf:.3f}\")\n",
    "print(f\"  RMSE: {rmse_cf:.3f}\")\n",
    "print(f\"  95% CI è¦†ç›–ç‡: {coverage_cf:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸‰ç§æ–¹æ³•å¯¹æ¯”\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "methods = ['Causal Tree', 'Honest Causal Tree', 'Causal Forest']\n",
    "predictions = [pred_cate, pred_cate_honest, pred_cate_cf]\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "for i, (method, pred, color) in enumerate(zip(methods, predictions, colors)):\n",
    "    ax = axes[i]\n",
    "    ax.scatter(true_cate, pred, alpha=0.3, s=20, c=color)\n",
    "    ax.plot([true_cate.min(), true_cate.max()], [true_cate.min(), true_cate.max()], 'k--')\n",
    "    \n",
    "    corr = np.corrcoef(pred, true_cate)[0, 1]\n",
    "    rmse = np.sqrt(np.mean((pred - true_cate) ** 2))\n",
    "    \n",
    "    ax.set_xlabel('çœŸå® CATE')\n",
    "    ax.set_ylabel('é¢„æµ‹ CATE')\n",
    "    ax.set_title(f'{method}\\nCorr={corr:.3f}, RMSE={rmse:.3f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# æ±‡æ€»è¡¨æ ¼\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"æ–¹æ³•å¯¹æ¯”æ±‡æ€»\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{'æ–¹æ³•':<25} {'ç›¸å…³ç³»æ•°':<12} {'RMSE':<12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Causal Tree':<25} {corr:.3f}        {rmse:.3f}\")\n",
    "print(f\"{'Honest Causal Tree':<25} {corr_honest:.3f}        {rmse_honest:.3f}\")\n",
    "print(f\"{'Causal Forest':<25} {corr_cf:.3f}        {rmse_cf:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: ä¸ EconML çš„ CausalForest å¯¹æ¯”\n",
    "\n",
    "è®©æˆ‘ä»¬å°†è‡ªå·±å®ç°çš„ç‰ˆæœ¬ä¸ EconML çš„å®ç°è¿›è¡Œå¯¹æ¯”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from econml.dml import CausalForestDML\n",
    "    \n",
    "    # è®­ç»ƒ EconML çš„ Causal Forest\n",
    "    print(\"è®­ç»ƒ EconML CausalForestDML...\")\n",
    "    cf_econml = CausalForestDML(\n",
    "        n_estimators=100,\n",
    "        max_depth=4,\n",
    "        min_samples_leaf=30,\n",
    "        random_state=42\n",
    "    )\n",
    "    cf_econml.fit(Y, T, X=X, W=None)\n",
    "    \n",
    "    # é¢„æµ‹\n",
    "    pred_econml = cf_econml.effect(X)\n",
    "    pred_econml_lb, pred_econml_ub = cf_econml.effect_interval(X, alpha=0.05)\n",
    "    \n",
    "    # è¯„ä¼°\n",
    "    corr_econml = np.corrcoef(pred_econml.flatten(), true_cate)[0, 1]\n",
    "    rmse_econml = np.sqrt(np.mean((pred_econml.flatten() - true_cate) ** 2))\n",
    "    coverage_econml = np.mean((true_cate >= pred_econml_lb.flatten()) & \n",
    "                               (true_cate <= pred_econml_ub.flatten()))\n",
    "    \n",
    "    print(f\"\\nEconML CausalForestDML è¯„ä¼°ç»“æœï¼š\")\n",
    "    print(f\"  ç›¸å…³ç³»æ•°: {corr_econml:.3f}\")\n",
    "    print(f\"  RMSE: {rmse_econml:.3f}\")\n",
    "    print(f\"  95% CI è¦†ç›–ç‡: {coverage_econml:.1%}\")\n",
    "    \n",
    "    # å¯¹æ¯”å¯è§†åŒ–\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    ax1 = axes[0]\n",
    "    ax1.scatter(true_cate, pred_cate_cf, alpha=0.3, label='è‡ªå®ç°', s=20)\n",
    "    ax1.scatter(true_cate, pred_econml.flatten(), alpha=0.3, label='EconML', s=20)\n",
    "    ax1.plot([true_cate.min(), true_cate.max()], [true_cate.min(), true_cate.max()], 'k--')\n",
    "    ax1.set_xlabel('çœŸå® CATE')\n",
    "    ax1.set_ylabel('é¢„æµ‹ CATE')\n",
    "    ax1.set_title('è‡ªå®ç° vs EconML')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2 = axes[1]\n",
    "    methods = ['è‡ªå®ç° CF', 'EconML CF']\n",
    "    corrs = [corr_cf, corr_econml]\n",
    "    rmses = [rmse_cf, rmse_econml]\n",
    "    \n",
    "    x = np.arange(2)\n",
    "    width = 0.35\n",
    "    ax2.bar(x - width/2, corrs, width, label='ç›¸å…³ç³»æ•°', color='#3498db')\n",
    "    ax2.bar(x + width/2, [r/10 for r in rmses], width, label='RMSE/10', color='#e74c3c')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(methods)\n",
    "    ax2.set_ylabel('å€¼')\n",
    "    ax2.set_title('æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âš ï¸ EconML æœªå®‰è£…ï¼Œè·³è¿‡å¯¹æ¯”\")\n",
    "    print(\"   å®‰è£…å‘½ä»¤: pip install econml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¡ æ€è€ƒé¢˜\n",
    "\n",
    "1. **åˆ†è£‚å‡†åˆ™å˜ä½“**ï¼šé™¤äº†æœ€å¤§åŒ– CATE å·®å¼‚ï¼Œè¿˜æœ‰ä»€ä¹ˆå…¶ä»–åˆ†è£‚å‡†åˆ™ï¼Ÿ\n",
    "   - æç¤ºï¼šè€ƒè™‘ CATE çš„æ–¹å·®ã€MSE ç­‰\n",
    "\n",
    "2. **æƒé‡è°ƒæ•´**ï¼šå¦‚æœå¤„ç†ç»„å’Œæ§åˆ¶ç»„æ ·æœ¬ä¸å¹³è¡¡ï¼Œåˆ†è£‚å‡†åˆ™åº”è¯¥å¦‚ä½•è°ƒæ•´ï¼Ÿ\n",
    "   - æç¤ºï¼šè€ƒè™‘ IPW æƒé‡\n",
    "\n",
    "3. **ç½®ä¿¡åŒºé—´æ ¡å‡†**ï¼šå¦‚æœç½®ä¿¡åŒºé—´è¦†ç›–ç‡ä¸è¶³ 95%ï¼Œå¦‚ä½•æ”¹è¿›ï¼Ÿ\n",
    "   - æç¤ºï¼šBootstrapã€äº¤å‰éªŒè¯\n",
    "\n",
    "4. **ç‰¹å¾é‡è¦æ€§**ï¼šå¦‚ä½•è®¡ç®— Causal Forest ä¸­çš„ç‰¹å¾é‡è¦æ€§ï¼Ÿ\n",
    "   - æç¤ºï¼šåŸºäº CATE å¢ç›Šçš„ç´¯ç§¯\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ æ€»ç»“\n",
    "\n",
    "### æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "| æ¦‚å¿µ | æè¿° |\n",
    "|------|------|\n",
    "| CATE å¢ç›Š | (n_L * n_R / nÂ²) * (Ï„_L - Ï„_R)Â² |\n",
    "| Honest Splitting | åˆ†è£‚å’Œä¼°è®¡ä½¿ç”¨ä¸åŒæ ·æœ¬ |\n",
    "| Causal Forest | Causal Tree + Bootstrap + ç‰¹å¾éšæœº |\n",
    "\n",
    "### CART vs Causal Tree å¯¹æ¯”\n",
    "\n",
    "| ç»´åº¦ | CART | Causal Tree |\n",
    "|------|------|-------------|\n",
    "| ä¼˜åŒ–ç›®æ ‡ | æœ€å°åŒ– Y çš„æ–¹å·® | æœ€å¤§åŒ– CATE å·®å¼‚ |\n",
    "| å¶èŠ‚ç‚¹è¾“å‡º | E[Y] | Ï„ = E[Y(1) - Y(0)] |\n",
    "| é€‚ç”¨åœºæ™¯ | é¢„æµ‹ | å› æœæ•ˆåº”ä¼°è®¡ |\n",
    "\n",
    "### é¢è¯•è¦ç‚¹\n",
    "\n",
    "- èƒ½è§£é‡Š Causal Tree ä¸ CART çš„æœ¬è´¨åŒºåˆ«\n",
    "- èƒ½å†™å‡º CATE å¢ç›Šçš„å…¬å¼\n",
    "- ç†è§£ Honest Splitting çš„å¿…è¦æ€§\n",
    "- çŸ¥é“å¦‚ä½•è¾“å‡ºç½®ä¿¡åŒºé—´"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”— å‚è€ƒèµ„æ–™\n",
    "\n",
    "1. Athey, S., & Imbens, G. W. (2016). Recursive Partitioning for Heterogeneous Causal Effects. PNAS.\n",
    "2. Wager, S., & Athey, S. (2018). Estimation and Inference of Heterogeneous Treatment Effects using Random Forests. JASA.\n",
    "3. EconML Documentation: https://econml.azurewebsites.net/\n",
    "4. GRF (Generalized Random Forests): https://grf-labs.github.io/grf/"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## ğŸ¤ é¢è¯•æ¨¡æ‹Ÿç¯èŠ‚\n\n### é—®é¢˜ 1: CART vs Causal Tree - æœ¬è´¨åŒºåˆ«\n\n**é¢è¯•å®˜**: CART å’Œ Causal Tree çš„åˆ†è£‚å‡†åˆ™æœ‰ä»€ä¹ˆæœ¬è´¨åŒºåˆ«ï¼Ÿä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥ç”¨ CART ä¼°è®¡ CATEï¼Ÿ\n\n**å‚è€ƒç­”æ¡ˆ**:\n\n**æ ¸å¿ƒåŒºåˆ«**:\n\n| ç»´åº¦ | CART | Causal Tree |\n|------|------|-------------|\n| **ä¼˜åŒ–ç›®æ ‡** | æœ€å°åŒ– Y çš„æ–¹å·® | æœ€å¤§åŒ– CATE çš„å¼‚è´¨æ€§ |\n| **åˆ†è£‚å¢ç›Š** | $\\Delta \\text{Var}(Y)$ | $\\frac{n_L n_R}{n^2}(\\tau_L - \\tau_R)^2$ |\n| **å¶èŠ‚ç‚¹è¾“å‡º** | $\\bar{Y}$ | $\\tau = \\bar{Y}_1 - \\bar{Y}_0$ |\n\n**ä¸ºä»€ä¹ˆ CART ä¸é€‚åˆ**:\n\n```python\n# åœºæ™¯ï¼šä¸¤ä¸ªå€™é€‰åˆ†è£‚\n# åˆ†è£‚A: å‡å°‘ Y æ–¹å·®å¾ˆå¤šï¼Œä½† CATE æ— å·®å¼‚\n# åˆ†è£‚B: Y æ–¹å·®ä¸å˜ï¼Œä½† CATE å·®å¼‚å·¨å¤§\n\n# CART ä¼šé€‰æ‹© Aï¼ˆå› ä¸ºå‡å°‘äº† Y æ–¹å·®ï¼‰\n# ä½†æˆ‘ä»¬çœŸæ­£éœ€è¦çš„æ˜¯ Bï¼ˆå› ä¸ºæ•æ‰äº† CATE å¼‚è´¨æ€§ï¼‰\n```\n\n**æ•°å­¦æ¨å¯¼**:\n\nCART æœ€å¤§åŒ–:\n$$\\text{Gain}_{CART} = \\text{Var}(Y_S) - \\left[\\frac{n_L}{n}\\text{Var}(Y_L) + \\frac{n_R}{n}\\text{Var}(Y_R)\\right]$$\n\nCausal Tree æœ€å¤§åŒ–:\n$$\\text{Gain}_{Causal} = \\frac{n_L n_R}{n^2}(\\hat{\\tau}_L - \\hat{\\tau}_R)^2$$\n\nå…³é”®æ´å¯Ÿ: CART å…³å¿ƒ $E[Y|X]$ çš„é¢„æµ‹ï¼ŒCausal Tree å…³å¿ƒ $E[Y(1)-Y(0)|X]$ çš„å¼‚è´¨æ€§ï¼\n\n---\n\n### é—®é¢˜ 2: Honest Splitting - ä¸ºä»€ä¹ˆéœ€è¦ï¼Ÿ\n\n**é¢è¯•å®˜**: ä»€ä¹ˆæ˜¯ Honest Splittingï¼Ÿä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿç›´æ¥ç”¨åŒä¸€ä»½æ•°æ®ä¸è¡Œå—ï¼Ÿ\n\n**å‚è€ƒç­”æ¡ˆ**:\n\n**Honest Splitting å®šä¹‰**:\nå°†æ•°æ®åˆ†æˆä¸¤éƒ¨åˆ†ï¼š\n- **Splitting Sample**: ç”¨äºå†³å®šæ ‘ç»“æ„ï¼ˆåˆ†è£‚ç‚¹é€‰æ‹©ï¼‰\n- **Estimation Sample**: ç”¨äºä¼°è®¡å¶èŠ‚ç‚¹çš„ CATE\n\n**ä¸ºä»€ä¹ˆéœ€è¦**:\n\nå¦‚æœç”¨åŒä¸€ä»½æ•°æ®æ—¢åˆ†è£‚åˆä¼°è®¡ï¼Œä¼šäº§ç”Ÿä¸‰å¤§é—®é¢˜ï¼š\n\n1. **è¿‡æ‹Ÿåˆå™ªå£°**\n```python\n# å‡è®¾çœŸå® CATE = 5ï¼ˆå¸¸æ•°ï¼‰\n# ä½†æ•°æ®ä¸­æœ‰å™ªå£°\n# åˆ†è£‚ç®—æ³•ä¼šæ‰¾åˆ°\"æœ€ä¼˜\"åˆ†è£‚ç‚¹ï¼Œä½¿å¾—å·¦å³å·®å¼‚æœ€å¤§\n# ä½†è¿™ä¸ªå·®å¼‚å¾ˆå¯èƒ½åªæ˜¯å™ªå£°ï¼\n\n# ä¾‹å­ï¼š\nå·¦å­èŠ‚ç‚¹: CATEä¼°è®¡ = 8ï¼ˆå®é™…ä¸Šæ˜¯ 5 + å™ªå£°ï¼‰\nå³å­èŠ‚ç‚¹: CATEä¼°è®¡ = 2ï¼ˆå®é™…ä¸Šæ˜¯ 5 - å™ªå£°ï¼‰\nå·®å¼‚ = 6  # çœ‹èµ·æ¥å¾ˆå¤§ï¼Œä½†å…¶å®æ˜¯å‡çš„ï¼\n```\n\n2. **ç½®ä¿¡åŒºé—´å¤±æ•ˆ**\n```python\n# æ ‡å‡†è¯¯çš„è®¡ç®—å‡è®¾ï¼šä¼°è®¡æ ·æœ¬ç‹¬ç«‹äºæ¨¡å‹é€‰æ‹©\n# å¦‚æœç”¨åŒæ ·çš„æ•°æ®é€‰æ‹©åˆ†è£‚ï¼Œè¿™ä¸ªå‡è®¾è¢«è¿å\n# å¯¼è‡´ç½®ä¿¡åŒºé—´è¿‡äºä¹è§‚ï¼Œè¦†ç›–ç‡ä½äºåä¹‰æ°´å¹³\n```\n\n3. **é€‰æ‹©åå·®**\n```python\n# åˆ†è£‚ç‚¹æ˜¯\"æŒ‘é€‰\"å‡ºæ¥çš„ï¼ˆæœ€å¤§åŒ–å¢ç›Šï¼‰\n# ç”¨åŒæ ·çš„æ•°æ®ä¼°è®¡ï¼Œä¼šé«˜ä¼°æ•ˆåº”å·®å¼‚\n```\n\n**Honest Splitting å¦‚ä½•è§£å†³**:\n\n```python\n# Step 1: ç”¨ Splitting Sample é€‰æ‹©åˆ†è£‚ç‚¹\n#   â†’ è¿™éƒ¨åˆ†æ•°æ®å¯èƒ½è¿‡æ‹Ÿåˆå™ªå£°\nsplit_sample â†’ å†³å®šæ ‘ç»“æ„\n\n# Step 2: ç”¨ç‹¬ç«‹çš„ Estimation Sample ä¼°è®¡ CATE\n#   â†’ è¿™éƒ¨åˆ†æ•°æ®æ²¡æœ‰å‚ä¸åˆ†è£‚å†³ç­–ï¼Œæ˜¯\"è¯šå®\"çš„ä¼°è®¡\nestimation_sample â†’ ä¼°è®¡å¶èŠ‚ç‚¹ CATE + ç½®ä¿¡åŒºé—´\n\n# ç»“æœï¼šæ— åä¼°è®¡ + æ­£ç¡®çš„ç½®ä¿¡åŒºé—´\n```\n\n**ä»£ä»·**:\n- æœ‰æ•ˆæ ·æœ¬é‡å‡åŠï¼ˆä¸€åŠç”¨äºåˆ†è£‚ï¼Œä¸€åŠç”¨äºä¼°è®¡ï¼‰\n- ä½†æ¢æ¥çš„æ˜¯æ— åæ€§å’Œæ­£ç¡®çš„ç»Ÿè®¡æ¨æ–­\n\n**ç±»æ¯”**:\nç±»ä¼¼äºè®­ç»ƒé›†/æµ‹è¯•é›†åˆ’åˆ†ï¼š\n- ä¸èƒ½ç”¨è®­ç»ƒé›†è¯„ä¼°æ¨¡å‹ï¼ˆè¿‡äºä¹è§‚ï¼‰\n- éœ€è¦ç‹¬ç«‹çš„æµ‹è¯•é›†ï¼ˆè¯šå®è¯„ä¼°ï¼‰\n\n---\n\n### é—®é¢˜ 3: Causal Forest ç½®ä¿¡åŒºé—´\n\n**é¢è¯•å®˜**: Causal Forest å¦‚ä½•è®¡ç®—ç½®ä¿¡åŒºé—´ï¼Ÿå’Œæ™®é€šéšæœºæ£®æ—æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ\n\n**å‚è€ƒç­”æ¡ˆ**:\n\n**æ™®é€šéšæœºæ£®æ—**:\n- é€šå¸¸ä¸æä¾›ç½®ä¿¡åŒºé—´\n- å³ä½¿ç”¨ Bootstrap æ–¹æ³•ï¼Œä¹Ÿæ²¡æœ‰ç†è®ºä¿è¯\n\n**Causal Forest çš„ç½®ä¿¡åŒºé—´**:\n\nåŸºäº Wager & Athey (2018) çš„ç†è®ºï¼ŒCausal Forest å¯ä»¥æä¾›æ¸è¿‘æ­£æ€çš„ç½®ä¿¡åŒºé—´ã€‚\n\n**å…³é”®è¦ç´ **:\n\n1. **Honest Splitting**ï¼ˆå¿…éœ€ï¼ï¼‰\n```python\n# åªæœ‰ Honest ç‰ˆæœ¬æ‰èƒ½ä¿è¯ç½®ä¿¡åŒºé—´çš„æœ‰æ•ˆæ€§\n# å› ä¸º Estimation Sample ç‹¬ç«‹äºæ ‘ç»“æ„é€‰æ‹©\n```\n\n2. **Subsamplingï¼ˆå­é‡‡æ ·ï¼‰**\n```python\n# æ¯æ£µæ ‘ä½¿ç”¨ä¸åŒçš„å­æ ·æœ¬ï¼ˆä¸æ˜¯ Bootstrapï¼‰\n# å­é‡‡æ ·æ¯”ä¾‹é€šå¸¸æ˜¯ 50%\n# è¿™æ ·ä¸åŒæ ‘ä¹‹é—´æœ‰ä¸€å®šç‹¬ç«‹æ€§\n```\n\n3. **æ–¹å·®ä¼°è®¡**\n```python\n# å¯¹äºæ ·æœ¬ i çš„ CATE ä¼°è®¡\n# æ”¶é›†æ‰€æœ‰åŒ…å« i çš„æ ‘ï¼ˆä½œä¸º out-of-bag æ ·æœ¬ï¼‰\n# è¿™äº›æ ‘çš„é¢„æµ‹çš„æ–¹å·® â†’ ä¼°è®¡æ–¹å·®\n\nV(Ï„Ì‚(x_i)) = Var({Ï„Ì‚_b(x_i) : i âˆˆ OOB_b})\n```\n\n**å®ç°**:\n\n```python\nclass HonestCausalForest:\n    def predict_with_ci(self, X, alpha=0.05):\n        n_samples = len(X)\n        predictions = []  # æ¯æ£µæ ‘çš„é¢„æµ‹\n\n        # æ”¶é›†æ‰€æœ‰æ ‘çš„é¢„æµ‹\n        for tree in self.trees:\n            pred = tree.predict(X)\n            predictions.append(pred)\n\n        predictions = np.array(predictions)  # (n_trees, n_samples)\n\n        # ç‚¹ä¼°è®¡ï¼šæ‰€æœ‰æ ‘çš„å¹³å‡\n        point_estimate = predictions.mean(axis=0)\n\n        # æ–¹å·®ä¼°è®¡ï¼šæ ‘ä¹‹é—´é¢„æµ‹çš„æ–¹å·®\n        variance = predictions.var(axis=0, ddof=1) / self.n_trees\n\n        # ç½®ä¿¡åŒºé—´\n        z = stats.norm.ppf(1 - alpha/2)\n        se = np.sqrt(variance)\n        ci_lower = point_estimate - z * se\n        ci_upper = point_estimate + z * se\n\n        return point_estimate, ci_lower, ci_upper\n```\n\n**è¦†ç›–ç‡éªŒè¯**:\n```python\n# åœ¨ç†æƒ³æ¡ä»¶ä¸‹ï¼ˆå¤§æ ·æœ¬ + æ­£ç¡®æ¨¡å‹å‡è®¾ï¼‰\n# 95% CI åº”è¯¥è¦†ç›–çœŸå® CATE çº¦ 95% çš„æ ·æœ¬\ncoverage = np.mean((true_cate >= ci_lower) & (true_cate <= ci_upper))\n# åº”è¯¥æ¥è¿‘ 0.95\n```\n\n**ä¸ Bootstrap çš„åŒºåˆ«**:\n\n| æ–¹æ³• | Bootstrap | Causal Forest CI |\n|------|-----------|------------------|\n| ç†è®ºä¿è¯ | æ— ï¼ˆå¯å‘å¼ï¼‰ | æœ‰ï¼ˆæ¸è¿‘æ­£æ€æ€§ï¼‰ |\n| éœ€è¦ Honest | ä¸éœ€è¦ | å¿…éœ€ |\n| è®¡ç®—æˆæœ¬ | é«˜ï¼ˆéœ€è¦é‡å¤è®­ç»ƒï¼‰ | ä½ï¼ˆä¸€æ¬¡è®­ç»ƒï¼‰ |\n\n---\n\n### é—®é¢˜ 4: å®æˆ˜åœºæ™¯ - CATE ä¸ä¸šåŠ¡ç›´è§‰å†²çª\n\n**é¢è¯•å®˜**: ä½ ç”¨ Causal Forest é¢„æµ‹äº†ç”¨æˆ·çš„ CATEï¼Œä½†ç»“æœå’Œä¸šåŠ¡å›¢é˜Ÿçš„ç›´è§‰ç›¸åã€‚ä¸šåŠ¡è®¤ä¸ºé«˜ä»·å€¼ç”¨æˆ·å¯¹ä¼˜æƒ æ•æ„Ÿï¼Œä½†æ¨¡å‹é¢„æµ‹ä»–ä»¬çš„ CATE å¾ˆå°ã€‚ä½ ä¼šæ€ä¹ˆåŠï¼Ÿ\n\n**å‚è€ƒç­”æ¡ˆ**:\n\n**Step 1: éªŒè¯æ¨¡å‹æœ¬èº«**\n\n```python\n# 1. æ£€æŸ¥æ¨¡å‹è¯Šæ–­æŒ‡æ ‡\ndef validate_model(model, X, Y, T, true_cate=None):\n    # a) äº¤å‰éªŒè¯æ€§èƒ½\n    cv_score = cross_val_cate_score(model, X, Y, T)\n\n    # b) ç‰¹å¾é‡è¦æ€§ï¼ˆæ˜¯å¦åˆç†ï¼Ÿï¼‰\n    feature_importance = model.feature_importances_\n\n    # c) é¢„æµ‹åˆ†å¸ƒï¼ˆæ˜¯å¦æœ‰å¼‚å¸¸å€¼ï¼Ÿï¼‰\n    pred_cate = model.predict(X)\n    print(f\"CATE èŒƒå›´: [{pred_cate.min():.2f}, {pred_cate.max():.2f}]\")\n\n    # d) å¦‚æœæœ‰çœŸå® CATEï¼ˆæ¨¡æ‹Ÿï¼‰ï¼Œè®¡ç®—ç›¸å…³æ€§\n    if true_cate is not None:\n        corr = np.corrcoef(pred_cate, true_cate)[0, 1]\n        print(f\"ä¸çœŸå® CATE ç›¸å…³æ€§: {corr:.3f}\")\n\n    return {'cv_score': cv_score, 'feature_importance': feature_importance}\n```\n\n**Step 2: æ£€æŸ¥æ•°æ®è´¨é‡**\n\n```python\n# 2. é«˜ä»·å€¼ç”¨æˆ·çš„æ ·æœ¬é‡è¶³å¤Ÿå—ï¼Ÿ\nhigh_value_mask = X[:, 'value_score'] > 0.8\nprint(f\"é«˜ä»·å€¼ç”¨æˆ·æ ·æœ¬é‡: {high_value_mask.sum()}\")\nprint(f\"  å¤„ç†ç»„: {(high_value_mask & (T==1)).sum()}\")\nprint(f\"  æ§åˆ¶ç»„: {(high_value_mask & (T==0)).sum()}\")\n\n# å¦‚æœæ ·æœ¬é‡ä¸è¶³ï¼ŒCATE ä¼°è®¡ä¸å¯é ï¼\n```\n\n**Step 3: ç†è§£ä¸šåŠ¡é€»è¾‘**\n\nå¯èƒ½çš„è§£é‡Šï¼š\n\n**è§£é‡ŠA: ä¸šåŠ¡ç›´è§‰å¯èƒ½æ˜¯é”™çš„**\n```\nä¸šåŠ¡è§‚å¯Ÿ: é«˜ä»·å€¼ç”¨æˆ·æ”¶åˆ°ä¼˜æƒ åæ¶ˆè´¹æ›´å¤š\nä¸šåŠ¡ç»“è®º: ä»–ä»¬å¯¹ä¼˜æƒ æ•æ„Ÿï¼ˆCATE å¤§ï¼‰\n\nä½†çœŸç›¸å¯èƒ½æ˜¯ï¼š\n- é«˜ä»·å€¼ç”¨æˆ·æœ¬èº«å°±æ¶ˆè´¹å¤šï¼ˆé«˜ Y(0)ï¼‰\n- ä¼˜æƒ åªæ˜¯é”¦ä¸Šæ·»èŠ±ï¼ˆCATE å°ï¼‰\n- ä½ä»·å€¼ç”¨æˆ·æ‰æ˜¯è¢«ä¼˜æƒ \"æ¿€æ´»\"çš„ï¼ˆCATE å¤§ï¼‰\n\nè¿™æ˜¯æ··æ·†äº† Y(1) å’Œ CATEï¼\n```\n\n**è§£é‡ŠB: ç¼ºå°‘å…³é”®ç‰¹å¾**\n```python\n# ä¸šåŠ¡å¯èƒ½åœ¨ç”¨éšå«çš„ç»†åˆ†ï¼š\n# \"é«˜ä»·å€¼ä½†å¯¹ä»·æ ¼æ•æ„Ÿçš„ç”¨æˆ·\" vs \"é«˜ä»·å€¼ä½†ä¸åœ¨æ„ä»·æ ¼çš„ç”¨æˆ·\"\n\n# ä½†æ¨¡å‹å¯èƒ½ç¼ºå°‘\"ä»·æ ¼æ•æ„Ÿåº¦\"è¿™ä¸ªç‰¹å¾\n# å¯¼è‡´æŠŠä¸¤ç±»ç”¨æˆ·æ··åœ¨ä¸€èµ·ï¼ŒCATE è¢«å¹³å‡æ‰äº†\n\n# è§£å†³ï¼šè¡¥å……ç‰¹å¾\nX_new = add_feature(X, 'price_sensitivity')\n```\n\n**è§£é‡ŠC: å¤„ç†åˆ†é…åå·®**\n```python\n# æ£€æŸ¥å€¾å‘å¾—åˆ†\ne = estimate_propensity(X, T)\n\nprint(\"é«˜ä»·å€¼ç”¨æˆ·çš„å€¾å‘å¾—åˆ†:\")\nprint(e[high_value_mask].describe())\n\n# å¦‚æœ e â‰ˆ 1ï¼ˆå‡ ä¹éƒ½è¢«å¤„ç†ï¼‰\n# ç¼ºå°‘æœªå¤„ç†çš„å¯¹ç…§ç»„ â†’ CATE ä¼°è®¡ä¸å‡†\n```\n\n**Step 4: ä¸ä¸šåŠ¡æ²Ÿé€š**\n\n**é”™è¯¯åšæ³•**:\n```\n\"æ¨¡å‹è¯´ä½ ä»¬é”™äº†ï¼Œé«˜ä»·å€¼ç”¨æˆ· CATE å°±æ˜¯å°ã€‚\"\n```\n\n**æ­£ç¡®åšæ³•**:\n```\n\"æˆ‘ä»¬çš„æ¨¡å‹å‘ç°äº†ä¸€ä¸ªæœ‰è¶£çš„ç°è±¡ã€‚è®©æˆ‘ä»¬ä¸€èµ·æ·±å…¥åˆ†æï¼š\n\n1. æ•°æ®å±‚é¢ï¼š\n   - é«˜ä»·å€¼ç”¨æˆ·ä¸­ï¼Œæœ‰å¤šå°‘æ”¶åˆ°è¿‡ä¼˜æƒ ï¼Ÿ\n   - æœ‰æ²¡æœ‰æœªæ”¶åˆ°ä¼˜æƒ çš„é«˜ä»·å€¼ç”¨æˆ·ä½œä¸ºå¯¹ç…§ï¼Ÿ\n\n2. å®šä¹‰å±‚é¢ï¼š\n   - ä½ ä»¬è¯´çš„'å¯¹ä¼˜æƒ æ•æ„Ÿ'æ˜¯æŒ‡ï¼š\n     a) æ”¶åˆ°ä¼˜æƒ åæ¶ˆè´¹å¤šï¼ˆé«˜ Y(1)ï¼‰ï¼Ÿ\n     b) è¿˜æ˜¯ç›¸å¯¹ä¸å‘ä¼˜æƒ æå‡å¤§ï¼ˆé«˜ CATEï¼‰ï¼Ÿ\n\n3. ç»†åˆ†å±‚é¢ï¼š\n   - é«˜ä»·å€¼ç”¨æˆ·å†…éƒ¨æ˜¯å¦è¿˜æœ‰ç»†åˆ†ï¼Ÿ\n   - æ˜¯å¦æœ‰éšå«çš„ç‰¹å¾æˆ‘ä»¬è¿˜æ²¡æœ‰æ•æ‰ï¼Ÿ\n\n4. éªŒè¯æ–¹æ¡ˆï¼š\n   - æˆ‘ä»¬å¯ä»¥åšä¸€ä¸ªå°è§„æ¨¡ A/B æµ‹è¯•éªŒè¯æ¨¡å‹é¢„æµ‹\n   - ç‰¹åˆ«é’ˆå¯¹é«˜ä»·å€¼ç”¨æˆ·è¿™ä¸ªç¾¤ä½“\"\n```\n\n**Step 5: åç»­è¡ŒåŠ¨**\n\n```python\n# æ–¹æ¡ˆA: å¦‚æœæ ·æœ¬ä¸è¶³ â†’ è¡¥å……æ•°æ®\nrun_targeted_experiment(segment='high_value_users')\n\n# æ–¹æ¡ˆB: å¦‚æœç‰¹å¾ä¸è¶³ â†’ è¡¥å……ç‰¹å¾\nX_augmented = engineer_features(X, business_knowledge)\n\n# æ–¹æ¡ˆC: å¦‚æœæ¨¡å‹è¿‡ç®€å• â†’ æ¢æ¨¡å‹\n# Causal Forest â†’ Neural Network (DRNet)\n\n# æ–¹æ¡ˆD: å¦‚æœä¸šåŠ¡ç†è§£æœ‰å â†’ æ•™è‚²ä¸šåŠ¡\nvisualize_cate_vs_y1(high_value_users)\n```\n\n**å…³é”®å¯ç¤º**:\n- æ¨¡å‹å’Œç›´è§‰å†²çªæ—¶ï¼Œä¸¤è€…éƒ½å¯èƒ½é”™\n- ä¸è¦æ€¥äºä¸‹ç»“è®ºï¼Œç”¨æ•°æ®å’Œé€»è¾‘åˆ†æ\n- ä¸ä¸šåŠ¡æ·±åº¦æ²Ÿé€šï¼Œå»ºç«‹ä¿¡ä»»\n- è®¾è®¡éªŒè¯æ–¹æ¡ˆï¼Œç”¨å®éªŒè¯´è¯",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}