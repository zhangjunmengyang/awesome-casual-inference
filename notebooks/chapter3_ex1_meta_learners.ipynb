{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 Exercise 1: Meta-Learners - å› æœæ•ˆåº”ä¼°è®¡çš„ç‘å£«å†›åˆ€\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "1. ç†è§£ S-Learner å’Œ T-Learner çš„åŸç†\n",
    "2. å®ç°åŸºç¡€çš„ Meta-Learner ç®—æ³•\n",
    "3. ç†è§£ä¸åŒæ–¹æ³•çš„ä¼˜ç¼ºç‚¹\n",
    "4. æŒæ¡ CATE (æ¡ä»¶å¹³å‡å¤„ç†æ•ˆåº”) ä¼°è®¡å’Œè¯„ä¼°\n",
    "\n",
    "---\n",
    "\n",
    "## ä»€ä¹ˆæ˜¯ Meta-Learners?\n",
    "\n",
    "æƒ³è±¡ä½ æ˜¯ä¸€ä½åŒ»ç”Ÿï¼Œæƒ³çŸ¥é“æŸç§æ–°è¯å¯¹ä¸åŒç—…äººçš„æ•ˆæœã€‚é—®é¢˜æ˜¯ï¼šæ¯ä¸ªç—…äººåªèƒ½é€‰æ‹©åƒè¯æˆ–ä¸åƒè¯ä¸­çš„ä¸€ç§ï¼Œä½ æ°¸è¿œæ— æ³•åŒæ—¶è§‚å¯Ÿåˆ°ä¸¤ç§ç»“æœã€‚\n",
    "\n",
    "**Meta-Learners** å°±æ˜¯ç”¨ \"å…ƒå­¦ä¹ \" çš„æ€æƒ³æ¥è§£å†³è¿™ä¸ªé—®é¢˜â€”â€”å®ƒä»¬æŠŠå› æœæ•ˆåº”ä¼°è®¡è½¬åŒ–ä¸ºç›‘ç£å­¦ä¹ é—®é¢˜ï¼Œè®©æˆ‘ä»¬å¯ä»¥ç”¨ä»»ä½•æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚ Random Forestã€XGBoostï¼‰æ¥ä¼°è®¡å¤„ç†æ•ˆåº”ï¼\n",
    "\n",
    "è¿™å°±åƒæ˜¯ç»™ä½ ä¸€å¥—ä¸‡èƒ½å·¥å…·ï¼Œå¯ä»¥æŠŠå„ç§ ML æ¨¡å‹å˜æˆå› æœæ¨æ–­å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç”Ÿæ´»åŒ–ç±»æ¯”ï¼šé¤å…ä¼šå‘˜å¡çš„æ•ˆæœ\n",
    "\n",
    "å‡è®¾ä½ ç»è¥ä¸€å®¶é¤å…ï¼Œæ¨å‡ºäº†ä¼šå‘˜å¡ï¼ˆå¤„ç† Tï¼‰ï¼š\n",
    "- **å¤„ç†ç»„ (T=1)**ï¼šæ‹¿åˆ°ä¼šå‘˜å¡çš„é¡¾å®¢\n",
    "- **æ§åˆ¶ç»„ (T=0)**ï¼šæ²¡æœ‰ä¼šå‘˜å¡çš„é¡¾å®¢\n",
    "- **ç»“æœ Y**ï¼šæœˆæ¶ˆè´¹é‡‘é¢\n",
    "\n",
    "ä½ æƒ³çŸ¥é“ï¼š**ä¼šå‘˜å¡åˆ°åº•è®©é¡¾å®¢å¤šèŠ±äº†å¤šå°‘é’±ï¼Ÿ** è€Œä¸”æ›´è¿›ä¸€æ­¥ï¼š**å¯¹å“ªäº›é¡¾å®¢æ•ˆæœæœ€å¥½ï¼Ÿ**\n",
    "\n",
    "| é¡¾å®¢ç±»å‹ | åŸæœ¬æ¶ˆè´¹ | æœ‰ä¼šå‘˜å¡åæ¶ˆè´¹ | å¤„ç†æ•ˆåº” |\n",
    "|---------|---------|--------------|--------|\n",
    "| å­¦ç”Ÿå…š | 200 | 350 | **+150** (æ•ˆæœå¥½!) |\n",
    "| ä¸Šç­æ— | 500 | 520 | +20 (æ•ˆæœä¸€èˆ¬) |\n",
    "| åœŸè±ª | 2000 | 2010 | +10 (å‡ ä¹æ²¡æ•ˆæœ) |\n",
    "\n",
    "è¿™ç§ **å› äººè€Œå¼‚** çš„æ•ˆåº”å°±å«åš **CATE (Conditional Average Treatment Effect)**â€”â€”æ¡ä»¶å¹³å‡å¤„ç†æ•ˆåº”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from typing import Tuple\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"ç¯å¢ƒå‡†å¤‡å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: S-Learner (Single Model Learner)\n",
    "\n",
    "### æ ¸å¿ƒæ€æƒ³\n",
    "\n",
    "S-Learner æ˜¯æœ€ç®€å•çš„ Meta-Learnerï¼š\n",
    "\n",
    "**æŠŠå¤„ç† T å½“ä½œæ™®é€šç‰¹å¾ï¼Œè®­ç»ƒä¸€ä¸ªæ¨¡å‹åŒæ—¶é¢„æµ‹æ‰€æœ‰äººçš„ç»“æœ**\n",
    "\n",
    "$$\\hat{\\mu}(x, t) = \\hat{E}[Y | X=x, T=t]$$\n",
    "\n",
    "ç„¶åï¼ŒCATE å°±æ˜¯é¢„æµ‹å·®å€¼ï¼š\n",
    "\n",
    "$$\\hat{\\tau}(x) = \\hat{\\mu}(x, 1) - \\hat{\\mu}(x, 0)$$\n",
    "\n",
    "### ç±»æ¯”ï¼šä¸€ä¸ªç­çº§ï¼Œä¸€ä½è€å¸ˆ\n",
    "\n",
    "æƒ³è±¡ä¸€ä¸ªç­çº§é‡Œæœ‰ç”·ç”Ÿå’Œå¥³ç”Ÿï¼Œè€å¸ˆè¦é¢„æµ‹ä»–ä»¬çš„è€ƒè¯•æˆç»©ï¼š\n",
    "\n",
    "- **S-Learner æ–¹æ³•**ï¼šè€å¸ˆæŠŠ \"æ€§åˆ«\" ä½œä¸ºä¸€ä¸ªç‰¹å¾ï¼Œç”¨åŒä¸€å¥—æ¨¡å‹é¢„æµ‹æ‰€æœ‰å­¦ç”Ÿçš„æˆç»©\n",
    "- ç„¶åæ¯”è¾ƒï¼šå¦‚æœè¿™ä¸ªå­¦ç”Ÿæ˜¯ç”·ç”Ÿä¼šè€ƒå¤šå°‘åˆ†ï¼Ÿå¦‚æœæ˜¯å¥³ç”Ÿä¼šè€ƒå¤šå°‘åˆ†ï¼Ÿå·®å€¼å°±æ˜¯ \"æ€§åˆ«æ•ˆåº”\"\n",
    "\n",
    "### S-Learner çš„æµç¨‹å›¾\n",
    "\n",
    "```\n",
    "è®­ç»ƒé˜¶æ®µ:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  ç‰¹å¾ X + å¤„ç† T â”‚ â”€â”€â”€â–º â”‚  å•ä¸€æ¨¡å‹ f(X,T) â”‚ â”€â”€â”€â–º é¢„æµ‹ Y\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "é¢„æµ‹é˜¶æ®µ:\n",
    "                         â”Œâ”€ f(X, T=1) â”€â”\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”                 â”‚             â”‚    å‡æ³•\n",
    "â”‚ ç‰¹å¾ Xâ”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–º CATE\n",
    "â””â”€â”€â”€â”€â”€â”€â”˜                 â”‚             â”‚\n",
    "                         â””â”€ f(X, T=0) â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹  1.1: å®ç° S-Learner\n",
    "\n",
    "class SimpleSLearner:\n",
    "    \"\"\"\n",
    "    S-Learner (Single Model Learner)\n",
    "    \n",
    "    æ ¸å¿ƒæ€æƒ³:\n",
    "    - å°†å¤„ç† T ä½œä¸ºä¸€ä¸ªç‰¹å¾\n",
    "    - è®­ç»ƒå•ä¸€æ¨¡å‹: Y = f(X, T)\n",
    "    - CATE ä¼°è®¡: tau(x) = f(x, 1) - f(x, 0)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # TODO: åˆå§‹åŒ–åŸºç¡€æ¨¡å‹\n",
    "        # å¯ä»¥ä½¿ç”¨ LinearRegression æˆ– RandomForestRegressor\n",
    "        self.model = None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    def fit(self, X: np.ndarray, T: np.ndarray, Y: np.ndarray):\n",
    "        \"\"\"\n",
    "        è®­ç»ƒ S-Learner\n",
    "        \n",
    "        TODO:\n",
    "        1. å°† T å’Œ X åˆå¹¶ä¸ºç‰¹å¾çŸ©é˜µ (T ä½œä¸ºæœ€åä¸€åˆ—)\n",
    "        2. è®­ç»ƒæ¨¡å‹é¢„æµ‹ Y\n",
    "        \n",
    "        æç¤º: ä½¿ç”¨ np.column_stack([X, T.reshape(-1, 1)]) åˆå¹¶\n",
    "        \"\"\"\n",
    "        # ä½ çš„ä»£ç \n",
    "        pass\n",
    "    \n",
    "    def predict_cate(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        é¢„æµ‹ CATE (ä¸ªä½“å¤„ç†æ•ˆåº”)\n",
    "        \n",
    "        TODO:\n",
    "        1. æ„é€  T=1 çš„ç‰¹å¾: æŠŠ 1 æ·»åŠ åˆ° X åé¢\n",
    "        2. æ„é€  T=0 çš„ç‰¹å¾: æŠŠ 0 æ·»åŠ åˆ° X åé¢\n",
    "        3. åˆ†åˆ«é¢„æµ‹ Y(1) å’Œ Y(0)\n",
    "        4. è¿”å›å·®å€¼: Y(1) - Y(0)\n",
    "        \"\"\"\n",
    "        # ä½ çš„ä»£ç \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: T-Learner (Two Model Learner)\n",
    "\n",
    "### æ ¸å¿ƒæ€æƒ³\n",
    "\n",
    "T-Learner è®¤ä¸ºï¼šå¤„ç†ç»„å’Œæ§åˆ¶ç»„å¯èƒ½éµå¾ªå®Œå…¨ä¸åŒçš„è§„å¾‹ï¼Œæ‰€ä»¥åº”è¯¥åˆ†å¼€å»ºæ¨¡ï¼\n",
    "\n",
    "$$\\hat{\\mu}_0(x) = \\hat{E}[Y | X=x, T=0] \\quad \\text{(æ§åˆ¶ç»„æ¨¡å‹)}$$\n",
    "$$\\hat{\\mu}_1(x) = \\hat{E}[Y | X=x, T=1] \\quad \\text{(å¤„ç†ç»„æ¨¡å‹)}$$\n",
    "\n",
    "CATE ä¼°è®¡ï¼š\n",
    "$$\\hat{\\tau}(x) = \\hat{\\mu}_1(x) - \\hat{\\mu}_0(x)$$\n",
    "\n",
    "### ç±»æ¯”ï¼šä¸¤ä¸ªç­çº§ï¼Œä¸¤ä½è€å¸ˆ\n",
    "\n",
    "- **T-Learner æ–¹æ³•**ï¼šç”·ç”Ÿå’Œå¥³ç”Ÿåˆ†æˆä¸¤ä¸ªç­ï¼Œç”±ä¸åŒçš„è€å¸ˆæ•™\n",
    "- æ¯ä½è€å¸ˆåªäº†è§£è‡ªå·±ç­çº§çš„å­¦ç”Ÿ\n",
    "- æ¯”è¾ƒä¸¤ä¸ªè€å¸ˆçš„é¢„æµ‹å·®å€¼æ¥ä¼°è®¡ \"æ€§åˆ«æ•ˆåº”\"\n",
    "\n",
    "### T-Learner çš„æµç¨‹å›¾\n",
    "\n",
    "```\n",
    "è®­ç»ƒé˜¶æ®µ:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ æ§åˆ¶ç»„ (T=0)   â”‚ â”€â”€â”€â–º â”‚  æ¨¡å‹ 0: Î¼â‚€(X)  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ å¤„ç†ç»„ (T=1)   â”‚ â”€â”€â”€â–º â”‚  æ¨¡å‹ 1: Î¼â‚(X)  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "é¢„æµ‹é˜¶æ®µ:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     \n",
    "â”‚ç‰¹å¾ Xâ”‚ â”€â”€â”€â–º â”‚ æ¨¡å‹ 0  â”‚ â”€â”€â”€â–º Y(0)  â”\n",
    "â””â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ å‡æ³•\n",
    "   â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”œâ”€â”€â”€â”€â–º CATE\n",
    "   â””â”€â”€â”€â”€â”€â”€â”€â–º â”‚ æ¨¡å‹ 1  â”‚ â”€â”€â”€â–º Y(1)  â”˜\n",
    "             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹  1.2: å®ç° T-Learner\n",
    "\n",
    "class SimpleTLearner:\n",
    "    \"\"\"\n",
    "    T-Learner (Two Model Learner)\n",
    "    \n",
    "    æ ¸å¿ƒæ€æƒ³:\n",
    "    - åˆ†åˆ«ä¸ºå¤„ç†ç»„å’Œæ§åˆ¶ç»„è®­ç»ƒä¸¤ä¸ªæ¨¡å‹\n",
    "    - mu_0(x) = E[Y|X=x, T=0]  (æ§åˆ¶ç»„æ¨¡å‹)\n",
    "    - mu_1(x) = E[Y|X=x, T=1]  (å¤„ç†ç»„æ¨¡å‹)\n",
    "    - CATE ä¼°è®¡: tau(x) = mu_1(x) - mu_0(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # TODO: åˆå§‹åŒ–ä¸¤ä¸ªæ¨¡å‹\n",
    "        self.model_0 = None  # æ§åˆ¶ç»„æ¨¡å‹\n",
    "        self.model_1 = None  # å¤„ç†ç»„æ¨¡å‹\n",
    "    \n",
    "    def fit(self, X: np.ndarray, T: np.ndarray, Y: np.ndarray):\n",
    "        \"\"\"\n",
    "        è®­ç»ƒ T-Learner\n",
    "        \n",
    "        TODO:\n",
    "        1. å°†æ•°æ®æŒ‰ T åˆ†æˆä¸¤ç»„ (mask_0 = T == 0, mask_1 = T == 1)\n",
    "        2. ç”¨æ§åˆ¶ç»„æ•°æ®è®­ç»ƒ model_0\n",
    "        3. ç”¨å¤„ç†ç»„æ•°æ®è®­ç»ƒ model_1\n",
    "        \"\"\"\n",
    "        # ä½ çš„ä»£ç \n",
    "        pass\n",
    "    \n",
    "    def predict_cate(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        é¢„æµ‹ CATE\n",
    "        \n",
    "        TODO:\n",
    "        1. ä½¿ç”¨ model_1 é¢„æµ‹ Y(1)\n",
    "        2. ä½¿ç”¨ model_0 é¢„æµ‹ Y(0)\n",
    "        3. è¿”å›å·®å€¼ Y(1) - Y(0)\n",
    "        \"\"\"\n",
    "        # ä½ çš„ä»£ç \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: ç”Ÿæˆ Uplift æ•°æ®\n",
    "\n",
    "### æ•°æ®ç”Ÿæˆè¿‡ç¨‹ (DGP) çš„é‡è¦æ€§\n",
    "\n",
    "åœ¨å› æœæ¨æ–­ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸éœ€è¦ç”¨æ¨¡æ‹Ÿæ•°æ®æ¥éªŒè¯æ–¹æ³•æ˜¯å¦æœ‰æ•ˆã€‚å› ä¸ºåœ¨æ¨¡æ‹Ÿæ•°æ®ä¸­ï¼Œæˆ‘ä»¬ **çŸ¥é“çœŸå®çš„å› æœæ•ˆåº”**ï¼\n",
    "\n",
    "### æˆ‘ä»¬çš„ DGP\n",
    "\n",
    "å‡è®¾æˆ‘ä»¬åœ¨ç ”ç©¶ã€Œè¯¾å¤–è¡¥ä¹ ã€å¯¹ã€Œè€ƒè¯•æˆç»©ã€çš„æ•ˆæœï¼š\n",
    "\n",
    "- **X1**: å­¦ç”Ÿçš„å­¦ä¹ èƒ½åŠ› (æ ‡å‡†æ­£æ€åˆ†å¸ƒ)\n",
    "- **X2**: å­¦ç”Ÿçš„å­¦ä¹ æ—¶é—´ (æ ‡å‡†æ­£æ€åˆ†å¸ƒ)\n",
    "- **T**: æ˜¯å¦å‚åŠ è¡¥ä¹  (éšæœºåˆ†é…)\n",
    "- **Y(0)**: ä¸è¡¥ä¹ çš„æˆç»© = $5 + 2 \\cdot X_1 + X_2 + \\epsilon$\n",
    "- **Y(1)**: è¡¥ä¹ åçš„æˆç»© = $Y(0) + \\tau(X)$\n",
    "\n",
    "å…¶ä¸­ï¼Œ**å¼‚è´¨æ€§æ•ˆåº”**ï¼š\n",
    "$$\\tau(X) = 2 + X_1 - 0.5 \\cdot X_2$$\n",
    "\n",
    "è¿™æ„å‘³ç€ï¼š\n",
    "- å­¦ä¹ èƒ½åŠ›å¼ºçš„å­¦ç”Ÿ (X1 é«˜) â†’ è¡¥ä¹ æ•ˆæœæ›´å¥½\n",
    "- å­¦ä¹ æ—¶é—´é•¿çš„å­¦ç”Ÿ (X2 é«˜) â†’ è¡¥ä¹ æ•ˆæœç¨å·® (å› ä¸ºå·²ç»å¾ˆåŠªåŠ›äº†)\n",
    "- å¹³å‡å¤„ç†æ•ˆåº” ATE â‰ˆ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹  1.3: ç”Ÿæˆ Uplift æ•°æ®\n",
    "\n",
    "def generate_simple_uplift_data(\n",
    "    n: int = 1000,\n",
    "    heterogeneous: bool = True,\n",
    "    seed: int = 42\n",
    ") -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆç®€å•çš„ Uplift æ•°æ®\n",
    "    \n",
    "    æ•°æ®ç”Ÿæˆè¿‡ç¨‹ (DGP):\n",
    "    - X1, X2 ~ N(0, 1)\n",
    "    - T ~ Bernoulli(0.5)  (éšæœºåˆ†é…)\n",
    "    - Y(0) = 5 + 2*X1 + X2 + noise\n",
    "    - Y(1) = Y(0) + tau(X)\n",
    "    \n",
    "    å…¶ä¸­:\n",
    "    - å¦‚æœ heterogeneous=True: tau(X) = 2 + X1 - 0.5*X2  (å¼‚è´¨æ€§æ•ˆåº”)\n",
    "    - å¦‚æœ heterogeneous=False: tau(X) = 2  (å¸¸æ•°æ•ˆåº”)\n",
    "    \n",
    "    TODO: å®Œæˆæ•°æ®ç”Ÿæˆä»£ç \n",
    "    \n",
    "    Returns:\n",
    "        (DataFrame, true_cate)\n",
    "        DataFrame columns: X1, X2, T, Y\n",
    "        true_cate: çœŸå®çš„ä¸ªä½“å¤„ç†æ•ˆåº”\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆç‰¹å¾ X1, X2 (æ ‡å‡†æ­£æ€åˆ†å¸ƒ)\n",
    "    X1 = None  # ä½ çš„ä»£ç : np.random.randn(n)\n",
    "    X2 = None  # ä½ çš„ä»£ç : np.random.randn(n)\n",
    "    \n",
    "    # TODO: éšæœºåˆ†é…å¤„ç† T (ä¼¯åŠªåˆ©åˆ†å¸ƒ, p=0.5)\n",
    "    T = None  # ä½ çš„ä»£ç : np.random.binomial(1, 0.5, n)\n",
    "    \n",
    "    # TODO: è®¡ç®—çœŸå® CATE\n",
    "    if heterogeneous:\n",
    "        true_cate = None  # å¼‚è´¨æ€§: 2 + X1 - 0.5*X2\n",
    "    else:\n",
    "        true_cate = None  # å¸¸æ•°: np.ones(n) * 2\n",
    "    \n",
    "    # TODO: ç”Ÿæˆæ½œåœ¨ç»“æœ\n",
    "    noise = np.random.randn(n) * 0.5\n",
    "    # Y(0) = 5 + 2*X1 + X2 + noise\n",
    "    Y0 = None  # ä½ çš„ä»£ç \n",
    "    # Y(1) = Y(0) + true_cate\n",
    "    Y1 = None  # ä½ çš„ä»£ç \n",
    "    # è§‚æµ‹åˆ°çš„ Y = T * Y(1) + (1-T) * Y(0)\n",
    "    Y = None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'X1': X1,\n",
    "        'X2': X2,\n",
    "        'T': T,\n",
    "        'Y': Y\n",
    "    })\n",
    "    \n",
    "    return df, true_cate\n",
    "\n",
    "# æµ‹è¯•æ•°æ®ç”Ÿæˆ\n",
    "df, true_cate = generate_simple_uplift_data(n=100)\n",
    "if df is not None and true_cate is not None:\n",
    "    print(f\"æ ·æœ¬é‡: {len(df)}\")\n",
    "    print(f\"çœŸå®å¹³å‡ CATE (ATE): {true_cate.mean():.4f}\")\n",
    "    print(f\"CATE èŒƒå›´: [{true_cate.min():.2f}, {true_cate.max():.2f}]\")\n",
    "    print(\"\\næ•°æ®é¢„è§ˆ:\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"[æœªå®Œæˆ] è¯·å®Œæˆ generate_simple_uplift_data å‡½æ•°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: è¯„ä¼° CATE ä¼°è®¡è´¨é‡\n",
    "\n",
    "### å…³é”®æŒ‡æ ‡\n",
    "\n",
    "| æŒ‡æ ‡ | å…¬å¼ | å«ä¹‰ |\n",
    "|------|------|------|\n",
    "| **MSE** | $\\frac{1}{n}\\sum(\\tau_{true} - \\tau_{pred})^2$ | å‡æ–¹è¯¯å·®ï¼Œè¶Šå°è¶Šå¥½ |\n",
    "| **MAE** | $\\frac{1}{n}\\sum|\\tau_{true} - \\tau_{pred}|$ | å¹³å‡ç»å¯¹è¯¯å·® |\n",
    "| **Correlation** | $corr(\\tau_{true}, \\tau_{pred})$ | ç›¸å…³æ€§ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½ |\n",
    "| **PEHE** | $\\sqrt{MSE}$ | Precision in Estimation of HTEï¼Œæœ€å¸¸ç”¨æŒ‡æ ‡ |\n",
    "\n",
    "### PEHE çš„é‡è¦æ€§\n",
    "\n",
    "**PEHE (Precision in Estimation of Heterogeneous Effect)** æ˜¯è¯„ä¼° CATE ä¼°è®¡çš„é»„é‡‘æ ‡å‡†ï¼š\n",
    "\n",
    "$$PEHE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(\\tau_i^{true} - \\tau_i^{pred})^2}$$\n",
    "\n",
    "å®ƒå‘Šè¯‰æˆ‘ä»¬ï¼š**æ¨¡å‹é¢„æµ‹çš„ä¸ªä½“æ•ˆåº”ä¸çœŸå®æ•ˆåº”æœ‰å¤šæ¥è¿‘ï¼Ÿ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹  1.4: è¯„ä¼° CATE ä¼°è®¡\n",
    "\n",
    "def evaluate_cate_estimation(\n",
    "    true_cate: np.ndarray,\n",
    "    predicted_cate: np.ndarray\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    è¯„ä¼° CATE ä¼°è®¡çš„è´¨é‡\n",
    "    \n",
    "    TODO: è®¡ç®—ä»¥ä¸‹æŒ‡æ ‡:\n",
    "    1. MSE: å‡æ–¹è¯¯å·® = mean((true - pred)^2)\n",
    "    2. MAE: å¹³å‡ç»å¯¹è¯¯å·® = mean(|true - pred|)\n",
    "    3. Correlation: ä¸çœŸå® CATE çš„ç›¸å…³ç³»æ•°\n",
    "    4. PEHE: sqrt(MSE)\n",
    "    \n",
    "    Returns:\n",
    "        å­—å…¸åŒ…å«æ‰€æœ‰æŒ‡æ ‡\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'MSE': None,        # ä½ çš„ä»£ç : np.mean((true_cate - predicted_cate)**2)\n",
    "        'MAE': None,        # ä½ çš„ä»£ç : np.mean(np.abs(true_cate - predicted_cate))\n",
    "        'Correlation': None,# ä½ çš„ä»£ç : np.corrcoef(true_cate, predicted_cate)[0, 1]\n",
    "        'PEHE': None        # ä½ çš„ä»£ç : np.sqrt(MSE)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# æµ‹è¯•è¯„ä¼°å‡½æ•°\n",
    "if true_cate is not None:\n",
    "    # ç”¨ä¸€ä¸ªéšæœºé¢„æµ‹æµ‹è¯•\n",
    "    random_pred = np.random.randn(len(true_cate)) * 2 + 2\n",
    "    metrics = evaluate_cate_estimation(true_cate, random_pred)\n",
    "    if metrics['MSE'] is not None:\n",
    "        print(\"éšæœºé¢„æµ‹çš„è¯„ä¼°ç»“æœ:\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(\"[æœªå®Œæˆ] è¯·å®Œæˆ evaluate_cate_estimation å‡½æ•°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: S-Learner vs T-Learner å®æˆ˜å¯¹æ¯”\n",
    "\n",
    "### ä¸¤ç§æ–¹æ³•çš„å¯¹æ¯”\n",
    "\n",
    "| ç‰¹æ€§ | S-Learner | T-Learner |\n",
    "|------|-----------|------------|\n",
    "| æ¨¡å‹æ•°é‡ | 1ä¸ª | 2ä¸ª |\n",
    "| æ ·æœ¬åˆ©ç”¨ | ä½¿ç”¨å…¨éƒ¨æ•°æ® | åˆ†ç»„ä½¿ç”¨ |\n",
    "| å¤„ç†æ•ˆåº” | ä»æ¨¡å‹ç³»æ•°ä¸­å­¦ä¹  | ç›´æ¥æ¯”è¾ƒé¢„æµ‹å€¼ |\n",
    "| æ­£åˆ™åŒ–åå·® | å¯èƒ½ä½ä¼°æ•ˆåº” | è¾ƒå° |\n",
    "| æ–¹å·® | è¾ƒä½ | è¾ƒé«˜ (ç‰¹åˆ«æ˜¯æ ·æœ¬ä¸å¹³è¡¡æ—¶) |\n",
    "\n",
    "### ä»€ä¹ˆæ—¶å€™ç”¨å“ªä¸ªï¼Ÿ\n",
    "\n",
    "- **S-Learner æ›´å¥½**: å¤„ç†æ•ˆåº”è¾ƒå°ã€æ ·æœ¬é‡æœ‰é™ã€å¤„ç†ç»„å’Œæ§åˆ¶ç»„ç›¸ä¼¼\n",
    "- **T-Learner æ›´å¥½**: å¤„ç†æ•ˆåº”æ˜¾è‘—ã€ä¸¤ç»„è§„å¾‹ä¸åŒã€å¼‚è´¨æ€§å¼º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹  1.5: æ¯”è¾ƒ S-Learner å’Œ T-Learner\n",
    "\n",
    "def compare_s_and_t_learner(\n",
    "    n_samples: int = 2000,\n",
    "    heterogeneous: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    æ¯”è¾ƒ S-Learner å’Œ T-Learner çš„æ€§èƒ½\n",
    "    \n",
    "    TODO:\n",
    "    1. ç”Ÿæˆæ•°æ®\n",
    "    2. è®­ç»ƒ S-Learner å¹¶é¢„æµ‹ CATE\n",
    "    3. è®­ç»ƒ T-Learner å¹¶é¢„æµ‹ CATE\n",
    "    4. è¯„ä¼°ä¸¤è€…çš„ CATE ä¼°è®¡\n",
    "    5. è¿”å›å¯¹æ¯”ç»“æœ\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with comparison results\n",
    "    \"\"\"\n",
    "    # TODO: ç”Ÿæˆæ•°æ®\n",
    "    df, true_cate = generate_simple_uplift_data(n_samples, heterogeneous)\n",
    "    \n",
    "    X = df[['X1', 'X2']].values\n",
    "    T = df['T'].values\n",
    "    Y = df['Y'].values\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # TODO: è®­ç»ƒ S-Learner\n",
    "    s_learner = SimpleSLearner()\n",
    "    # s_learner.fit(X, T, Y)\n",
    "    # s_pred = s_learner.predict_cate(X)\n",
    "    s_pred = None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    # TODO: è®­ç»ƒ T-Learner\n",
    "    t_learner = SimpleTLearner()\n",
    "    # t_learner.fit(X, T, Y)\n",
    "    # t_pred = t_learner.predict_cate(X)\n",
    "    t_pred = None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    # TODO: è¯„ä¼°å¹¶æ”¶é›†ç»“æœ\n",
    "    if s_pred is not None:\n",
    "        s_metrics = evaluate_cate_estimation(true_cate, s_pred)\n",
    "        s_metrics['Method'] = 'S-Learner'\n",
    "        results.append(s_metrics)\n",
    "    \n",
    "    if t_pred is not None:\n",
    "        t_metrics = evaluate_cate_estimation(true_cate, t_pred)\n",
    "        t_metrics['Method'] = 'T-Learner'\n",
    "        results.append(t_metrics)\n",
    "    \n",
    "    return pd.DataFrame(results) if results else None, s_pred, t_pred, true_cate\n",
    "\n",
    "# è¿è¡Œå¯¹æ¯”å®éªŒ\n",
    "print(\"=\" * 50)\n",
    "print(\"åœºæ™¯ 1: å¼‚è´¨æ€§æ•ˆåº”\")\n",
    "print(\"=\" * 50)\n",
    "result, s_pred, t_pred, true_cate = compare_s_and_t_learner(n_samples=1000, heterogeneous=True)\n",
    "if result is not None:\n",
    "    display(result)\n",
    "else:\n",
    "    print(\"[æœªå®Œæˆ] è¯·å®Œæˆæ‰€æœ‰ç»ƒä¹ åé‡æ–°è¿è¡Œ\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"åœºæ™¯ 2: å¸¸æ•°æ•ˆåº”\")\n",
    "print(\"=\" * 50)\n",
    "result2, _, _, _ = compare_s_and_t_learner(n_samples=1000, heterogeneous=False)\n",
    "if result2 is not None:\n",
    "    display(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: å¯è§†åŒ– CATE ä¼°è®¡ç»“æœ\n",
    "\n",
    "è®©æˆ‘ä»¬å¯è§†åŒ–æ¨¡å‹çš„é¢„æµ‹æ•ˆæœï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– CATE ä¼°è®¡ç»“æœ\n",
    "\n",
    "if s_pred is not None and t_pred is not None:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # å›¾1: çœŸå® vs S-Learner\n",
    "    axes[0].scatter(true_cate, s_pred, alpha=0.5, s=10)\n",
    "    axes[0].plot([true_cate.min(), true_cate.max()], \n",
    "                 [true_cate.min(), true_cate.max()], 'r--', lw=2)\n",
    "    axes[0].set_xlabel('True CATE')\n",
    "    axes[0].set_ylabel('Predicted CATE')\n",
    "    axes[0].set_title('S-Learner: True vs Predicted')\n",
    "    \n",
    "    # å›¾2: çœŸå® vs T-Learner\n",
    "    axes[1].scatter(true_cate, t_pred, alpha=0.5, s=10)\n",
    "    axes[1].plot([true_cate.min(), true_cate.max()], \n",
    "                 [true_cate.min(), true_cate.max()], 'r--', lw=2)\n",
    "    axes[1].set_xlabel('True CATE')\n",
    "    axes[1].set_ylabel('Predicted CATE')\n",
    "    axes[1].set_title('T-Learner: True vs Predicted')\n",
    "    \n",
    "    # å›¾3: CATE åˆ†å¸ƒå¯¹æ¯”\n",
    "    axes[2].hist(true_cate, bins=30, alpha=0.5, label='True CATE', density=True)\n",
    "    axes[2].hist(s_pred, bins=30, alpha=0.5, label='S-Learner', density=True)\n",
    "    axes[2].hist(t_pred, bins=30, alpha=0.5, label='T-Learner', density=True)\n",
    "    axes[2].set_xlabel('CATE')\n",
    "    axes[2].set_ylabel('Density')\n",
    "    axes[2].set_title('CATE Distribution')\n",
    "    axes[2].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"è¯·å…ˆå®Œæˆä¸Šé¢çš„ç»ƒä¹ ï¼Œç”Ÿæˆé¢„æµ‹ç»“æœ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## æ€è€ƒé¢˜\n",
    "\n",
    "è¯·åœ¨ä¸‹é¢çš„ markdown å•å…ƒæ ¼ä¸­å†™ä¸‹ä½ çš„ç­”æ¡ˆï¼š\n",
    "\n",
    "### 1. S-Learner çš„ä¼˜ç‚¹å’Œç¼ºç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "ä¼˜ç‚¹:\n",
    "- \n",
    "- \n",
    "\n",
    "ç¼ºç‚¹:\n",
    "- \n",
    "- \n",
    "\n",
    "### 2. T-Learner çš„ä¼˜ç‚¹å’Œç¼ºç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "ä¼˜ç‚¹:\n",
    "- \n",
    "- \n",
    "\n",
    "ç¼ºç‚¹:\n",
    "- \n",
    "- \n",
    "\n",
    "### 3. åœ¨ä»€ä¹ˆæƒ…å†µä¸‹ S-Learner å¯èƒ½è¡¨ç°æ›´å¥½ï¼Ÿåœ¨ä»€ä¹ˆæƒ…å†µä¸‹ T-Learner å¯èƒ½è¡¨ç°æ›´å¥½ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "S-Learner æ›´å¥½:\n",
    "- \n",
    "\n",
    "T-Learner æ›´å¥½:\n",
    "- \n",
    "\n",
    "### 4. X-Learner ç›¸æ¯” S-Learner å’Œ T-Learner æœ‰ä»€ä¹ˆåˆ›æ–°ä¹‹å¤„ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "- \n",
    "- \n",
    "\n",
    "### 5. å¦‚æœå¤„ç†ç»„å’Œæ§åˆ¶ç»„çš„æ ·æœ¬é‡ä¸¥é‡ä¸å¹³è¡¡ (æ¯”å¦‚ 90% vs 10%)ï¼Œåº”è¯¥é€‰æ‹©å“ªç§ Meta-Learnerï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## æ€»ç»“\n",
    "\n",
    "### ä»Šå¤©å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "| æ¦‚å¿µ | è¦ç‚¹ |\n",
    "|------|------|\n",
    "| **Meta-Learners** | æŠŠå› æœæ¨æ–­é—®é¢˜è½¬åŒ–ä¸ºç›‘ç£å­¦ä¹ é—®é¢˜çš„é€šç”¨æ–¹æ³• |\n",
    "| **S-Learner** | å•æ¨¡å‹ï¼ŒæŠŠ T å½“ç‰¹å¾ï¼Œç®€å•ä½†å¯èƒ½ä½ä¼°æ•ˆåº” |\n",
    "| **T-Learner** | åŒæ¨¡å‹ï¼Œåˆ†åˆ«å»ºæ¨¡ï¼Œçµæ´»ä½†å¯èƒ½æ–¹å·®å¤§ |\n",
    "| **CATE** | æ¡ä»¶å¹³å‡å¤„ç†æ•ˆåº”ï¼Œåæ˜ æ•ˆåº”çš„å¼‚è´¨æ€§ |\n",
    "| **PEHE** | è¯„ä¼° CATE ä¼°è®¡çš„é»„é‡‘æ ‡å‡† |\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "åœ¨ä¸‹ä¸€ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹  **Uplift Tree** â€”â€” ä¸€ç§ä¸“é—¨ä¸ºå› æœæ¨æ–­è®¾è®¡çš„å†³ç­–æ ‘ï¼\n",
    "\n",
    "---\n",
    "\n",
    "*æ­å–œä½ å®Œæˆäº† Meta-Learners çš„å­¦ä¹ ï¼* ğŸ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
