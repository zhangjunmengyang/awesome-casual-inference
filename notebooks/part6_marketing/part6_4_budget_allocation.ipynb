{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# é¢„ç®—åˆ†é…ä¼˜åŒ– - æŠŠé’±èŠ±åœ¨åˆ€åˆƒä¸Š\n",
    "\n",
    "> *\"ä¸æ˜¯é’±ä¸å¤Ÿï¼Œæ˜¯æ²¡èŠ±å¯¹åœ°æ–¹\"*\n",
    "\n",
    "## å¼€åœºæ•…äº‹\n",
    "\n",
    "æƒ³è±¡ä½ æ˜¯ä¸€å®¶ç”µå•†å…¬å¸çš„è¥é”€æ€»ç›‘ï¼Œæ‰‹æ¡ 1000 ä¸‡å¹¿å‘Šé¢„ç®—ï¼Œé¢å¯¹ 5 ä¸ªæŠ•æ”¾æ¸ é“ï¼š\n",
    "\n",
    "- **æœç´¢å¹¿å‘Š**ï¼šç²¾å‡†ä½†è´µï¼Œå•æ¬¡ç‚¹å‡» 10 å…ƒ\n",
    "- **ä¿¡æ¯æµ**ï¼šé‡å¤§ä¾¿å®œï¼Œå•æ¬¡ç‚¹å‡» 2 å…ƒ\n",
    "- **KOL åˆä½œ**ï¼šå“æ•ˆåˆä¸€ï¼Œä½†ä¸ç¡®å®šæ€§é«˜\n",
    "- **çŸ­è§†é¢‘**ï¼šå¹´è½»ç”¨æˆ·å¤šï¼Œè½¬åŒ–ç‡ä¸€èˆ¬\n",
    "- **æˆ·å¤–å¹¿å‘Š**ï¼šæ›å…‰é‡å¤§ï¼Œä½†éš¾ä»¥è¿½è¸ª\n",
    "\n",
    "ä½ ä¼šæ€ä¹ˆåˆ†é…è¿™ 1000 ä¸‡ï¼Ÿå¹³å‡åˆ†ï¼Ÿå…¨æŠ• ROI æœ€é«˜çš„ï¼Ÿè¿˜æ˜¯...\n",
    "\n",
    "è¿™å°±æ˜¯æˆ‘ä»¬ä»Šå¤©è¦è§£å†³çš„é—®é¢˜ï¼š**é¢„ç®—åˆ†é…ä¼˜åŒ–**ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## å­¦ä¹ è·¯çº¿å›¾\n",
    "\n",
    "```\n",
    "é¢„ç®—åˆ†é…é—®é¢˜ â†’ è¾¹é™… ROI â†’ çº¦æŸä¼˜åŒ– â†’ å¤šæ¸ é“åˆ†é… â†’ ç¨³å¥ä¼˜åŒ– â†’ å®æˆ˜æ¡ˆä¾‹\n",
    "    â†“              â†“           â†“            â†“             â†“          â†“\n",
    "  ä¸ºä»€ä¹ˆä¼˜åŒ–    æ”¶ç›Šé€’å‡      æ•°å­¦å»ºæ¨¡     è”åˆä¼˜åŒ–      åº”å¯¹ä¸ç¡®å®š   ä¸šåŠ¡è½åœ°\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯å¢ƒå‡†å¤‡\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.optimize import minimize, LinearConstraint, NonlinearConstraint\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "np.random.seed(42)\n",
    "\n",
    "# é¢œè‰²æ–¹æ¡ˆ\n",
    "COLORS = {\n",
    "    'primary': '#2D9CDB',\n",
    "    'success': '#27AE60',\n",
    "    'warning': '#F2C94C',\n",
    "    'danger': '#EB5757',\n",
    "    'purple': '#9B51E0',\n",
    "    'teal': '#56CCF2'\n",
    "}\n",
    "\n",
    "print(\"âœ“ ç¯å¢ƒå‡†å¤‡å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: é¢„ç®—åˆ†é…é—®é¢˜\n",
    "\n",
    "## 1.1 ä¸ºä»€ä¹ˆéœ€è¦ä¼˜åŒ–ï¼Ÿ\n",
    "\n",
    "### å¸¸è§çš„é¢„ç®—åˆ†é…æ–¹å¼ï¼ˆéƒ½æœ‰é—®é¢˜ï¼ï¼‰\n",
    "\n",
    "| æ–¹å¼ | æè¿° | é—®é¢˜ |\n",
    "|------|------|------|\n",
    "| **å¹³å‡åˆ†é…** | æ¯ä¸ªæ¸ é“åˆ† 200 ä¸‡ | å¿½ç•¥æ¸ é“æ•ˆæœå·®å¼‚ |\n",
    "| **æŒ‰å†å²å æ¯”** | å»å¹´æ€ä¹ˆåˆ†ä»Šå¹´å°±æ€ä¹ˆåˆ† | å¸‚åœºåœ¨å˜åŒ– |\n",
    "| **å…¨æŠ•æœ€ä¼˜æ¸ é“** | ROI æœ€é«˜çš„æ¸ é“å…¨æŠ• | è¾¹é™…æ”¶ç›Šé€’å‡ |\n",
    "| **æ‹è„‘è¢‹å†³ç­–** | è€æ¿è¯´è¿™ä¸ªæ¸ é“é‡è¦ | ç¼ºä¹æ•°æ®æ”¯æ’‘ |\n",
    "\n",
    "### ä¼˜åŒ–çš„æ ¸å¿ƒæ€æƒ³\n",
    "\n",
    "**è®©æ¯ä¸€å—é’±çš„è¾¹é™…æ”¶ç›Šç›¸ç­‰**\n",
    "\n",
    "å°±åƒç»™å¤šä¸ªæ°´æ¡¶åŠ æ°´ï¼Œæœ€ä¼˜ç­–ç•¥æ˜¯ï¼šè®©æ‰€æœ‰æ°´æ¡¶çš„**æ°´é¢é«˜åº¦ç›¸åŒ**ï¼ˆè¾¹é™…æ•ˆç”¨ç›¸ç­‰ï¼‰ï¼Œè€Œä¸æ˜¯è®©æŸä¸ªæ¡¶æœ€æ»¡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 è¾¹é™…æ”¶ç›Šé€’å‡åŸç†\n",
    "\n",
    "### ç”Ÿæ´»ä¸­çš„ä¾‹å­\n",
    "\n",
    "- **åƒç«é”…**ï¼šç¬¬ä¸€ç›˜è‚¥ç‰›å¾ˆé¦™ï¼Œç¬¬äº”ç›˜å°±è…»äº†\n",
    "- **åˆ·é¢˜**ï¼šå‰ 100 é“æå‡å¤§ï¼Œå 100 é“æ”¶ç›Šé€’å‡\n",
    "- **å¹¿å‘ŠæŠ•æ”¾**ï¼šå‰ 100 ä¸‡è§¦è¾¾ç²¾å‡†ç”¨æˆ·ï¼Œå 100 ä¸‡é‡å¤æ›å…‰\n",
    "\n",
    "### æ•°å­¦è¡¨è¾¾\n",
    "\n",
    "å“åº”æ›²çº¿ï¼ˆResponse Curveï¼‰ï¼š\n",
    "\n",
    "$$\n",
    "R(x) = a \\cdot \\frac{x^\\alpha}{c^\\alpha + x^\\alpha}\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- $R(x)$: æŠ•å…¥ $x$ å¸¦æ¥çš„æ”¶ç›Š\n",
    "- $a$: é¥±å’Œæ”¶ç›Šï¼ˆæœ€å¤§æ”¶ç›Šï¼‰\n",
    "- $c$: åŠé¥±å’Œç‚¹ï¼ˆè¾¾åˆ° 50% æœ€å¤§æ”¶ç›Šæ—¶çš„æŠ•å…¥ï¼‰\n",
    "- $\\alpha$: å½¢çŠ¶å‚æ•°ï¼ˆé€šå¸¸ 0.5-2ï¼‰\n",
    "\n",
    "è¾¹é™…æ”¶ç›Šï¼š\n",
    "\n",
    "$$\n",
    "R'(x) = \\frac{dR}{dx} = a \\cdot \\alpha \\cdot \\frac{c^\\alpha \\cdot x^{\\alpha-1}}{(c^\\alpha + x^\\alpha)^2}\n",
    "$$\n",
    "\n",
    "**å…³é”®æ€§è´¨**ï¼š$R'(x)$ éš $x$ é€’å‡ï¼ˆè¾¹é™…æ”¶ç›Šé€’å‡ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ï¼šè¾¹é™…æ”¶ç›Šé€’å‡\n",
    "\n",
    "def response_curve(x, a, c, alpha):\n",
    "    \"\"\"å“åº”æ›²çº¿ï¼ˆHill Equationï¼‰\"\"\"\n",
    "    return a * (x**alpha) / (c**alpha + x**alpha)\n",
    "\n",
    "def marginal_response(x, a, c, alpha):\n",
    "    \"\"\"è¾¹é™…å“åº”ï¼ˆå¯¼æ•°ï¼‰\"\"\"\n",
    "    return a * alpha * (c**alpha) * (x**(alpha-1)) / ((c**alpha + x**alpha)**2)\n",
    "\n",
    "# å‚æ•°è®¾ç½®ï¼š3 ä¸ªæ¸ é“\n",
    "channels = {\n",
    "    'æœç´¢å¹¿å‘Š': {'a': 500, 'c': 150, 'alpha': 0.8},  # é«˜æ•ˆä½†å¿«é¥±å’Œ\n",
    "    'ä¿¡æ¯æµ': {'a': 800, 'c': 300, 'alpha': 1.2},    # æ½œåŠ›å¤§ä½†éœ€è¦é‡\n",
    "    'çŸ­è§†é¢‘': {'a': 600, 'c': 200, 'alpha': 1.0}     # ä¸­ç­‰\n",
    "}\n",
    "\n",
    "x = np.linspace(0, 500, 200)\n",
    "\n",
    "# åˆ›å»ºå­å›¾\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=['å“åº”æ›²çº¿ R(x)', 'è¾¹é™…å“åº” R\\'(x)'],\n",
    "    horizontal_spacing=0.12\n",
    ")\n",
    "\n",
    "colors_list = [COLORS['primary'], COLORS['success'], COLORS['warning']]\n",
    "\n",
    "for i, (name, params) in enumerate(channels.items()):\n",
    "    # å“åº”æ›²çº¿\n",
    "    y = response_curve(x, **params)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x, y=y, name=name,\n",
    "            line=dict(color=colors_list[i], width=3),\n",
    "            mode='lines'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # è¾¹é™…å“åº”\n",
    "    y_marginal = marginal_response(x, **params)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x, y=y_marginal, name=name,\n",
    "            line=dict(color=colors_list[i], width=3, dash='dot'),\n",
    "            mode='lines',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(title_text=\"æŠ•å…¥é¢„ç®— (ä¸‡å…ƒ)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"æŠ•å…¥é¢„ç®— (ä¸‡å…ƒ)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"æ€»æ”¶ç›Š (ä¸‡å…ƒ)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"è¾¹é™…æ”¶ç›Š (å…ƒ/å…ƒ)\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=400,\n",
    "    template='plotly_white',\n",
    "    title_text=\"è¾¹é™…æ”¶ç›Šé€’å‡åŸç†\",\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ è§‚å¯Ÿè¦ç‚¹ï¼š\")\n",
    "print(\"1. å“åº”æ›²çº¿ï¼šæŠ•å…¥è¶Šå¤šï¼Œæ”¶ç›Šå¢é•¿è¶Šæ…¢ï¼ˆSå‹æ›²çº¿ï¼‰\")\n",
    "print(\"2. è¾¹é™…å“åº”ï¼šæŠ•å…¥è¶Šå¤šï¼Œæ¯å¢åŠ 1å…ƒçš„æ”¶ç›Šè¶Šä½ï¼ˆé€’å‡æ›²çº¿ï¼‰\")\n",
    "print(\"3. ä¸åŒæ¸ é“æœ‰ä¸åŒçš„é¥±å’Œç‚¹å’Œå½¢çŠ¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 å¤šç›®æ ‡æƒè¡¡\n",
    "\n",
    "å®é™…ä¸šåŠ¡ä¸­ï¼Œé¢„ç®—åˆ†é…å¾€å¾€éœ€è¦è€ƒè™‘å¤šä¸ªç›®æ ‡ï¼š\n",
    "\n",
    "### å¸¸è§ç›®æ ‡\n",
    "\n",
    "1. **çŸ­æœŸ ROI æœ€å¤§åŒ–**ï¼šç«‹å³å›æœ¬\n",
    "2. **é•¿æœŸç”¨æˆ·ä»·å€¼ï¼ˆLTVï¼‰**ï¼šå“ç‰Œå»ºè®¾\n",
    "3. **å¸‚åœºä»½é¢**ï¼šæˆ˜ç•¥å¡ä½\n",
    "4. **é£é™©åˆ†æ•£**ï¼šä¸æŠŠé¸¡è›‹æ”¾ä¸€ä¸ªç¯®å­\n",
    "\n",
    "### æƒè¡¡æ–¹æ³•\n",
    "\n",
    "**åŠ æƒç›®æ ‡å‡½æ•°**ï¼š\n",
    "\n",
    "$$\n",
    "\\max_{x_1, \\ldots, x_n} \\quad w_1 \\cdot ROI(x) + w_2 \\cdot LTV(x) - w_3 \\cdot Risk(x)\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ $w_1, w_2, w_3$ æ˜¯ä¸šåŠ¡æƒé‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ï¼šå¤šç›®æ ‡æƒè¡¡\n",
    "\n",
    "# æ¨¡æ‹Ÿæ•°æ®ï¼šä¸åŒåˆ†é…æ–¹æ¡ˆçš„è¡¨ç°\n",
    "strategies = {\n",
    "    'å…¨æŠ•æœç´¢': {'ROI': 3.5, 'LTV': 2.0, 'Risk': 8.0},\n",
    "    'å¹³å‡åˆ†é…': {'ROI': 2.8, 'LTV': 3.5, 'Risk': 3.0},\n",
    "    'ä¼˜åŒ–åˆ†é…': {'ROI': 3.2, 'LTV': 4.0, 'Risk': 2.5},\n",
    "    'å“ç‰Œå¯¼å‘': {'ROI': 2.0, 'LTV': 5.0, 'Risk': 4.0}\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(strategies).T.reset_index()\n",
    "df.columns = ['ç­–ç•¥', 'ROI', 'LTV', 'é£é™©']\n",
    "\n",
    "# é›·è¾¾å›¾\n",
    "fig = go.Figure()\n",
    "\n",
    "categories = ['ROI', 'LTV', 'é£é™©ï¼ˆä½æ›´å¥½ï¼‰']\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    values = [row['ROI'], row['LTV'], 10 - row['é£é™©']]  # é£é™©å–å\n",
    "    values += [values[0]]  # é—­åˆ\n",
    "    \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=values,\n",
    "        theta=categories + [categories[0]],\n",
    "        name=row['ç­–ç•¥'],\n",
    "        fill='toself',\n",
    "        line=dict(width=2)\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 10]\n",
    "        )\n",
    "    ),\n",
    "    title=\"ä¸åŒé¢„ç®—åˆ†é…ç­–ç•¥çš„å¤šç›®æ ‡è¡¨ç°\",\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ æ´å¯Ÿï¼š\")\n",
    "print(\"â€¢ å…¨æŠ•æœç´¢ï¼šROIé«˜ä½†é£é™©å¤§\")\n",
    "print(\"â€¢ å¹³å‡åˆ†é…ï¼šä¿å®ˆç¨³å¥ï¼Œä½†æ”¶ç›Šä¸€èˆ¬\")\n",
    "print(\"â€¢ ä¼˜åŒ–åˆ†é…ï¼šåœ¨å¤šä¸ªç›®æ ‡é—´å–å¾—å¹³è¡¡\")\n",
    "print(\"â€¢ å“ç‰Œå¯¼å‘ï¼šç‰ºç‰²çŸ­æœŸROIï¼Œé‡è§†é•¿æœŸä»·å€¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: è¾¹é™… ROI ä¼˜åŒ–\n",
    "\n",
    "## 2.1 è¾¹é™… ROI çš„å®šä¹‰\n",
    "\n",
    "### ROI vs è¾¹é™… ROI\n",
    "\n",
    "**å¹³å‡ ROI**ï¼ˆå®¹æ˜“è¯¯å¯¼å†³ç­–ï¼‰ï¼š\n",
    "$$\n",
    "ROI_{avg} = \\frac{R(x)}{x}\n",
    "$$\n",
    "\n",
    "**è¾¹é™… ROI**ï¼ˆä¼˜åŒ–çš„å…³é”®æŒ‡æ ‡ï¼‰ï¼š\n",
    "$$\n",
    "ROI_{marginal} = \\frac{dR}{dx} = R'(x)\n",
    "$$\n",
    "\n",
    "### ç”Ÿæ´»ä¸­çš„æ¯”å–»\n",
    "\n",
    "- **å¹³å‡æˆç»©**ï¼šä½ è€ƒäº† 5 æ¬¡è¯•ï¼Œå¹³å‡ 85 åˆ†\n",
    "- **è¾¹é™…æå‡**ï¼šå†å­¦ 1 å°æ—¶ï¼Œä¸‹æ¬¡èƒ½æå‡å‡ åˆ†ï¼Ÿ\n",
    "\n",
    "å†³ç­–æ—¶è¦çœ‹**è¾¹é™…æå‡**ï¼Œä¸æ˜¯å¹³å‡åˆ†ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ï¼šå¹³å‡ ROI vs è¾¹é™… ROI\n",
    "\n",
    "def avg_roi(x, a, c, alpha):\n",
    "    \"\"\"å¹³å‡ ROI\"\"\"\n",
    "    return response_curve(x, a, c, alpha) / (x + 1e-10)\n",
    "\n",
    "# ä½¿ç”¨æœç´¢å¹¿å‘Šçš„å‚æ•°\n",
    "params = channels['æœç´¢å¹¿å‘Š']\n",
    "x = np.linspace(1, 400, 200)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# å¹³å‡ ROI\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=avg_roi(x, **params),\n",
    "    name='å¹³å‡ ROI',\n",
    "    line=dict(color=COLORS['primary'], width=3)\n",
    "))\n",
    "\n",
    "# è¾¹é™… ROI\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=marginal_response(x, **params),\n",
    "    name='è¾¹é™… ROI',\n",
    "    line=dict(color=COLORS['danger'], width=3, dash='dash')\n",
    "))\n",
    "\n",
    "# æ ‡æ³¨å…³é”®ç‚¹\n",
    "x_point = 200\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[x_point, x_point],\n",
    "    y=[avg_roi(x_point, **params), marginal_response(x_point, **params)],\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=12, color=['blue', 'red']),\n",
    "    text=[f'å¹³å‡: {avg_roi(x_point, **params):.2f}', \n",
    "          f'è¾¹é™…: {marginal_response(x_point, **params):.2f}'],\n",
    "    textposition=['top center', 'bottom center'],\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"å¹³å‡ ROI vs è¾¹é™… ROIï¼ˆæœç´¢å¹¿å‘Šï¼‰\",\n",
    "    xaxis_title=\"æŠ•å…¥é¢„ç®— (ä¸‡å…ƒ)\",\n",
    "    yaxis_title=\"ROI (å…ƒ/å…ƒ)\",\n",
    "    template='plotly_white',\n",
    "    height=400,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nâš ï¸ è­¦ç¤ºæ¡ˆä¾‹ï¼š\")\n",
    "print(f\"å‡è®¾å·²æŠ•å…¥ {x_point} ä¸‡å…ƒï¼š\")\n",
    "print(f\"â€¢ å¹³å‡ ROI = {avg_roi(x_point, **params):.2f}ï¼Œçœ‹èµ·æ¥ä¸é”™\")\n",
    "print(f\"â€¢ ä½†è¾¹é™… ROI = {marginal_response(x_point, **params):.2f}ï¼Œå·²ç»å¾ˆä½äº†\")\n",
    "print(f\"â€¢ å†æŠ•å…¥çš„é’±åº”è¯¥åˆ†é…ç»™å…¶ä»–æ¸ é“ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 æœ€ä¼˜åˆ†é…æ¡ä»¶\n",
    "\n",
    "### æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•çš„ç›´è§‰\n",
    "\n",
    "**é—®é¢˜**ï¼šé¢„ç®— $B$ï¼Œ$n$ ä¸ªæ¸ é“ï¼Œå¦‚ä½•åˆ†é… $x_1, \\ldots, x_n$ï¼Ÿ\n",
    "\n",
    "**ä¼˜åŒ–ç›®æ ‡**ï¼š\n",
    "$$\n",
    "\\max_{x_1, \\ldots, x_n} \\quad \\sum_{i=1}^n R_i(x_i)\n",
    "$$\n",
    "\n",
    "**çº¦æŸæ¡ä»¶**ï¼š\n",
    "$$\n",
    "\\sum_{i=1}^n x_i = B, \\quad x_i \\geq 0\n",
    "$$\n",
    "\n",
    "### æœ€ä¼˜æ€§æ¡ä»¶ï¼ˆä¸€é˜¶æ¡ä»¶ï¼‰\n",
    "\n",
    "$$\n",
    "R_1'(x_1^*) = R_2'(x_2^*) = \\cdots = R_n'(x_n^*) = \\lambda\n",
    "$$\n",
    "\n",
    "**è§£è¯»**ï¼šæ‰€æœ‰æ¸ é“çš„**è¾¹é™… ROI ç›¸ç­‰**ï¼Œç­‰äºæ‹‰æ ¼æœ—æ—¥ä¹˜æ•° $\\lambda$ï¼ˆå½±å­ä»·æ ¼ï¼‰ã€‚\n",
    "\n",
    "### æ°´æ¡¶æ¨¡å‹\n",
    "\n",
    "æƒ³è±¡ $n$ ä¸ªå½¢çŠ¶ä¸åŒçš„æ°´æ¡¶ï¼ˆå“åº”æ›²çº¿ä¸åŒï¼‰ï¼š\n",
    "- æœ€ä¼˜åˆ†é… = è®©æ‰€æœ‰æ°´æ¡¶çš„**æ°´é¢é«˜åº¦ç›¸åŒ**ï¼ˆè¾¹é™… ROI ç›¸ç­‰ï¼‰\n",
    "- å¦‚æœæŸä¸ªæ¡¶çš„æ°´é¢æ›´é«˜ï¼ˆè¾¹é™… ROI æ›´é«˜ï¼‰ï¼Œåº”è¯¥ä»å…¶ä»–æ¡¶è½¬ç§»æ°´è¿‡æ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# TODO 1: å®ç°è¾¹é™… ROI ç›¸ç­‰çš„æœ€ä¼˜åˆ†é…\n\ndef optimize_budget_marginal_equal(channels_params, total_budget):\n    \"\"\"\n    ä½¿ç”¨æ•°å€¼ä¼˜åŒ–æ‰¾åˆ°è¾¹é™… ROI ç›¸ç­‰çš„é¢„ç®—åˆ†é…\n    \n    å‚æ•°:\n        channels_params: dict, æ¯ä¸ªæ¸ é“çš„å‚æ•° {'channel': {'a': ..., 'c': ..., 'alpha': ...}}\n        total_budget: float, æ€»é¢„ç®—\n    \n    è¿”å›:\n        allocation: dict, æœ€ä¼˜åˆ†é…æ–¹æ¡ˆ\n        metrics: dict, æ€§èƒ½æŒ‡æ ‡\n    \"\"\"\n    n_channels = len(channels_params)\n    channel_names = list(channels_params.keys())\n    \n    # ç›®æ ‡å‡½æ•°ï¼šæœ€å¤§åŒ–æ€»æ”¶ç›Šï¼ˆè´Ÿå·è½¬ä¸ºæœ€å°åŒ–ï¼‰\n    def objective(x):\n        total_response = 0\n        for i, name in enumerate(channel_names):\n            params = channels_params[name]\n            total_response += response_curve(x[i], **params)\n        return -total_response  # è´Ÿå·ï¼šæœ€å¤§åŒ–è½¬æœ€å°åŒ–\n    \n    # çº¦æŸæ¡ä»¶\n    constraints = [\n        # æ·»åŠ é¢„ç®—æ€»å’Œç­‰äº total_budget çš„çº¦æŸ\n        LinearConstraint(np.ones(n_channels), total_budget, total_budget)\n    ]\n    \n    # è¾¹ç•Œï¼šæ¯ä¸ªæ¸ é“é¢„ç®— >= 0\n    bounds = [(0, total_budget) for _ in range(n_channels)]\n    \n    # åˆå§‹çŒœæµ‹ï¼šå¹³å‡åˆ†é…\n    x0 = np.ones(n_channels) * total_budget / n_channels\n    \n    # ä½¿ç”¨ scipy.optimize.minimize æ±‚è§£\n    result = minimize(\n        objective,\n        x0,\n        method='SLSQP',\n        bounds=bounds,\n        constraints=constraints\n    )\n    \n    # è§£æç»“æœ\n    optimal_allocation = dict(zip(channel_names, result.x))\n    \n    # è®¡ç®—è¾¹é™… ROIï¼ˆéªŒè¯æ˜¯å¦ç›¸ç­‰ï¼‰\n    marginal_rois = {}\n    total_response = 0\n    for name, budget in optimal_allocation.items():\n        params = channels_params[name]\n        marginal_rois[name] = marginal_response(budget, **params)\n        total_response += response_curve(budget, **params)\n    \n    metrics = {\n        'total_response': total_response,\n        'avg_roi': total_response / total_budget,\n        'marginal_rois': marginal_rois,\n        'shadow_price': np.mean(list(marginal_rois.values()))\n    }\n    \n    return optimal_allocation, metrics\n\n# æµ‹è¯•\ntotal_budget = 1000  # 1000 ä¸‡\nallocation, metrics = optimize_budget_marginal_equal(channels, total_budget)\n\nprint(\"\\nğŸ¯ æœ€ä¼˜é¢„ç®—åˆ†é…ï¼š\")\nfor channel, budget in allocation.items():\n    print(f\"  {channel}: {budget:.1f} ä¸‡å…ƒ ({budget/total_budget*100:.1f}%)\")\n\nprint(f\"\\nğŸ“Š æ€§èƒ½æŒ‡æ ‡ï¼š\")\nprint(f\"  æ€»æ”¶ç›Š: {metrics['total_response']:.1f} ä¸‡å…ƒ\")\nprint(f\"  å¹³å‡ ROI: {metrics['avg_roi']:.2f}\")\nprint(f\"  å½±å­ä»·æ ¼ Î»: {metrics['shadow_price']:.3f}\")\n\nprint(f\"\\nğŸ” è¾¹é™… ROIï¼ˆéªŒè¯æ˜¯å¦ç›¸ç­‰ï¼‰ï¼š\")\nfor channel, mroi in metrics['marginal_rois'].items():\n    print(f\"  {channel}: {mroi:.3f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ï¼šæœ€ä¼˜åˆ†é… vs å…¶ä»–ç­–ç•¥\n",
    "\n",
    "# å¯¹æ¯”ä¸åŒåˆ†é…ç­–ç•¥\n",
    "strategies_comparison = {\n",
    "    'å¹³å‡åˆ†é…': {ch: total_budget / len(channels) for ch in channels.keys()},\n",
    "    'æœ€ä¼˜åˆ†é…': allocation\n",
    "}\n",
    "\n",
    "# è®¡ç®—æ¯ç§ç­–ç•¥çš„æ€»æ”¶ç›Š\n",
    "def calc_total_response(allocation, channels_params):\n",
    "    total = 0\n",
    "    for ch, budget in allocation.items():\n",
    "        total += response_curve(budget, **channels_params[ch])\n",
    "    return total\n",
    "\n",
    "results = []\n",
    "for strategy_name, alloc in strategies_comparison.items():\n",
    "    total_resp = calc_total_response(alloc, channels)\n",
    "    for ch, budget in alloc.items():\n",
    "        results.append({\n",
    "            'ç­–ç•¥': strategy_name,\n",
    "            'æ¸ é“': ch,\n",
    "            'é¢„ç®—': budget,\n",
    "            'æ”¶ç›Š': response_curve(budget, **channels[ch]),\n",
    "            'è¾¹é™…ROI': marginal_response(budget, **channels[ch])\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# åˆ†ç»„æŸ±çŠ¶å›¾\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=['é¢„ç®—åˆ†é…', 'è¾¹é™… ROI'],\n",
    "    specs=[[{'type': 'bar'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "for strategy in ['å¹³å‡åˆ†é…', 'æœ€ä¼˜åˆ†é…']:\n",
    "    df_sub = df_results[df_results['ç­–ç•¥'] == strategy]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_sub['æ¸ é“'],\n",
    "            y=df_sub['é¢„ç®—'],\n",
    "            name=strategy,\n",
    "            text=df_sub['é¢„ç®—'].apply(lambda x: f'{x:.0f}'),\n",
    "            textposition='auto'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_sub['æ¸ é“'],\n",
    "            y=df_sub['è¾¹é™…ROI'],\n",
    "            name=strategy,\n",
    "            text=df_sub['è¾¹é™…ROI'].apply(lambda x: f'{x:.2f}'),\n",
    "            textposition='auto',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(title_text=\"æ¸ é“\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"æ¸ é“\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"é¢„ç®— (ä¸‡å…ƒ)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"è¾¹é™… ROI\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=400,\n",
    "    template='plotly_white',\n",
    "    title_text=\"é¢„ç®—åˆ†é…ç­–ç•¥å¯¹æ¯”\",\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# è®¡ç®—æ”¶ç›Šæå‡\n",
    "avg_response = calc_total_response(strategies_comparison['å¹³å‡åˆ†é…'], channels)\n",
    "opt_response = calc_total_response(strategies_comparison['æœ€ä¼˜åˆ†é…'], channels)\n",
    "improvement = (opt_response - avg_response) / avg_response * 100\n",
    "\n",
    "print(f\"\\nğŸ’° ä¼˜åŒ–æ•ˆæœï¼š\")\n",
    "print(f\"  å¹³å‡åˆ†é…æ€»æ”¶ç›Š: {avg_response:.1f} ä¸‡å…ƒ\")\n",
    "print(f\"  æœ€ä¼˜åˆ†é…æ€»æ”¶ç›Š: {opt_response:.1f} ä¸‡å…ƒ\")\n",
    "print(f\"  æå‡: {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: çº¦æŸä¼˜åŒ–å»ºæ¨¡\n",
    "\n",
    "## 3.1 å®é™…ä¸šåŠ¡çº¦æŸ\n",
    "\n",
    "ç°å®ä¸­çš„é¢„ç®—åˆ†é…è¿œæ¯”ç†è®ºå¤æ‚ï¼Œéœ€è¦è€ƒè™‘å„ç§ä¸šåŠ¡çº¦æŸï¼š\n",
    "\n",
    "### å¸¸è§çº¦æŸç±»å‹\n",
    "\n",
    "| çº¦æŸç±»å‹ | æ•°å­¦è¡¨è¾¾ | ä¸šåŠ¡åœºæ™¯ |\n",
    "|----------|----------|----------|\n",
    "| **æœ€å°é¢„ç®—** | $x_i \\geq x_i^{min}$ | ä¿æŒæ¸ é“æ´»è·ƒ |\n",
    "| **æœ€å¤§é¢„ç®—** | $x_i \\leq x_i^{max}$ | ä¾›ç»™é™åˆ¶ |\n",
    "| **å æ¯”çº¦æŸ** | $x_i \\leq \\alpha \\cdot B$ | é£é™©æ§åˆ¶ |\n",
    "| **åˆ†ç»„çº¦æŸ** | $\\sum_{i \\in G} x_i \\leq B_G$ | å“ç‰Œé¢„ç®—ä¸Šé™ |\n",
    "| **ä¾èµ–å…³ç³»** | $x_i \\geq \\beta \\cdot x_j$ | ååŒæ•ˆåº” |\n",
    "\n",
    "### å®Œæ•´ä¼˜åŒ–æ¨¡å‹\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\max_{x_1, \\ldots, x_n} \\quad & \\sum_{i=1}^n R_i(x_i) \\\\\n",
    "\\text{s.t.} \\quad & \\sum_{i=1}^n x_i = B \\\\\n",
    "& x_i^{min} \\leq x_i \\leq x_i^{max}, \\quad \\forall i \\\\\n",
    "& x_i \\leq \\alpha_i \\cdot B, \\quad \\forall i \\\\\n",
    "& \\text{å…¶ä»–ä¸šåŠ¡çº¦æŸ}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# TODO 2: å®ç°å¸¦çº¦æŸçš„é¢„ç®—ä¼˜åŒ–\n\ndef optimize_with_constraints(channels_params, total_budget, constraints_config):\n    \"\"\"\n    å¸¦ä¸šåŠ¡çº¦æŸçš„é¢„ç®—ä¼˜åŒ–\n    \n    å‚æ•°:\n        channels_params: dict, æ¸ é“å‚æ•°\n        total_budget: float, æ€»é¢„ç®—\n        constraints_config: dict, çº¦æŸé…ç½®\n            {\n                'min_budget': {channel: min_value},  # æœ€å°é¢„ç®—\n                'max_budget': {channel: max_value},  # æœ€å¤§é¢„ç®—\n                'max_share': {channel: max_ratio}    # æœ€å¤§å æ¯”\n            }\n    \"\"\"\n    n_channels = len(channels_params)\n    channel_names = list(channels_params.keys())\n    \n    # ç›®æ ‡å‡½æ•°\n    def objective(x):\n        total_response = 0\n        for i, name in enumerate(channel_names):\n            params = channels_params[name]\n            total_response += response_curve(x[i], **params)\n        return -total_response\n    \n    # æ„å»ºçº¦æŸæ¡ä»¶åˆ—è¡¨\n    constraints = []\n    \n    # 1. é¢„ç®—æ€»å’Œçº¦æŸ\n    constraints.append(\n        LinearConstraint(np.ones(n_channels), total_budget, total_budget)\n    )\n    \n    # è¾¹ç•Œçº¦æŸ\n    bounds = []\n    for i, name in enumerate(channel_names):\n        min_b = constraints_config.get('min_budget', {}).get(name, 0)\n        max_b = constraints_config.get('max_budget', {}).get(name, total_budget)\n        \n        # è€ƒè™‘å æ¯”çº¦æŸ\n        if name in constraints_config.get('max_share', {}):\n            max_share = constraints_config['max_share'][name]\n            max_b = min(max_b, total_budget * max_share)\n        \n        bounds.append((min_b, max_b))\n    \n    # åˆå§‹çŒœæµ‹\n    x0 = np.ones(n_channels) * total_budget / n_channels\n    \n    # ä¼˜åŒ–æ±‚è§£\n    result = minimize(\n        objective,\n        x0,\n        method='SLSQP',\n        bounds=bounds,\n        constraints=constraints,\n        options={'maxiter': 1000}\n    )\n    \n    if not result.success:\n        print(f\"âš ï¸ ä¼˜åŒ–è­¦å‘Š: {result.message}\")\n    \n    optimal_allocation = dict(zip(channel_names, result.x))\n    total_response = -result.fun\n    \n    return optimal_allocation, total_response\n\n# å®šä¹‰ä¸šåŠ¡çº¦æŸ\nconstraints_config = {\n    'min_budget': {\n        'æœç´¢å¹¿å‘Š': 50,   # è‡³å°‘æŠ• 50 ä¸‡ä¿æŒæ´»è·ƒ\n        'ä¿¡æ¯æµ': 100,    # ä¿¡æ¯æµéœ€è¦é‡\n        'çŸ­è§†é¢‘': 30\n    },\n    'max_budget': {\n        'æœç´¢å¹¿å‘Š': 400,  # æœç´¢å¹¿å‘Šä¾›ç»™æœ‰é™\n    },\n    'max_share': {\n        'æœç´¢å¹¿å‘Š': 0.5,  # å•æ¸ é“ä¸è¶…è¿‡ 50%ï¼ˆé£é™©æ§åˆ¶ï¼‰\n    }\n}\n\n# ä¼˜åŒ–\nallocation_constrained, response_constrained = optimize_with_constraints(\n    channels, total_budget, constraints_config\n)\n\nprint(\"\\nğŸ¯ å¸¦çº¦æŸçš„æœ€ä¼˜åˆ†é…ï¼š\")\nfor channel, budget in allocation_constrained.items():\n    print(f\"  {channel}: {budget:.1f} ä¸‡å…ƒ ({budget/total_budget*100:.1f}%)\")\n    \n    # æ£€æŸ¥çº¦æŸ\n    if channel in constraints_config['min_budget']:\n        min_b = constraints_config['min_budget'][channel]\n        if budget <= min_b + 1:\n            print(f\"    âš ï¸ è§¦åŠæœ€å°é¢„ç®—çº¦æŸ {min_b}\")\n    \n    if channel in constraints_config['max_budget']:\n        max_b = constraints_config['max_budget'][channel]\n        if budget >= max_b - 1:\n            print(f\"    âš ï¸ è§¦åŠæœ€å¤§é¢„ç®—çº¦æŸ {max_b}\")\n\nprint(f\"\\nğŸ“Š æ€»æ”¶ç›Š: {response_constrained:.1f} ä¸‡å…ƒ\")\n\n# å¯¹æ¯”æ— çº¦æŸä¼˜åŒ–\nresponse_unconstrained = calc_total_response(allocation, channels)\nloss = (response_unconstrained - response_constrained) / response_unconstrained * 100\nprint(f\"\\nğŸ’¡ çº¦æŸå¯¼è‡´çš„æ”¶ç›ŠæŸå¤±: {loss:.1f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 æ‹‰æ ¼æœ—æ—¥æ–¹æ³•çš„ç»æµå­¦è§£é‡Š\n",
    "\n",
    "### æ‹‰æ ¼æœ—æ—¥å‡½æ•°\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(x, \\lambda) = \\sum_{i=1}^n R_i(x_i) - \\lambda \\left( \\sum_{i=1}^n x_i - B \\right)\n",
    "$$\n",
    "\n",
    "### å½±å­ä»·æ ¼ï¼ˆShadow Priceï¼‰\n",
    "\n",
    "æ‹‰æ ¼æœ—æ—¥ä¹˜æ•° $\\lambda$ è¡¨ç¤ºï¼š\n",
    "- **å†å¢åŠ  1 å…ƒé¢„ç®—ï¼Œæ€»æ”¶ç›Šä¼šå¢åŠ å¤šå°‘**\n",
    "- åœ¨æœ€ä¼˜ç‚¹ï¼Œ$\\lambda$ = æ‰€æœ‰æ¸ é“çš„è¾¹é™… ROI\n",
    "\n",
    "### å®é™…åº”ç”¨\n",
    "\n",
    "å¦‚æœè€æ¿é—®ï¼š\"å†ç»™ä½  100 ä¸‡ï¼Œèƒ½æå‡å¤šå°‘æ”¶ç›Šï¼Ÿ\"\n",
    "\n",
    "ç­”æ¡ˆå°±æ˜¯ï¼š$\\Delta R \\approx \\lambda \\cdot 100$ï¼ˆçº¿æ€§è¿‘ä¼¼ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ï¼šå½±å­ä»·æ ¼åˆ†æ\n",
    "\n",
    "# æµ‹è¯•ä¸åŒé¢„ç®—ä¸‹çš„æœ€ä¼˜æ”¶ç›Šå’Œå½±å­ä»·æ ¼\n",
    "budgets = np.linspace(500, 2000, 20)\n",
    "responses = []\n",
    "shadow_prices = []\n",
    "\n",
    "for B in budgets:\n",
    "    alloc, metrics = optimize_budget_marginal_equal(channels, B)\n",
    "    responses.append(metrics['total_response'])\n",
    "    shadow_prices.append(metrics['shadow_price'])\n",
    "\n",
    "# è®¡ç®—æ•°å€¼å¯¼æ•°ï¼ˆéªŒè¯å½±å­ä»·æ ¼ï¼‰\n",
    "numerical_derivatives = np.gradient(responses, budgets)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=['æ€»æ”¶ç›Šæ›²çº¿', 'å½±å­ä»·æ ¼ï¼ˆè¾¹é™…æ”¶ç›Šï¼‰']\n",
    ")\n",
    "\n",
    "# æ€»æ”¶ç›Š\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=budgets,\n",
    "        y=responses,\n",
    "        mode='lines+markers',\n",
    "        name='æ€»æ”¶ç›Š',\n",
    "        line=dict(color=COLORS['primary'], width=3)\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# å½±å­ä»·æ ¼ vs æ•°å€¼å¯¼æ•°\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=budgets,\n",
    "        y=shadow_prices,\n",
    "        mode='lines+markers',\n",
    "        name='å½±å­ä»·æ ¼ Î»',\n",
    "        line=dict(color=COLORS['success'], width=3)\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=budgets,\n",
    "        y=numerical_derivatives,\n",
    "        mode='lines',\n",
    "        name='æ•°å€¼å¯¼æ•° dR/dB',\n",
    "        line=dict(color=COLORS['danger'], width=2, dash='dash')\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"æ€»é¢„ç®— (ä¸‡å…ƒ)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"æ€»é¢„ç®— (ä¸‡å…ƒ)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"æ€»æ”¶ç›Š (ä¸‡å…ƒ)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"è¾¹é™…æ”¶ç›Š (å…ƒ/å…ƒ)\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=400,\n",
    "    template='plotly_white',\n",
    "    title_text=\"å½±å­ä»·æ ¼åˆ†æ\",\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ æ´å¯Ÿï¼š\")\n",
    "print(\"1. å½±å­ä»·æ ¼ Î» ä¸æ•°å€¼å¯¼æ•° dR/dB åŸºæœ¬ä¸€è‡´ï¼ˆéªŒè¯äº†ç†è®ºï¼‰\")\n",
    "print(\"2. éšç€é¢„ç®—å¢åŠ ï¼Œå½±å­ä»·æ ¼é€’å‡ï¼ˆæ•´ä½“è¾¹é™…æ”¶ç›Šé€’å‡ï¼‰\")\n",
    "print(f\"3. å½“å‰é¢„ç®— {total_budget} ä¸‡æ—¶ï¼ŒÎ» â‰ˆ {metrics['shadow_price']:.3f}\")\n",
    "print(f\"   â†’ å†å¢åŠ  100 ä¸‡é¢„ç®—ï¼Œé¢„æœŸå¢åŠ æ”¶ç›Šçº¦ {metrics['shadow_price']*100:.1f} ä¸‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: å¤šæ¸ é“åˆ†é…å®æˆ˜\n",
    "\n",
    "## 4.1 æ¸ é“é—´çš„äº¤äº’æ•ˆåº”\n",
    "\n",
    "ç°å®ä¸­ï¼Œæ¸ é“ä¹‹é—´ä¸æ˜¯ç‹¬ç«‹çš„ï¼š\n",
    "\n",
    "### ååŒæ•ˆåº”ï¼ˆSynergyï¼‰\n",
    "\n",
    "æŸäº›æ¸ é“ç»„åˆä¼šäº§ç”Ÿ 1+1>2 çš„æ•ˆæœï¼š\n",
    "\n",
    "$$\n",
    "R(x_1, x_2) = R_1(x_1) + R_2(x_2) + \\gamma \\cdot \\sqrt{x_1 \\cdot x_2}\n",
    "$$\n",
    "\n",
    "**ä¾‹å­**ï¼š\n",
    "- å“ç‰Œå¹¿å‘Šï¼ˆæˆ·å¤–ï¼‰+ æ•ˆæœå¹¿å‘Šï¼ˆæœç´¢ï¼‰ï¼šå“ç‰Œæå‡æœç´¢è½¬åŒ–ç‡\n",
    "- KOL ç§è‰ + ä¿¡æ¯æµæ”¶å‰²ï¼šä¸Šä¸‹æ¸¸é…åˆ\n",
    "\n",
    "### æ›¿ä»£æ•ˆåº”ï¼ˆSubstitutionï¼‰\n",
    "\n",
    "æŸäº›æ¸ é“ä¼šæŠ¢å¤ºåŒä¸€æ‰¹ç”¨æˆ·ï¼š\n",
    "\n",
    "$$\n",
    "R(x_1, x_2) = R_1(x_1) + R_2(x_2) - \\delta \\cdot \\min(x_1, x_2)\n",
    "$$\n",
    "\n",
    "**ä¾‹å­**ï¼š\n",
    "- æœç´¢å¹¿å‘Š vs ä¿¡æ¯æµï¼šåŒæ—¶è§¦è¾¾åŒä¸€ç”¨æˆ·ï¼ˆæµªè´¹ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# TODO 3: å®ç°è€ƒè™‘äº¤äº’æ•ˆåº”çš„é¢„ç®—ä¼˜åŒ–\n\ndef optimize_with_interaction(channels_params, total_budget, interaction_matrix):\n    \"\"\"\n    è€ƒè™‘æ¸ é“äº¤äº’æ•ˆåº”çš„é¢„ç®—ä¼˜åŒ–\n    \n    å‚æ•°:\n        channels_params: dict, æ¸ é“å‚æ•°\n        total_budget: float, æ€»é¢„ç®—\n        interaction_matrix: np.ndarray, äº¤äº’çŸ©é˜µ\n            interaction_matrix[i, j] > 0: ååŒæ•ˆåº”\n            interaction_matrix[i, j] < 0: æ›¿ä»£æ•ˆåº”\n    \"\"\"\n    n_channels = len(channels_params)\n    channel_names = list(channels_params.keys())\n    \n    # å®šä¹‰åŒ…å«äº¤äº’é¡¹çš„ç›®æ ‡å‡½æ•°\n    def objective(x):\n        # åŸºç¡€æ”¶ç›Š\n        total_response = 0\n        for i, name in enumerate(channel_names):\n            params = channels_params[name]\n            total_response += response_curve(x[i], **params)\n        \n        # äº¤äº’æ•ˆåº”\n        for i in range(n_channels):\n            for j in range(i+1, n_channels):\n                gamma = interaction_matrix[i, j]\n                if gamma != 0:\n                    # ä½¿ç”¨å‡ ä½•å¹³å‡å»ºæ¨¡äº¤äº’\n                    interaction_term = gamma * np.sqrt(x[i] * x[j] + 1e-10)\n                    total_response += interaction_term\n        \n        return -total_response\n    \n    # çº¦æŸå’Œè¾¹ç•Œ\n    constraints = [\n        LinearConstraint(np.ones(n_channels), total_budget, total_budget)\n    ]\n    bounds = [(0, total_budget) for _ in range(n_channels)]\n    x0 = np.ones(n_channels) * total_budget / n_channels\n    \n    # ä¼˜åŒ–\n    result = minimize(\n        objective,\n        x0,\n        method='SLSQP',\n        bounds=bounds,\n        constraints=constraints\n    )\n    \n    optimal_allocation = dict(zip(channel_names, result.x))\n    total_response = -result.fun\n    \n    return optimal_allocation, total_response\n\n# å®šä¹‰äº¤äº’çŸ©é˜µï¼ˆå¯¹ç§°çŸ©é˜µï¼‰\n# 0: æœç´¢å¹¿å‘Š, 1: ä¿¡æ¯æµ, 2: çŸ­è§†é¢‘\ninteraction_matrix = np.array([\n    [0,    -0.2,  0.3],   # æœç´¢ï¼šä¸ä¿¡æ¯æµæ›¿ä»£ï¼Œä¸çŸ­è§†é¢‘ååŒ\n    [-0.2,  0,    0.1],   # ä¿¡æ¯æµï¼šä¸çŸ­è§†é¢‘å¼±ååŒ\n    [0.3,   0.1,  0]      # çŸ­è§†é¢‘\n])\n\nprint(\"ğŸ“Š æ¸ é“äº¤äº’çŸ©é˜µï¼š\")\nprint(\"   æœç´¢  ä¿¡æ¯æµ  çŸ­è§†é¢‘\")\nfor i, name in enumerate(channels.keys()):\n    print(f\"{name:6s} {interaction_matrix[i]}\")\nprint(\"\\nè¯´æ˜: >0 ååŒ, <0 æ›¿ä»£\")\n\n# ä¼˜åŒ–ï¼ˆæœ‰äº¤äº’ vs æ— äº¤äº’ï¼‰\nallocation_no_interact, response_no_interact = optimize_budget_marginal_equal(channels, total_budget)\nallocation_with_interact, response_with_interact = optimize_with_interaction(\n    channels, total_budget, interaction_matrix\n)\n\nprint(\"\\nğŸ¯ åˆ†é…å¯¹æ¯”ï¼š\")\nprint(f\"{'æ¸ é“':<10} {'æ— äº¤äº’':<12} {'æœ‰äº¤äº’':<12} {'å˜åŒ–'}\")\nprint(\"-\" * 50)\nfor ch in channels.keys():\n    no_int = allocation_no_interact[ch]\n    with_int = allocation_with_interact[ch]\n    change = with_int - no_int\n    print(f\"{ch:<10} {no_int:>8.1f} ä¸‡   {with_int:>8.1f} ä¸‡   {change:+7.1f}\")\n\nprint(f\"\\nğŸ“Š æ€»æ”¶ç›Šå¯¹æ¯”ï¼š\")\nprint(f\"  æ— äº¤äº’: {response_no_interact:.1f} ä¸‡å…ƒ\")\nprint(f\"  æœ‰äº¤äº’: {response_with_interact:.1f} ä¸‡å…ƒ\")\nprint(f\"  æå‡: {(response_with_interact - response_no_interact):.1f} ä¸‡å…ƒ\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 å®é™…æ“ä½œæµç¨‹\n",
    "\n",
    "### é¢„ç®—ä¼˜åŒ–çš„å®Œæ•´æµç¨‹\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[æ•°æ®æ”¶é›†] --> B[å“åº”æ›²çº¿å»ºæ¨¡]\n",
    "    B --> C[å®šä¹‰çº¦æŸæ¡ä»¶]\n",
    "    C --> D[ä¼˜åŒ–æ±‚è§£]\n",
    "    D --> E[æ•æ„Ÿæ€§åˆ†æ]\n",
    "    E --> F[ä¸šåŠ¡è¯„å®¡]\n",
    "    F --> G{é€šè¿‡?}\n",
    "    G -->|æ˜¯| H[æ‰§è¡Œåˆ†é…]\n",
    "    G -->|å¦| C\n",
    "    H --> I[æ•ˆæœç›‘æ§]\n",
    "    I --> J[å‚æ•°æ›´æ–°]\n",
    "    J --> B\n",
    "```\n",
    "\n",
    "### å…³é”®æ­¥éª¤è¯¦è§£\n",
    "\n",
    "1. **æ•°æ®æ”¶é›†**ï¼ˆ2-4å‘¨ï¼‰\n",
    "   - å†å²æŠ•æ”¾æ•°æ®\n",
    "   - ä¸åŒé¢„ç®—æ°´å¹³çš„æ•ˆæœ\n",
    "   - A/B æµ‹è¯•æ•°æ®\n",
    "\n",
    "2. **å“åº”æ›²çº¿å»ºæ¨¡**ï¼ˆ1å‘¨ï¼‰\n",
    "   - æ‹Ÿåˆ Hill æ–¹ç¨‹æˆ– Logistic æ›²çº¿\n",
    "   - ä¼°è®¡å‚æ•°ï¼ˆa, c, Î±ï¼‰\n",
    "   - æ¨¡å‹éªŒè¯\n",
    "\n",
    "3. **å®šä¹‰çº¦æŸ**ï¼ˆä¸ä¸šåŠ¡è®¨è®ºï¼‰\n",
    "   - æœ€å°é¢„ç®—ï¼ˆä¿æŒæ´»è·ƒï¼‰\n",
    "   - æœ€å¤§é¢„ç®—ï¼ˆä¾›ç»™é™åˆ¶ï¼‰\n",
    "   - é£é™©æ§åˆ¶ï¼ˆå æ¯”ä¸Šé™ï¼‰\n",
    "\n",
    "4. **ä¼˜åŒ–æ±‚è§£**ï¼ˆæ•°å°æ—¶ï¼‰\n",
    "   - ä½¿ç”¨ SLSQP / IPOPT æ±‚è§£å™¨\n",
    "   - æ£€æŸ¥æ”¶æ•›æ€§\n",
    "\n",
    "5. **æ•æ„Ÿæ€§åˆ†æ**ï¼ˆ1-2å¤©ï¼‰\n",
    "   - å‚æ•°æ‰°åŠ¨\n",
    "   - What-if åˆ†æ\n",
    "\n",
    "6. **ä¸šåŠ¡è¯„å®¡**ï¼ˆä¼šè®®ï¼‰\n",
    "   - å‘ç®¡ç†å±‚æ±‡æŠ¥\n",
    "   - è°ƒæ•´çº¦æŸ\n",
    "\n",
    "7. **æ•ˆæœç›‘æ§**ï¼ˆæŒç»­ï¼‰\n",
    "   - å®é™… vs é¢„æµ‹\n",
    "   - æ¨¡å‹æ ¡å‡†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®æˆ˜å·¥å…·ï¼šé¢„ç®—ä¼˜åŒ–å™¨ç±»\n",
    "\n",
    "class BudgetOptimizer:\n",
    "    \"\"\"\n",
    "    é¢„ç®—ä¼˜åŒ–å™¨\n",
    "    \n",
    "    å°è£…å®Œæ•´çš„ä¼˜åŒ–æµç¨‹\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channels_params):\n",
    "        self.channels = channels_params\n",
    "        self.channel_names = list(channels_params.keys())\n",
    "        self.n_channels = len(channels_params)\n",
    "        self.history = []\n",
    "    \n",
    "    def fit_response_curve(self, data):\n",
    "        \"\"\"ä»å†å²æ•°æ®æ‹Ÿåˆå“åº”æ›²çº¿\"\"\"\n",
    "        # ç®€åŒ–ç‰ˆï¼šè¿™é‡Œå‡è®¾å‚æ•°å·²ç»™å®š\n",
    "        # å®é™…åº”è¯¥ç”¨éçº¿æ€§å›å½’æ‹Ÿåˆ\n",
    "        pass\n",
    "    \n",
    "    def optimize(self, total_budget, constraints=None, interaction_matrix=None):\n",
    "        \"\"\"æ‰§è¡Œä¼˜åŒ–\"\"\"\n",
    "        n = self.n_channels\n",
    "        \n",
    "        def objective(x):\n",
    "            total = 0\n",
    "            for i, name in enumerate(self.channel_names):\n",
    "                total += response_curve(x[i], **self.channels[name])\n",
    "            \n",
    "            # äº¤äº’é¡¹\n",
    "            if interaction_matrix is not None:\n",
    "                for i in range(n):\n",
    "                    for j in range(i+1, n):\n",
    "                        gamma = interaction_matrix[i, j]\n",
    "                        if gamma != 0:\n",
    "                            total += gamma * np.sqrt(x[i] * x[j] + 1e-10)\n",
    "            \n",
    "            return -total\n",
    "        \n",
    "        # çº¦æŸ\n",
    "        cons = [LinearConstraint(np.ones(n), total_budget, total_budget)]\n",
    "        \n",
    "        # è¾¹ç•Œ\n",
    "        bounds = [(0, total_budget) for _ in range(n)]\n",
    "        if constraints and 'min_budget' in constraints:\n",
    "            for i, name in enumerate(self.channel_names):\n",
    "                if name in constraints['min_budget']:\n",
    "                    bounds[i] = (constraints['min_budget'][name], bounds[i][1])\n",
    "        \n",
    "        x0 = np.ones(n) * total_budget / n\n",
    "        result = minimize(objective, x0, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "        \n",
    "        allocation = dict(zip(self.channel_names, result.x))\n",
    "        total_response = -result.fun\n",
    "        \n",
    "        # è®°å½•å†å²\n",
    "        self.history.append({\n",
    "            'budget': total_budget,\n",
    "            'allocation': allocation,\n",
    "            'response': total_response\n",
    "        })\n",
    "        \n",
    "        return allocation, total_response\n",
    "    \n",
    "    def sensitivity_analysis(self, base_budget, budget_range):\n",
    "        \"\"\"æ•æ„Ÿæ€§åˆ†æï¼šä¸åŒé¢„ç®—ä¸‹çš„æœ€ä¼˜åˆ†é…\"\"\"\n",
    "        results = []\n",
    "        for B in budget_range:\n",
    "            alloc, resp = self.optimize(B)\n",
    "            results.append({'budget': B, 'response': resp, 'allocation': alloc})\n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def what_if(self, scenario_name, **kwargs):\n",
    "        \"\"\"What-if åˆ†æ\"\"\"\n",
    "        print(f\"\\nğŸ“Š Scenario: {scenario_name}\")\n",
    "        allocation, response = self.optimize(**kwargs)\n",
    "        \n",
    "        for ch, budget in allocation.items():\n",
    "            print(f\"  {ch}: {budget:.1f} ä¸‡å…ƒ\")\n",
    "        print(f\"  æ€»æ”¶ç›Š: {response:.1f} ä¸‡å…ƒ\")\n",
    "        \n",
    "        return allocation, response\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "optimizer = BudgetOptimizer(channels)\n",
    "\n",
    "# Scenario 1: åŸºå‡†æƒ…å†µ\n",
    "optimizer.what_if(\n",
    "    \"åŸºå‡†æƒ…å†µ\",\n",
    "    total_budget=1000\n",
    ")\n",
    "\n",
    "# Scenario 2: é¢„ç®—å‰Šå‡ 20%\n",
    "optimizer.what_if(\n",
    "    \"é¢„ç®—å‰Šå‡ 20%\",\n",
    "    total_budget=800\n",
    ")\n",
    "\n",
    "# Scenario 3: é¢„ç®—å¢åŠ ï¼Œä½†æœç´¢å¹¿å‘Šå—é™\n",
    "optimizer.what_if(\n",
    "    \"é¢„ç®—å¢åŠ ï¼Œæœç´¢å—é™\",\n",
    "    total_budget=1200,\n",
    "    constraints={'min_budget': {'æœç´¢å¹¿å‘Š': 50}, 'max_budget': {'æœç´¢å¹¿å‘Š': 300}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: ä¸ç¡®å®šæ€§ä¸ç¨³å¥ä¼˜åŒ–\n",
    "\n",
    "## 5.1 å‚æ•°ä¼°è®¡çš„ä¸ç¡®å®šæ€§\n",
    "\n",
    "å“åº”æ›²çº¿çš„å‚æ•°ï¼ˆa, c, Î±ï¼‰æ˜¯ä»å†å²æ•°æ®**ä¼°è®¡**çš„ï¼Œå­˜åœ¨ä¸ç¡®å®šæ€§ï¼š\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = (\\hat{a}, \\hat{c}, \\hat{\\alpha}) \\sim \\mathcal{N}(\\theta^*, \\Sigma)\n",
    "$$\n",
    "\n",
    "### ä¸ç¡®å®šæ€§çš„æ¥æº\n",
    "\n",
    "1. **æ•°æ®å™ªå£°**ï¼šè§‚æµ‹è¯¯å·®\n",
    "2. **æ ·æœ¬é‡æœ‰é™**ï¼šä¼°è®¡æ–¹å·®\n",
    "3. **æ¨¡å‹è¯¯è®¾**ï¼šå“åº”æ›²çº¿å¯èƒ½ä¸å‡†ç¡®\n",
    "4. **å¤–éƒ¨å†²å‡»**ï¼šå¸‚åœºå˜åŒ–ã€ç«äº‰å¯¹æ‰‹\n",
    "\n",
    "### ç¨³å¥ä¼˜åŒ–çš„ç›®æ ‡\n",
    "\n",
    "æ‰¾åˆ°åœ¨å‚æ•°ä¸ç¡®å®šæ€§ä¸‹**ä»ç„¶è¡¨ç°è‰¯å¥½**çš„åˆ†é…æ–¹æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 ç¨³å¥ä¼˜åŒ–æ–¹æ³•\n",
    "\n",
    "### æ–¹æ³• 1: æœŸæœ›æœ€å¤§åŒ–\n",
    "\n",
    "$$\n",
    "\\max_{x} \\quad \\mathbb{E}_{\\theta} \\left[ \\sum_i R_i(x_i; \\theta) \\right]\n",
    "$$\n",
    "\n",
    "å¹³å‡æ¥çœ‹æœ€ä¼˜ï¼ˆé£é™©ä¸­æ€§ï¼‰\n",
    "\n",
    "### æ–¹æ³• 2: æœ€åæƒ…å†µä¼˜åŒ–ï¼ˆWorst-Caseï¼‰\n",
    "\n",
    "$$\n",
    "\\max_{x} \\min_{\\theta \\in \\Theta} \\quad \\sum_i R_i(x_i; \\theta)\n",
    "$$\n",
    "\n",
    "ä¿å®ˆç­–ç•¥ï¼Œä¿è¯æœ€åæƒ…å†µä¸å¤ªå·®ï¼ˆé£é™©åŒæ¶ï¼‰\n",
    "\n",
    "### æ–¹æ³• 3: CVaR ä¼˜åŒ–ï¼ˆConditional Value at Riskï¼‰\n",
    "\n",
    "$$\n",
    "\\max_{x} \\quad \\text{CVaR}_{\\alpha}\\left[ \\sum_i R_i(x_i; \\theta) \\right]\n",
    "$$\n",
    "\n",
    "ä¼˜åŒ–æœ€å·®çš„ Î±% æƒ…å†µä¸‹çš„å¹³å‡æ”¶ç›Šï¼ˆå¹³è¡¡æœŸæœ›å’Œé£é™©ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¨³å¥ä¼˜åŒ–ç¤ºä¾‹ï¼šè’™ç‰¹å¡æ´›æ–¹æ³•\n",
    "\n",
    "def robust_optimization_mc(channels_params, total_budget, param_uncertainty, n_scenarios=1000):\n",
    "    \"\"\"\n",
    "    è’™ç‰¹å¡æ´›ç¨³å¥ä¼˜åŒ–\n",
    "    \n",
    "    å‚æ•°:\n",
    "        channels_params: dict, æ¸ é“å‚æ•°çš„å‡å€¼\n",
    "        total_budget: float, æ€»é¢„ç®—\n",
    "        param_uncertainty: dict, å‚æ•°çš„æ ‡å‡†å·®\n",
    "            {'channel': {'a_std': ..., 'c_std': ..., 'alpha_std': ...}}\n",
    "        n_scenarios: int, åœºæ™¯æ•°é‡\n",
    "    \"\"\"\n",
    "    n_channels = len(channels_params)\n",
    "    channel_names = list(channels_params.keys())\n",
    "    \n",
    "    # ç”Ÿæˆå‚æ•°åœºæ™¯\n",
    "    scenarios = []\n",
    "    for _ in range(n_scenarios):\n",
    "        scenario = {}\n",
    "        for name in channel_names:\n",
    "            base = channels_params[name]\n",
    "            unc = param_uncertainty.get(name, {'a_std': 0, 'c_std': 0, 'alpha_std': 0})\n",
    "            \n",
    "            # é‡‡æ ·å‚æ•°ï¼ˆç¡®ä¿ > 0ï¼‰\n",
    "            scenario[name] = {\n",
    "                'a': max(0.1, np.random.normal(base['a'], unc.get('a_std', 0))),\n",
    "                'c': max(1, np.random.normal(base['c'], unc.get('c_std', 0))),\n",
    "                'alpha': max(0.1, np.random.normal(base['alpha'], unc.get('alpha_std', 0)))\n",
    "            }\n",
    "        scenarios.append(scenario)\n",
    "    \n",
    "    # ä¼˜åŒ–ï¼šæœŸæœ›æœ€å¤§åŒ–\n",
    "    def objective_expected(x):\n",
    "        expected_response = 0\n",
    "        for scenario in scenarios:\n",
    "            scenario_response = 0\n",
    "            for i, name in enumerate(channel_names):\n",
    "                scenario_response += response_curve(x[i], **scenario[name])\n",
    "            expected_response += scenario_response\n",
    "        expected_response /= n_scenarios\n",
    "        return -expected_response\n",
    "    \n",
    "    # æ±‚è§£\n",
    "    constraints = [LinearConstraint(np.ones(n_channels), total_budget, total_budget)]\n",
    "    bounds = [(0, total_budget) for _ in range(n_channels)]\n",
    "    x0 = np.ones(n_channels) * total_budget / n_channels\n",
    "    \n",
    "    result = minimize(\n",
    "        objective_expected,\n",
    "        x0,\n",
    "        method='SLSQP',\n",
    "        bounds=bounds,\n",
    "        constraints=constraints\n",
    "    )\n",
    "    \n",
    "    allocation = dict(zip(channel_names, result.x))\n",
    "    \n",
    "    # è¯„ä¼°è¯¥åˆ†é…åœ¨æ‰€æœ‰åœºæ™¯ä¸‹çš„è¡¨ç°\n",
    "    performances = []\n",
    "    for scenario in scenarios:\n",
    "        perf = sum(response_curve(allocation[name], **scenario[name]) for name in channel_names)\n",
    "        performances.append(perf)\n",
    "    \n",
    "    performances = np.array(performances)\n",
    "    \n",
    "    stats = {\n",
    "        'mean': np.mean(performances),\n",
    "        'std': np.std(performances),\n",
    "        'min': np.min(performances),\n",
    "        'percentile_5': np.percentile(performances, 5),\n",
    "        'percentile_95': np.percentile(performances, 95),\n",
    "        'max': np.max(performances)\n",
    "    }\n",
    "    \n",
    "    return allocation, stats, performances\n",
    "\n",
    "# å®šä¹‰å‚æ•°ä¸ç¡®å®šæ€§ï¼ˆæ ‡å‡†å·®ï¼‰\n",
    "param_uncertainty = {\n",
    "    'æœç´¢å¹¿å‘Š': {'a_std': 50, 'c_std': 20, 'alpha_std': 0.1},\n",
    "    'ä¿¡æ¯æµ': {'a_std': 80, 'c_std': 40, 'alpha_std': 0.15},\n",
    "    'çŸ­è§†é¢‘': {'a_std': 60, 'c_std': 30, 'alpha_std': 0.12}\n",
    "}\n",
    "\n",
    "# ç¨³å¥ä¼˜åŒ–\n",
    "allocation_robust, stats_robust, performances = robust_optimization_mc(\n",
    "    channels, total_budget, param_uncertainty, n_scenarios=500\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ¯ ç¨³å¥ä¼˜åŒ–åˆ†é…ï¼š\")\n",
    "for ch, budget in allocation_robust.items():\n",
    "    print(f\"  {ch}: {budget:.1f} ä¸‡å…ƒ\")\n",
    "\n",
    "print(f\"\\nğŸ“Š æ€§èƒ½åˆ†å¸ƒï¼ˆ500 ä¸ªåœºæ™¯ï¼‰ï¼š\")\n",
    "print(f\"  æœŸæœ›æ”¶ç›Š: {stats_robust['mean']:.1f} ä¸‡å…ƒ\")\n",
    "print(f\"  æ ‡å‡†å·®: {stats_robust['std']:.1f} ä¸‡å…ƒ\")\n",
    "print(f\"  æœ€å·®æƒ…å†µ: {stats_robust['min']:.1f} ä¸‡å…ƒ\")\n",
    "print(f\"  5% åˆ†ä½æ•°: {stats_robust['percentile_5']:.1f} ä¸‡å…ƒ\")\n",
    "print(f\"  95% åˆ†ä½æ•°: {stats_robust['percentile_95']:.1f} ä¸‡å…ƒ\")\n",
    "print(f\"  æœ€å¥½æƒ…å†µ: {stats_robust['max']:.1f} ä¸‡å…ƒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ï¼šæ€§èƒ½åˆ†å¸ƒ\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# ç›´æ–¹å›¾\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=performances,\n",
    "    nbinsx=30,\n",
    "    name='æ”¶ç›Šåˆ†å¸ƒ',\n",
    "    marker=dict(color=COLORS['primary'], opacity=0.7)\n",
    "))\n",
    "\n",
    "# æ ‡æ³¨å…³é”®ç‚¹\n",
    "fig.add_vline(\n",
    "    x=stats_robust['mean'],\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"green\",\n",
    "    annotation_text=f\"æœŸæœ›: {stats_robust['mean']:.0f}\"\n",
    ")\n",
    "\n",
    "fig.add_vline(\n",
    "    x=stats_robust['percentile_5'],\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"red\",\n",
    "    annotation_text=f\"5%: {stats_robust['percentile_5']:.0f}\"\n",
    ")\n",
    "\n",
    "fig.add_vline(\n",
    "    x=stats_robust['percentile_95'],\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"red\",\n",
    "    annotation_text=f\"95%: {stats_robust['percentile_95']:.0f}\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"ç¨³å¥ä¼˜åŒ–ï¼šæ”¶ç›Šåˆ†å¸ƒï¼ˆ500 ä¸ªå‚æ•°åœºæ™¯ï¼‰\",\n",
    "    xaxis_title=\"æ€»æ”¶ç›Š (ä¸‡å…ƒ)\",\n",
    "    yaxis_title=\"é¢‘æ•°\",\n",
    "    template='plotly_white',\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ è§£è¯»ï¼š\")\n",
    "print(\"1. æ”¶ç›Šåˆ†å¸ƒè¿‘ä¼¼æ­£æ€ï¼ˆå‚æ•°ä¸ç¡®å®šæ€§ä¼ å¯¼ï¼‰\")\n",
    "print(\"2. 90% ç½®ä¿¡åŒºé—´ï¼š[{:.0f}, {:.0f}]\".format(\n",
    "    stats_robust['percentile_5'], stats_robust['percentile_95']\n",
    "))\n",
    "print(\"3. å³ä½¿åœ¨æœ€å·®çš„ 5% æƒ…å†µä¸‹ï¼Œä»èƒ½è·å¾— {:.0f} ä¸‡æ”¶ç›Š\".format(\n",
    "    stats_robust['percentile_5']\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 æ•æ„Ÿæ€§åˆ†æ\n",
    "\n",
    "### Tornado å›¾ï¼ˆé¾™å·é£å›¾ï¼‰\n",
    "\n",
    "å±•ç¤ºå„å‚æ•°å˜åŒ–å¯¹æœ€ä¼˜åˆ†é…çš„å½±å“ï¼š\n",
    "- æ¨ªè½´ï¼šå‚æ•°å˜åŒ–èŒƒå›´ï¼ˆå¦‚ Â±20%ï¼‰\n",
    "- çºµè½´ï¼šå¯¹æŸæ¸ é“é¢„ç®—çš„å½±å“\n",
    "- æ¡å½¢é•¿åº¦ï¼šæ•æ„Ÿæ€§å¤§å°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tornado å›¾ï¼šå‚æ•°æ•æ„Ÿæ€§åˆ†æ\n",
    "\n",
    "def sensitivity_tornado(channels_params, total_budget, param_name, param_range):\n",
    "    \"\"\"\n",
    "    å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ\n",
    "    \n",
    "    å‚æ•°:\n",
    "        param_name: str, å¦‚ 'æœç´¢å¹¿å‘Š.a'\n",
    "        param_range: tuple, å¦‚ (0.8, 1.2) è¡¨ç¤º Â±20%\n",
    "    \"\"\"\n",
    "    channel_name, param = param_name.split('.')\n",
    "    base_value = channels_params[channel_name][param]\n",
    "    \n",
    "    results = []\n",
    "    for factor in np.linspace(param_range[0], param_range[1], 20):\n",
    "        # ä¿®æ”¹å‚æ•°\n",
    "        modified_params = {k: v.copy() for k, v in channels_params.items()}\n",
    "        modified_params[channel_name][param] = base_value * factor\n",
    "        \n",
    "        # é‡æ–°ä¼˜åŒ–\n",
    "        alloc, _ = optimize_budget_marginal_equal(modified_params, total_budget)\n",
    "        \n",
    "        results.append({\n",
    "            'factor': factor,\n",
    "            'param_value': base_value * factor,\n",
    "            **{f'{ch}_budget': alloc[ch] for ch in channels_params.keys()}\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# åˆ†æå¤šä¸ªå‚æ•°\n",
    "params_to_test = [\n",
    "    ('æœç´¢å¹¿å‘Š.a', (0.8, 1.2)),\n",
    "    ('ä¿¡æ¯æµ.c', (0.8, 1.2)),\n",
    "    ('çŸ­è§†é¢‘.alpha', (0.8, 1.2))\n",
    "]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for param_name, param_range in params_to_test:\n",
    "    df_sens = sensitivity_tornado(channels, total_budget, param_name, param_range)\n",
    "    \n",
    "    # ç»˜åˆ¶æ¯ä¸ªæ¸ é“çš„é¢„ç®—å˜åŒ–\n",
    "    for ch in channels.keys():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_sens['factor'],\n",
    "            y=df_sens[f'{ch}_budget'],\n",
    "            mode='lines',\n",
    "            name=f\"{param_name} â†’ {ch}\",\n",
    "            line=dict(width=2)\n",
    "        ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼šå‚æ•°å˜åŒ– â†’ é¢„ç®—åˆ†é…å˜åŒ–\",\n",
    "    xaxis_title=\"å‚æ•°å˜åŒ–å€æ•°ï¼ˆ1.0 = åŸºå‡†ï¼‰\",\n",
    "    yaxis_title=\"æ¸ é“é¢„ç®— (ä¸‡å…ƒ)\",\n",
    "    template='plotly_white',\n",
    "    height=500,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ è§‚å¯Ÿè¦ç‚¹ï¼š\")\n",
    "print(\"1. æ–œç‡é™¡çš„æ›²çº¿ï¼šå¯¹è¯¥å‚æ•°æ•æ„Ÿ\")\n",
    "print(\"2. æ–œç‡å¹³çš„æ›²çº¿ï¼šå¯¹è¯¥å‚æ•°ä¸æ•æ„Ÿï¼ˆç¨³å¥ï¼‰\")\n",
    "print(\"3. äº¤å‰çš„æ›²çº¿ï¼šå‚æ•°å˜åŒ–å¯¼è‡´æ¸ é“é—´é¢„ç®—é‡æ–°åˆ†é…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: ä¸šåŠ¡æ¡ˆä¾‹\n",
    "\n",
    "## æ¡ˆä¾‹ 1: ç”µå•†åŒåä¸€å¹¿å‘Šé¢„ç®—åˆ†é…\n",
    "\n",
    "### èƒŒæ™¯\n",
    "\n",
    "æŸç”µå•†å¹³å°åŒåä¸€å¤§ä¿ƒï¼Œå‡†å¤‡ 5000 ä¸‡å¹¿å‘Šé¢„ç®—ï¼ŒæŠ•æ”¾ 6 ä¸ªæ¸ é“ï¼š\n",
    "\n",
    "| æ¸ é“ | å†å² ROI | ç‰¹ç‚¹ |\n",
    "|------|----------|------|\n",
    "| æœç´¢å¹¿å‘Š | 3.5 | ç²¾å‡†ä½†è´µ |\n",
    "| ä¿¡æ¯æµ | 2.8 | é‡å¤§ä»·ä¼˜ |\n",
    "| çŸ­è§†é¢‘ | 2.2 | å¹´è½»ç”¨æˆ· |\n",
    "| KOL åˆä½œ | 3.0 | ä¸ç¡®å®šæ€§é«˜ |\n",
    "| ç›´æ’­å¸¦è´§ | 4.2 | çˆ†å‘åŠ›å¼º |\n",
    "| æˆ·å¤–å¹¿å‘Š | 1.5 | å“ç‰Œæ›å…‰ |\n",
    "\n",
    "### çº¦æŸæ¡ä»¶\n",
    "\n",
    "1. æ¯ä¸ªæ¸ é“è‡³å°‘æŠ• 200 ä¸‡ï¼ˆä¿æŒæ´»è·ƒï¼‰\n",
    "2. ç›´æ’­å¸¦è´§æœ€å¤šæŠ• 1500 ä¸‡ï¼ˆä¸»æ’­æ¡£æœŸæœ‰é™ï¼‰\n",
    "3. çº¿ä¸Šæ¸ é“ï¼ˆå‰5ä¸ªï¼‰è‡³å°‘å  80%ï¼ˆæ•ˆæœå¯è¿½è¸ªï¼‰\n",
    "4. KOL å’Œç›´æ’­æœ‰ååŒæ•ˆåº”ï¼ˆç³»æ•° 0.5ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¡ˆä¾‹ 1: ç”µå•†åŒåä¸€\n",
    "\n",
    "# å®šä¹‰ 6 ä¸ªæ¸ é“ï¼ˆæ ¹æ®å†å²æ•°æ®æ‹Ÿåˆçš„å“åº”æ›²çº¿ï¼‰\n",
    "channels_1111 = {\n",
    "    'æœç´¢å¹¿å‘Š': {'a': 1500, 'c': 400, 'alpha': 0.9},\n",
    "    'ä¿¡æ¯æµ': {'a': 2500, 'c': 800, 'alpha': 1.1},\n",
    "    'çŸ­è§†é¢‘': {'a': 2000, 'c': 700, 'alpha': 1.0},\n",
    "    'KOLåˆä½œ': {'a': 1800, 'c': 500, 'alpha': 0.8},\n",
    "    'ç›´æ’­å¸¦è´§': {'a': 2200, 'c': 600, 'alpha': 1.2},\n",
    "    'æˆ·å¤–å¹¿å‘Š': {'a': 1000, 'c': 900, 'alpha': 0.7}\n",
    "}\n",
    "\n",
    "total_budget_1111 = 5000\n",
    "\n",
    "# äº¤äº’çŸ©é˜µï¼ˆKOL å’Œç›´æ’­ååŒï¼‰\n",
    "interaction_1111 = np.zeros((6, 6))\n",
    "interaction_1111[3, 4] = 0.5  # KOL (3) å’Œç›´æ’­ (4) ååŒ\n",
    "interaction_1111[4, 3] = 0.5\n",
    "\n",
    "# å®šä¹‰çº¦æŸ\n",
    "def optimize_case1():\n",
    "    n = 6\n",
    "    channel_names = list(channels_1111.keys())\n",
    "    \n",
    "    def objective(x):\n",
    "        total = 0\n",
    "        for i, name in enumerate(channel_names):\n",
    "            total += response_curve(x[i], **channels_1111[name])\n",
    "        \n",
    "        # ååŒæ•ˆåº”\n",
    "        total += 0.5 * np.sqrt(x[3] * x[4] + 1e-10)  # KOL * ç›´æ’­\n",
    "        \n",
    "        return -total\n",
    "    \n",
    "    # çº¦æŸ\n",
    "    constraints = [\n",
    "        # é¢„ç®—æ€»å’Œ\n",
    "        LinearConstraint(np.ones(n), total_budget_1111, total_budget_1111),\n",
    "        # çº¿ä¸Šæ¸ é“è‡³å°‘ 80%\n",
    "        LinearConstraint(\n",
    "            [1, 1, 1, 1, 1, 0],  # å‰ 5 ä¸ªæ˜¯çº¿ä¸Š\n",
    "            total_budget_1111 * 0.8,\n",
    "            total_budget_1111\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # è¾¹ç•Œ\n",
    "    bounds = [\n",
    "        (200, total_budget_1111),  # æœç´¢\n",
    "        (200, total_budget_1111),  # ä¿¡æ¯æµ\n",
    "        (200, total_budget_1111),  # çŸ­è§†é¢‘\n",
    "        (200, total_budget_1111),  # KOL\n",
    "        (200, 1500),               # ç›´æ’­ï¼ˆä¸Šé™ 1500ï¼‰\n",
    "        (200, total_budget_1111)   # æˆ·å¤–\n",
    "    ]\n",
    "    \n",
    "    x0 = np.ones(n) * total_budget_1111 / n\n",
    "    result = minimize(objective, x0, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    allocation = dict(zip(channel_names, result.x))\n",
    "    total_response = -result.fun\n",
    "    \n",
    "    return allocation, total_response\n",
    "\n",
    "allocation_1111, response_1111 = optimize_case1()\n",
    "\n",
    "print(\"\\nğŸ¯ åŒåä¸€æœ€ä¼˜é¢„ç®—åˆ†é…ï¼ˆ5000 ä¸‡æ€»é¢„ç®—ï¼‰ï¼š\\n\")\n",
    "print(f\"{'æ¸ é“':<10} {'é¢„ç®—(ä¸‡)':<12} {'å æ¯”':<10} {'é¢„æœŸæ”¶ç›Š(ä¸‡)'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for ch, budget in allocation_1111.items():\n",
    "    revenue = response_curve(budget, **channels_1111[ch])\n",
    "    print(f\"{ch:<10} {budget:>8.0f}      {budget/total_budget_1111*100:>5.1f}%     {revenue:>8.0f}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'æ€»è®¡':<10} {sum(allocation_1111.values()):>8.0f}      100.0%     {response_1111:>8.0f}\")\n",
    "\n",
    "# è®¡ç®—æ•´ä½“ ROI\n",
    "overall_roi = response_1111 / total_budget_1111\n",
    "print(f\"\\nğŸ“Š æ•´ä½“ ROI: {overall_roi:.2f}\")\n",
    "\n",
    "# æ£€æŸ¥çº¦æŸ\n",
    "online_budget = sum(allocation_1111[ch] for ch in list(channels_1111.keys())[:5])\n",
    "print(f\"\\nâœ“ çº¿ä¸Šæ¸ é“å æ¯”: {online_budget/total_budget_1111*100:.1f}% (è¦æ±‚ â‰¥80%)\")\n",
    "print(f\"âœ“ ç›´æ’­é¢„ç®—: {allocation_1111['ç›´æ’­å¸¦è´§']:.0f} ä¸‡ (ä¸Šé™ 1500 ä¸‡)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ï¼šé¢„ç®—åˆ†é…é¥¼å›¾ + æ”¶ç›Šå¯¹æ¯”\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    specs=[[{'type': 'pie'}, {'type': 'bar'}]],\n",
    "    subplot_titles=['é¢„ç®—åˆ†é…', 'å„æ¸ é“æ”¶ç›Šè´¡çŒ®']\n",
    ")\n",
    "\n",
    "# é¥¼å›¾\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=list(allocation_1111.keys()),\n",
    "        values=list(allocation_1111.values()),\n",
    "        textinfo='label+percent',\n",
    "        textposition='inside',\n",
    "        hovertemplate='%{label}<br>%{value:.0f} ä¸‡å…ƒ<br>%{percent}'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# æŸ±çŠ¶å›¾\n",
    "revenues = [response_curve(allocation_1111[ch], **channels_1111[ch]) for ch in channels_1111.keys()]\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=list(channels_1111.keys()),\n",
    "        y=revenues,\n",
    "        text=[f'{r:.0f}' for r in revenues],\n",
    "        textposition='auto',\n",
    "        marker=dict(color=COLORS['success'])\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickangle=45, row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"æ”¶ç›Š (ä¸‡å…ƒ)\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"åŒåä¸€é¢„ç®—åˆ†é…æ–¹æ¡ˆ\",\n",
    "    template='plotly_white',\n",
    "    height=400,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¡ˆä¾‹ 2: ä¼˜æƒ åˆ¸ç±»å‹é¢„ç®—åˆ†é…\n",
    "\n",
    "### èƒŒæ™¯\n",
    "\n",
    "æŸ O2O å¹³å°å‘æ”¾ä¼˜æƒ åˆ¸ï¼Œæœ‰ 4 ç§ç±»å‹ï¼š\n",
    "\n",
    "| åˆ¸ç±»å‹ | æˆæœ¬ | æ ¸é”€ç‡ | å®¢å•ä»·æå‡ | ROI |\n",
    "|--------|------|--------|------------|-----|\n",
    "| æ»¡å‡åˆ¸ | 5å…ƒ | 60% | +15å…ƒ | 1.8 |\n",
    "| æŠ˜æ‰£åˆ¸ | 8å…ƒ | 70% | +20å…ƒ | 1.75 |\n",
    "| æ–°äººåˆ¸ | 15å…ƒ | 80% | +50å…ƒ | 2.67 |\n",
    "| ä¼šå‘˜åˆ¸ | 3å…ƒ | 50% | +10å…ƒ | 1.67 |\n",
    "\n",
    "æ€»é¢„ç®— 2000 ä¸‡ï¼Œå¦‚ä½•åˆ†é…ï¼Ÿ\n",
    "\n",
    "### ç‰¹æ®Šè€ƒè™‘\n",
    "\n",
    "- æ–°äººåˆ¸æœ‰å¢é•¿æˆ˜ç•¥ä»·å€¼ï¼ˆLTV æ›´é«˜ï¼‰\n",
    "- ä¼šå‘˜åˆ¸ç»´æŠ¤è€å®¢æˆ·ï¼ˆç•™å­˜é‡è¦ï¼‰\n",
    "- æ»¡å‡å’ŒæŠ˜æ‰£æœ‰éƒ¨åˆ†ç”¨æˆ·é‡å ï¼ˆæ›¿ä»£æ•ˆåº”ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¡ˆä¾‹ 2: ä¼˜æƒ åˆ¸åˆ†é…\n",
    "\n",
    "# å“åº”æ›²çº¿ï¼ˆåŸºäºå†å²æ ¸é”€æ•°æ®æ‹Ÿåˆï¼‰\n",
    "coupon_types = {\n",
    "    'æ»¡å‡åˆ¸': {'a': 800, 'c': 350, 'alpha': 1.0},\n",
    "    'æŠ˜æ‰£åˆ¸': {'a': 750, 'c': 300, 'alpha': 0.95},\n",
    "    'æ–°äººåˆ¸': {'a': 1200, 'c': 400, 'alpha': 1.1},\n",
    "    'ä¼šå‘˜åˆ¸': {'a': 600, 'c': 250, 'alpha': 0.85}\n",
    "}\n",
    "\n",
    "total_budget_coupon = 2000\n",
    "\n",
    "# äº¤äº’æ•ˆåº”ï¼ˆæ»¡å‡å’ŒæŠ˜æ‰£æœ‰æ›¿ä»£ï¼‰\n",
    "interaction_coupon = np.array([\n",
    "    [0,    -0.15,  0,     0.1],   # æ»¡å‡ï¼šä¸æŠ˜æ‰£æ›¿ä»£ï¼Œä¸ä¼šå‘˜ååŒ\n",
    "    [-0.15, 0,     0,     0],     # æŠ˜æ‰£\n",
    "    [0,     0,     0,     0.2],   # æ–°äººï¼šä¸ä¼šå‘˜ååŒï¼ˆæ–°è€ç»“åˆï¼‰\n",
    "    [0.1,   0,     0.2,   0]      # ä¼šå‘˜\n",
    "])\n",
    "\n",
    "# ä¼˜åŒ–ï¼ˆè€ƒè™‘å¤šç›®æ ‡ï¼šçŸ­æœŸ ROI + é•¿æœŸä»·å€¼ï¼‰\n",
    "def optimize_coupon_with_ltv(ltv_weights):\n",
    "    \"\"\"\n",
    "    ltv_weights: dict, æ¯ç§åˆ¸çš„é•¿æœŸä»·å€¼æƒé‡\n",
    "    \"\"\"\n",
    "    n = 4\n",
    "    coupon_names = list(coupon_types.keys())\n",
    "    \n",
    "    def objective(x):\n",
    "        # çŸ­æœŸæ”¶ç›Š\n",
    "        short_term = 0\n",
    "        for i, name in enumerate(coupon_names):\n",
    "            short_term += response_curve(x[i], **coupon_types[name])\n",
    "        \n",
    "        # äº¤äº’æ•ˆåº”\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                gamma = interaction_coupon[i, j]\n",
    "                if gamma != 0:\n",
    "                    short_term += gamma * np.sqrt(x[i] * x[j] + 1e-10)\n",
    "        \n",
    "        # é•¿æœŸä»·å€¼ï¼ˆåŠ æƒï¼‰\n",
    "        long_term = sum(ltv_weights[name] * x[i] for i, name in enumerate(coupon_names))\n",
    "        \n",
    "        # ç»¼åˆç›®æ ‡ï¼ˆ70% çŸ­æœŸ + 30% é•¿æœŸï¼‰\n",
    "        total = 0.7 * short_term + 0.3 * long_term\n",
    "        \n",
    "        return -total\n",
    "    \n",
    "    constraints = [\n",
    "        LinearConstraint(np.ones(n), total_budget_coupon, total_budget_coupon)\n",
    "    ]\n",
    "    bounds = [(100, total_budget_coupon) for _ in range(n)]  # æ¯ç§è‡³å°‘ 100 ä¸‡\n",
    "    x0 = np.ones(n) * total_budget_coupon / n\n",
    "    \n",
    "    result = minimize(objective, x0, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    allocation = dict(zip(coupon_names, result.x))\n",
    "    total_value = -result.fun\n",
    "    \n",
    "    return allocation, total_value\n",
    "\n",
    "# LTV æƒé‡ï¼ˆå½’ä¸€åŒ–åçš„ç›¸å¯¹ä»·å€¼ï¼‰\n",
    "ltv_weights = {\n",
    "    'æ»¡å‡åˆ¸': 0.3,\n",
    "    'æŠ˜æ‰£åˆ¸': 0.25,\n",
    "    'æ–°äººåˆ¸': 0.8,   # æ–°å®¢æˆ· LTV é«˜\n",
    "    'ä¼šå‘˜åˆ¸': 0.5    # è€å®¢æˆ·ç•™å­˜ä»·å€¼\n",
    "}\n",
    "\n",
    "allocation_coupon, value_coupon = optimize_coupon_with_ltv(ltv_weights)\n",
    "\n",
    "print(\"\\nğŸ¯ ä¼˜æƒ åˆ¸é¢„ç®—åˆ†é…ï¼ˆ2000 ä¸‡æ€»é¢„ç®—ï¼‰ï¼š\\n\")\n",
    "print(f\"{'åˆ¸ç±»å‹':<10} {'é¢„ç®—(ä¸‡)':<12} {'å æ¯”':<10} {'é¢„æœŸçŸ­æœŸROI'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "total_short_term_revenue = 0\n",
    "for name, budget in allocation_coupon.items():\n",
    "    revenue = response_curve(budget, **coupon_types[name])\n",
    "    total_short_term_revenue += revenue\n",
    "    roi = revenue / budget\n",
    "    print(f\"{name:<10} {budget:>8.0f}      {budget/total_budget_coupon*100:>5.1f}%     {roi:>6.2f}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "overall_short_roi = total_short_term_revenue / total_budget_coupon\n",
    "print(f\"\\nğŸ“Š æ•´ä½“çŸ­æœŸ ROI: {overall_short_roi:.2f}\")\n",
    "print(f\"ğŸ“Š ç»¼åˆä»·å€¼ï¼ˆå« LTVï¼‰: {value_coupon:.0f}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ è§£è¯»ï¼š\")\n",
    "print(f\"â€¢ æ–°äººåˆ¸å æ¯” {allocation_coupon['æ–°äººåˆ¸']/total_budget_coupon*100:.1f}%ï¼Œæˆ˜ç•¥é‡ç‚¹\")\n",
    "print(f\"â€¢ æ»¡å‡åˆ¸è™½ç„¶çŸ­æœŸROIä¸æ˜¯æœ€é«˜ï¼Œä½†ä¸ä¼šå‘˜åˆ¸ååŒ\")\n",
    "print(f\"â€¢ è€ƒè™‘ LTV åï¼Œæ›´å€¾å‘äºé•¿æœŸä»·å€¼é«˜çš„åˆ¸ç§\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 7: ç»ƒä¹ ä¸æ€è€ƒé¢˜\n",
    "\n",
    "## ç»ƒä¹  1: å®ç° CVaR ä¼˜åŒ–\n",
    "\n",
    "åœ¨å‰é¢çš„ç¨³å¥ä¼˜åŒ–ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æœŸæœ›æœ€å¤§åŒ–ã€‚ç°åœ¨è¯·å®ç° CVaRï¼ˆConditional Value at Riskï¼‰ä¼˜åŒ–ï¼š\n",
    "\n",
    "$$\n",
    "\\max_{x} \\quad \\text{CVaR}_{0.1}[R(x)] = \\mathbb{E}[R(x) \\mid R(x) \\leq F^{-1}(0.1)]\n",
    "$$\n",
    "\n",
    "å³ï¼šä¼˜åŒ–æœ€å·®çš„ 10% æƒ…å†µä¸‹çš„å¹³å‡æ”¶ç›Šã€‚\n",
    "\n",
    "**æç¤º**ï¼š\n",
    "1. ç”Ÿæˆå¤šä¸ªå‚æ•°åœºæ™¯\n",
    "2. å¯¹æ¯ä¸ªåˆ†é…æ–¹æ¡ˆï¼Œè®¡ç®—æ‰€æœ‰åœºæ™¯ä¸‹çš„æ”¶ç›Š\n",
    "3. å–æœ€å·®çš„ 10% åœºæ™¯ï¼Œè®¡ç®—å¹³å‡å€¼ä½œä¸ºç›®æ ‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ç»ƒä¹  1 - CVaR ä¼˜åŒ–\n",
    "\n",
    "def optimize_cvar(channels_params, total_budget, param_uncertainty, alpha=0.1, n_scenarios=500):\n",
    "    \"\"\"\n",
    "    CVaR ä¼˜åŒ–\n",
    "    \n",
    "    å‚æ•°:\n",
    "        alpha: float, é£é™©æ°´å¹³ï¼ˆå¦‚ 0.1 è¡¨ç¤ºæœ€å·®çš„ 10%ï¼‰\n",
    "    \n",
    "    è¿”å›:\n",
    "        allocation: dict, æœ€ä¼˜åˆ†é…\n",
    "        cvar: float, CVaR å€¼\n",
    "    \"\"\"\n",
    "    # TODO: å®ç° CVaR ä¼˜åŒ–\n",
    "    # æ­¥éª¤:\n",
    "    # 1. ç”Ÿæˆå‚æ•°åœºæ™¯\n",
    "    # 2. å®šä¹‰ç›®æ ‡å‡½æ•°ï¼šç»™å®š xï¼Œè®¡ç®— CVaR\n",
    "    # 3. ä¼˜åŒ–\n",
    "    \n",
    "    pass\n",
    "\n",
    "# æµ‹è¯•ä½ çš„å®ç°\n",
    "# allocation_cvar, cvar_value = optimize_cvar(channels, total_budget, param_uncertainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  2: åŠ¨æ€é¢„ç®—åˆ†é…\n",
    "\n",
    "å‡è®¾é¢„ç®—åˆ† 4 ä¸ªå­£åº¦å‘æ”¾ï¼Œæ¯ä¸ªå­£åº¦å¯ä»¥æ ¹æ®å‰æœŸæ•ˆæœè°ƒæ•´åˆ†é…ã€‚è¯·è®¾è®¡ä¸€ä¸ª**åŠ¨æ€ä¼˜åŒ–**ç­–ç•¥ï¼š\n",
    "\n",
    "- Q1: åˆå§‹åˆ†é…ï¼ˆåŸºäºå†å²æ•°æ®ï¼‰\n",
    "- Q2-Q4: æ ¹æ®å®é™…è§‚æµ‹åˆ°çš„å“åº”æ›²çº¿å‚æ•°ï¼Œæ›´æ–°åˆ†é…\n",
    "\n",
    "è¿™æ¶‰åŠ**è´å¶æ–¯æ›´æ–°** + **æ»šåŠ¨ä¼˜åŒ–**ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ç»ƒä¹  2 - åŠ¨æ€é¢„ç®—åˆ†é…\n",
    "\n",
    "def dynamic_budget_allocation(channels_params_prior, total_budget_per_quarter, n_quarters=4):\n",
    "    \"\"\"\n",
    "    åŠ¨æ€é¢„ç®—åˆ†é…ï¼ˆå¤šæœŸä¼˜åŒ–ï¼‰\n",
    "    \n",
    "    å‚æ•°:\n",
    "        channels_params_prior: dict, å…ˆéªŒå‚æ•°åˆ†å¸ƒ\n",
    "        total_budget_per_quarter: float, æ¯å­£åº¦é¢„ç®—\n",
    "        n_quarters: int, å­£åº¦æ•°\n",
    "    \n",
    "    è¿”å›:\n",
    "        history: list, æ¯ä¸ªå­£åº¦çš„åˆ†é…æ–¹æ¡ˆå’Œæ•ˆæœ\n",
    "    \"\"\"\n",
    "    # TODO: å®ç°åŠ¨æ€ä¼˜åŒ–\n",
    "    # ä¼ªä»£ç :\n",
    "    # for q in 1 to n_quarters:\n",
    "    #     1. åŸºäºå½“å‰å‚æ•°ä¼°è®¡ï¼Œä¼˜åŒ–åˆ†é…\n",
    "    #     2. æ‰§è¡Œåˆ†é…ï¼Œè§‚æµ‹å®é™…æ•ˆæœ\n",
    "    #     3. è´å¶æ–¯æ›´æ–°å‚æ•°ä¼°è®¡\n",
    "    #     4. è¿›å…¥ä¸‹ä¸€å­£åº¦\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€è€ƒé¢˜\n",
    "\n",
    "### æ€è€ƒ 1: ä¸ºä»€ä¹ˆä¸èƒ½åªçœ‹å¹³å‡ ROIï¼Ÿ\n",
    "\n",
    "å‡è®¾ï¼š\n",
    "- æ¸ é“ Aï¼šæŠ•å…¥ 100 ä¸‡ï¼Œå›æŠ¥ 300 ä¸‡ï¼ŒROI = 3.0\n",
    "- æ¸ é“ Bï¼šæŠ•å…¥ 10 ä¸‡ï¼Œå›æŠ¥ 50 ä¸‡ï¼ŒROI = 5.0\n",
    "\n",
    "å¦‚æœåªçœ‹ ROIï¼Œåº”è¯¥å…¨æŠ• Bã€‚ä½†ä¸ºä»€ä¹ˆå®é™…ä¸­æˆ‘ä»¬è¿˜è¦æŠ• Aï¼Ÿ\n",
    "\n",
    "**æç¤º**ï¼šè€ƒè™‘è¾¹é™…æ”¶ç›Šé€’å‡ + è§„æ¨¡æ•ˆåº”ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### æ€è€ƒ 2: å¦‚ä½•å¤„ç†æ—¶æ»æ•ˆåº”ï¼Ÿ\n",
    "\n",
    "æŸäº›æ¸ é“çš„æ•ˆæœæœ‰å»¶è¿Ÿï¼š\n",
    "- å“ç‰Œå¹¿å‘Šï¼šæŠ•æ”¾å 3 ä¸ªæœˆæ‰çœ‹åˆ°è½¬åŒ–æå‡\n",
    "- KOL ç§è‰ï¼š1-2 å‘¨åæ‰æœ‰æœç´¢é‡å¢åŠ \n",
    "\n",
    "å¦‚ä½•åœ¨ä¼˜åŒ–æ¨¡å‹ä¸­è€ƒè™‘æ—¶æ»ï¼Ÿ\n",
    "\n",
    "**æç¤º**ï¼šåˆ†å¸ƒå¼æ»åæ¨¡å‹ï¼ˆDistributed Lag Modelï¼‰ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### æ€è€ƒ 3: ç«äº‰å¯¹æ‰‹çš„å½±å“\n",
    "\n",
    "å¦‚æœç«äº‰å¯¹æ‰‹ä¹Ÿåœ¨åŒä¸€æ¸ é“æŠ•æ”¾ï¼Œä½ çš„æ•ˆæœä¼šå—å½±å“ï¼ˆæ‹¥æŒ¤æ•ˆåº”ï¼‰ã€‚å¦‚ä½•å»ºæ¨¡ï¼Ÿ\n",
    "\n",
    "**æç¤º**ï¼šåšå¼ˆè®º + çº³ä»€å‡è¡¡ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### æ€è€ƒ 4: åœ¨çº¿å­¦ä¹ ä¸å®æ—¶è°ƒæ•´\n",
    "\n",
    "èƒ½å¦è®¾è®¡ä¸€ä¸ª**åœ¨çº¿ç®—æ³•**ï¼Œæ¯å¤©æ ¹æ®å®æ—¶æ•ˆæœè°ƒæ•´é¢„ç®—åˆ†é…ï¼ˆç±»ä¼¼ Multi-Armed Banditï¼‰ï¼Ÿ\n",
    "\n",
    "**æç¤º**ï¼šThompson Sampling / UCB ç®—æ³•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# æ€»ç»“\n",
    "\n",
    "## æ ¸å¿ƒè¦ç‚¹å›é¡¾\n",
    "\n",
    "| æ¦‚å¿µ | å…³é”®å…¬å¼ | å®è·µæ„ä¹‰ |\n",
    "|------|----------|----------|\n",
    "| **è¾¹é™…æ”¶ç›Šé€’å‡** | $R''(x) < 0$ | ä¸èƒ½åªæŠ•ä¸€ä¸ªæ¸ é“ |\n",
    "| **è¾¹é™… ROI ç›¸ç­‰** | $R_1'(x_1) = R_2'(x_2) = \\lambda$ | æœ€ä¼˜åˆ†é…æ¡ä»¶ |\n",
    "| **å½±å­ä»·æ ¼** | $\\lambda = \\frac{\\partial R}{\\partial B}$ | é¢„ç®—ä»·å€¼ |\n",
    "| **ç¨³å¥ä¼˜åŒ–** | $\\max \\mathbb{E}[R]$ æˆ– $\\max \\text{CVaR}[R]$ | åº”å¯¹ä¸ç¡®å®šæ€§ |\n",
    "| **äº¤äº’æ•ˆåº”** | $R(x_1, x_2) \\neq R_1(x_1) + R_2(x_2)$ | æ¸ é“ä¸ç‹¬ç«‹ |\n",
    "\n",
    "## å®æˆ˜æ¸…å•\n",
    "\n",
    "- [ ] æ”¶é›†å†å²æŠ•æ”¾æ•°æ®ï¼ˆè‡³å°‘ 3 ä¸ªæœˆï¼‰\n",
    "- [ ] æ‹Ÿåˆå“åº”æ›²çº¿ï¼ˆHill æ–¹ç¨‹ / Logisticï¼‰\n",
    "- [ ] å®šä¹‰ä¸šåŠ¡çº¦æŸï¼ˆä¸å›¢é˜Ÿè®¨è®ºï¼‰\n",
    "- [ ] è¿è¡Œä¼˜åŒ–ï¼ˆæœ¬ Notebook çš„ä»£ç ï¼‰\n",
    "- [ ] æ•æ„Ÿæ€§åˆ†æï¼ˆå‚æ•° Â±20%ï¼‰\n",
    "- [ ] ä¸šåŠ¡è¯„å®¡ï¼ˆå‘è€æ¿æ±‡æŠ¥ï¼‰\n",
    "- [ ] æ‰§è¡Œç›‘æ§ï¼ˆå®é™… vs é¢„æµ‹ï¼‰\n",
    "- [ ] å®šæœŸæ›´æ–°ï¼ˆæ¯å­£åº¦é‡æ–°ä¼˜åŒ–ï¼‰\n",
    "\n",
    "## è¿›é˜¶å­¦ä¹ èµ„æº\n",
    "\n",
    "### è®ºæ–‡\n",
    "1. **Marketing Mix Modeling**: \"Bayesian Methods for Media Mix Modeling\" (Google)\n",
    "2. **Robust Optimization**: \"Robust Optimization for Budget Allocation\" (Operations Research)\n",
    "3. **Multi-Armed Bandit**: \"Thompson Sampling for Budget Allocation\" (NIPS)\n",
    "\n",
    "### å·¥å…·\n",
    "- **Google Lightweight MMM**: å¼€æºè¥é”€ç»„åˆå»ºæ¨¡å·¥å…·\n",
    "- **Facebook Robyn**: è‡ªåŠ¨åŒ– MMM æ¡†æ¶\n",
    "- **PyOMO**: Python ä¼˜åŒ–å»ºæ¨¡è¯­è¨€\n",
    "\n",
    "### ä¹¦ç±\n",
    "- *\"Marketing Engineering\"* by Lilien & Rangaswamy\n",
    "- *\"Convex Optimization\"* by Boyd & Vandenbergheï¼ˆç¬¬4ç« ï¼šä¼˜åŒ–åº”ç”¨ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "**æ­å–œä½ å®Œæˆæœ¬ Notebookï¼**\n",
    "\n",
    "ä½ å·²ç»æŒæ¡äº†é¢„ç®—åˆ†é…ä¼˜åŒ–çš„æ ¸å¿ƒæ–¹æ³•ï¼Œå¯ä»¥åº”ç”¨åˆ°å®é™…ä¸šåŠ¡ä¸­ã€‚è®°ä½ï¼š\n",
    "\n",
    "> *\"ä¼˜åŒ–ä¸æ˜¯ä¸€æ¬¡æ€§çš„ï¼Œè€Œæ˜¯æŒç»­å­¦ä¹ å’Œè°ƒæ•´çš„è¿‡ç¨‹ã€‚\"*\n",
    "\n",
    "ç°åœ¨ï¼Œå»ä¼˜åŒ–ä½ çš„é¢„ç®—å§ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}