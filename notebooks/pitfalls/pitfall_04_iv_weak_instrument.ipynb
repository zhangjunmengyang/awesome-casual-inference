{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitfall 04: å¼±å·¥å…·å˜é‡çš„è¯Šæ–­ä¸å¤„ç†\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "å®Œæˆæœ¬ notebook åï¼Œä½ å°†èƒ½å¤Ÿï¼š\n",
    "\n",
    "1. **ç†è§£** å¼±å·¥å…·å˜é‡é—®é¢˜çš„æœ¬è´¨å’Œåæœ\n",
    "2. **è¯Šæ–­** å·¥å…·å˜é‡æ˜¯å¦ä¸ºå¼±å·¥å…·ï¼ˆF ç»Ÿè®¡é‡è§„åˆ™ï¼‰\n",
    "3. **åº”ç”¨** å¼±å·¥å…·å˜é‡çš„ç¨³å¥æ¨æ–­æ–¹æ³•\n",
    "4. **è¯†åˆ«** å·¥å…·å˜é‡çš„æ’æ–¥æ€§å‡è®¾è¿èƒŒ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“– èƒŒæ™¯æ•…äº‹\n",
    "\n",
    "> **åœºæ™¯ï¼šæ•™è‚²å›æŠ¥ç‡ä¼°è®¡**\n",
    ">\n",
    "> ä½ æƒ³ä¼°è®¡å¤šå—ä¸€å¹´æ•™è‚²å¯¹æ”¶å…¥çš„å½±å“ã€‚ä½†æ•™è‚²æ˜¯å†…ç”Ÿçš„ï¼ˆèƒ½åŠ›é«˜çš„äººæ—¢ä¸Šæ›´å¤šå­¦åˆèµšæ›´å¤šé’±ï¼‰ã€‚\n",
    ">\n",
    "> ä½ æ‰¾åˆ°ä¸€ä¸ªå·¥å…·å˜é‡ï¼šå‡ºç”Ÿå­£åº¦ã€‚ç†è®ºä¸Šï¼Œå‡ºç”Ÿå­£åº¦å½±å“å…¥å­¦å¹´é¾„ï¼Œä»è€Œå½±å“å—æ•™è‚²å¹´é™ï¼Œ\n",
    "> ä½†ä¸ç›´æ¥å½±å“æ”¶å…¥ã€‚\n",
    ">\n",
    "> ä½†åˆ†æç»“æœå¾ˆå¥‡æ€ªï¼š\n",
    "> - ä¼°è®¡å€¼ä¸ç¨³å®šï¼ˆæ¯æ¬¡å·®åˆ«å¾ˆå¤§ï¼‰\n",
    "> - ç½®ä¿¡åŒºé—´å¼‚å¸¸å®½\n",
    "> - æœ‰æ—¶å€™ç”šè‡³æ˜¯è´Ÿæ•°ï¼ˆæ•™è‚²é™ä½æ”¶å…¥ï¼Ÿï¼‰\n",
    ">\n",
    "> **è¿™å°±æ˜¯å¼±å·¥å…·å˜é‡é—®é¢˜ï¼æœ¬ notebook å°†å¸®ä½ è¯Šæ–­å’Œè§£å†³ã€‚**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: IV æ–¹æ³•å›é¡¾\n",
    "\n",
    "### 1.1 ä¸ºä»€ä¹ˆéœ€è¦å·¥å…·å˜é‡ï¼Ÿ\n",
    "\n",
    "å½“å¤„ç†å˜é‡ $D$ ä¸è¯¯å·®é¡¹ $\\epsilon$ ç›¸å…³æ—¶ï¼ŒOLS æœ‰åã€‚\n",
    "\n",
    "$$Y = \\beta D + \\epsilon, \\quad Cov(D, \\epsilon) \\neq 0$$\n",
    "\n",
    "### 1.2 å·¥å…·å˜é‡æ¡ä»¶\n",
    "\n",
    "å·¥å…·å˜é‡ $Z$ éœ€è¦æ»¡è¶³ï¼š\n",
    "\n",
    "1. **ç›¸å…³æ€§ (Relevance)**: $Cov(Z, D) \\neq 0$\n",
    "2. **æ’æ–¥æ€§ (Exclusion)**: $Cov(Z, \\epsilon) = 0$ï¼ˆZ åªé€šè¿‡ D å½±å“ Yï¼‰\n",
    "\n",
    "### 1.3 2SLS ä¼°è®¡\n",
    "\n",
    "**ç¬¬ä¸€é˜¶æ®µ**: $D = \\pi Z + X\\gamma + v$\n",
    "\n",
    "**ç¬¬äºŒé˜¶æ®µ**: $Y = \\beta \\hat{D} + X\\delta + u$\n",
    "\n",
    "### 1.4 å¼±å·¥å…·å˜é‡é—®é¢˜\n",
    "\n",
    "å½“ $Cov(Z, D)$ å¾ˆå°ï¼ˆæ¥è¿‘ 0ï¼‰æ—¶ï¼š\n",
    "- ç¬¬ä¸€é˜¶æ®µ $\\hat{D}$ ä¸ç²¾ç¡®\n",
    "- ç¬¬äºŒé˜¶æ®µä¼°è®¡æ–¹å·®çˆ†ç‚¸\n",
    "- å³ä½¿æ ·æœ¬é‡å¾ˆå¤§ï¼Œä¼°è®¡ä»æœ‰å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯å¢ƒå‡†å¤‡\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from linearmodels.iv import IV2SLS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['font.family'] = ['Arial Unicode MS', 'SimHei', 'sans-serif']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_iv_data(n=1000, beta_true=0.5, iv_strength='strong', seed=42):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆ IV æ¨¡æ‹Ÿæ•°æ®\n",
    "    \n",
    "    Args:\n",
    "        n: æ ·æœ¬é‡\n",
    "        beta_true: çœŸå®å¤„ç†æ•ˆåº”\n",
    "        iv_strength: å·¥å…·å˜é‡å¼ºåº¦ ('strong', 'moderate', 'weak', 'very_weak')\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # å·¥å…·å˜é‡å¼ºåº¦å‚æ•°\n",
    "    strength_params = {\n",
    "        'strong': 0.5,      # Ï€ = 0.5\n",
    "        'moderate': 0.2,    # Ï€ = 0.2\n",
    "        'weak': 0.1,        # Ï€ = 0.1\n",
    "        'very_weak': 0.03   # Ï€ = 0.03\n",
    "    }\n",
    "    pi = strength_params[iv_strength]\n",
    "    \n",
    "    # æœªè§‚æµ‹æ··æ·†å˜é‡\n",
    "    U = np.random.randn(n)\n",
    "    \n",
    "    # å·¥å…·å˜é‡ï¼ˆä¸ U ç‹¬ç«‹ï¼‰\n",
    "    Z = np.random.randn(n)\n",
    "    \n",
    "    # å¤„ç†å˜é‡ï¼ˆå— Z å’Œ U å½±å“ï¼‰\n",
    "    D = pi * Z + 0.5 * U + np.random.randn(n) * 0.5\n",
    "    \n",
    "    # ç»“æœå˜é‡ï¼ˆå— D å’Œ U å½±å“ï¼‰\n",
    "    Y = beta_true * D + 0.8 * U + np.random.randn(n) * 0.5\n",
    "    \n",
    "    # è®¡ç®—ç†è®º F ç»Ÿè®¡é‡\n",
    "    # F â‰ˆ n * Ï€^2 / var(v)\n",
    "    theoretical_F = n * pi**2 / 0.25  # ç®€åŒ–ä¼°è®¡\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'Y': Y,\n",
    "        'D': D,\n",
    "        'Z': Z\n",
    "    }), theoretical_F\n",
    "\n",
    "# ç”Ÿæˆä¸åŒå¼ºåº¦çš„æ•°æ®\n",
    "data_strong, F_strong = generate_iv_data(iv_strength='strong')\n",
    "data_moderate, F_moderate = generate_iv_data(iv_strength='moderate')\n",
    "data_weak, F_weak = generate_iv_data(iv_strength='weak')\n",
    "data_very_weak, F_very_weak = generate_iv_data(iv_strength='very_weak')\n",
    "\n",
    "print(\"ç”Ÿæˆä¸åŒ IV å¼ºåº¦çš„æ•°æ®ï¼š\")\n",
    "print(f\"  å¼º IV: ç†è®º F â‰ˆ {F_strong:.1f}\")\n",
    "print(f\"  ä¸­ç­‰ IV: ç†è®º F â‰ˆ {F_moderate:.1f}\")\n",
    "print(f\"  å¼± IV: ç†è®º F â‰ˆ {F_weak:.1f}\")\n",
    "print(f\"  æå¼± IV: ç†è®º F â‰ˆ {F_very_weak:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: å¼±å·¥å…·å˜é‡è¯Šæ–­\n",
    "\n",
    "### 2.1 ç¬¬ä¸€é˜¶æ®µ F ç»Ÿè®¡é‡\n",
    "\n",
    "**ç»éªŒæ³•åˆ™** (Stock & Yogo, 2005):\n",
    "- F > 10: å·¥å…·å˜é‡è¶³å¤Ÿå¼º\n",
    "- F < 10: å¯èƒ½æ˜¯å¼±å·¥å…·å˜é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_stage_diagnostics(df):\n",
    "    \"\"\"\n",
    "    ç¬¬ä¸€é˜¶æ®µè¯Šæ–­\n",
    "    \"\"\"\n",
    "    Y, D, Z = df['Y'], df['D'], df['Z']\n",
    "    \n",
    "    # ç¬¬ä¸€é˜¶æ®µå›å½’: D ~ Z\n",
    "    Z_with_const = sm.add_constant(Z)\n",
    "    first_stage = sm.OLS(D, Z_with_const).fit()\n",
    "    \n",
    "    # F ç»Ÿè®¡é‡\n",
    "    # å¯¹äºå•ä¸ªå·¥å…·å˜é‡ï¼ŒF = t^2\n",
    "    t_stat = first_stage.tvalues[1]\n",
    "    F_stat = t_stat ** 2\n",
    "    \n",
    "    # R^2\n",
    "    r_squared = first_stage.rsquared\n",
    "    \n",
    "    return {\n",
    "        'F_stat': F_stat,\n",
    "        'r_squared': r_squared,\n",
    "        'pi_hat': first_stage.params[1],\n",
    "        'pi_se': first_stage.bse[1],\n",
    "        't_stat': t_stat,\n",
    "        'p_value': first_stage.pvalues[1]\n",
    "    }\n",
    "\n",
    "def iv_estimate(df):\n",
    "    \"\"\"\n",
    "    2SLS ä¼°è®¡\n",
    "    \"\"\"\n",
    "    # ä½¿ç”¨ linearmodels\n",
    "    df = df.copy()\n",
    "    df['const'] = 1\n",
    "    \n",
    "    model = IV2SLS(df['Y'], df[['const']], df['D'], df['Z']).fit()\n",
    "    \n",
    "    return {\n",
    "        'beta_hat': model.params['D'],\n",
    "        'se': model.std_errors['D'],\n",
    "        'ci_lower': model.params['D'] - 1.96 * model.std_errors['D'],\n",
    "        'ci_upper': model.params['D'] + 1.96 * model.std_errors['D']\n",
    "    }\n",
    "\n",
    "# è¯Šæ–­æ‰€æœ‰æ•°æ®é›†\n",
    "print(\"=\" * 70)\n",
    "print(\"å¼±å·¥å…·å˜é‡è¯Šæ–­ (çœŸå® Î² = 0.5)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n{'IV å¼ºåº¦':<12} {'ç¬¬ä¸€é˜¶æ®µ F':<15} {'Ï€ ä¼°è®¡':<12} {'2SLS Î²':<12} {'95% CI':<25}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "datasets = [\n",
    "    ('å¼º', data_strong),\n",
    "    ('ä¸­ç­‰', data_moderate),\n",
    "    ('å¼±', data_weak),\n",
    "    ('æå¼±', data_very_weak)\n",
    "]\n",
    "\n",
    "for name, df in datasets:\n",
    "    diag = first_stage_diagnostics(df)\n",
    "    est = iv_estimate(df)\n",
    "    \n",
    "    weak = 'âš ï¸' if diag['F_stat'] < 10 else 'âœ…'\n",
    "    ci = f\"[{est['ci_lower']:.3f}, {est['ci_upper']:.3f}]\"\n",
    "    \n",
    "    print(f\"{name:<12} {diag['F_stat']:<15.2f} {diag['pi_hat']:<12.3f} {est['beta_hat']:<12.3f} {ci:<25} {weak}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– F ç»Ÿè®¡é‡ä¸ä¼°è®¡ç²¾åº¦çš„å…³ç³»\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# ç¬¬ä¸€é˜¶æ®µæ•£ç‚¹å›¾\n",
    "for ax, (name, df) in zip(axes[0], [('å¼º IV', data_strong), ('å¼± IV', data_weak)]):\n",
    "    ax.scatter(df['Z'], df['D'], alpha=0.3, s=20)\n",
    "    \n",
    "    # æ‹Ÿåˆçº¿\n",
    "    z = np.linspace(df['Z'].min(), df['Z'].max(), 100)\n",
    "    diag = first_stage_diagnostics(df)\n",
    "    d_hat = diag['pi_hat'] * z\n",
    "    ax.plot(z, d_hat, 'r-', linewidth=2, label=f'Ï€ = {diag[\"pi_hat\"]:.3f}')\n",
    "    \n",
    "    ax.set_xlabel('å·¥å…·å˜é‡ Z')\n",
    "    ax.set_ylabel('å¤„ç†å˜é‡ D')\n",
    "    ax.set_title(f'{name}: ç¬¬ä¸€é˜¶æ®µå…³ç³»\\nF = {diag[\"F_stat\"]:.1f}')\n",
    "    ax.legend()\n",
    "\n",
    "# æ¨¡æ‹Ÿä¼°è®¡åˆ†å¸ƒ\n",
    "def simulate_iv_distribution(iv_strength, n_sims=500, n_samples=1000):\n",
    "    estimates = []\n",
    "    for i in range(n_sims):\n",
    "        df, _ = generate_iv_data(n=n_samples, iv_strength=iv_strength, seed=i)\n",
    "        est = iv_estimate(df)\n",
    "        estimates.append(est['beta_hat'])\n",
    "    return np.array(estimates)\n",
    "\n",
    "# å¼º IV vs å¼± IV çš„ä¼°è®¡åˆ†å¸ƒ\n",
    "print(\"æ¨¡æ‹Ÿ IV ä¼°è®¡åˆ†å¸ƒ (500 æ¬¡æ¨¡æ‹Ÿ)...\")\n",
    "estimates_strong = simulate_iv_distribution('strong', n_sims=500)\n",
    "estimates_weak = simulate_iv_distribution('weak', n_sims=500)\n",
    "\n",
    "ax = axes[1, 0]\n",
    "ax.hist(estimates_strong, bins=30, alpha=0.6, label='å¼º IV', color='#2ecc71')\n",
    "ax.hist(estimates_weak, bins=30, alpha=0.6, label='å¼± IV', color='#e74c3c')\n",
    "ax.axvline(x=0.5, color='black', linestyle='--', linewidth=2, label='çœŸå®å€¼')\n",
    "ax.set_xlabel('Î² ä¼°è®¡å€¼')\n",
    "ax.set_ylabel('é¢‘æ•°')\n",
    "ax.set_title('å¼º IV vs å¼± IV çš„ä¼°è®¡åˆ†å¸ƒ')\n",
    "ax.legend()\n",
    "\n",
    "# ä¼°è®¡ç»Ÿè®¡é‡\n",
    "ax = axes[1, 1]\n",
    "stats_data = {\n",
    "    'å¼º IV': [np.mean(estimates_strong), np.std(estimates_strong), \n",
    "              np.mean(np.abs(estimates_strong - 0.5))],\n",
    "    'å¼± IV': [np.mean(estimates_weak), np.std(estimates_weak),\n",
    "              np.mean(np.abs(estimates_weak - 0.5))]\n",
    "}\n",
    "\n",
    "x = np.arange(3)\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, stats_data['å¼º IV'], width, label='å¼º IV', color='#2ecc71')\n",
    "ax.bar(x + width/2, stats_data['å¼± IV'], width, label='å¼± IV', color='#e74c3c')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['å‡å€¼', 'æ ‡å‡†å·®', 'MAE'])\n",
    "ax.set_ylabel('å€¼')\n",
    "ax.set_title('ä¼°è®¡è´¨é‡æ¯”è¾ƒ')\n",
    "ax.legend()\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nç»Ÿè®¡é‡:\")\n",
    "print(f\"  å¼º IV: å‡å€¼={np.mean(estimates_strong):.3f}, æ ‡å‡†å·®={np.std(estimates_strong):.3f}\")\n",
    "print(f\"  å¼± IV: å‡å€¼={np.mean(estimates_weak):.3f}, æ ‡å‡†å·®={np.std(estimates_weak):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Stock-Yogo ä¸´ç•Œå€¼\n",
    "\n",
    "Stock & Yogo (2005) æä¾›äº†æ›´ç²¾ç¡®çš„å¼±å·¥å…·å˜é‡æ£€éªŒä¸´ç•Œå€¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weak_iv_test(df, max_bias=0.1):\n",
    "    \"\"\"\n",
    "    å¼±å·¥å…·å˜é‡æ£€éªŒ\n",
    "    \n",
    "    Args:\n",
    "        df: æ•°æ®\n",
    "        max_bias: å¯æ¥å—çš„æœ€å¤§ç›¸å¯¹åå·® (10% = 0.1)\n",
    "    \n",
    "    Returns:\n",
    "        æ˜¯å¦é€šè¿‡æ£€éªŒ\n",
    "    \"\"\"\n",
    "    diag = first_stage_diagnostics(df)\n",
    "    F = diag['F_stat']\n",
    "    \n",
    "    # Stock-Yogo ä¸´ç•Œå€¼ (å•ä¸ªå†…ç”Ÿå˜é‡ï¼Œå•ä¸ªå·¥å…·å˜é‡)\n",
    "    # åå·®é˜ˆå€¼    10%   15%   20%   25%\n",
    "    critical_values = {\n",
    "        0.10: 16.38,\n",
    "        0.15: 8.96,\n",
    "        0.20: 6.66,\n",
    "        0.25: 5.53\n",
    "    }\n",
    "    \n",
    "    cv = critical_values.get(max_bias, 10)  # é»˜è®¤ç”¨ 10\n",
    "    \n",
    "    print(\"Stock-Yogo å¼±å·¥å…·å˜é‡æ£€éªŒ\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"  ç¬¬ä¸€é˜¶æ®µ F ç»Ÿè®¡é‡: {F:.2f}\")\n",
    "    print(f\"  å¯æ¥å—ç›¸å¯¹åå·®: {max_bias:.0%}\")\n",
    "    print(f\"  ä¸´ç•Œå€¼: {cv:.2f}\")\n",
    "    print()\n",
    "    \n",
    "    if F > cv:\n",
    "        print(f\"  âœ… F > {cv:.2f}ï¼Œæ‹’ç»å¼±å·¥å…·å˜é‡å‡è®¾\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"  âŒ F < {cv:.2f}ï¼Œä¸èƒ½æ‹’ç»å¼±å·¥å…·å˜é‡å‡è®¾\")\n",
    "        return False\n",
    "\n",
    "# æ£€éªŒ\n",
    "print(\"\\n--- å¼º IV æ•°æ® ---\")\n",
    "weak_iv_test(data_strong, max_bias=0.10)\n",
    "\n",
    "print(\"\\n--- å¼± IV æ•°æ® ---\")\n",
    "weak_iv_test(data_weak, max_bias=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: å¼±å·¥å…·å˜é‡çš„ç¨³å¥æ¨æ–­\n",
    "\n",
    "### 3.1 Anderson-Rubin ç½®ä¿¡åŒºé—´\n",
    "\n",
    "å³ä½¿åœ¨å¼±å·¥å…·å˜é‡æƒ…å†µä¸‹ä¹Ÿä¿æŒæ­£ç¡®è¦†ç›–ç‡çš„æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anderson_rubin_ci(df, alpha=0.05, n_grid=100):\n",
    "    \"\"\"\n",
    "    Anderson-Rubin ç½®ä¿¡åŒºé—´\n",
    "    \n",
    "    å¯¹äºæ¯ä¸ªå€™é€‰ Î²ï¼Œæ£€éªŒ H0: Î² = Î²0\n",
    "    \"\"\"\n",
    "    Y, D, Z = df['Y'].values, df['D'].values, df['Z'].values\n",
    "    n = len(Y)\n",
    "    \n",
    "    # æœç´¢ Î² çš„èŒƒå›´\n",
    "    beta_range = np.linspace(-2, 3, n_grid)\n",
    "    p_values = []\n",
    "    \n",
    "    for beta in beta_range:\n",
    "        # æ„é€ æ®‹å·®\n",
    "        residual = Y - beta * D\n",
    "        \n",
    "        # å›å½’æ®‹å·®å¯¹ Z\n",
    "        Z_with_const = sm.add_constant(Z)\n",
    "        model = sm.OLS(residual, Z_with_const).fit()\n",
    "        \n",
    "        # F æ£€éªŒ\n",
    "        f_stat = model.fvalue\n",
    "        p_value = model.f_pvalue\n",
    "        p_values.append(p_value)\n",
    "    \n",
    "    p_values = np.array(p_values)\n",
    "    \n",
    "    # æ‰¾åˆ°ä¸è¢«æ‹’ç»çš„åŒºé—´\n",
    "    in_ci = p_values > alpha\n",
    "    \n",
    "    if np.any(in_ci):\n",
    "        ci_lower = beta_range[in_ci].min()\n",
    "        ci_upper = beta_range[in_ci].max()\n",
    "    else:\n",
    "        ci_lower = np.nan\n",
    "        ci_upper = np.nan\n",
    "    \n",
    "    return {\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper,\n",
    "        'beta_range': beta_range,\n",
    "        'p_values': p_values\n",
    "    }\n",
    "\n",
    "# æ¯”è¾ƒæ ‡å‡† CI å’Œ AR CI\n",
    "print(\"=\" * 60)\n",
    "print(\"æ ‡å‡† 2SLS CI vs Anderson-Rubin CI\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, df in [('å¼º IV', data_strong), ('å¼± IV', data_weak)]:\n",
    "    est = iv_estimate(df)\n",
    "    ar = anderson_rubin_ci(df)\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  2SLS ä¼°è®¡: {est['beta_hat']:.3f}\")\n",
    "    print(f\"  æ ‡å‡† CI:   [{est['ci_lower']:.3f}, {est['ci_upper']:.3f}] (å®½åº¦: {est['ci_upper']-est['ci_lower']:.3f})\")\n",
    "    print(f\"  AR CI:     [{ar['ci_lower']:.3f}, {ar['ci_upper']:.3f}] (å®½åº¦: {ar['ci_upper']-ar['ci_lower']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– AR ç½®ä¿¡åŒºé—´\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, (name, df) in zip(axes, [('å¼º IV', data_strong), ('å¼± IV', data_weak)]):\n",
    "    ar = anderson_rubin_ci(df, n_grid=200)\n",
    "    \n",
    "    ax.plot(ar['beta_range'], ar['p_values'], 'b-', linewidth=2)\n",
    "    ax.axhline(y=0.05, color='red', linestyle='--', label='Î± = 0.05')\n",
    "    ax.axvline(x=0.5, color='green', linestyle='--', label='çœŸå® Î² = 0.5')\n",
    "    \n",
    "    # æ ‡è®° CI\n",
    "    ax.fill_between(ar['beta_range'], 0, ar['p_values'], \n",
    "                   where=ar['p_values'] > 0.05, alpha=0.3, color='blue',\n",
    "                   label=f'95% CI: [{ar[\"ci_lower\"]:.2f}, {ar[\"ci_upper\"]:.2f}]')\n",
    "    \n",
    "    ax.set_xlabel('Î²')\n",
    "    ax.set_ylabel('p-value')\n",
    "    ax.set_title(f'{name}: Anderson-Rubin æ£€éªŒ')\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 LIML ä¼°è®¡\n",
    "\n",
    "Limited Information Maximum Likelihood åœ¨å¼±å·¥å…·å˜é‡ä¸‹æ¯” 2SLS æ›´ç¨³å¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liml_estimate(df):\n",
    "    \"\"\"\n",
    "    LIML ä¼°è®¡\n",
    "    \n",
    "    æ¯” 2SLS æ›´ç¨³å¥çš„ IV ä¼°è®¡æ–¹æ³•\n",
    "    \"\"\"\n",
    "    from linearmodels.iv import IVLIML\n",
    "    \n",
    "    df = df.copy()\n",
    "    df['const'] = 1\n",
    "    \n",
    "    model = IVLIML(df['Y'], df[['const']], df['D'], df['Z']).fit()\n",
    "    \n",
    "    return {\n",
    "        'beta_hat': model.params['D'],\n",
    "        'se': model.std_errors['D'],\n",
    "        'ci_lower': model.params['D'] - 1.96 * model.std_errors['D'],\n",
    "        'ci_upper': model.params['D'] + 1.96 * model.std_errors['D']\n",
    "    }\n",
    "\n",
    "# æ¯”è¾ƒ 2SLS å’Œ LIML\n",
    "print(\"=\" * 60)\n",
    "print(\"2SLS vs LIML æ¯”è¾ƒ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, df in datasets:\n",
    "    est_2sls = iv_estimate(df)\n",
    "    est_liml = liml_estimate(df)\n",
    "    \n",
    "    print(f\"\\n{name} IV:\")\n",
    "    print(f\"  2SLS: Î² = {est_2sls['beta_hat']:.3f} (SE = {est_2sls['se']:.3f})\")\n",
    "    print(f\"  LIML: Î² = {est_liml['beta_hat']:.3f} (SE = {est_liml['se']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: æ’æ–¥æ€§å‡è®¾è¿èƒŒ\n",
    "\n",
    "### 4.1 é—®é¢˜æè¿°\n",
    "\n",
    "æ’æ–¥æ€§å‡è®¾ï¼šå·¥å…·å˜é‡ $Z$ åªé€šè¿‡å¤„ç† $D$ å½±å“ç»“æœ $Y$ã€‚\n",
    "\n",
    "å¦‚æœ $Z$ ç›´æ¥å½±å“ $Y$ï¼ŒIV ä¼°è®¡æœ‰åã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_invalid_iv_data(n=1000, beta_true=0.5, direct_effect=0.3, seed=42):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆè¿åæ’æ–¥æ€§å‡è®¾çš„ IV æ•°æ®\n",
    "    \n",
    "    Z ç›´æ¥å½±å“ Yï¼ˆä¸ä»…é€šè¿‡ Dï¼‰\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    U = np.random.randn(n)\n",
    "    Z = np.random.randn(n)\n",
    "    \n",
    "    D = 0.5 * Z + 0.5 * U + np.random.randn(n) * 0.5\n",
    "    \n",
    "    # Y å— Dã€U å’Œ Zï¼ˆç›´æ¥æ•ˆåº”ï¼‰å½±å“\n",
    "    Y = beta_true * D + 0.8 * U + direct_effect * Z + np.random.randn(n) * 0.5\n",
    "    \n",
    "    return pd.DataFrame({'Y': Y, 'D': D, 'Z': Z})\n",
    "\n",
    "# ç”Ÿæˆæ— æ•ˆ IV æ•°æ®\n",
    "data_invalid = generate_invalid_iv_data(direct_effect=0.3)\n",
    "\n",
    "# ä¼°è®¡\n",
    "est_invalid = iv_estimate(data_invalid)\n",
    "diag_invalid = first_stage_diagnostics(data_invalid)\n",
    "\n",
    "print(\"æ’æ–¥æ€§å‡è®¾è¿èƒŒç¤ºä¾‹\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"çœŸå® Î² = 0.5, Z çš„ç›´æ¥æ•ˆåº” = 0.3\")\n",
    "print(f\"\\n2SLS ä¼°è®¡: {est_invalid['beta_hat']:.3f}\")\n",
    "print(f\"ç¬¬ä¸€é˜¶æ®µ F: {diag_invalid['F_stat']:.1f}\")\n",
    "print(f\"\\nâš ï¸ ä¼°è®¡ä¸¥é‡åç¦»çœŸå®å€¼!\")\n",
    "print(f\"   åå·®æ¥æº: Z ç›´æ¥å½±å“ Yï¼Œè¿åæ’æ–¥æ€§\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Sargan-Hansen è¿‡åº¦è¯†åˆ«æ£€éªŒ\n",
    "\n",
    "å½“æœ‰å¤šä¸ªå·¥å…·å˜é‡æ—¶ï¼Œå¯ä»¥æ£€éªŒæ’æ–¥æ€§å‡è®¾ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multiple_iv_data(n=1000, beta_true=0.5, invalid_iv=False, seed=42):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆå¤šå·¥å…·å˜é‡æ•°æ®\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    U = np.random.randn(n)\n",
    "    Z1 = np.random.randn(n)\n",
    "    Z2 = np.random.randn(n)\n",
    "    \n",
    "    D = 0.4 * Z1 + 0.3 * Z2 + 0.5 * U + np.random.randn(n) * 0.5\n",
    "    \n",
    "    if invalid_iv:\n",
    "        # Z2 ç›´æ¥å½±å“ Yï¼ˆæ— æ•ˆï¼‰\n",
    "        Y = beta_true * D + 0.8 * U + 0.4 * Z2 + np.random.randn(n) * 0.5\n",
    "    else:\n",
    "        Y = beta_true * D + 0.8 * U + np.random.randn(n) * 0.5\n",
    "    \n",
    "    return pd.DataFrame({'Y': Y, 'D': D, 'Z1': Z1, 'Z2': Z2})\n",
    "\n",
    "def overidentification_test(df):\n",
    "    \"\"\"\n",
    "    Sargan-Hansen è¿‡åº¦è¯†åˆ«æ£€éªŒ\n",
    "    \n",
    "    H0: æ‰€æœ‰å·¥å…·å˜é‡éƒ½æ˜¯æœ‰æ•ˆçš„\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['const'] = 1\n",
    "    \n",
    "    model = IV2SLS(df['Y'], df[['const']], df['D'], df[['Z1', 'Z2']]).fit()\n",
    "    \n",
    "    # Sargan æ£€éªŒç»Ÿè®¡é‡\n",
    "    sargan_stat = model.sargan.stat\n",
    "    sargan_pval = model.sargan.pval\n",
    "    \n",
    "    return {\n",
    "        'sargan_stat': sargan_stat,\n",
    "        'p_value': sargan_pval,\n",
    "        'beta_hat': model.params['D'],\n",
    "        'se': model.std_errors['D']\n",
    "    }\n",
    "\n",
    "# æœ‰æ•ˆ IV\n",
    "data_valid_multi = generate_multiple_iv_data(invalid_iv=False)\n",
    "test_valid = overidentification_test(data_valid_multi)\n",
    "\n",
    "# æ— æ•ˆ IV\n",
    "data_invalid_multi = generate_multiple_iv_data(invalid_iv=True)\n",
    "test_invalid = overidentification_test(data_invalid_multi)\n",
    "\n",
    "print(\"Sargan-Hansen è¿‡åº¦è¯†åˆ«æ£€éªŒ\")\n",
    "print(\"=\" * 50)\n",
    "print(\"H0: æ‰€æœ‰å·¥å…·å˜é‡éƒ½æ˜¯æœ‰æ•ˆçš„\")\n",
    "\n",
    "print(f\"\\næœ‰æ•ˆ IV æƒ…å†µ:\")\n",
    "print(f\"  Sargan ç»Ÿè®¡é‡: {test_valid['sargan_stat']:.3f}\")\n",
    "print(f\"  p-value: {test_valid['p_value']:.4f}\")\n",
    "print(f\"  ç»“è®º: {'âœ… ä¸æ‹’ç» H0' if test_valid['p_value'] > 0.05 else 'âŒ æ‹’ç» H0'}\")\n",
    "\n",
    "print(f\"\\næ— æ•ˆ IV æƒ…å†µ (Z2 ç›´æ¥å½±å“ Y):\")\n",
    "print(f\"  Sargan ç»Ÿè®¡é‡: {test_invalid['sargan_stat']:.3f}\")\n",
    "print(f\"  p-value: {test_invalid['p_value']:.4f}\")\n",
    "print(f\"  ç»“è®º: {'âœ… ä¸æ‹’ç» H0' if test_invalid['p_value'] > 0.05 else 'âŒ æ‹’ç» H0ï¼Œå­˜åœ¨æ— æ•ˆ IV'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: å®Œæ•´è¯Šæ–­æµç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iv_diagnostic_pipeline(df, iv_cols=['Z'], alpha=0.05):\n",
    "    \"\"\"\n",
    "    å®Œæ•´çš„ IV è¯Šæ–­æµç¨‹\n",
    "    \"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"å·¥å…·å˜é‡è¯Šæ–­æŠ¥å‘Š\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Step 1: ç¬¬ä¸€é˜¶æ®µè¯Šæ–­\n",
    "    print(\"\\nã€Step 1: ç¬¬ä¸€é˜¶æ®µè¯Šæ–­ã€‘\")\n",
    "    diag = first_stage_diagnostics(df)\n",
    "    print(f\"  Ï€ (IV â†’ D): {diag['pi_hat']:.4f} (SE = {diag['pi_se']:.4f})\")\n",
    "    print(f\"  t ç»Ÿè®¡é‡: {diag['t_stat']:.2f}\")\n",
    "    print(f\"  F ç»Ÿè®¡é‡: {diag['F_stat']:.2f}\")\n",
    "    \n",
    "    # Step 2: å¼± IV æ£€éªŒ\n",
    "    print(\"\\nã€Step 2: å¼±å·¥å…·å˜é‡æ£€éªŒã€‘\")\n",
    "    if diag['F_stat'] > 16.38:\n",
    "        print(f\"  âœ… F > 16.38ï¼ŒIV è¶³å¤Ÿå¼ºï¼ˆåå·® < 10%ï¼‰\")\n",
    "        weak_iv = False\n",
    "    elif diag['F_stat'] > 10:\n",
    "        print(f\"  âš¡ 10 < F < 16.38ï¼ŒIV ä¸­ç­‰å¼ºåº¦\")\n",
    "        weak_iv = False\n",
    "    else:\n",
    "        print(f\"  âŒ F < 10ï¼Œå­˜åœ¨å¼±å·¥å…·å˜é‡é—®é¢˜\")\n",
    "        weak_iv = True\n",
    "    \n",
    "    # Step 3: ä¼°è®¡\n",
    "    print(\"\\nã€Step 3: å‚æ•°ä¼°è®¡ã€‘\")\n",
    "    est_2sls = iv_estimate(df)\n",
    "    print(f\"  2SLS ä¼°è®¡: {est_2sls['beta_hat']:.4f}\")\n",
    "    print(f\"  æ ‡å‡† CI: [{est_2sls['ci_lower']:.4f}, {est_2sls['ci_upper']:.4f}]\")\n",
    "    \n",
    "    if weak_iv:\n",
    "        ar = anderson_rubin_ci(df)\n",
    "        print(f\"  AR CI: [{ar['ci_lower']:.4f}, {ar['ci_upper']:.4f}] (å¯¹å¼± IV ç¨³å¥)\")\n",
    "    \n",
    "    # Step 4: å»ºè®®\n",
    "    print(\"\\nã€Step 4: å»ºè®®ã€‘\")\n",
    "    if weak_iv:\n",
    "        print(\"  âš ï¸ æ£€æµ‹åˆ°å¼±å·¥å…·å˜é‡:\")\n",
    "        print(\"     1. ä½¿ç”¨ Anderson-Rubin ç½®ä¿¡åŒºé—´\")\n",
    "        print(\"     2. è€ƒè™‘ LIML ä¼°è®¡\")\n",
    "        print(\"     3. å¯»æ‰¾æ›´å¼ºçš„å·¥å…·å˜é‡\")\n",
    "    else:\n",
    "        print(\"  âœ… å·¥å…·å˜é‡è¶³å¤Ÿå¼ºï¼Œå¯ä½¿ç”¨æ ‡å‡† 2SLS\")\n",
    "    \n",
    "    return {\n",
    "        'weak_iv': weak_iv,\n",
    "        'F_stat': diag['F_stat'],\n",
    "        'beta_2sls': est_2sls['beta_hat']\n",
    "    }\n",
    "\n",
    "# è¿è¡Œè¯Šæ–­\n",
    "print(\"\\n\" + \"#\" * 70)\n",
    "print(\"åœºæ™¯: å¼±å·¥å…·å˜é‡\")\n",
    "print(\"#\" * 70)\n",
    "iv_diagnostic_pipeline(data_weak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¡ æ€è€ƒé¢˜\n",
    "\n",
    "1. **å¤šå¼±å·¥å…·å˜é‡**ï¼šå¦‚æœæœ‰å¤šä¸ªå¼±å·¥å…·å˜é‡ï¼Œèƒ½å¦\"åŠ æ€»\"æˆä¸€ä¸ªå¼ºå·¥å…·ï¼Ÿ\n",
    "   - æç¤ºï¼šè€ƒè™‘ JIVE ä¼°è®¡\n",
    "\n",
    "2. **å±€éƒ¨å¤„ç†æ•ˆåº”**ï¼šIV ä¼°è®¡çš„æ˜¯ä»€ä¹ˆæ•ˆåº”ï¼Ÿä¸ ATE æœ‰ä½•åŒºåˆ«ï¼Ÿ\n",
    "   - æç¤ºï¼šLATE (Local Average Treatment Effect)\n",
    "\n",
    "3. **å·¥å…·å˜é‡é€‰æ‹©**ï¼šå¦‚ä½•åˆ¤æ–­ä¸€ä¸ªå˜é‡æ˜¯å¦é€‚åˆåšå·¥å…·å˜é‡ï¼Ÿ\n",
    "   - æç¤ºï¼šéœ€è¦é¢†åŸŸçŸ¥è¯†ï¼Œç»Ÿè®¡æ£€éªŒåªèƒ½æ£€éªŒç›¸å…³æ€§\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ æ€»ç»“\n",
    "\n",
    "### å¼± IV è¯Šæ–­è§„åˆ™\n",
    "\n",
    "| F ç»Ÿè®¡é‡ | è¯Šæ–­ | å»ºè®® |\n",
    "|---------|------|------|\n",
    "| F > 16.38 | å¼º IV | æ ‡å‡† 2SLS |\n",
    "| 10 < F < 16.38 | ä¸­ç­‰ | è°¨æ…ä½¿ç”¨ï¼ŒæŠ¥å‘Š AR CI |\n",
    "| F < 10 | å¼± IV | ä½¿ç”¨ AR/LIMLï¼Œæˆ–å¯»æ‰¾æ›´å¥½çš„ IV |\n",
    "\n",
    "### å¼± IV ç¨³å¥æ–¹æ³•\n",
    "\n",
    "| æ–¹æ³• | ä¼˜ç‚¹ | ç¼ºç‚¹ |\n",
    "|------|------|------|\n",
    "| Anderson-Rubin | æ­£ç¡®è¦†ç›–ç‡ | CI å¯èƒ½å¾ˆå®½ |\n",
    "| LIML | åå·®æ›´å° | æ–¹å·®å¯èƒ½æ›´å¤§ |\n",
    "| JIVE | é€‚åˆå¤š IV | è®¡ç®—å¤æ‚ |\n",
    "\n",
    "### é¢è¯•è¦ç‚¹\n",
    "\n",
    "- èƒ½è§£é‡Šå·¥å…·å˜é‡çš„ä¸¤ä¸ªæ¡ä»¶\n",
    "- çŸ¥é“ F > 10 è§„åˆ™\n",
    "- äº†è§£å¼± IV çš„ç¨³å¥æ–¹æ³•\n",
    "- ç†è§£è¿‡åº¦è¯†åˆ«æ£€éªŒçš„ä½œç”¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
