# 因果推断完全学习指南

> **从「相关性」到「因果性」的思维跃迁**
>
> 本教程包含 **54 个 Jupyter Notebook**，系统化讲解因果推断的理论与实践。

---

## 学习路线总览

```
Part 0: 基础理论 ─────── "什么是因果？如何思考因果？"
    │
    ▼
Part 1: 随机实验 ─────── "金标准：A/B 测试的设计与优化"
    │
    ▼
Part 2: 观测性研究 ──── "没有实验怎么办？从历史数据挖掘因果"
    │
    ▼
Part 3: 准实验设计 ──── "借助自然实验：DID、RDD、IV"
    │
    ▼
Part 4: 异质性效应 ──── "对谁有效？个性化因果推断"
    │
    ▼
Part 5: 深度学习 ────── "神经网络 × 因果推断"
    │
    ▼
Part 6: 营销应用 ────── "因果推断的业务落地"
    │
    ▼
Part 7: 高级主题 ────── "复杂因果问题的前沿方法"
    │
    ▼
Part 8: 技术深挖 ────── "核心算法的底层原理"
    │
    ▼
Part 9: 常见陷阱 ────── "实践中必须避开的坑"
```

---

## Part 0: 因果推断基础

### 引言

> **学完这章，你能回答：**
> - 为什么「冰淇淋销量上升导致溺水人数增加」是错误的推断？
> - 什么是反事实？为什么我们永远无法观察到它？
> - 如何用图形化思维分析因果关系？

因果推断的核心挑战是：**我们永远无法同时观察到一个人接受治疗和不接受治疗的结果**。这被称为因果推断的根本问题。本章建立理解因果的数学框架和图形化工具。

### 学习内容

| Notebook | 主题 | 核心内容 |
|----------|------|----------|
| **0.1 潜在结果框架** | Potential Outcomes | Y(0)、Y(1)、ITE、ATE、反事实思维、为什么随机化有效 |
| **0.2 因果图 DAG** | Causal Graphs | Fork/Chain/Collider 三种结构、后门路径、d-分离、后门准则 |
| **0.3 识别策略** | Identification | 什么条件下能识别因果效应、各种识别假设 |
| **0.4 混淆偏差** | Confounding Bias | Bias = γ × δ 公式、Simpson 悖论、敏感性分析 |

### 核心公式

```
个体处理效应:  ITE_i = Y_i(1) - Y_i(0)
平均处理效应:  ATE = E[Y(1) - Y(0)]
观测结果:      Y = T·Y(1) + (1-T)·Y(0)
混淆偏差:      Bias = γ × δ  (混淆对Y的效应 × 混淆与T的关联)
```

### 场景对应

| 业务场景 | 对应内容 |
|----------|----------|
| 老板问「这个广告有没有效果」，你要理解什么是「效果」 | 0.1 潜在结果 |
| 数据分析师说「X 和 Y 高度相关」，你要判断能否推出因果 | 0.2 DAG |
| 产品说「用户活跃度高的人付费率也高」，你要识别混淆因素 | 0.4 混淆偏差 |

---

## Part 1: 随机实验设计

### 引言

> **学完这章，你能回答：**
> - A/B 测试需要多少样本？实验要跑多久？
> - 为什么不能提前偷看结果？
> - 用户之间会互相影响怎么办？

随机实验是因果推断的「金标准」。通过随机分配，我们打破了混淆因素的影响。但实验设计远比「随机分两组」复杂——功效分析、方差缩减、网络效应都是实战中的关键问题。

### 学习内容

| Notebook | 主题 | 核心内容 |
|----------|------|----------|
| **1.0 功效分析** | Power Analysis | 样本量计算、MDE、Type I/II Error、功效曲线 |
| **1.1 A/B 测试基础** | AB Testing Basics | 随机化原理、实验单元、指标体系、AA 测试、SRM 检验 |
| **1.2 CUPED 方差缩减** | Variance Reduction | 利用历史数据提高实验灵敏度，缩短实验周期 |
| **1.3 分层分析** | Stratified Analysis | 分层随机化、异质效应检测、HTE 分析 |
| **1.4 网络效应** | Network Effects | SUTVA 违背、聚类随机化、直接效应 vs 溢出效应 |
| **1.5 切换实验** | Switchback | 时间序列实验设计、处理时间混淆 |
| **1.6 长期效应** | Long-term Effects | 短期到长期的外推、因果建模 |
| **1.7 多臂老虎机** | Multi-Armed Bandits | 探索与利用权衡、Thompson Sampling、Contextual Bandit |

### 核心公式

```
样本量(连续):    n = 2σ²(z_α + z_β)² / δ²
样本量(二元):    n = 2p̄(1-p̄)(z_α + z_β)² / Δp²
MDE:            MDE = (z_α + z_β) × √(2σ²/n)
CUPED 调整:     Y_adj = Y - θ(X_pre - X̄_pre)，方差缩减 = 1 - ρ²
设计效应:       DE = 1 + (m-1) × ICC
```

### 场景对应

| 业务场景 | 对应内容 |
|----------|----------|
| 产品问「这个实验要跑多久」 | 1.0 功效分析 |
| 实验跑了一周还没显著，能不能停 | 1.1 A/B 基础 |
| 实验效果不显著但老板觉得有效，怎么提高灵敏度 | 1.2 CUPED |
| 推荐系统实验，用户之间会互相影响 | 1.4 网络效应 |
| 打车平台的司乘匹配实验 | 1.5 切换实验 |
| 有 10 个广告创意，怎么快速找到最好的 | 1.7 多臂老虎机 |

---

## Part 2: 观测性研究

### 引言

> **学完这章，你能回答：**
> - 没法做实验时，如何从历史数据中挖掘因果效应？
> - 什么是倾向得分？为什么它能帮助我们？
> - 如何评估结论对未观测混淆的稳健性？

现实中，很多问题无法做随机实验：已经上线的功能、历史决策的评估、伦理限制等。观测性研究通过统计方法「模拟」随机化，核心思想是：**让处理组和对照组在协变量上尽可能相似**。

### 学习内容

| Notebook | 主题 | 核心内容 |
|----------|------|----------|
| **2.1 倾向得分** | Propensity Score | e(X) = P(T=1\|X)，维度缩减，Rosenbaum-Rubin 定理 |
| **2.2 匹配方法** | Matching | PSM、精确匹配、CEM、马氏距离匹配、共同支撑检验 |
| **2.3 逆概率加权** | IPW | Horvitz-Thompson 估计、权重极端值处理、有效样本量 |
| **2.4 双重稳健** | Doubly Robust | AIPW，两道防线任一有效即可，交叉拟合 |
| **2.5 敏感性分析** | Sensitivity Analysis | Rosenbaum Bounds、**E-value**（最重要）、Placebo 检验 |
| **2.6 Double ML** | Double Machine Learning | 正则化偏差、Neyman 正交性、Cross-fitting |

### 核心公式

```
倾向得分:        e(X) = P(T=1|X)
IPW 权重:        w = T/e(X) + (1-T)/(1-e(X))
AIPW:           τ̂ = 回归调整 + IPW修正项（双重稳健）
E-value:        E = RR + √(RR × (RR-1))  用于评估敏感性
DML:            残差化后回归，τ̂ = Σỹᵢt̃ᵢ / Σt̃ᵢ²
```

### 场景对应

| 业务场景 | 对应内容 |
|----------|----------|
| 评估某个已上线功能的效果（无法做 A/B） | 2.2 PSM |
| 高价值用户天然更多使用会员服务，如何评估会员服务效果 | 2.3 IPW |
| 担心有遗漏的混淆因素 | 2.5 敏感性分析 |
| 特征维度很高，传统方法不稳定 | 2.6 Double ML |

---

## Part 3: 准实验设计

### 引言

> **学完这章，你能回答：**
> - 政策变化、地理边界、时间断点能否帮助我们识别因果？
> - 什么是「平行趋势假设」？如何检验它？
> - 什么时候用工具变量？它识别的是什么效应？

准实验利用现实中的「自然实验」：政策变化、地理边界、时间断点等。这些方法不依赖「无混淆假设」，而是利用数据结构本身来识别因果效应。

### 学习内容

| Notebook | 主题 | 核心内容 |
|----------|------|----------|
| **3.1 双重差分 DID** | Difference-in-Differences | 平行趋势假设、Event Study、交错 DID、时间固定效应 |
| **3.2 合成控制法** | Synthetic Control | 构造「合成」对照组、权重优化、Placebo 检验、适用于单一处理单位 |
| **3.3 断点回归 RDD** | Regression Discontinuity | 利用阈值的局部随机性、Sharp vs Fuzzy RDD、带宽选择、McCrary 检验 |
| **3.4 工具变量 IV** | Instrumental Variables | 两阶段最小二乘、弱工具诊断、LATE 与 Compliers、过度识别检验 |

### 核心公式

```
DID:            τ = (Ȳ_T,post - Ȳ_T,pre) - (Ȳ_C,post - Ȳ_C,pre)
合成控制:       Ŷ₁ₜ = Σwⱼ·Yⱼₜ  (加权组合)
RDD:            τ = lim(x→c⁺)E[Y|X] - lim(x→c⁻)E[Y|X]
2SLS:           τ̂ = Cov(Z,Y) / Cov(Z,T)  (Wald 估计量)
LATE:           = ITT / First Stage = E[Y(1)-Y(0)|Compliers]
```

### 场景对应

| 业务场景 | 对应内容 |
|----------|----------|
| 某城市上线了新政策，想评估效果 | 3.1 DID |
| 只有一个处理单位（如一个省），没有对照 | 3.2 合成控制 |
| 评估「信用分 600 以上可借款」政策的效果 | 3.3 RDD |
| 处理变量有内生性，但有外生的工具 | 3.4 IV |

---

## Part 4: 异质性效应与提升建模

### 引言

> **学完这章，你能回答：**
> - 同一个策略，对谁效果好？对谁没用？
> - 如何估计每个人的个体处理效应？
> - 如何评估一个 CATE 模型的好坏？

平均处理效应 (ATE) 告诉我们「总体有没有效」，但实际决策需要知道「对谁有效」。CATE (条件平均处理效应) 让我们可以做精准化运营：**给对的人推对的策略**。

### 学习内容

| Notebook | 主题 | 核心内容 |
|----------|------|----------|
| **4.1 CATE 基础** | CATE Basics | 异质性效应定义、T-Learner 入门、PEHE 评估指标 |
| **4.2 Meta-Learners** | S/T/X/R-Learner | 四种元学习范式、各自优缺点、双重去偏思想 |
| **4.3 因果森林** | Causal Forest | 专为 CATE 设计的分裂准则、**Honest Splitting**、置信区间 |
| **4.4 提升树** | Uplift Tree | KL 散度/欧氏距离分裂准则、直接优化提升 |
| **4.5 提升评估** | Uplift Evaluation | **Qini 曲线**、AUUC、累积增益、最优干预比例 |

### 核心公式

```
CATE:           τ(x) = E[Y(1) - Y(0) | X=x]
T-Learner:      τ̂(x) = μ̂₁(x) - μ̂₀(x)
X-Learner:      三阶段，处理倾向得分加权
因果森林分裂:   Gain = (n_L·n_R/n²) × (τ̂_L - τ̂_R)²
Qini:          Qini(k) = Y_t(k) - Y_c(k) × n_t(k)/n_c(k)
```

### 场景对应

| 业务场景 | 对应内容 |
|----------|----------|
| 优惠券对哪类用户最有效 | 4.2 Meta-Learners |
| 用 ML 模型估计个体处理效应，需要置信区间 | 4.3 因果森林 |
| 选出「发券能带来增量」的用户 | 4.4 提升树 |
| 如何比较两个 CATE 模型的好坏 | 4.5 Qini 曲线 |

---

## Part 5: 深度学习方法

### 引言

> **学完这章，你能回答：**
> - 神经网络如何应用于因果推断？
> - 什么是表示学习？为什么它对因果推断很重要？
> - 如何处理连续的处理变量（如价格、剂量）？

当特征维度很高、关系非线性时，深度学习提供了强大的表示学习能力。本章介绍专门为因果推断设计的神经网络架构。

### 学习内容

| Notebook | 主题 | 核心内容 |
|----------|------|----------|
| **5.1 表示学习** | Representation Learning | 自动特征提取、IPM 平衡、MMD 距离 |
| **5.2 TARNet/DragonNet** | Treatment-Agnostic Networks | 共享表示 + 双头预测、三头架构、Targeted Regularization |
| **5.3 CEVAE** | Causal Effect VAE | 变分自编码器、隐变量建模、处理未观测混淆 |
| **5.4 GANITE** | GAN for Causal Inference | 用 GAN 生成反事实、两阶段架构 |
| **5.5 VCNet** | Varying Coefficient Network | **连续处理效应**、剂量-响应曲线、样条基函数 |

### 核心架构

```
TARNet:     X → [共享表示Φ] → [Head₀: Ŷ(0)] + [Head₁: Ŷ(1)]

DragonNet:  X → [共享表示Φ] → [Head₀] + [Head₁] + [倾向得分头ê(X)]
            Loss = L_outcome + α·L_propensity + β·L_targeted

VCNet:      Y = W(T)·Φ(X)  (处理强度调制特征影响)
```

### 场景对应

| 业务场景 | 对应内容 |
|----------|----------|
| 特征是图像/文本等非结构化数据 | 5.1 表示学习 |
| 需要端到端训练的因果模型 | 5.2 TARNet/DragonNet |
| 存在未观测的混淆因素 | 5.3 CEVAE |
| 处理变量是连续的（如价格、剂量） | 5.5 VCNet |

---

## Part 6: 营销应用

### 引言

> **学完这章，你能回答：**
> - 优惠券应该发给谁？为什么有些人发券反而有害？
> - 什么是「Sleeping Dogs」？如何识别他们？
> - 多个渠道如何分配预算才能 ROI 最大化？

理论最终要服务于业务。本章聚焦营销场景，展示因果推断如何解决归因、定向、优化等核心问题。

### 学习内容

| Notebook | 主题 | 核心内容 |
|----------|------|----------|
| **6.1 智能发券** | Coupon Targeting | 四类用户（Persuadables、Sure Things、Lost Causes、**Sleeping Dogs**）、Uplift 建模 |
| **6.2 优惠券优化** | Coupon Optimization | 响应率 vs Uplift 建模、反向效应识别、ROI 计算 |
| **6.3 用户定向** | User Targeting | T-Learner/X-Learner 应用、最优策略学习、成本-收益权衡 |
| **6.4 预算分配** | Budget Allocation | 边际收益递减、拉格朗日乘数、影子价格、协同/替代效应、稳健优化 |

### 四类用户

| 用户类型 | 不发券 | 发券 | Uplift | 策略 |
|----------|--------|------|--------|------|
| **Persuadables** | 不来 | 来了 | 高正 | 重点发券 |
| **Sure Things** | 来了 | 来了 | 0 | 浪费钱 |
| **Lost Causes** | 不来 | 不来 | 0 | 别浪费 |
| **Sleeping Dogs** | 来了 | 不来 | 负 | 千万别发 |

### 场景对应

| 业务场景 | 对应内容 |
|----------|----------|
| 有 100 万预算发优惠券，发给谁 | 6.1/6.2 Uplift 建模 |
| 选出最值得投放的用户群体 | 6.3 用户定向 |
| 多个渠道如何分配预算 | 6.4 预算分配 |
| 为什么高端用户发券后转化反而下降 | 6.2 Sleeping Dogs |

---

## Part 7: 高级主题

### 引言

> **学完这章，你能回答：**
> - 如何从数据中发现因果结构（而不是假设它）？
> - 处理变量是连续的、随时间变化的、有中介机制的怎么办？
> - 工具变量估计的效应是针对谁的？

真实世界的因果问题往往更复杂。本章拓展因果推断的边界，处理各种非标准情形。

### 学习内容

| Notebook | 主题 | 核心内容 |
|----------|------|----------|
| **7.1 因果发现** | Causal Discovery | PC/GES/LiNGAM 算法、从数据学习因果图、隐变量处理 |
| **7.2 连续处理** | Continuous Treatment | 广义倾向得分 GPS、剂量-响应函数、边际效应 |
| **7.3 时变处理** | Time-Varying Treatment | 边际结构模型 MSM、序贯忽略假设、G-computation |
| **7.4 中介分析** | Mediation Analysis | 直接效应 NDE vs 间接效应 NIE、Baron-Kenny 方法、g-formula |
| **7.5 多重处理** | Multiple Treatments | 多档位策略比较、多分类倾向得分、最优处理选择 |
| **7.6 Bunching** | Bunching Design | 政策阈值行为堆积、弹性估计、缺失质量 |
| **7.7 Complier 分析** | LATE & CACE | 四种合规类型、工具变量识别的是谁的效应 |

### 核心公式

```
GPS:            r(t,X) = f_T(t|X)  (条件密度函数)
MSM:            E[Y(ā)] = β₀ + β₁·Σaₜ
中介分解:       TE = NDE + NIE
LATE:           E[Y(1)-Y(0)|Compliers] = ITT / First Stage
Bunching 弹性:  ε = B / (h₀(z*)·Δz*) × z* / Δln(1-t)
```

### 场景对应

| 业务场景 | 对应内容 |
|----------|----------|
| 不知道因果图长什么样，想从数据学 | 7.1 因果发现 |
| 广告投放金额（连续）对 ROI 的影响 | 7.2 连续处理 |
| 用户多次收到不同干预，如何评估 | 7.3 时变处理 |
| 效应是直接的还是通过某个中间变量 | 7.4 中介分析 |
| 有多个策略档位，想比较它们 | 7.5 多重处理 |

---

## Part 8: 技术深挖

### 引言

> **学完这章，你能回答：**
> - 处理组严重不平衡时，IPW 为什么会失效？怎么修复？
> - 因果森林的分裂准则和普通随机森林有什么本质区别？
> - 新用户没有历史数据，如何做 Uplift 建模？

深入技术细节，适合想要彻底理解原理的学习者。每个 Deep Dive 都对应前面章节的核心技术，建议在学完对应章节后深入学习。

### 学习内容

| Notebook | 主题 | 核心要点 | 建议学习时机 |
|----------|------|----------|--------------|
| **8.1 处理不平衡** | Imbalanced Treatment | Focal Loss、Overlap Weights、Stabilized Weights、ESS 诊断 | Part 2 (IPW) 之后 |
| **8.2 DragonNet 多处理** | Multi-Treatment | 二分类→多分类、Softmax、ModuleList | Part 5.2 之后 |
| **8.3 因果森林分裂** | Splitting Criterion | CATE 方差最大化、Honest Splitting 原理、CART vs Causal Tree | Part 4.3 之后 |
| **8.4 冷启动 Uplift** | Cold Start | Thompson Sampling、信息先验、探索-利用权衡 | Part 4 + 1.7 之后 |
| **8.5 极端倾向得分** | Extreme Propensity | 权重爆炸诊断、Trimming vs Overlap vs CRUMP Bounds | Part 2.3 之后 |

### 前置依赖

```
8.1 处理不平衡      ← Part 2.3 IPW
8.2 DragonNet 多处理 ← Part 5.2 TARNet/DragonNet
8.3 因果森林分裂     ← Part 4.3 因果森林
8.4 冷启动 Uplift    ← Part 4 + Part 1.7 多臂老虎机
8.5 极端倾向得分     ← Part 2.1-2.3 倾向得分/IPW
```

---

## Part 9: 常见陷阱

### 引言

> **学完这章，你能回答：**
> - PSM 在什么情况下会彻底失效？
> - CUPED 用错了协变量会导致什么后果？
> - A/B 测试中「偷看数据」为什么是大忌？

这些是实践中最容易犯的错误，**强烈建议在学完对应章节后立即学习**，避免在实际工作中踩坑。

### 学习内容

| Notebook | 主题 | 核心警示 | 建议学习时机 |
|----------|------|----------|--------------|
| **9.1 PSM 失效模式** | PSM Failure Modes | 什么情况下匹配会失败、共同支撑检验 | Part 2.2 之后 |
| **9.2 CUPED 误用** | CUPED Misuse | 协变量选择错误、使用实验后变量 | Part 1.2 之后 |
| **9.3 DID 假设违背** | DID Violations | 平行趋势假设不成立时的处理 | Part 3.1 之后 |
| **9.4 弱工具变量** | Weak IV | F 统计量诊断、弱工具的后果 | Part 3.4 之后 |
| **9.5 A/B 测试错误** | AB Testing Mistakes | 提前停止、多重比较、SRM 问题 | Part 1.0-1.1 之后 |

### 前置依赖

```
9.1 PSM 失效       ← Part 2.2 匹配方法
9.2 CUPED 误用     ← Part 1.2 CUPED
9.3 DID 假设违背   ← Part 3.1 双重差分
9.4 弱工具变量     ← Part 3.4 工具变量
9.5 A/B 测试错误   ← Part 1.0-1.1 A/B 基础
```

### 学习建议

**推荐的 Pitfall 学习顺序：**

1. 学完 Part 1.0-1.2 → 立即看 **9.5 A/B 测试错误** + **9.2 CUPED 误用**
2. 学完 Part 2.1-2.3 → 立即看 **9.1 PSM 失效模式**
3. 学完 Part 3.1 → 立即看 **9.3 DID 假设违背**
4. 学完 Part 3.4 → 立即看 **9.4 弱工具变量**

---

## 学习建议

### 推荐路线（每天 5-8 小时）

**快速入门 (3 天)**
```
Day 1: Part 0 全部 (4 notebooks)
Day 2: Part 1.0-1.2 + 9.5 A/B 错误 + 9.2 CUPED 误用
Day 3: Part 2.1-2.4 + 9.1 PSM 失效
```

**系统掌握 (1 周)**
```
Day 1-2: Part 1 完整 (8 notebooks)
Day 3:   Part 2.5-2.6 + Part 3.1-3.2 + 9.3 DID 违背
Day 4:   Part 3.3-3.4 + 9.4 弱工具
Day 5:   Part 4 全部 + 8.3 因果森林分裂
```

**全面精通 (2 周)**
```
Week 1: 系统掌握内容
Week 2:
  Day 1-2: Part 5 + 8.2 DragonNet 多处理
  Day 3:   Part 6 全部
  Day 4-5: Part 7 全部
  Day 6:   Part 8 剩余 + Part 9 剩余
```

### 学习方法

1. **先理论后代码**：每个 notebook 先理解数学框架，再看实现
2. **动手做 TODO**：notebook 中的 TODO 是刻意设计的练习
3. **关联业务场景**：学完一个方法，想想工作中能用在哪
4. **及时看 Pitfalls**：学完一个主题后，**立即**看对应的 Part 9 陷阱章节
5. **按需深挖**：遇到实际问题时，回头看对应的 Part 8 技术细节

---

## 方法选择决策树

```
能做随机实验吗？
├── 能 → Part 1 (实验设计)
│       ├── 用户互相影响 → 1.4 网络效应
│       ├── 需要快速迭代 → 1.7 多臂老虎机
│       └── 标准 A/B → 1.0-1.3
│
└── 不能 → 有自然实验结构吗？
          ├── 有 → Part 3 (准实验)
          │       ├── 有前后 + 处理/对照 → 3.1 DID
          │       ├── 只有一个处理单位 → 3.2 合成控制
          │       ├── 有阈值断点 → 3.3 RDD
          │       └── 有工具变量 → 3.4 IV
          │
          └── 没有 → Part 2 (观测性研究)
                    ├── 需要个体效应 → Part 4/5
                    │       ├── 传统 ML → 4.2-4.4
                    │       └── 深度学习 → 5.2-5.4
                    ├── 高维特征 → 2.6 Double ML
                    └── 只需平均效应 → 2.2-2.4 PSM/IPW/DR
```

---

## 核心公式速查

| 概念 | 公式 | 章节 |
|------|------|------|
| 个体处理效应 | ITE = Y(1) - Y(0) | 0.1 |
| 平均处理效应 | ATE = E[Y(1) - Y(0)] | 0.1 |
| 混淆偏差 | Bias = γ × δ | 0.4 |
| 样本量 | n = 2σ²(z_α + z_β)² / δ² | 1.0 |
| CUPED | Y_adj = Y - θ(X_pre - X̄) | 1.2 |
| 倾向得分 | e(X) = P(T=1\|X) | 2.1 |
| IPW | E[Y(1)] = E[Y·T/e(X)] | 2.3 |
| DID | (Ȳ_T,post - Ȳ_T,pre) - (Ȳ_C,post - Ȳ_C,pre) | 3.1 |
| LATE | ITT / First Stage | 3.4 |
| CATE | τ(X) = E[Y(1) - Y(0) \| X] | 4.1 |

---

## 项目统计

- **总 Notebook 数量**: 54 个
- **总学习时长**: 约 100-150 小时
- **覆盖方法**: 30+ 种因果推断技术
- **业务场景**: 电商、营销、医疗、政策评估

---

> *「相关不是因果，但因果一定相关。学会区分它们，是数据科学家的核心能力。」*
