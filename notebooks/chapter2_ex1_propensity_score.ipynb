{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ ç¬¬äºŒç«  ç»ƒä¹  1: å€¾å‘å¾—åˆ†åŒ¹é… (Propensity Score Matching)\n",
    "\n",
    "---\n",
    "\n",
    "## ä»ã€Œæ‰¾ç›¸ä¼¼çš„äººã€å¼€å§‹\n",
    "\n",
    "åœ¨ç¬¬ä¸€ç« ï¼Œæˆ‘ä»¬çŸ¥é“äº†éšæœºå®éªŒä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸ºå¤„ç†ç»„å’Œæ§åˆ¶ç»„çš„ç‰¹å¾åˆ†å¸ƒç›¸åŒã€‚ä½†åœ¨è§‚æµ‹æ•°æ®ä¸­ï¼Œè¿™ä¸ªæ¡ä»¶é€šå¸¸ä¸æ»¡è¶³ã€‚\n",
    "\n",
    "é‚£æ€ä¹ˆåŠå‘¢ï¼Ÿ\n",
    "\n",
    "ä¸€ä¸ªç›´è§‰çš„æƒ³æ³•ï¼š**æ—¢ç„¶ä¸¤ç»„äººä¸ä¸€æ ·ï¼Œé‚£å°±æ‰¾ä¸€æ ·çš„å‘—ï¼**\n",
    "\n",
    "### ç›¸äº²çš„è‰ºæœ¯ ğŸ’‘\n",
    "\n",
    "æƒ³è±¡ä½ æ˜¯ä¸€ä¸ªç›¸äº²å¹³å°çš„ç®—æ³•å·¥ç¨‹å¸ˆã€‚ä½ è¦å¸®åŠ©è¯„ä¼°ã€Œé€ç«ç‘°èŠ±ã€å¯¹ã€Œç›¸äº²æˆåŠŸç‡ã€çš„å½±å“ã€‚\n",
    "\n",
    "é—®é¢˜æ˜¯ï¼šé€èŠ±çš„äººå’Œä¸é€èŠ±çš„äººæœ¬æ¥å°±ä¸ä¸€æ ·â€”â€”\n",
    "- é€èŠ±çš„äººå¯èƒ½æ›´æµªæ¼«\n",
    "- é€èŠ±çš„äººå¯èƒ½æ”¶å…¥æ›´é«˜ï¼ˆä¹°å¾—èµ·èŠ±ï¼‰\n",
    "- é€èŠ±çš„äººå¯èƒ½æ›´é‡è§†è¿™æ®µå…³ç³»\n",
    "\n",
    "æ‰€ä»¥ç®€å•æ¯”è¾ƒé€èŠ±è€…å’Œä¸é€èŠ±è€…çš„æˆåŠŸç‡æ˜¯æœ‰åçš„ã€‚\n",
    "\n",
    "**è§£å†³æ–¹æ¡ˆ**: ä¸ºæ¯ä¸ªé€èŠ±çš„äººï¼Œæ‰¾ä¸€ä¸ªã€Œå‡ ä¹ä¸€æ¨¡ä¸€æ ·ä½†æ²¡é€èŠ±ã€çš„äººåšå¯¹æ¯”ï¼\n",
    "\n",
    "è¿™å°±æ˜¯**åŒ¹é… (Matching)** çš„æ ¸å¿ƒæ€æƒ³ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š æœ¬èŠ‚å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "1. ç†è§£å€¾å‘å¾—åˆ†çš„æ¦‚å¿µå’Œæ•°å­¦åŸç†\n",
    "2. å®ç°å€¾å‘å¾—åˆ†åŒ¹é… (PSM) ç®—æ³•\n",
    "3. è¯„ä¼°åŒ¹é…è´¨é‡ï¼ˆSMDã€æ–¹å·®æ¯”ï¼‰\n",
    "4. ç†è§£ PSM çš„å‡è®¾å’Œå±€é™æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "# è®¾ç½®\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæ¯•ï¼è®©æˆ‘ä»¬å¼€å§‹å­¦ä¹  PSMï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸŒŸ Part 1: ä»€ä¹ˆæ˜¯å€¾å‘å¾—åˆ†ï¼Ÿ\n",
    "\n",
    "### æ ¸å¿ƒå®šä¹‰\n",
    "\n",
    "**å€¾å‘å¾—åˆ† (Propensity Score)** æ˜¯ç»™å®šåå˜é‡ Xï¼Œä¸ªä½“æ¥å—å¤„ç†çš„æ¦‚ç‡ï¼š\n",
    "\n",
    "$$e(X) = P(T=1 | X)$$\n",
    "\n",
    "### ç›´è§‰ç†è§£\n",
    "\n",
    "å€¾å‘å¾—åˆ†å‘Šè¯‰æˆ‘ä»¬ï¼šã€Œè¿™ä¸ªäººæœ‰å¤šå¤§å¯èƒ½æ¥å—å¤„ç†ã€\n",
    "\n",
    "| åœºæ™¯ | å¤„ç† T | å€¾å‘å¾—åˆ†çš„å«ä¹‰ |\n",
    "|-----|--------|---------------|\n",
    "| è¥é”€ | å‘ä¼˜æƒ åˆ¸ | ç”¨æˆ·å¤šå¤§æ¦‚ç‡ä¼šæ”¶åˆ°åˆ¸ |\n",
    "| åŒ»å­¦ | æœç”¨æ–°è¯ | æ‚£è€…å¤šå¤§æ¦‚ç‡ä¼šè¢«å¤„æ–¹æ–°è¯ |\n",
    "| æ•™è‚² | å‚åŠ åŸ¹è®­ | å‘˜å·¥å¤šå¤§æ¦‚ç‡ä¼šå‚åŠ åŸ¹è®­ |\n",
    "\n",
    "### ä¸ºä»€ä¹ˆå€¾å‘å¾—åˆ†å¦‚æ­¤ç¥å¥‡ï¼Ÿ\n",
    "\n",
    "**Rosenbaum & Rubin (1983)** è¯æ˜äº†ä¸€ä¸ªæƒŠäººçš„å®šç†ï¼š\n",
    "\n",
    "> å¦‚æœç»™å®š Xï¼Œæ½œåœ¨ç»“æœä¸ T ç‹¬ç«‹ï¼Œé‚£ä¹ˆç»™å®š e(X)ï¼Œæ½œåœ¨ç»“æœä¹Ÿä¸ T ç‹¬ç«‹ï¼\n",
    "\n",
    "$$Y(0), Y(1) \\perp T | X \\Rightarrow Y(0), Y(1) \\perp T | e(X)$$\n",
    "\n",
    "**ç¿»è¯‘æˆäººè¯**ï¼šæˆ‘ä»¬ä¸éœ€è¦åœ¨æ¯ä¸ªåå˜é‡ä¸Šéƒ½åŒ¹é…ï¼Œåªéœ€è¦åœ¨å€¾å‘å¾—åˆ†è¿™ä¸€ä¸ªæ•°ä¸ŠåŒ¹é…å°±å¤Ÿäº†ï¼\n",
    "\n",
    "è¿™å¤§å¤§é™ä½äº†åŒ¹é…çš„éš¾åº¦ï¼Œå› ä¸ºæˆ‘ä»¬æŠŠé«˜ç»´çš„ X å‹ç¼©æˆäº†ä¸€ç»´çš„ e(X)ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¬ åŠ¨æ‰‹ä¼°è®¡å€¾å‘å¾—åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confounded_data(n: int = 2000, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆæœ‰æ··æ·†çš„è§‚æµ‹æ•°æ®\n",
    "    \n",
    "    DAG: X -> T, X -> Y, T -> Y\n",
    "    \n",
    "    åœºæ™¯: ç ”ç©¶ã€Œå¥èº«ã€å¯¹ã€Œå¥åº·æŒ‡æ•°ã€çš„å½±å“\n",
    "    - X1: å¹´é¾„ï¼ˆå¹´è½»äººæ›´çˆ±å¥èº«ï¼Œå¥åº·ä¹Ÿæ›´å¥½ï¼‰\n",
    "    - X2: æ”¶å…¥ï¼ˆé«˜æ”¶å…¥æ›´å¯èƒ½æœ‰æ—¶é—´å¥èº«ï¼‰\n",
    "    - X3: é—ä¼ å› ç´ ï¼ˆä¸å¥èº«æ— å…³ï¼‰\n",
    "    \n",
    "    çœŸå® ATE = 2\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆä¸‰ä¸ªåå˜é‡\n",
    "    X1 = None  # ğŸ‘ˆ ä½ çš„ä»£ç : np.random.randn(n)  # å¹´é¾„ï¼ˆæ ‡å‡†åŒ–ï¼‰\n",
    "    X2 = None  # ğŸ‘ˆ ä½ çš„ä»£ç : np.random.randn(n)  # æ”¶å…¥\n",
    "    X3 = None  # ğŸ‘ˆ ä½ çš„ä»£ç : np.random.randn(n)  # é—ä¼ å› ç´ \n",
    "    \n",
    "    # TODO: ç”Ÿæˆå¤„ç† Tï¼ˆæ˜¯å¦å¥èº«ï¼‰\n",
    "    # å¹´è½»äººï¼ˆX1ä½ï¼‰å’Œé«˜æ”¶å…¥è€…ï¼ˆX2é«˜ï¼‰æ›´å¯èƒ½å¥èº«\n",
    "    # logit(e) = -0.5*X1 + 0.8*X2\n",
    "    propensity_logit = -0.5 * X1 + 0.8 * X2 if X1 is not None else np.zeros(n)\n",
    "    propensity = 1 / (1 + np.exp(-propensity_logit))\n",
    "    T = None  # ğŸ‘ˆ ä½ çš„ä»£ç : np.random.binomial(1, propensity)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆç»“æœ Yï¼ˆå¥åº·æŒ‡æ•°ï¼‰\n",
    "    # Y = 50 + 2*T - 1.5*X1 + 0.8*X2 + 0.5*X3 + noise\n",
    "    # çœŸå® ATE = 2\n",
    "    Y = None  # ğŸ‘ˆ ä½ çš„ä»£ç \n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'X1': X1, 'X2': X2, 'X3': X3, 'T': T, 'Y': Y\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_propensity_score(X: np.ndarray, T: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    ä¼°è®¡å€¾å‘å¾—åˆ† e(X) = P(T=1|X)\n",
    "    \n",
    "    ä½¿ç”¨é€»è¾‘å›å½’æ¥ä¼°è®¡\n",
    "    \n",
    "    Args:\n",
    "        X: ç‰¹å¾çŸ©é˜µ (n, p)\n",
    "        T: å¤„ç†çŠ¶æ€ (n,)\n",
    "    \n",
    "    Returns:\n",
    "        å€¾å‘å¾—åˆ†æ•°ç»„ (n,)\n",
    "    \"\"\"\n",
    "    # TODO: ä½¿ç”¨ LogisticRegression æ‹Ÿåˆ T ~ X\n",
    "    # æç¤º: \n",
    "    # 1. åˆ›å»º LogisticRegression(max_iter=1000)\n",
    "    # 2. è°ƒç”¨ fit(X, T)\n",
    "    # 3. ä½¿ç”¨ predict_proba(X)[:, 1] è·å– P(T=1|X)\n",
    "    \n",
    "    # ğŸ‘ˆ ä½ çš„ä»£ç \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•æ•°æ®ç”Ÿæˆå’Œå€¾å‘å¾—åˆ†ä¼°è®¡\n",
    "df = generate_confounded_data(n=2000, seed=42)\n",
    "\n",
    "if df['X1'] is not None:\n",
    "    print(\"ğŸ“Š æ•°æ®æ¦‚è§ˆ:\")\n",
    "    print(f\"   æ ·æœ¬é‡: {len(df)}\")\n",
    "    print(f\"   å¤„ç†ç»„: {df['T'].sum()} ({df['T'].mean()*100:.1f}%)\")\n",
    "    print(f\"   æ§åˆ¶ç»„: {(1-df['T']).sum()} ({(1-df['T']).mean()*100:.1f}%)\")\n",
    "    \n",
    "    # æœ´ç´ ä¼°è®¡\n",
    "    naive_ate = df[df['T']==1]['Y'].mean() - df[df['T']==0]['Y'].mean()\n",
    "    print(f\"\\n   æœ´ç´  ATE ä¼°è®¡: {naive_ate:.4f}\")\n",
    "    print(f\"   çœŸå® ATE: 2.0\")\n",
    "    print(f\"   åå·®: {naive_ate - 2.0:+.4f}\")\n",
    "    \n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"âŒ è¯·å®Œæˆ generate_confounded_data å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¼°è®¡å€¾å‘å¾—åˆ†\n",
    "if df['X1'] is not None:\n",
    "    X = df[['X1', 'X2', 'X3']].values\n",
    "    T = df['T'].values\n",
    "    Y = df['Y'].values\n",
    "    \n",
    "    propensity = estimate_propensity_score(X, T)\n",
    "    \n",
    "    if propensity is not None:\n",
    "        df['propensity'] = propensity\n",
    "        \n",
    "        print(\"ğŸ“ˆ å€¾å‘å¾—åˆ†ç»Ÿè®¡:\")\n",
    "        print(f\"   èŒƒå›´: [{propensity.min():.4f}, {propensity.max():.4f}]\")\n",
    "        print(f\"   å¤„ç†ç»„å¹³å‡: {propensity[T==1].mean():.4f}\")\n",
    "        print(f\"   æ§åˆ¶ç»„å¹³å‡: {propensity[T==0].mean():.4f}\")\n",
    "        \n",
    "        # å¯è§†åŒ–\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # å›¾1: å€¾å‘å¾—åˆ†åˆ†å¸ƒ\n",
    "        ax1 = axes[0]\n",
    "        ax1.hist(propensity[T==1], bins=30, alpha=0.5, label='å¤„ç†ç»„', color='coral', density=True)\n",
    "        ax1.hist(propensity[T==0], bins=30, alpha=0.5, label='æ§åˆ¶ç»„', color='steelblue', density=True)\n",
    "        ax1.set_xlabel('å€¾å‘å¾—åˆ† e(X)', fontsize=12)\n",
    "        ax1.set_ylabel('å¯†åº¦', fontsize=12)\n",
    "        ax1.set_title('å€¾å‘å¾—åˆ†åˆ†å¸ƒ', fontsize=14)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # å›¾2: å…±åŒæ”¯æ’‘\n",
    "        ax2 = axes[1]\n",
    "        ax2.scatter(propensity[T==0], np.random.uniform(-0.1, 0.1, (T==0).sum()), \n",
    "                   alpha=0.3, label='æ§åˆ¶ç»„', c='steelblue', s=20)\n",
    "        ax2.scatter(propensity[T==1], np.random.uniform(0.9, 1.1, (T==1).sum()), \n",
    "                   alpha=0.3, label='å¤„ç†ç»„', c='coral', s=20)\n",
    "        \n",
    "        # é‡å åŒºåŸŸ\n",
    "        overlap_min = max(propensity[T==0].min(), propensity[T==1].min())\n",
    "        overlap_max = min(propensity[T==0].max(), propensity[T==1].max())\n",
    "        ax2.axvspan(overlap_min, overlap_max, alpha=0.2, color='green', label='å…±åŒæ”¯æ’‘åŒºåŸŸ')\n",
    "        \n",
    "        ax2.set_xlabel('å€¾å‘å¾—åˆ† e(X)', fontsize=12)\n",
    "        ax2.set_yticks([0, 1])\n",
    "        ax2.set_yticklabels(['æ§åˆ¶ç»„', 'å¤„ç†ç»„'])\n",
    "        ax2.set_title('å…±åŒæ”¯æ’‘ (Common Support)', fontsize=14)\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"âŒ è¯·å®Œæˆ estimate_propensity_score å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”— Part 2: å®ç°å€¾å‘å¾—åˆ†åŒ¹é…\n",
    "\n",
    "### åŒ¹é…ç®—æ³•\n",
    "\n",
    "æœ€å¸¸ç”¨çš„åŒ¹é…æ–¹æ³•æ˜¯**æœ€è¿‘é‚»åŒ¹é… (Nearest Neighbor Matching)**ï¼š\n",
    "\n",
    "1. å¯¹äºæ¯ä¸ªå¤„ç†ç»„ä¸ªä½“ï¼Œæ‰¾åˆ°å€¾å‘å¾—åˆ†æœ€æ¥è¿‘çš„æ§åˆ¶ç»„ä¸ªä½“\n",
    "2. è¿™äº›é…å¯¹å°±æ˜¯ã€Œå¯æ¯”è¾ƒã€çš„\n",
    "3. ç”¨é…å¯¹åçš„æ•°æ®ä¼°è®¡ ATE\n",
    "\n",
    "### å¡å°ºåŒ¹é… (Caliper Matching)\n",
    "\n",
    "æœ‰æ—¶å€™æœ€è¿‘çš„é‚»å±…ä¹Ÿå¯èƒ½å¾ˆè¿œï¼Œè¿™æ—¶å€™å¯ä»¥è®¾ç½®ä¸€ä¸ªã€Œå¡å°ºã€é™åˆ¶æœ€å¤§è·ç¦»ï¼š\n",
    "\n",
    "$$|e(X_i) - e(X_j)| < \\text{caliper}$$\n",
    "\n",
    "è¶…è¿‡å¡å°ºçš„åŒ¹é…å°†è¢«ä¸¢å¼ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propensity_score_matching(\n",
    "    propensity: np.ndarray,\n",
    "    treatment: np.ndarray,\n",
    "    n_neighbors: int = 1,\n",
    "    caliper: Optional[float] = None\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    æ‰§è¡Œå€¾å‘å¾—åˆ†åŒ¹é…\n",
    "    \n",
    "    ä¸ºæ¯ä¸ªå¤„ç†ç»„ä¸ªä½“æ‰¾åˆ°å€¾å‘å¾—åˆ†æœ€æ¥è¿‘çš„æ§åˆ¶ç»„ä¸ªä½“\n",
    "    \n",
    "    Args:\n",
    "        propensity: å€¾å‘å¾—åˆ†\n",
    "        treatment: å¤„ç†çŠ¶æ€\n",
    "        n_neighbors: åŒ¹é…çš„é‚»å±…æ•°é‡\n",
    "        caliper: å¡å°ºå®½åº¦ï¼ˆæœ€å¤§å…è®¸çš„å€¾å‘å¾—åˆ†å·®å¼‚ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "        (matched_treated_indices, matched_control_indices)\n",
    "    \"\"\"\n",
    "    # è·å–å¤„ç†ç»„å’Œæ§åˆ¶ç»„çš„ç´¢å¼•\n",
    "    treated_idx = np.where(treatment == 1)[0]\n",
    "    control_idx = np.where(treatment == 0)[0]\n",
    "    \n",
    "    # TODO: ä½¿ç”¨ NearestNeighbors è¿›è¡ŒåŒ¹é…\n",
    "    # 1. ç”¨æ§åˆ¶ç»„çš„å€¾å‘å¾—åˆ†è®­ç»ƒ KNN\n",
    "    # 2. ä¸ºæ¯ä¸ªå¤„ç†ç»„ä¸ªä½“æ‰¾æœ€è¿‘çš„æ§åˆ¶ç»„ä¸ªä½“\n",
    "    \n",
    "    # ğŸ‘ˆ ä½ çš„ä»£ç \n",
    "    # knn = NearestNeighbors(n_neighbors=n_neighbors, metric='euclidean')\n",
    "    # knn.fit(propensity[control_idx].reshape(-1, 1))\n",
    "    # distances, indices = knn.kneighbors(propensity[treated_idx].reshape(-1, 1))\n",
    "    \n",
    "    knn = None\n",
    "    distances = None\n",
    "    indices = None\n",
    "    \n",
    "    if knn is None:\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    # åº”ç”¨å¡å°ºçº¦æŸ\n",
    "    matched_treated = []\n",
    "    matched_control = []\n",
    "    \n",
    "    for i, (dist, idx) in enumerate(zip(distances, indices)):\n",
    "        # TODO: å¦‚æœä½¿ç”¨å¡å°ºï¼Œæ£€æŸ¥è·ç¦»æ˜¯å¦åœ¨èŒƒå›´å†…\n",
    "        if caliper is None or dist[0] <= caliper:\n",
    "            matched_treated.append(treated_idx[i])\n",
    "            matched_control.append(control_idx[idx[0]])\n",
    "    \n",
    "    return np.array(matched_treated), np.array(matched_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_ate_psm(\n",
    "    Y: np.ndarray,\n",
    "    matched_treated_idx: np.ndarray,\n",
    "    matched_control_idx: np.ndarray\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ PSM ä¼°è®¡ ATE\n",
    "    \n",
    "    ATE = mean(Y_treated) - mean(Y_control)\n",
    "    \n",
    "    Returns:\n",
    "        (ATEä¼°è®¡, æ ‡å‡†è¯¯)\n",
    "    \"\"\"\n",
    "    if len(matched_treated_idx) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    # TODO: è®¡ç®—åŒ¹é…åçš„ ATE\n",
    "    y_treated = Y[matched_treated_idx]\n",
    "    y_control = Y[matched_control_idx]\n",
    "    \n",
    "    ate = None  # ğŸ‘ˆ ä½ çš„ä»£ç : y_treated.mean() - y_control.mean()\n",
    "    \n",
    "    # æ ‡å‡†è¯¯ï¼ˆç®€åŒ–ç‰ˆï¼‰\n",
    "    diff = y_treated - y_control\n",
    "    se = None  # ğŸ‘ˆ ä½ çš„ä»£ç : diff.std() / np.sqrt(len(diff))\n",
    "    \n",
    "    return ate, se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯• PSM\n",
    "if propensity is not None:\n",
    "    matched_t, matched_c = propensity_score_matching(propensity, T, caliper=None)\n",
    "    \n",
    "    if len(matched_t) > 0:\n",
    "        print(\"ğŸ”— PSM åŒ¹é…ç»“æœ:\")\n",
    "        print(f\"   åŒ¹é…å¯¹æ•°: {len(matched_t)}\")\n",
    "        print(f\"   åŒ¹é…ç‡: {len(matched_t) / T.sum() * 100:.1f}%\")\n",
    "        \n",
    "        # ä¼°è®¡ ATE\n",
    "        psm_ate, psm_se = estimate_ate_psm(Y, matched_t, matched_c)\n",
    "        \n",
    "        if psm_ate is not None:\n",
    "            print(f\"\\nğŸ“Š ATE ä¼°è®¡:\")\n",
    "            print(f\"   PSM ATE: {psm_ate:.4f} Â± {psm_se:.4f}\")\n",
    "            print(f\"   95% CI: [{psm_ate - 1.96*psm_se:.4f}, {psm_ate + 1.96*psm_se:.4f}]\")\n",
    "            print(f\"   åå·®: {psm_ate - 2.0:+.4f}\")\n",
    "            print(f\"\\n   å¯¹æ¯”æœ´ç´ ä¼°è®¡: {naive_ate:.4f} (åå·®: {naive_ate - 2.0:+.4f})\")\n",
    "            \n",
    "            if abs(psm_ate - 2.0) < abs(naive_ate - 2.0):\n",
    "                print(f\"\\n   âœ… PSM å‡å°‘äº† {abs(naive_ate - 2.0) - abs(psm_ate - 2.0):.2f} çš„åå·®ï¼\")\n",
    "        else:\n",
    "            print(\"âŒ è¯·å®Œæˆ estimate_ate_psm å‡½æ•°ï¼\")\n",
    "    else:\n",
    "        print(\"âŒ è¯·å®Œæˆ propensity_score_matching å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Part 3: è¯„ä¼°åŒ¹é…è´¨é‡\n",
    "\n",
    "åŒ¹é…ä¹‹åï¼Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥ï¼š**å¤„ç†ç»„å’Œæ§åˆ¶ç»„ç°åœ¨çœŸçš„ã€Œå¯æ¯”è¾ƒã€äº†å—ï¼Ÿ**\n",
    "\n",
    "### æ ‡å‡†åŒ–å‡å€¼å·® (Standardized Mean Difference, SMD)\n",
    "\n",
    "$$\\text{SMD} = \\frac{\\bar{X}_{\\text{treated}} - \\bar{X}_{\\text{control}}}{\\sqrt{(s^2_{\\text{treated}} + s^2_{\\text{control}})/2}}$$\n",
    "\n",
    "**ç»éªŒæ³•åˆ™**: |SMD| < 0.1 è¡¨ç¤ºè‰¯å¥½çš„å¹³è¡¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_smd(X_treated: np.ndarray, X_control: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    è®¡ç®—æ ‡å‡†åŒ–å‡å€¼å·® (SMD)\n",
    "    \n",
    "    SMD = (mean_treated - mean_control) / pooled_std\n",
    "    \"\"\"\n",
    "    # TODO: è®¡ç®—å‡å€¼å·®\n",
    "    mean_treated = X_treated.mean(axis=0)\n",
    "    mean_control = X_control.mean(axis=0)\n",
    "    mean_diff = None  # ğŸ‘ˆ ä½ çš„ä»£ç \n",
    "    \n",
    "    # TODO: è®¡ç®—åˆå¹¶æ ‡å‡†å·®\n",
    "    var_treated = X_treated.var(axis=0)\n",
    "    var_control = X_control.var(axis=0)\n",
    "    pooled_std = None  # ğŸ‘ˆ ä½ çš„ä»£ç : np.sqrt((var_treated + var_control) / 2)\n",
    "    \n",
    "    # TODO: è®¡ç®— SMD\n",
    "    smd = None  # ğŸ‘ˆ ä½ çš„ä»£ç : mean_diff / pooled_std\n",
    "    \n",
    "    return smd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_balance(\n",
    "    X: np.ndarray,\n",
    "    treatment: np.ndarray,\n",
    "    matched_treated_idx: Optional[np.ndarray] = None,\n",
    "    matched_control_idx: Optional[np.ndarray] = None,\n",
    "    feature_names: List[str] = None\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    è¯„ä¼°åŒ¹é…å‰åçš„åå˜é‡å¹³è¡¡\n",
    "    \"\"\"\n",
    "    if feature_names is None:\n",
    "        feature_names = [f'X{i+1}' for i in range(X.shape[1])]\n",
    "    \n",
    "    # åŒ¹é…å‰çš„ SMD\n",
    "    smd_before = compute_smd(X[treatment == 1], X[treatment == 0])\n",
    "    \n",
    "    # åŒ¹é…åçš„ SMD\n",
    "    if matched_treated_idx is not None and matched_control_idx is not None:\n",
    "        smd_after = compute_smd(X[matched_treated_idx], X[matched_control_idx])\n",
    "    else:\n",
    "        smd_after = None\n",
    "    \n",
    "    return smd_before, smd_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯„ä¼°åŒ¹é…è´¨é‡\n",
    "if len(matched_t) > 0:\n",
    "    smd_before, smd_after = evaluate_balance(X, T, matched_t, matched_c)\n",
    "    \n",
    "    if smd_before is not None and smd_after is not None:\n",
    "        feature_names = ['X1 (å¹´é¾„)', 'X2 (æ”¶å…¥)', 'X3 (é—ä¼ )']\n",
    "        \n",
    "        print(\"ğŸ“ åå˜é‡å¹³è¡¡æ£€æŸ¥:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"{'å˜é‡':<15} {'åŒ¹é…å‰ SMD':>12} {'åŒ¹é…å SMD':>12} {'æ”¹å–„':>8}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for i, name in enumerate(feature_names):\n",
    "            before = smd_before[i]\n",
    "            after = smd_after[i]\n",
    "            improvement = abs(before) - abs(after)\n",
    "            status = 'âœ…' if abs(after) < 0.1 else 'âš ï¸'\n",
    "            print(f\"{name:<15} {before:>12.4f} {after:>12.4f} {improvement:>+8.4f} {status}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "        print(f\"{'å¹³å‡ |SMD|':<15} {np.abs(smd_before).mean():>12.4f} {np.abs(smd_after).mean():>12.4f}\")\n",
    "        \n",
    "        # å¯è§†åŒ–\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        y_pos = np.arange(len(feature_names))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = ax.barh(y_pos - width/2, np.abs(smd_before), width, \n",
    "                       label='åŒ¹é…å‰', color='coral', alpha=0.7)\n",
    "        bars2 = ax.barh(y_pos + width/2, np.abs(smd_after), width, \n",
    "                       label='åŒ¹é…å', color='steelblue', alpha=0.7)\n",
    "        \n",
    "        ax.axvline(0.1, color='green', linestyle='--', linewidth=2, label='|SMD| = 0.1 é˜ˆå€¼')\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(feature_names)\n",
    "        ax.set_xlabel('|SMD|', fontsize=12)\n",
    "        ax.set_title('åŒ¹é…å‰åçš„åå˜é‡å¹³è¡¡', fontsize=14)\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.invert_yaxis()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"âŒ è¯·å®Œæˆ compute_smd å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ” Part 4: å…±åŒæ”¯æ’‘æ£€æŸ¥\n",
    "\n",
    "### ä»€ä¹ˆæ˜¯å…±åŒæ”¯æ’‘ (Common Support)ï¼Ÿ\n",
    "\n",
    "å…±åŒæ”¯æ’‘å‡è®¾è¦æ±‚ï¼šå¯¹äºä»»ä½•åå˜é‡å€¼ Xï¼Œéƒ½æœ‰ä¸€å®šæ¦‚ç‡æ¥å—æˆ–ä¸æ¥å—å¤„ç†ï¼š\n",
    "\n",
    "$$0 < P(T=1|X) < 1$$\n",
    "\n",
    "**ç›´è§‰ç†è§£**ï¼šå¦‚æœæŸäº›äºº 100% ä¼šæ¥å—å¤„ç†ï¼ˆæˆ– 100% ä¸ä¼šï¼‰ï¼Œé‚£æˆ‘ä»¬å°±æ‰¾ä¸åˆ°å¯¹ç…§ç»„æ¥æ¯”è¾ƒäº†ã€‚\n",
    "\n",
    "**ä¾‹å­**ï¼šå¦‚æœåªæœ‰å¹´æ”¶å…¥è¶…è¿‡ 100 ä¸‡çš„äººæ‰èƒ½ä¹°å¾—èµ·æŸç§å¥¢ä¾ˆä¿å¥å“ï¼Œé‚£æˆ‘ä»¬æ— æ³•ç”¨è¿™ä¸ªæ•°æ®æ¥æ¨æ–­ä¿å¥å“å¯¹æ™®é€šäººçš„æ•ˆæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_common_support(\n",
    "    propensity: np.ndarray,\n",
    "    treatment: np.ndarray\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    æ£€æŸ¥å…±åŒæ”¯æ’‘å‡è®¾\n",
    "    \"\"\"\n",
    "    prop_treated = propensity[treatment == 1]\n",
    "    prop_control = propensity[treatment == 0]\n",
    "    \n",
    "    # TODO: è®¡ç®—é‡å åŒºé—´\n",
    "    overlap_min = None  # ğŸ‘ˆ ä½ çš„ä»£ç : max(prop_treated.min(), prop_control.min())\n",
    "    overlap_max = None  # ğŸ‘ˆ ä½ çš„ä»£ç : min(prop_treated.max(), prop_control.max())\n",
    "    \n",
    "    # TODO: è®¡ç®—åœ¨é‡å åŒºé—´å¤–çš„æ ·æœ¬æ¯”ä¾‹\n",
    "    n_outside = 0\n",
    "    if overlap_min is not None and overlap_max is not None:\n",
    "        n_outside = ((propensity < overlap_min) | (propensity > overlap_max)).sum()\n",
    "    outside_pct = n_outside / len(propensity) if overlap_min is not None else 0\n",
    "    \n",
    "    return {\n",
    "        'treated_min': prop_treated.min(),\n",
    "        'treated_max': prop_treated.max(),\n",
    "        'control_min': prop_control.min(),\n",
    "        'control_max': prop_control.max(),\n",
    "        'overlap_min': overlap_min,\n",
    "        'overlap_max': overlap_max,\n",
    "        'outside_overlap_pct': outside_pct * 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥å…±åŒæ”¯æ’‘\n",
    "if propensity is not None:\n",
    "    support = check_common_support(propensity, T)\n",
    "    \n",
    "    if support['overlap_min'] is not None:\n",
    "        print(\"ğŸ” å…±åŒæ”¯æ’‘æ£€æŸ¥:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"å¤„ç†ç»„å€¾å‘å¾—åˆ†èŒƒå›´: [{support['treated_min']:.4f}, {support['treated_max']:.4f}]\")\n",
    "        print(f\"æ§åˆ¶ç»„å€¾å‘å¾—åˆ†èŒƒå›´: [{support['control_min']:.4f}, {support['control_max']:.4f}]\")\n",
    "        print(f\"é‡å åŒºé—´: [{support['overlap_min']:.4f}, {support['overlap_max']:.4f}]\")\n",
    "        print(f\"åŒºé—´å¤–æ ·æœ¬æ¯”ä¾‹: {support['outside_overlap_pct']:.2f}%\")\n",
    "        \n",
    "        if support['outside_overlap_pct'] < 5:\n",
    "            print(\"\\nâœ… å…±åŒæ”¯æ’‘è‰¯å¥½ï¼\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ æœ‰è¾ƒå¤šæ ·æœ¬åœ¨å…±åŒæ”¯æ’‘åŒºé—´å¤–ï¼Œå¯èƒ½éœ€è¦ä¿®å‰ªæ ·æœ¬ã€‚\")\n",
    "    else:\n",
    "        print(\"âŒ è¯·å®Œæˆ check_common_support å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸšï¸ Part 5: å¡å°ºå®½åº¦çš„é€‰æ‹©\n",
    "\n",
    "å¡å°ºå®½åº¦æ˜¯ä¸€ä¸ªæƒè¡¡ï¼š\n",
    "\n",
    "| å¡å°ºå®½åº¦ | åŒ¹é…ç‡ | åŒ¹é…è´¨é‡ |\n",
    "|---------|--------|----------|\n",
    "| å¾ˆå° | ä½ï¼ˆå¾ˆå¤šåŒ¹é…ä¸ä¸Šï¼‰| é«˜ï¼ˆåŒ¹é…å¾ˆç²¾ç¡®ï¼‰|\n",
    "| å¾ˆå¤§/æ— é™ | é«˜ï¼ˆéƒ½èƒ½åŒ¹é…ä¸Šï¼‰| ä½ï¼ˆåŒ¹é…å¯èƒ½å¾ˆå·®ï¼‰|\n",
    "\n",
    "å¸¸ç”¨çš„å¡å°ºå®½åº¦æ˜¯å€¾å‘å¾—åˆ†æ ‡å‡†å·®çš„ 0.2 å€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_caliper_widths(\n",
    "    propensity: np.ndarray,\n",
    "    treatment: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    caliper_widths: List[float] = [0.01, 0.05, 0.1, 0.2, None]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    æ¯”è¾ƒä¸åŒå¡å°ºå®½åº¦çš„æ•ˆæœ\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for caliper in caliper_widths:\n",
    "        matched_t, matched_c = propensity_score_matching(propensity, treatment, caliper=caliper)\n",
    "        \n",
    "        if len(matched_t) == 0:\n",
    "            continue\n",
    "        \n",
    "        # è®¡ç®—åŒ¹é…ç‡\n",
    "        match_rate = len(matched_t) / treatment.sum()\n",
    "        \n",
    "        # è®¡ç®— ATE\n",
    "        ate, se = estimate_ate_psm(Y, matched_t, matched_c)\n",
    "        \n",
    "        results.append({\n",
    "            'caliper': caliper if caliper else 'æ— é™',\n",
    "            'matched_pairs': len(matched_t),\n",
    "            'match_rate': f\"{match_rate:.1%}\",\n",
    "            'ate': ate,\n",
    "            'se': se,\n",
    "            'bias': ate - 2.0 if ate else None\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¯”è¾ƒä¸åŒå¡å°º\n",
    "if propensity is not None:\n",
    "    caliper_results = compare_caliper_widths(propensity, T, Y)\n",
    "    \n",
    "    if not caliper_results.empty:\n",
    "        print(\"ğŸšï¸ ä¸åŒå¡å°ºå®½åº¦çš„æ¯”è¾ƒ:\")\n",
    "        print(\"=\" * 70)\n",
    "        display(caliper_results)\n",
    "        \n",
    "        print(\"\\nğŸ’¡ è§‚å¯Ÿ:\")\n",
    "        print(\"   - å¡å°ºè¶Šå°ï¼ŒåŒ¹é…è¶Šç²¾ç¡®ï¼Œä½†åŒ¹é…å¯¹æ•°è¶Šå°‘\")\n",
    "        print(\"   - å¡å°ºè¿‡å°å¯èƒ½å¯¼è‡´ä¼°è®¡ä¸ç¨³å®šï¼ˆæ ‡å‡†è¯¯å¢å¤§ï¼‰\")\n",
    "        print(\"   - æ¨èä½¿ç”¨ 0.2 Ã— std(propensity) ä½œä¸ºå¡å°º\")\n",
    "        print(f\"   - æœ¬æ•°æ®æ¨èå¡å°º: {0.2 * propensity.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Part 6: æ€è€ƒé¢˜\n",
    "\n",
    "### é—®é¢˜ 1: å€¾å‘å¾—åˆ†çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆåœ¨å€¾å‘å¾—åˆ†ä¸ŠåŒ¹é…å¯ä»¥å¹³è¡¡åå˜é‡ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 2: PSM ä¼°è®¡çš„æ˜¯ ATE è¿˜æ˜¯ ATTï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**æç¤º:** æƒ³æƒ³æˆ‘ä»¬æ˜¯ä¸ºè°æ‰¾åŒ¹é…å¯¹è±¡çš„...\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 3: ä»€ä¹ˆæ˜¯å…±åŒæ”¯æ’‘å‡è®¾ï¼Ÿä¸ºä»€ä¹ˆå®ƒå¾ˆé‡è¦ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 4: å¦‚æœåŒ¹é…åæŸäº›åå˜é‡çš„ SMD ä»ç„¶å¾ˆå¤§ï¼Œåº”è¯¥æ€ä¹ˆåŠï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 5: PSM ç›¸æ¯”çº¿æ€§å›å½’è°ƒæ•´æœ‰ä»€ä¹ˆä¼˜ç¼ºç‚¹ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ‰ æ€»ç»“\n",
    "\n",
    "### æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "| æ¦‚å¿µ | å®šä¹‰ | ä½œç”¨ |\n",
    "|-----|------|------|\n",
    "| å€¾å‘å¾—åˆ† | $e(X) = P(T=1|X)$ | æŠŠé«˜ç»´ X å‹ç¼©æˆä¸€ç»´ |\n",
    "| PSM | åœ¨ e(X) ä¸Šå¯»æ‰¾æœ€è¿‘é‚» | åˆ›å»ºå¯æ¯”è¾ƒçš„é…å¯¹ |\n",
    "| SMD | æ ‡å‡†åŒ–å‡å€¼å·® | è¯„ä¼°åå˜é‡å¹³è¡¡ |\n",
    "| å…±åŒæ”¯æ’‘ | $0 < e(X) < 1$ | ç¡®ä¿å¯æ¯”è¾ƒæ€§ |\n",
    "\n",
    "### PSM çš„æ­¥éª¤\n",
    "\n",
    "1. **ä¼°è®¡å€¾å‘å¾—åˆ†**: ç”¨é€»è¾‘å›å½’æ‹Ÿåˆ $T \\sim X$\n",
    "2. **æ£€æŸ¥å…±åŒæ”¯æ’‘**: ç¡®ä¿ä¸¤ç»„çš„å€¾å‘å¾—åˆ†æœ‰é‡å \n",
    "3. **æ‰§è¡ŒåŒ¹é…**: ä¸ºæ¯ä¸ªå¤„ç†ä¸ªä½“æ‰¾æœ€ç›¸ä¼¼çš„æ§åˆ¶ä¸ªä½“\n",
    "4. **è¯„ä¼°å¹³è¡¡**: æ£€æŸ¥åŒ¹é…åçš„ SMD\n",
    "5. **ä¼°è®¡æ•ˆåº”**: ç”¨åŒ¹é…æ ·æœ¬è®¡ç®— ATE\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "PSM æœ‰ä¸€ä¸ªé—®é¢˜ï¼šå®ƒä¸¢å¼ƒäº†å¾ˆå¤šæ ·æœ¬ï¼ˆæœªè¢«åŒ¹é…çš„æ§åˆ¶ç»„ï¼‰ã€‚ä¸‹ä¸€ä¸ªç»ƒä¹ æˆ‘ä»¬å°†å­¦ä¹ **é€†æ¦‚ç‡åŠ æƒ (IPW)**â€”â€”ä¸€ç§åˆ©ç”¨æ‰€æœ‰æ ·æœ¬çš„æ–¹æ³•ï¼\n",
    "\n",
    "---\n",
    "\n",
    "**ã€Œæ‰¾åˆ°å¯¹çš„äººæ¯”è¾ƒï¼Œæ‰èƒ½å¾—å‡ºå¯¹çš„ç»“è®ºã€‚ã€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
