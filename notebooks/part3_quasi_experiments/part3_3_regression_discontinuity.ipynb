{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ–­ç‚¹å›å½’ (RDD) - é—¨æ§›å¤„çš„è‡ªç„¶å®éªŒ\n",
    "\n",
    "**å­¦ä¹ ç›®æ ‡**ï¼š\n",
    "1. ç†è§£ RDD çš„æ ¸å¿ƒæ€æƒ³ï¼šåˆ©ç”¨ã€Œé—¨æ§›ã€åˆ›é€ çš„å±€éƒ¨éšæœºåŒ–\n",
    "2. æŒæ¡ Sharp RDD å’Œ Fuzzy RDD çš„åŒºåˆ«ä¸åº”ç”¨\n",
    "3. å­¦ä¹ å¸¦å®½é€‰æ‹©ã€ç¨³å¥æ¨æ–­å’Œæœ‰æ•ˆæ€§æ£€éªŒæ–¹æ³•\n",
    "\n",
    "---\n",
    "\n",
    "## å¼•å­ï¼šæ»¡ 200 å‡ 50 çš„ç§˜å¯†\n",
    "\n",
    "æƒ³è±¡ä½ æ˜¯ç”µå•†å¹³å°çš„æ•°æ®åˆ†æå¸ˆï¼Œè¿è¥å›¢é˜Ÿæ¨å‡ºäº†ã€Œæ»¡ 200 å‡ 50ã€çš„ä¼˜æƒ åˆ¸ã€‚ä½ æƒ³çŸ¥é“ï¼š**è¿™ 50 å…ƒä¼˜æƒ çœŸçš„æå‡äº†ç”¨æˆ·çš„å¤è´­ç‡å—ï¼Ÿ**\n",
    "\n",
    "### æŒ‘æˆ˜\n",
    "- âŒ ä¸èƒ½ç›´æ¥å¯¹æ¯”ã€Œç”¨åˆ¸ç”¨æˆ·ã€vsã€Œæœªç”¨åˆ¸ç”¨æˆ·ã€â€”â€” ä»–ä»¬æœ¬èº«å°±ä¸åŒï¼ˆé€‰æ‹©åå·®ï¼‰\n",
    "- âŒ ä¸èƒ½åšéšæœºå®éªŒ â€”â€” ä¼˜æƒ åˆ¸å·²ç»å‘æ”¾ï¼Œæ— æ³•æ’¤å›\n",
    "\n",
    "### æ´å¯Ÿ\n",
    "ä½†ä½ æ³¨æ„åˆ°ä¸€ä¸ªæœ‰è¶£çš„ç°è±¡ï¼š\n",
    "- æ¶ˆè´¹ **199 å…ƒ**çš„ç”¨æˆ·ï¼šæ²¡åˆ¸\n",
    "- æ¶ˆè´¹ **201 å…ƒ**çš„ç”¨æˆ·ï¼šæœ‰åˆ¸\n",
    "\n",
    "**è¿™ä¸¤ä¸ªç”¨æˆ·å‡ ä¹ä¸€æ ·ï¼** åªæ˜¯å› ä¸º 2 å…ƒçš„å·®è·ï¼Œä¸€ä¸ªåˆšå¥½æ²¡è¾¾æ ‡ï¼Œä¸€ä¸ªåˆšå¥½è¾¾æ ‡ã€‚åœ¨é—¨æ§›å¤„ï¼ˆ200 å…ƒï¼‰ï¼Œç”¨åˆ¸ä¸å¦è¿‘ä¼¼**éšæœº**ã€‚\n",
    "\n",
    "è¿™å°±æ˜¯ **æ–­ç‚¹å›å½’ (Regression Discontinuity Design, RDD)** çš„æ ¸å¿ƒæ€æƒ³ã€‚\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯å¢ƒè®¾ç½®\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize_scalar\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotly é…ç½®\n",
    "COLORS = {\n",
    "    'primary': '#2D9CDB',\n",
    "    'secondary': '#27AE60',\n",
    "    'danger': '#EB5757',\n",
    "    'warning': '#F2994A',\n",
    "    'light': '#E0E0E0'\n",
    "}\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: RDD çš„ç›´è§‰ â€”â€” é—¨æ§›åˆ›é€ çš„å±€éƒ¨éšæœºåŒ–\n",
    "\n",
    "### 1.1 æ ¸å¿ƒæ€æƒ³\n",
    "\n",
    "RDD åˆ©ç”¨æ”¿ç­–ã€è§„åˆ™äº§ç”Ÿçš„ **ä¸è¿ç»­æ€§ï¼ˆé—¨æ§›ï¼‰** æ¥è¯†åˆ«å› æœæ•ˆåº”ã€‚\n",
    "\n",
    "**å…³é”®å‡è®¾**ï¼šåœ¨é—¨æ§›é™„è¿‘ï¼Œä¸ªä½“çš„ç‰¹å¾æ˜¯**è¿ç»­çš„**ï¼Œåªæœ‰å¤„ç†çŠ¶æ€å‘ç”Ÿè·³è·ƒã€‚\n",
    "\n",
    "### æ¯”å–»ï¼šè€ƒè¯•åŠæ ¼çº¿\n",
    "\n",
    "- è€ƒè¯•åˆ†æ•° 59 åˆ† vs 60 åˆ†ï¼Œèƒ½åŠ›å·®åˆ«å¾®ä¹å…¶å¾®\n",
    "- ä½† 60 åˆ†åŠæ ¼ï¼Œå¯ä»¥è·å¾—å¥–å­¦é‡‘ï¼›59 åˆ†ä¸åŠæ ¼ï¼Œæ²¡æœ‰å¥–å­¦é‡‘\n",
    "- åœ¨ 60 åˆ†è¿™ä¸ªé—¨æ§›å¤„ï¼Œã€Œæ˜¯å¦è·å¾—å¥–å­¦é‡‘ã€è¿‘ä¼¼éšæœºåˆ†é…\n",
    "- å¯¹æ¯” 59 åˆ†å’Œ 60 åˆ†å­¦ç”Ÿçš„åç»­è¡¨ç°ï¼Œå¯ä»¥ä¼°è®¡å¥–å­¦é‡‘çš„å› æœæ•ˆåº”\n",
    "\n",
    "### 1.2 å½¢å¼åŒ–å®šä¹‰\n",
    "\n",
    "**Running Variableï¼ˆé©±åŠ¨å˜é‡ï¼‰** $X$ï¼šå†³å®šæ˜¯å¦æ¥å—å¤„ç†çš„è¿ç»­å˜é‡ï¼ˆå¦‚æ¶ˆè´¹é‡‘é¢ã€è€ƒè¯•åˆ†æ•°ï¼‰\n",
    "\n",
    "**Cutoffï¼ˆé—¨æ§›ï¼‰** $c$ï¼šå¤„ç†åˆ†é…çš„ä¸´ç•Œç‚¹ï¼ˆå¦‚ 200 å…ƒã€60 åˆ†ï¼‰\n",
    "\n",
    "**Treatmentï¼ˆå¤„ç†ï¼‰** $D$ï¼š\n",
    "$$\n",
    "D_i = \\begin{cases}\n",
    "1 & \\text{if } X_i \\geq c \\\\\n",
    "0 & \\text{if } X_i < c\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**å› æœæ•ˆåº”ï¼ˆåœ¨é—¨æ§›å¤„ï¼‰**ï¼š\n",
    "$$\n",
    "\\tau_{RDD} = \\lim_{x \\downarrow c} E[Y_i | X_i = x] - \\lim_{x \\uparrow c} E[Y_i | X_i = x]\n",
    "$$\n",
    "\n",
    "å³ï¼šé—¨æ§›å³ä¾§çš„æœŸæœ›ç»“æœ - é—¨æ§›å·¦ä¾§çš„æœŸæœ›ç»“æœã€‚\n",
    "\n",
    "### 1.3 ä¸ºä»€ä¹ˆæ–­ç‚¹å¤„å¯æ¯”ï¼Ÿ\n",
    "\n",
    "**è¿ç»­æ€§å‡è®¾**ï¼šå¦‚æœæ²¡æœ‰å¤„ç†ï¼Œç»“æœå˜é‡åœ¨é—¨æ§›å¤„åº”è¯¥æ˜¯è¿ç»­çš„ã€‚\n",
    "\n",
    "$$\n",
    "\\lim_{x \\downarrow c} E[Y_i(0) | X_i = x] = \\lim_{x \\uparrow c} E[Y_i(0) | X_i = x]\n",
    "$$\n",
    "\n",
    "è¿™æ„å‘³ç€ï¼š\n",
    "- åœ¨é—¨æ§›é™„è¿‘ï¼Œé™¤äº†å¤„ç†çŠ¶æ€ï¼Œå…¶ä»–ç‰¹å¾éƒ½æ˜¯è¿ç»­çš„\n",
    "- é—¨æ§›ä¸¤ä¾§çš„ä¸ªä½“**æœ¬è´¨ä¸Šç›¸åŒ**ï¼ˆå±€éƒ¨éšæœºåŒ–ï¼‰\n",
    "- ç»“æœçš„è·³è·ƒå®Œå…¨å½’å› äºå¤„ç†\n",
    "\n",
    "### 1.4 RDD vs éšæœºå®éªŒ\n",
    "\n",
    "| ç»´åº¦ | éšæœºå®éªŒ | RDD |\n",
    "|------|----------|-----|\n",
    "| å¯æ¯”æ€§èŒƒå›´ | å…¨å±€ | å±€éƒ¨ï¼ˆé—¨æ§›é™„è¿‘ï¼‰ |\n",
    "| å¤–éƒ¨æ•ˆåº¦ | é«˜ | ä½ï¼ˆåªèƒ½æ¨æ–­é—¨æ§›å¤„ï¼‰ |\n",
    "| å†…éƒ¨æ•ˆåº¦ | é«˜ | ä¸­ï¼ˆä¾èµ–å‡è®¾ï¼‰ |\n",
    "| å®æ–½æˆæœ¬ | é«˜ | ä½ï¼ˆè§‚å¯Ÿæ€§ï¼‰ |\n",
    "| é€‚ç”¨åœºæ™¯ | å¯æ§ç¯å¢ƒ | å·²æœ‰æ”¿ç­–/è§„åˆ™ |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ï¼šRDD çš„æ ¸å¿ƒç›´è§‰\n",
    "\n",
    "def simulate_rdd_data(n=500, cutoff=200, tau=15, noise=20):\n",
    "    \"\"\"\n",
    "    æ¨¡æ‹Ÿ RDD æ•°æ®\n",
    "    \n",
    "    å‚æ•°:\n",
    "        n: æ ·æœ¬é‡\n",
    "        cutoff: é—¨æ§›å€¼\n",
    "        tau: å¤„ç†æ•ˆåº”\n",
    "        noise: å™ªå£°æ ‡å‡†å·®\n",
    "    \"\"\"\n",
    "    # é©±åŠ¨å˜é‡ (æ¶ˆè´¹é‡‘é¢)\n",
    "    X = np.random.uniform(100, 300, n)\n",
    "    \n",
    "    # å¤„ç†çŠ¶æ€ (æ˜¯å¦è·å¾—ä¼˜æƒ åˆ¸)\n",
    "    D = (X >= cutoff).astype(int)\n",
    "    \n",
    "    # æ½œåœ¨ç»“æœ (å¤è´­ç‡, %)\n",
    "    # Y(0): åŸºçº¿ + X çš„çº¿æ€§æ•ˆåº”\n",
    "    Y0 = 30 + 0.1 * (X - cutoff) + np.random.normal(0, noise, n)\n",
    "    \n",
    "    # Y(1): åœ¨ Y(0) åŸºç¡€ä¸ŠåŠ å¤„ç†æ•ˆåº”\n",
    "    Y1 = Y0 + tau\n",
    "    \n",
    "    # è§‚æµ‹ç»“æœ\n",
    "    Y = D * Y1 + (1 - D) * Y0\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'spending': X,\n",
    "        'coupon': D,\n",
    "        'repurchase_rate': Y,\n",
    "        'Y0': Y0,\n",
    "        'Y1': Y1\n",
    "    })\n",
    "\n",
    "# ç”Ÿæˆæ•°æ®\n",
    "df = simulate_rdd_data(n=1000, cutoff=200, tau=15)\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig = go.Figure()\n",
    "\n",
    "# æ•£ç‚¹å›¾\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df[df['coupon']==0]['spending'],\n",
    "    y=df[df['coupon']==0]['repurchase_rate'],\n",
    "    mode='markers',\n",
    "    name='æœªè·åˆ¸ (X < 200)',\n",
    "    marker=dict(color=COLORS['danger'], size=5, opacity=0.5)\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df[df['coupon']==1]['spending'],\n",
    "    y=df[df['coupon']==1]['repurchase_rate'],\n",
    "    mode='markers',\n",
    "    name='è·åˆ¸ (X â‰¥ 200)',\n",
    "    marker=dict(color=COLORS['secondary'], size=5, opacity=0.5)\n",
    "))\n",
    "\n",
    "# æ‹Ÿåˆçº¿ (åˆ†æ®µçº¿æ€§)\n",
    "left = df[df['spending'] < 200]\n",
    "right = df[df['spending'] >= 200]\n",
    "\n",
    "# å·¦ä¾§æ‹Ÿåˆ\n",
    "X_left = left['spending'].values.reshape(-1, 1)\n",
    "y_left = left['repurchase_rate'].values\n",
    "model_left = LinearRegression().fit(X_left, y_left)\n",
    "x_left_line = np.linspace(100, 200, 100).reshape(-1, 1)\n",
    "y_left_pred = model_left.predict(x_left_line)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_left_line.flatten(),\n",
    "    y=y_left_pred,\n",
    "    mode='lines',\n",
    "    name='å·¦ä¾§æ‹Ÿåˆ',\n",
    "    line=dict(color=COLORS['danger'], width=3)\n",
    "))\n",
    "\n",
    "# å³ä¾§æ‹Ÿåˆ\n",
    "X_right = right['spending'].values.reshape(-1, 1)\n",
    "y_right = right['repurchase_rate'].values\n",
    "model_right = LinearRegression().fit(X_right, y_right)\n",
    "x_right_line = np.linspace(200, 300, 100).reshape(-1, 1)\n",
    "y_right_pred = model_right.predict(x_right_line)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_right_line.flatten(),\n",
    "    y=y_right_pred,\n",
    "    mode='lines',\n",
    "    name='å³ä¾§æ‹Ÿåˆ',\n",
    "    line=dict(color=COLORS['secondary'], width=3)\n",
    "))\n",
    "\n",
    "# é—¨æ§›çº¿\n",
    "fig.add_vline(x=200, line_dash=\"dash\", line_color=\"black\", \n",
    "              annotation_text=\"é—¨æ§›: 200 å…ƒ\")\n",
    "\n",
    "# æ ‡æ³¨è·³è·ƒ\n",
    "y_left_at_cutoff = model_left.predict([[200]])[0]\n",
    "y_right_at_cutoff = model_right.predict([[200]])[0]\n",
    "tau_est = y_right_at_cutoff - y_left_at_cutoff\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=200, y=(y_left_at_cutoff + y_right_at_cutoff) / 2,\n",
    "    text=f\"è·³è·ƒ â‰ˆ {tau_est:.1f}%\",\n",
    "    showarrow=True,\n",
    "    arrowhead=2,\n",
    "    arrowsize=1,\n",
    "    arrowwidth=2,\n",
    "    arrowcolor=COLORS['primary']\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='RDD æ ¸å¿ƒç›´è§‰ï¼šé—¨æ§›å¤„çš„è·³è·ƒå°±æ˜¯å› æœæ•ˆåº”',\n",
    "    xaxis_title='æ¶ˆè´¹é‡‘é¢ (å…ƒ)',\n",
    "    yaxis_title='å¤è´­ç‡ (%)',\n",
    "    template='plotly_white',\n",
    "    hovermode='closest',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nğŸ“Š ä¼°è®¡çš„å¤„ç†æ•ˆåº”: {tau_est:.2f}%\")\n",
    "print(f\"   çœŸå®å¤„ç†æ•ˆåº”: 15.00%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Sharp RDD â€”â€” é—¨æ§›å®Œå…¨å†³å®šå¤„ç†\n",
    "\n",
    "### 2.1 å®šä¹‰\n",
    "\n",
    "**Sharp RDD**ï¼šå¤„ç†çŠ¶æ€å®Œå…¨ç”±é©±åŠ¨å˜é‡å’Œé—¨æ§›å†³å®šï¼Œæ²¡æœ‰ä¾‹å¤–ã€‚\n",
    "\n",
    "$$\n",
    "P(D_i = 1 | X_i = x) = \\begin{cases}\n",
    "1 & \\text{if } x \\geq c \\\\\n",
    "0 & \\text{if } x < c\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**ä¾‹å­**ï¼š\n",
    "- âœ… æ³•å®šé¥®é…’å¹´é¾„ 21 å²\n",
    "- âœ… è€ƒè¯• 60 åˆ†åŠæ ¼\n",
    "- âœ… æ»¡ 200 å‡ 50ï¼ˆç³»ç»Ÿè‡ªåŠ¨ï¼‰\n",
    "\n",
    "### 2.2 ä¼°è®¡æ–¹æ³•ï¼šå±€éƒ¨å¤šé¡¹å¼å›å½’\n",
    "\n",
    "**åŸºæœ¬æ€è·¯**ï¼šåœ¨é—¨æ§›é™„è¿‘ç”¨å¤šé¡¹å¼æ‹Ÿåˆ $E[Y|X]$ï¼Œä¼°è®¡è·³è·ƒå¤§å°ã€‚\n",
    "\n",
    "#### çº¿æ€§è§„èŒƒï¼ˆæœ€å¸¸ç”¨ï¼‰\n",
    "\n",
    "$$\n",
    "Y_i = \\alpha + \\tau D_i + \\beta_1 (X_i - c) + \\beta_2 D_i \\cdot (X_i - c) + \\epsilon_i\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- $\\tau$: å¤„ç†æ•ˆåº”ï¼ˆé—¨æ§›å¤„çš„è·³è·ƒï¼‰\n",
    "- $\\beta_1$: å·¦ä¾§æ–œç‡\n",
    "- $\\beta_1 + \\beta_2$: å³ä¾§æ–œç‡\n",
    "- $(X_i - c)$: ä¸­å¿ƒåŒ–ï¼Œä½¿ $\\tau$ ä»£è¡¨é—¨æ§›å¤„çš„æ•ˆåº”\n",
    "\n",
    "#### é«˜é˜¶å¤šé¡¹å¼\n",
    "\n",
    "$$\n",
    "Y_i = \\alpha + \\tau D_i + \\sum_{p=1}^{P} \\left[ \\beta_p (X_i - c)^p + \\gamma_p D_i \\cdot (X_i - c)^p \\right] + \\epsilon_i\n",
    "$$\n",
    "\n",
    "**æ³¨æ„**ï¼šé«˜é˜¶å¤šé¡¹å¼å¯èƒ½è¿‡æ‹Ÿåˆï¼Œé€šå¸¸ $P \\leq 2$ã€‚\n",
    "\n",
    "### 2.3 å¸¦å®½é€‰æ‹©\n",
    "\n",
    "**å¸¦å®½ $h$**ï¼šåªä½¿ç”¨ $|X_i - c| \\leq h$ çš„æ ·æœ¬è¿›è¡Œä¼°è®¡ã€‚\n",
    "\n",
    "**æƒè¡¡**ï¼š\n",
    "- å°å¸¦å®½ â†’ ä½åå·®ï¼ˆæ›´æ¥è¿‘é—¨æ§›ï¼‰ï¼Œé«˜æ–¹å·®ï¼ˆæ ·æœ¬å°‘ï¼‰\n",
    "- å¤§å¸¦å®½ â†’ é«˜åå·®ï¼ˆè¿œç¦»é—¨æ§›ï¼‰ï¼Œä½æ–¹å·®ï¼ˆæ ·æœ¬å¤šï¼‰\n",
    "\n",
    "**æœ€ä¼˜å¸¦å®½**ï¼šæœ€å°åŒ–å‡æ–¹è¯¯å·® (MSE)\n",
    "\n",
    "$$\n",
    "h^* = \\arg\\min_h \\text{MSE}(\\hat{\\tau}) = \\arg\\min_h \\left[ \\text{Bias}(\\hat{\\tau})^2 + \\text{Var}(\\hat{\\tau}) \\right]\n",
    "$$\n",
    "\n",
    "**å®è·µä¸­**ï¼šä½¿ç”¨ Imbens-Kalyanaraman (2012) æˆ– Calonico-Cattaneo-Titiunik (2014) æ–¹æ³•è‡ªåŠ¨é€‰æ‹©ã€‚\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharp RDD ä¼°è®¡å™¨\n",
    "\n",
    "class SharpRDD:\n",
    "    \"\"\"\n",
    "    Sharp RDD ä¼°è®¡å™¨ï¼ˆå±€éƒ¨å¤šé¡¹å¼å›å½’ï¼‰\n",
    "    \"\"\"\n",
    "    def __init__(self, cutoff=0, bandwidth=None, polynomial_order=1, kernel='triangular'):\n",
    "        self.cutoff = cutoff\n",
    "        self.bandwidth = bandwidth\n",
    "        self.polynomial_order = polynomial_order\n",
    "        self.kernel = kernel\n",
    "        self.tau_ = None\n",
    "        self.se_ = None\n",
    "        \n",
    "    def _kernel_weight(self, x):\n",
    "        \"\"\"æ ¸æƒé‡å‡½æ•°\"\"\"\n",
    "        u = x / self.bandwidth\n",
    "        if self.kernel == 'uniform':\n",
    "            return (np.abs(u) <= 1).astype(float)\n",
    "        elif self.kernel == 'triangular':\n",
    "            return np.maximum(0, 1 - np.abs(u))\n",
    "        elif self.kernel == 'epanechnikov':\n",
    "            return np.maximum(0, 0.75 * (1 - u**2))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown kernel: {self.kernel}\")\n",
    "    \n",
    "    def _select_bandwidth_ik(self, X, Y, D):\n",
    "        \"\"\"\n",
    "        Imbens-Kalyanaraman (2012) å¸¦å®½é€‰æ‹©\n",
    "        ç®€åŒ–ç‰ˆå®ç°\n",
    "        \"\"\"\n",
    "        # ä½¿ç”¨å…¨æ ·æœ¬ä¼°è®¡\n",
    "        X_centered = X - self.cutoff\n",
    "        \n",
    "        # åˆ†åˆ«æ‹Ÿåˆå·¦å³ä¸¤ä¾§\n",
    "        left_mask = D == 0\n",
    "        right_mask = D == 1\n",
    "        \n",
    "        # ä¼°è®¡æ–¹å·®\n",
    "        var_left = np.var(Y[left_mask])\n",
    "        var_right = np.var(Y[right_mask])\n",
    "        \n",
    "        # ä¼°è®¡äºŒé˜¶å¯¼æ•°ï¼ˆç”¨ä¸‰é˜¶å¤šé¡¹å¼ï¼‰\n",
    "        poly = PolynomialFeatures(degree=3)\n",
    "        X_poly_left = poly.fit_transform(X_centered[left_mask].reshape(-1, 1))\n",
    "        X_poly_right = poly.fit_transform(X_centered[right_mask].reshape(-1, 1))\n",
    "        \n",
    "        model_left = LinearRegression().fit(X_poly_left, Y[left_mask])\n",
    "        model_right = LinearRegression().fit(X_poly_right, Y[right_mask])\n",
    "        \n",
    "        # ç®€åŒ–å…¬å¼ï¼ˆå®é™… IK æ›´å¤æ‚ï¼‰\n",
    "        n = len(X)\n",
    "        range_x = np.max(X) - np.min(X)\n",
    "        \n",
    "        # ç»éªŒå…¬å¼\n",
    "        h_ik = 1.84 * np.sqrt(var_left + var_right) * n**(-1/5) * range_x\n",
    "        \n",
    "        return h_ik\n",
    "    \n",
    "    def fit(self, X, Y, D=None):\n",
    "        \"\"\"\n",
    "        æ‹Ÿåˆ RDD æ¨¡å‹\n",
    "        \n",
    "        å‚æ•°:\n",
    "            X: é©±åŠ¨å˜é‡ (n,)\n",
    "            Y: ç»“æœå˜é‡ (n,)\n",
    "            D: å¤„ç†çŠ¶æ€ (n,), å¦‚æœä¸º None åˆ™æ ¹æ® cutoff è‡ªåŠ¨ç”Ÿæˆ\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        \n",
    "        if D is None:\n",
    "            D = (X >= self.cutoff).astype(int)\n",
    "        else:\n",
    "            D = np.array(D)\n",
    "        \n",
    "        # è‡ªåŠ¨é€‰æ‹©å¸¦å®½\n",
    "        if self.bandwidth is None:\n",
    "            self.bandwidth = self._select_bandwidth_ik(X, Y, D)\n",
    "            print(f\"è‡ªåŠ¨é€‰æ‹©å¸¦å®½: h = {self.bandwidth:.2f}\")\n",
    "        \n",
    "        # ç­›é€‰å¸¦å®½å†…çš„æ ·æœ¬\n",
    "        mask = np.abs(X - self.cutoff) <= self.bandwidth\n",
    "        X_bw = X[mask]\n",
    "        Y_bw = Y[mask]\n",
    "        D_bw = D[mask]\n",
    "        \n",
    "        # æ ¸æƒé‡\n",
    "        weights = self._kernel_weight(X_bw - self.cutoff)\n",
    "        \n",
    "        # æ„å»ºå¤šé¡¹å¼ç‰¹å¾\n",
    "        X_centered = (X_bw - self.cutoff).reshape(-1, 1)\n",
    "        \n",
    "        # ç‰¹å¾çŸ©é˜µ: [1, D, X-c, D*(X-c), (X-c)^2, D*(X-c)^2, ...]\n",
    "        features = [np.ones(len(X_bw)), D_bw]\n",
    "        for p in range(1, self.polynomial_order + 1):\n",
    "            features.append(X_centered.flatten() ** p)\n",
    "            features.append(D_bw * (X_centered.flatten() ** p))\n",
    "        \n",
    "        X_design = np.column_stack(features)\n",
    "        \n",
    "        # åŠ æƒæœ€å°äºŒä¹˜\n",
    "        W = np.diag(weights)\n",
    "        beta = np.linalg.solve(X_design.T @ W @ X_design, X_design.T @ W @ Y_bw)\n",
    "        \n",
    "        # æå–å¤„ç†æ•ˆåº”ï¼ˆç¬¬äºŒä¸ªç³»æ•°ï¼‰\n",
    "        self.tau_ = beta[1]\n",
    "        \n",
    "        # æ ‡å‡†è¯¯ï¼ˆç¨³å¥æ ‡å‡†è¯¯ï¼‰\n",
    "        residuals = Y_bw - X_design @ beta\n",
    "        meat = X_design.T @ W @ np.diag(residuals**2) @ W @ X_design\n",
    "        bread = np.linalg.inv(X_design.T @ W @ X_design)\n",
    "        vcov = bread @ meat @ bread\n",
    "        self.se_ = np.sqrt(vcov[1, 1])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def summary(self, alpha=0.05):\n",
    "        \"\"\"è¾“å‡ºä¼°è®¡ç»“æœ\"\"\"\n",
    "        if self.tau_ is None:\n",
    "            raise ValueError(\"æ¨¡å‹æœªæ‹Ÿåˆï¼Œè¯·å…ˆè°ƒç”¨ fit()\")\n",
    "        \n",
    "        z = stats.norm.ppf(1 - alpha/2)\n",
    "        ci_lower = self.tau_ - z * self.se_\n",
    "        ci_upper = self.tau_ + z * self.se_\n",
    "        t_stat = self.tau_ / self.se_\n",
    "        p_value = 2 * (1 - stats.norm.cdf(np.abs(t_stat)))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Sharp RDD ä¼°è®¡ç»“æœ\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"å¸¦å®½ (h):           {self.bandwidth:.2f}\")\n",
    "        print(f\"å¤šé¡¹å¼é˜¶æ•°:          {self.polynomial_order}\")\n",
    "        print(f\"æ ¸å‡½æ•°:             {self.kernel}\")\n",
    "        print(\"-\"*60)\n",
    "        print(f\"å¤„ç†æ•ˆåº” (Ï„):       {self.tau_:.4f}\")\n",
    "        print(f\"æ ‡å‡†è¯¯ (SE):        {self.se_:.4f}\")\n",
    "        print(f\"t ç»Ÿè®¡é‡:           {t_stat:.4f}\")\n",
    "        print(f\"p å€¼:              {p_value:.4f}\")\n",
    "        print(f\"{int((1-alpha)*100)}% ç½®ä¿¡åŒºé—´:      [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return {\n",
    "            'tau': self.tau_,\n",
    "            'se': self.se_,\n",
    "            'ci': (ci_lower, ci_upper),\n",
    "            'p_value': p_value\n",
    "        }\n",
    "\n",
    "# æµ‹è¯• Sharp RDD ä¼°è®¡å™¨\n",
    "rdd = SharpRDD(cutoff=200, polynomial_order=1)\n",
    "rdd.fit(df['spending'], df['repurchase_rate'])\n",
    "results = rdd.summary()\n",
    "\n",
    "print(f\"\\nâœ… çœŸå®æ•ˆåº”: 15.00%\")\n",
    "print(f\"âœ… ä¼°è®¡åå·®: {results['tau'] - 15:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ TODO 1: å¸¦å®½æ•æ„Ÿæ€§åˆ†æ\n",
    "\n",
    "ä¸åŒå¸¦å®½ä¼šå½±å“ä¼°è®¡ç»“æœã€‚è¯·å®Œæˆä¸‹é¢çš„ä»£ç ï¼Œç»˜åˆ¶ä¸åŒå¸¦å®½ä¸‹çš„ä¼°è®¡æ•ˆåº”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================",
    "# TODO 1: å¸¦å®½æ•æ„Ÿæ€§åˆ†æ - å®Œæ•´å®ç°",
    "# ===================================",
    "",
    "bandwidths = np.linspace(10, 100, 20)",
    "tau_estimates = []",
    "ci_lower_list = []",
    "ci_upper_list = []",
    "se_list = []",
    "",
    "for h in bandwidths:",
    "    # ç”¨ä¸åŒå¸¦å®½æ‹Ÿåˆ RDD æ¨¡å‹",
    "    rdd_temp = SharpRDD(cutoff=200, bandwidth=h, polynomial_order=1)",
    "    rdd_temp.fit(df['score'].values, df['conversion'].values)",
    "    ",
    "    tau_estimates.append(rdd_temp.tau_)",
    "    se_list.append(rdd_temp.se_)",
    "    ci_lower_list.append(rdd_temp.tau_ - 1.96 * rdd_temp.se_)",
    "    ci_upper_list.append(rdd_temp.tau_ + 1.96 * rdd_temp.se_)",
    "",
    "tau_estimates = np.array(tau_estimates)",
    "se_list = np.array(se_list)",
    "ci_lower_list = np.array(ci_lower_list)",
    "ci_upper_list = np.array(ci_upper_list)",
    "",
    "# å¯è§†åŒ–",
    "fig = make_subplots(",
    "    rows=1, cols=2,",
    "    subplot_titles=('å¤„ç†æ•ˆåº”ä¼°è®¡', 'æ ‡å‡†è¯¯')",
    ")",
    "",
    "# å·¦å›¾ï¼šç‚¹ä¼°è®¡ + ç½®ä¿¡åŒºé—´",
    "fig.add_trace(",
    "    go.Scatter(",
    "        x=bandwidths, y=tau_estimates,",
    "        mode='lines+markers',",
    "        name='RDD ä¼°è®¡',",
    "        line=dict(color=COLORS['treated'], width=2),",
    "        marker=dict(size=6),",
    "    ),",
    "    row=1, col=1",
    ")",
    "",
    "# ç½®ä¿¡åŒºé—´",
    "fig.add_trace(",
    "    go.Scatter(",
    "        x=np.concatenate([bandwidths, bandwidths[::-1]]),",
    "        y=np.concatenate([ci_upper_list, ci_lower_list[::-1]]),",
    "        fill='toself',",
    "        fillcolor='rgba(235, 87, 87, 0.2)',",
    "        line=dict(color='rgba(255,255,255,0)'),",
    "        showlegend=False,",
    "        name='95% CI',",
    "    ),",
    "    row=1, col=1",
    ")",
    "",
    "# é›¶çº¿",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", row=1, col=1)",
    "",
    "# å³å›¾ï¼šæ ‡å‡†è¯¯",
    "fig.add_trace(",
    "    go.Scatter(",
    "        x=bandwidths, y=se_list,",
    "        mode='lines+markers',",
    "        name='æ ‡å‡†è¯¯',",
    "        line=dict(color=COLORS['synthetic'], width=2),",
    "        marker=dict(size=6),",
    "        showlegend=False",
    "    ),",
    "    row=1, col=2",
    ")",
    "",
    "fig.update_xaxes(title_text=\"å¸¦å®½ (h)\", row=1, col=1)",
    "fig.update_xaxes(title_text=\"å¸¦å®½ (h)\", row=1, col=2)",
    "fig.update_yaxes(title_text=\"å¤„ç†æ•ˆåº”\", row=1, col=1)",
    "fig.update_yaxes(title_text=\"æ ‡å‡†è¯¯\", row=1, col=2)",
    "",
    "fig.update_layout(",
    "    title_text='å¸¦å®½æ•æ„Ÿæ€§åˆ†æ',",
    "    template='plotly_white',",
    "    height=400,",
    "    showlegend=True",
    ")",
    "",
    "fig.show()",
    "",
    "# æ‰“å°ç»“æœè¡¨æ ¼",
    "print(\"=\" * 70)",
    "print(\"å¸¦å®½æ•æ„Ÿæ€§åˆ†æç»“æœ\")",
    "print(\"=\" * 70)",
    "print(f\"{'å¸¦å®½':>8s} {'æ•ˆåº”':>10s} {'æ ‡å‡†è¯¯':>10s} {'95% CI':>25s} {'æ˜¾è‘—':>6s}\")",
    "print(\"-\" * 70)",
    "",
    "for i in range(0, len(bandwidths), 4):  # æ¯éš”4ä¸ªæ˜¾ç¤º",
    "    h = bandwidths[i]",
    "    tau = tau_estimates[i]",
    "    se = se_list[i]",
    "    ci_l = ci_lower_list[i]",
    "    ci_u = ci_upper_list[i]",
    "    sig = '***' if abs(tau/se) > 2.58 else ('**' if abs(tau/se) > 1.96 else '*' if abs(tau/se) > 1.65 else '')",
    "    ",
    "    print(f\"{h:8.1f} {tau:10.4f} {se:10.4f} [{ci_l:8.4f}, {ci_u:8.4f}] {sig:>6s}\")",
    "",
    "print(\"=\" * 70)",
    "",
    "print(\"\\nğŸ’¡ è§£è¯»:\")",
    "print(f\"  â€¢ ä¼°è®¡èŒƒå›´: [{min(tau_estimates):.4f}, {max(tau_estimates):.4f}]\")",
    "print(f\"  â€¢ æ ‡å‡†è¯¯èŒƒå›´: [{min(se_list):.4f}, {max(se_list):.4f}]\")",
    "print(f\"  â€¢ å¸¦å®½è¶Šå° â†’ åå·®å°ä½†æ–¹å·®å¤§ï¼ˆæ ·æœ¬å°‘ï¼‰\")",
    "print(f\"  â€¢ å¸¦å®½è¶Šå¤§ â†’ æ–¹å·®å°ä½†åå·®å¤§ï¼ˆåŒ…å«è¿œç¦»æ–­ç‚¹çš„è§‚æµ‹ï¼‰\")",
    "",
    "# æ£€æŸ¥ç¨³å¥æ€§",
    "cv = np.std(tau_estimates) / abs(np.mean(tau_estimates))",
    "print(f\"  â€¢ ä¼°è®¡çš„å˜å¼‚ç³»æ•°: {cv:.2f}\")",
    "if cv < 0.2:",
    "    print(f\"    âœ“ ç»“æœå¯¹å¸¦å®½ä¸æ•æ„Ÿï¼Œä¼°è®¡è¾ƒä¸ºç¨³å¥\")",
    "else:",
    "    print(f\"    âš  ç»“æœå¯¹å¸¦å®½è¾ƒæ•æ„Ÿï¼Œéœ€è°¨æ…è§£é‡Š\")",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Fuzzy RDD â€”â€” é—¨æ§›å½±å“å¤„ç†æ¦‚ç‡\n",
    "\n",
    "### 3.1 ä» Sharp åˆ° Fuzzy\n",
    "\n",
    "ç°å®ä¸­ï¼Œé—¨æ§›å¹¶ä¸æ€»æ˜¯å®Œå…¨å†³å®šå¤„ç†ï¼š\n",
    "- æœ‰äº›äººæ¶ˆè´¹è¶…è¿‡ 200 å…ƒï¼Œä½†**å¿˜è®°ä½¿ç”¨ä¼˜æƒ åˆ¸**\n",
    "- æœ‰äº›äººæ¶ˆè´¹ä¸è¶³ 200 å…ƒï¼Œä½†é€šè¿‡**å®¢æœç”³è¯‰**è·å¾—äº†ä¼˜æƒ åˆ¸\n",
    "\n",
    "è¿™å°±æ˜¯ **Fuzzy RDD**ã€‚\n",
    "\n",
    "### 3.2 å®šä¹‰\n",
    "\n",
    "**Fuzzy RDD**ï¼šé—¨æ§›å¤„å¤„ç†æ¦‚ç‡å‘ç”Ÿè·³è·ƒï¼Œä½†ä¸æ˜¯ 0 â†’ 1 çš„å®Œå…¨è·³è·ƒã€‚\n",
    "\n",
    "$$\n",
    "\\lim_{x \\downarrow c} P(D_i = 1 | X_i = x) \\neq \\lim_{x \\uparrow c} P(D_i = 1 | X_i = x)\n",
    "$$\n",
    "\n",
    "ä½†è·³è·ƒå¹…åº¦ < 1ï¼š\n",
    "$$\n",
    "0 < \\lim_{x \\downarrow c} P(D_i = 1 | X_i = x) - \\lim_{x \\uparrow c} P(D_i = 1 | X_i = x) < 1\n",
    "$$\n",
    "\n",
    "**ä¾‹å­**ï¼š\n",
    "- å¥–å­¦é‡‘æ”¿ç­–ï¼š60 åˆ†åŠæ ¼**æœ‰èµ„æ ¼**ç”³è¯·ï¼Œä½†ä¸æ˜¯æ‰€æœ‰äººéƒ½ç”³è¯·\n",
    "- ä¼˜æƒ åˆ¸ï¼šæ»¡ 200 å…ƒ**å¯ç”¨**ï¼Œä½†æœ‰äººå¿˜è®°ç”¨\n",
    "\n",
    "### 3.3 Fuzzy RDD ä¸ IV çš„å…³ç³»\n",
    "\n",
    "Fuzzy RDD æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ª **å·¥å…·å˜é‡ (IV)** è®¾è®¡ï¼š\n",
    "\n",
    "- **å·¥å…·å˜é‡ $Z_i$**ï¼šæ˜¯å¦è¶…è¿‡é—¨æ§›ï¼ˆ$Z_i = \\mathbb{1}[X_i \\geq c]$ï¼‰\n",
    "- **å¤„ç†å˜é‡ $D_i$**ï¼šæ˜¯å¦å®é™…æ¥å—å¤„ç†\n",
    "- **ç»“æœå˜é‡ $Y_i$**ï¼šæ„Ÿå…´è¶£çš„ç»“æœ\n",
    "\n",
    "IV å‡è®¾ï¼š\n",
    "1. **ç›¸å…³æ€§**ï¼š$Z$ å½±å“ $D$ï¼ˆé—¨æ§›å¤„å¤„ç†æ¦‚ç‡è·³è·ƒï¼‰\n",
    "2. **æ’ä»–æ€§**ï¼š$Z$ åªé€šè¿‡ $D$ å½±å“ $Y$ï¼ˆé—¨æ§›æœ¬èº«ä¸ç›´æ¥å½±å“ç»“æœï¼‰\n",
    "3. **å•è°ƒæ€§**ï¼š$Z=1$ ä¸ä¼šè®©æŸäº›äººåè€Œä¸æ¥å—å¤„ç†\n",
    "\n",
    "### 3.4 ä¼°è®¡æ–¹æ³•ï¼šTwo-Stage Least Squares (2SLS)\n",
    "\n",
    "**ç¬¬ä¸€é˜¶æ®µ**ï¼šç”¨ $Z$ é¢„æµ‹ $D$\n",
    "$$\n",
    "D_i = \\pi_0 + \\pi_1 Z_i + \\pi_2 (X_i - c) + \\pi_3 Z_i \\cdot (X_i - c) + \\nu_i\n",
    "$$\n",
    "\n",
    "**ç¬¬äºŒé˜¶æ®µ**ï¼šç”¨ $\\hat{D}$ ä¼°è®¡æ•ˆåº”\n",
    "$$\n",
    "Y_i = \\alpha + \\tau \\hat{D}_i + \\beta_1 (X_i - c) + \\beta_2 Z_i \\cdot (X_i - c) + \\epsilon_i\n",
    "$$\n",
    "\n",
    "**Wald ä¼°è®¡é‡**ï¼ˆç­‰ä»·ï¼‰ï¼š\n",
    "$$\n",
    "\\tau_{Fuzzy} = \\frac{\\lim_{x \\downarrow c} E[Y_i | X_i = x] - \\lim_{x \\uparrow c} E[Y_i | X_i = x]}{\\lim_{x \\downarrow c} E[D_i | X_i = x] - \\lim_{x \\uparrow c} E[D_i | X_i = x]} = \\frac{\\text{ç»“æœçš„è·³è·ƒ}}{\\text{å¤„ç†çš„è·³è·ƒ}}\n",
    "$$\n",
    "\n",
    "### 3.5 LATE è§£é‡Š\n",
    "\n",
    "Fuzzy RDD ä¼°è®¡çš„æ˜¯ **Local Average Treatment Effect (LATE)**ï¼Œå³ã€Œé¡ºä»è€…ã€çš„æ•ˆåº”ï¼š\n",
    "\n",
    "- **é¡ºä»è€… (Compliers)**ï¼šè¶…è¿‡é—¨æ§›å°±æ¥å—å¤„ç†ï¼Œä½äºé—¨æ§›å°±ä¸æ¥å—ï¼ˆ$D_i(1) = 1, D_i(0) = 0$ï¼‰\n",
    "- **æ€»æ˜¯æ¥å—è€… (Always-takers)**ï¼šæ— è®ºæ˜¯å¦è¶…è¿‡é—¨æ§›éƒ½æ¥å—å¤„ç†ï¼ˆ$D_i(1) = D_i(0) = 1$ï¼‰\n",
    "- **ä»ä¸æ¥å—è€… (Never-takers)**ï¼šæ— è®ºæ˜¯å¦è¶…è¿‡é—¨æ§›éƒ½ä¸æ¥å—ï¼ˆ$D_i(1) = D_i(0) = 0$ï¼‰\n",
    "\n",
    "$$\n",
    "\\tau_{LATE} = E[Y_i(1) - Y_i(0) | \\text{Complier}]\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy RDD æ¨¡æ‹Ÿä¸ä¼°è®¡\n",
    "\n",
    "def simulate_fuzzy_rdd(n=1000, cutoff=200, tau=15, compliance_rate=0.7):\n",
    "    \"\"\"\n",
    "    æ¨¡æ‹Ÿ Fuzzy RDD æ•°æ®\n",
    "    \n",
    "    å‚æ•°:\n",
    "        compliance_rate: é¡ºä»ç‡ï¼ˆè¶…è¿‡é—¨æ§›åå®é™…ä½¿ç”¨ä¼˜æƒ åˆ¸çš„æ¯”ä¾‹ï¼‰\n",
    "    \"\"\"\n",
    "    # é©±åŠ¨å˜é‡\n",
    "    X = np.random.uniform(100, 300, n)\n",
    "    \n",
    "    # å·¥å…·å˜é‡ï¼ˆæ˜¯å¦è¶…è¿‡é—¨æ§›ï¼‰\n",
    "    Z = (X >= cutoff).astype(int)\n",
    "    \n",
    "    # å¤„ç†çŠ¶æ€ï¼ˆä¸å®Œå…¨é¡ºä»ï¼‰\n",
    "    # è¶…è¿‡é—¨æ§›: compliance_rate çš„æ¦‚ç‡ä½¿ç”¨åˆ¸\n",
    "    # æœªè¶…è¿‡é—¨æ§›: 0.1 çš„æ¦‚ç‡ä¹Ÿèƒ½ç”¨åˆ¸ï¼ˆç”³è¯‰ï¼‰\n",
    "    D = np.zeros(n)\n",
    "    D[Z == 1] = np.random.binomial(1, compliance_rate, (Z == 1).sum())\n",
    "    D[Z == 0] = np.random.binomial(1, 0.1, (Z == 0).sum())\n",
    "    \n",
    "    # ç»“æœå˜é‡\n",
    "    Y0 = 30 + 0.1 * (X - cutoff) + np.random.normal(0, 20, n)\n",
    "    Y1 = Y0 + tau\n",
    "    Y = D * Y1 + (1 - D) * Y0\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'spending': X,\n",
    "        'eligible': Z,  # æ˜¯å¦æœ‰èµ„æ ¼\n",
    "        'coupon_used': D,  # æ˜¯å¦å®é™…ä½¿ç”¨\n",
    "        'repurchase_rate': Y\n",
    "    })\n",
    "\n",
    "# ç”Ÿæˆ Fuzzy RDD æ•°æ®\n",
    "df_fuzzy = simulate_fuzzy_rdd(n=1000, cutoff=200, tau=15, compliance_rate=0.7)\n",
    "\n",
    "# å¯è§†åŒ–ï¼šå¤„ç†çŠ¶æ€çš„è·³è·ƒ\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=['(a) å¤„ç†æ¦‚ç‡çš„è·³è·ƒï¼ˆç¬¬ä¸€é˜¶æ®µï¼‰', '(b) ç»“æœçš„è·³è·ƒï¼ˆçº¦åŒ–å¼ï¼‰']\n",
    ")\n",
    "\n",
    "# å·¦å›¾ï¼šå¤„ç†æ¦‚ç‡\n",
    "bins_x = np.linspace(100, 300, 30)\n",
    "bin_centers = (bins_x[:-1] + bins_x[1:]) / 2\n",
    "treatment_prob = []\n",
    "\n",
    "for i in range(len(bins_x) - 1):\n",
    "    mask = (df_fuzzy['spending'] >= bins_x[i]) & (df_fuzzy['spending'] < bins_x[i+1])\n",
    "    if mask.sum() > 0:\n",
    "        treatment_prob.append(df_fuzzy[mask]['coupon_used'].mean())\n",
    "    else:\n",
    "        treatment_prob.append(np.nan)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=bin_centers,\n",
    "        y=treatment_prob,\n",
    "        mode='markers',\n",
    "        marker=dict(size=8, color=COLORS['primary']),\n",
    "        name='å¤„ç†æ¦‚ç‡'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_vline(x=200, line_dash=\"dash\", line_color=\"black\", row=1, col=1)\n",
    "\n",
    "# å³å›¾ï¼šç»“æœçš„è·³è·ƒ\n",
    "avg_outcome = []\n",
    "for i in range(len(bins_x) - 1):\n",
    "    mask = (df_fuzzy['spending'] >= bins_x[i]) & (df_fuzzy['spending'] < bins_x[i+1])\n",
    "    if mask.sum() > 0:\n",
    "        avg_outcome.append(df_fuzzy[mask]['repurchase_rate'].mean())\n",
    "    else:\n",
    "        avg_outcome.append(np.nan)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=bin_centers,\n",
    "        y=avg_outcome,\n",
    "        mode='markers',\n",
    "        marker=dict(size=8, color=COLORS['secondary']),\n",
    "        name='å¹³å‡ç»“æœ'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_vline(x=200, line_dash=\"dash\", line_color=\"black\", row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"æ¶ˆè´¹é‡‘é¢ (å…ƒ)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"æ¶ˆè´¹é‡‘é¢ (å…ƒ)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"ä½¿ç”¨ä¼˜æƒ åˆ¸æ¦‚ç‡\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"å¤è´­ç‡ (%)\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_white',\n",
    "    height=400,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Fuzzy RDD ä¼°è®¡ï¼ˆ2SLSï¼‰\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# åªä½¿ç”¨å¸¦å®½å†…çš„æ ·æœ¬\n",
    "bandwidth = 50\n",
    "mask_bw = np.abs(df_fuzzy['spending'] - 200) <= bandwidth\n",
    "df_bw = df_fuzzy[mask_bw].copy()\n",
    "\n",
    "# æ„å»ºç‰¹å¾\n",
    "df_bw['X_centered'] = df_bw['spending'] - 200\n",
    "df_bw['Z_X'] = df_bw['eligible'] * df_bw['X_centered']\n",
    "\n",
    "# ç¬¬ä¸€é˜¶æ®µï¼šZ -> D\n",
    "X_first = df_bw[['eligible', 'X_centered', 'Z_X']].values\n",
    "D_bw = df_bw['coupon_used'].values\n",
    "\n",
    "first_stage = LinearRegression().fit(X_first, D_bw)\n",
    "D_hat = first_stage.predict(X_first)\n",
    "\n",
    "# ç¬¬äºŒé˜¶æ®µï¼šD_hat -> Y\n",
    "X_second = np.column_stack([D_hat, df_bw[['X_centered', 'Z_X']].values])\n",
    "Y_bw = df_bw['repurchase_rate'].values\n",
    "\n",
    "second_stage = LinearRegression().fit(X_second, Y_bw)\n",
    "tau_fuzzy = second_stage.coef_[0]\n",
    "\n",
    "# Wald ä¼°è®¡ï¼ˆç­‰ä»·ï¼‰\n",
    "left_mask = (df_bw['spending'] < 200)\n",
    "right_mask = (df_bw['spending'] >= 200)\n",
    "\n",
    "# ç»“æœçš„è·³è·ƒ\n",
    "reduced_form = df_bw[right_mask]['repurchase_rate'].mean() - df_bw[left_mask]['repurchase_rate'].mean()\n",
    "\n",
    "# å¤„ç†çš„è·³è·ƒ\n",
    "first_stage_jump = df_bw[right_mask]['coupon_used'].mean() - df_bw[left_mask]['coupon_used'].mean()\n",
    "\n",
    "tau_wald = reduced_form / first_stage_jump\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Fuzzy RDD ä¼°è®¡ç»“æœ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"å¤„ç†æ¦‚ç‡è·³è·ƒ:       {first_stage_jump:.3f}\")\n",
    "print(f\"ç»“æœè·³è·ƒ:          {reduced_form:.3f}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"2SLS ä¼°è®¡:         {tau_fuzzy:.3f}%\")\n",
    "print(f\"Wald ä¼°è®¡:         {tau_wald:.3f}%\")\n",
    "print(f\"çœŸå®æ•ˆåº”:          15.000%\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nğŸ’¡ è§£é‡Š: Fuzzy RDD ä¼°è®¡çš„æ˜¯é¡ºä»è€… (Compliers) çš„ LATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: å¸¦å®½é€‰æ‹© â€”â€” åå·®-æ–¹å·®æƒè¡¡\n",
    "\n",
    "### 4.1 å¸¦å®½çš„å›°å¢ƒ\n",
    "\n",
    "**å°å¸¦å®½**ï¼š\n",
    "- âœ… ä¼˜ç‚¹ï¼šæ›´æ¥è¿‘é—¨æ§›ï¼Œçº¿æ€§è¿‘ä¼¼æ›´å‡†ç¡®ï¼ˆä½åå·®ï¼‰\n",
    "- âŒ ç¼ºç‚¹ï¼šæ ·æœ¬å°‘ï¼Œä¼°è®¡ä¸ç¨³å®šï¼ˆé«˜æ–¹å·®ï¼‰\n",
    "\n",
    "**å¤§å¸¦å®½**ï¼š\n",
    "- âœ… ä¼˜ç‚¹ï¼šæ ·æœ¬å¤šï¼Œä¼°è®¡ç¨³å®šï¼ˆä½æ–¹å·®ï¼‰\n",
    "- âŒ ç¼ºç‚¹ï¼šè¿œç¦»é—¨æ§›ï¼Œçº¿æ€§è¿‘ä¼¼ä¸å‡†ï¼ˆé«˜åå·®ï¼‰\n",
    "\n",
    "### 4.2 MSE-optimal å¸¦å®½\n",
    "\n",
    "**ç›®æ ‡**ï¼šæœ€å°åŒ–å‡æ–¹è¯¯å·®\n",
    "\n",
    "$$\n",
    "\\text{MSE}(\\hat{\\tau}) = \\text{Bias}(\\hat{\\tau})^2 + \\text{Var}(\\hat{\\tau})\n",
    "$$\n",
    "\n",
    "**åå·®**ï¼šä¸ $h^{p+1}$ æˆæ­£æ¯”ï¼ˆ$p$ æ˜¯å¤šé¡¹å¼é˜¶æ•°ï¼‰\n",
    "\n",
    "$$\n",
    "\\text{Bias}(\\hat{\\tau}) \\approx C_1 \\cdot h^{p+1}\n",
    "$$\n",
    "\n",
    "**æ–¹å·®**ï¼šä¸ $1/(n \\cdot h)$ æˆæ­£æ¯”\n",
    "\n",
    "$$\n",
    "\\text{Var}(\\hat{\\tau}) \\approx \\frac{C_2}{n \\cdot h}\n",
    "$$\n",
    "\n",
    "**æœ€ä¼˜å¸¦å®½**ï¼š\n",
    "\n",
    "$$\n",
    "h_{MSE}^* \\propto n^{-1/(2p+3)}\n",
    "$$\n",
    "\n",
    "å¯¹äºçº¿æ€§æ¨¡å‹ï¼ˆ$p=1$ï¼‰ï¼Œ$h^* \\propto n^{-1/5}$ã€‚\n",
    "\n",
    "### 4.3 å®è·µæ–¹æ³•\n",
    "\n",
    "#### Imbens-Kalyanaraman (2012)\n",
    "- åŸºäº MSE æœ€ä¼˜åŒ–\n",
    "- é€‚ç”¨äºçº¿æ€§å’ŒäºŒæ¬¡å¤šé¡¹å¼\n",
    "- éœ€è¦ä¼°è®¡æ¡ä»¶æ–¹å·®å’Œé«˜é˜¶å¯¼æ•°\n",
    "\n",
    "#### Calonico-Cattaneo-Titiunik (CCT, 2014)\n",
    "- MSE-optimal å¸¦å®½\n",
    "- æä¾›åå·®æ ¡æ­£çš„ç¨³å¥æ¨æ–­\n",
    "- æˆä¸ºäº‹å®æ ‡å‡†\n",
    "\n",
    "### 4.4 ç¨³å¥æ€§æ£€éªŒ\n",
    "\n",
    "å³ä½¿é€‰æ‹©äº†\"æœ€ä¼˜\"å¸¦å®½ï¼Œä»éœ€æ£€éªŒç»“æœçš„ç¨³å¥æ€§ï¼š\n",
    "- **å¸¦å®½æ•æ„Ÿæ€§å›¾**ï¼šç»˜åˆ¶ä¸åŒå¸¦å®½ä¸‹çš„ä¼°è®¡å€¼å’Œç½®ä¿¡åŒºé—´\n",
    "- **å¤šç§å¸¦å®½**ï¼šæŠ¥å‘Š 0.5h*, h*, 2h* çš„ç»“æœ\n",
    "- **ä¸åŒå¤šé¡¹å¼**ï¼šçº¿æ€§ã€äºŒæ¬¡ã€ä¸‰æ¬¡çš„å¯¹æ¯”\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ TODO 2: å®ç° CCT å¸¦å®½é€‰æ‹©\n",
    "\n",
    "Calonico-Cattaneo-Titiunik (2014) æå‡ºäº† MSE-optimal å¸¦å®½ã€‚è¯·å®Œæˆç®€åŒ–ç‰ˆçš„å®ç°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================",
    "# TODO 2: CCT å¸¦å®½é€‰æ‹©ï¼ˆç®€åŒ–ç‰ˆï¼‰ - å®Œæ•´å®ç°",
    "# ===================================",
    "",
    "def cct_bandwidth(X, Y, cutoff, kernel='triangular'):",
    "    \"\"\"",
    "    Calonico-Cattaneo-Titiunik (2014) MSE-optimal å¸¦å®½é€‰æ‹©ï¼ˆç®€åŒ–å®ç°ï¼‰",
    "    ",
    "    å‚æ•°:",
    "    ------",
    "    X : array-like",
    "        Running variable",
    "    Y : array-like",
    "        Outcome variable",
    "    cutoff : float",
    "        Cutoff point",
    "    kernel : str",
    "        Kernel type",
    "    ",
    "    è¿”å›:",
    "    ------",
    "    h_opt : float",
    "        Optimal bandwidth",
    "    \"\"\"",
    "    X = np.asarray(X)",
    "    Y = np.asarray(Y)",
    "    ",
    "    # ä¸­å¿ƒåŒ–",
    "    X_centered = X - cutoff",
    "    ",
    "    # åˆ†å·¦å³ä¸¤ä¾§",
    "    left_mask = X_centered < 0",
    "    right_mask = X_centered >= 0",
    "    ",
    "    X_left = X_centered[left_mask]",
    "    Y_left = Y[left_mask]",
    "    X_right = X_centered[right_mask]",
    "    Y_right = Y[right_mask]",
    "    ",
    "    # Step 1: ä¼°è®¡æ¡ä»¶æ–¹å·®",
    "    # ç”¨äºŒæ¬¡å¤šé¡¹å¼å›å½’çš„æ®‹å·®ä¼°è®¡æ–¹å·®",
    "    from sklearn.linear_model import LinearRegression",
    "    ",
    "    # å·¦ä¾§",
    "    if len(X_left) > 3:",
    "        poly_left = np.column_stack([X_left, X_left**2])",
    "        model_left = LinearRegression().fit(poly_left, Y_left)",
    "        resid_left = Y_left - model_left.predict(poly_left)",
    "        sigma2_left = np.var(resid_left)",
    "    else:",
    "        sigma2_left = np.var(Y_left)",
    "    ",
    "    # å³ä¾§",
    "    if len(X_right) > 3:",
    "        poly_right = np.column_stack([X_right, X_right**2])",
    "        model_right = LinearRegression().fit(poly_right, Y_right)",
    "        resid_right = Y_right - model_right.predict(poly_right)",
    "        sigma2_right = np.var(resid_right)",
    "    else:",
    "        sigma2_right = np.var(Y_right)",
    "    ",
    "    # Step 2: ä¼°è®¡äºŒé˜¶å¯¼æ•°",
    "    # ç”¨ä¸‰æ¬¡å¤šé¡¹å¼çš„äºŒé˜¶å¯¼æ•°",
    "    if len(X_left) > 4:",
    "        poly3_left = np.column_stack([X_left, X_left**2, X_left**3])",
    "        model3_left = LinearRegression().fit(poly3_left, Y_left)",
    "        m2_left = 2 * model3_left.coef_[1]  # f''(0) = 2 * beta_2",
    "    else:",
    "        m2_left = 0.1",
    "    ",
    "    if len(X_right) > 4:",
    "        poly3_right = np.column_stack([X_right, X_right**2, X_right**3])",
    "        model3_right = LinearRegression().fit(poly3_right, Y_right)",
    "        m2_right = 2 * model3_right.coef_[1]",
    "    else:",
    "        m2_right = 0.1",
    "    ",
    "    # Step 3: è®¡ç®— MSE-optimal å¸¦å®½",
    "    # Fan & Gijbels (1996) å…¬å¼çš„ç®€åŒ–ç‰ˆæœ¬",
    "    # h_opt = C * (sigma^2 / (n * m2^2))^(1/5)",
    "    ",
    "    n_left = len(X_left)",
    "    n_right = len(X_right)",
    "    ",
    "    # Kernel å¸¸æ•°",
    "    if kernel == 'triangular':",
    "        C_K = 3.44",
    "    else:",
    "        C_K = 2.70",
    "    ",
    "    # è®¡ç®—å·¦å³ä¸¤ä¾§çš„æœ€ä¼˜å¸¦å®½",
    "    if abs(m2_left) > 1e-6:",
    "        h_left = C_K * (sigma2_left / (n_left * m2_left**2))**(1/5)",
    "    else:",
    "        h_left = 30.0",
    "    ",
    "    if abs(m2_right) > 1e-6:",
    "        h_right = C_K * (sigma2_right / (n_right * m2_right**2))**(1/5)",
    "    else:",
    "        h_right = 30.0",
    "    ",
    "    # å–å¹³å‡",
    "    h_opt = (h_left + h_right) / 2",
    "    ",
    "    # é™åˆ¶åœ¨åˆç†èŒƒå›´",
    "    h_opt = np.clip(h_opt, 10, 100)",
    "    ",
    "    return h_opt",
    "",
    "# ä½¿ç”¨ CCT å¸¦å®½é€‰æ‹©",
    "h_cct = cct_bandwidth(df['score'].values, df['conversion'].values, cutoff=200)",
    "",
    "print(\"=\" * 70)",
    "print(\"CCT å¸¦å®½é€‰æ‹©ç»“æœ\")",
    "print(\"=\" * 70)",
    "print(f\"CCT æœ€ä¼˜å¸¦å®½: h = {h_cct:.2f}\")",
    "print(\"=\" * 70)",
    "",
    "# ç”¨ CCT å¸¦å®½é‡æ–°ä¼°è®¡",
    "rdd_cct = SharpRDD(cutoff=200, bandwidth=h_cct, polynomial_order=1)",
    "rdd_cct.fit(df['score'].values, df['conversion'].values)",
    "",
    "print(f\"\\nä½¿ç”¨ CCT å¸¦å®½çš„ RDD ä¼°è®¡:\")",
    "print(f\"  å¤„ç†æ•ˆåº”: {rdd_cct.tau_:.4f}\")",
    "print(f\"  æ ‡å‡†è¯¯: {rdd_cct.se_:.4f}\")",
    "print(f\"  t-ç»Ÿè®¡é‡: {rdd_cct.tau_/rdd_cct.se_:.2f}\")",
    "print(f\"  p-value: {2*(1 - stats.norm.cdf(abs(rdd_cct.tau_/rdd_cct.se_))):.4f}\")",
    "print(f\"  95% CI: [{rdd_cct.tau_ - 1.96*rdd_cct.se_:.4f}, {rdd_cct.tau_ + 1.96*rdd_cct.se_:.4f}]\")",
    "",
    "# å¯¹æ¯”ä¸åŒå¸¦å®½",
    "print(\"\\n\" + \"=\" * 70)",
    "print(\"ä¸åŒå¸¦å®½ä¸‹çš„ä¼°è®¡å¯¹æ¯”\")",
    "print(\"=\" * 70)",
    "print(f\"{'æ–¹æ³•':<20s} {'å¸¦å®½':>10s} {'æ•ˆåº”':>10s} {'æ ‡å‡†è¯¯':>10s}\")",
    "print(\"-\" * 70)",
    "",
    "for h, name in [(20, 'å°å¸¦å®½'), (h_cct, 'CCTæœ€ä¼˜å¸¦å®½'), (60, 'å¤§å¸¦å®½')]:",
    "    rdd_temp = SharpRDD(cutoff=200, bandwidth=h, polynomial_order=1)",
    "    rdd_temp.fit(df['score'].values, df['conversion'].values)",
    "    print(f\"{name:<20s} {h:>10.1f} {rdd_temp.tau_:>10.4f} {rdd_temp.se_:>10.4f}\")",
    "",
    "print(\"=\" * 70)",
    "",
    "print(\"\\nğŸ’¡ è§£è¯»:\")",
    "print(\"  â€¢ CCT å¸¦å®½åœ¨ç†è®ºä¸Šæœ€å°åŒ– MSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰\")",
    "print(\"  â€¢ å®ƒåœ¨åå·®å’Œæ–¹å·®ä¹‹é—´å–å¾—æœ€ä¼˜å¹³è¡¡\")",
    "print(\"  â€¢ å®è·µä¸­ï¼Œå»ºè®®æŠ¥å‘Šå¤šä¸ªå¸¦å®½çš„ç»“æœï¼Œæ£€æŸ¥ç¨³å¥æ€§\")",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: æ£€éªŒæ–¹æ³• â€”â€” éªŒè¯ RDD å‡è®¾\n",
    "\n",
    "RDD çš„å¯ä¿¡åº¦ä¾èµ–äºå…³é”®å‡è®¾ã€‚æˆ‘ä»¬éœ€è¦ä¸€ç³»åˆ—æ£€éªŒæ¥éªŒè¯è®¾è®¡çš„æœ‰æ•ˆæ€§ã€‚\n",
    "\n",
    "### 5.1 McCrary å¯†åº¦æ£€éªŒï¼ˆæ“çºµæ£€éªŒï¼‰\n",
    "\n",
    "**ç›®çš„**ï¼šæ£€éªŒä¸ªä½“æ˜¯å¦èƒ½å¤Ÿç²¾ç¡®æ§åˆ¶é©±åŠ¨å˜é‡ï¼Œä»è€Œæ“çºµè‡ªå·±çš„å¤„ç†çŠ¶æ€ã€‚\n",
    "\n",
    "**é€»è¾‘**ï¼š\n",
    "- å¦‚æœä¸ªä½“èƒ½æ“çºµï¼ˆå¦‚è€ƒè¯•ä½œå¼Šåˆšå¥½è¾¾åˆ° 60 åˆ†ï¼‰ï¼Œé©±åŠ¨å˜é‡åœ¨é—¨æ§›å¤„çš„å¯†åº¦ä¼šæœ‰**ä¸è¿ç»­è·³è·ƒ**\n",
    "- å¦‚æœæ²¡æœ‰æ“çºµï¼Œå¯†åº¦åº”è¯¥**å¹³æ»‘è¿ç»­**\n",
    "\n",
    "**æ–¹æ³•**ï¼ˆMcCrary, 2008ï¼‰ï¼š\n",
    "1. å°†é©±åŠ¨å˜é‡åˆ†ç®±ï¼Œè®¡ç®—æ¯ä¸ªç®±çš„é¢‘æ•°\n",
    "2. åœ¨é—¨æ§›ä¸¤ä¾§åˆ†åˆ«æ‹Ÿåˆå¯†åº¦å‡½æ•°ï¼ˆå±€éƒ¨çº¿æ€§ï¼‰\n",
    "3. æ£€éªŒé—¨æ§›å¤„çš„å¯†åº¦è·³è·ƒæ˜¯å¦æ˜¾è‘—\n",
    "\n",
    "**æ£€éªŒç»Ÿè®¡é‡**ï¼š\n",
    "$$\n",
    "\\theta = \\log f_+(c) - \\log f_-(c)\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ $f_+(c)$ å’Œ $f_-(c)$ æ˜¯é—¨æ§›å³ä¾§å’Œå·¦ä¾§çš„å¯†åº¦ä¼°è®¡ã€‚\n",
    "\n",
    "**é›¶å‡è®¾**: $H_0: \\theta = 0$ï¼ˆå¯†åº¦è¿ç»­ï¼‰\n",
    "\n",
    "### 5.2 åå˜é‡è¿ç»­æ€§æ£€éªŒ\n",
    "\n",
    "**ç›®çš„**ï¼šæ£€éªŒä¸ªä½“ç‰¹å¾åœ¨é—¨æ§›å¤„æ˜¯å¦è¿ç»­ã€‚\n",
    "\n",
    "**é€»è¾‘**ï¼š\n",
    "- å¦‚æœé—¨æ§›é™„è¿‘çš„ä¸ªä½“å¯æ¯”ï¼Œä»–ä»¬çš„**åŸºçº¿ç‰¹å¾**åº”è¯¥ç›¸ä¼¼\n",
    "- å¯¹æ¯ä¸ªåå˜é‡ $X_k$ï¼Œæ£€éªŒå…¶åœ¨é—¨æ§›å¤„æ˜¯å¦æœ‰è·³è·ƒ\n",
    "\n",
    "**æ–¹æ³•**ï¼š\n",
    "1. å¯¹æ¯ä¸ªåå˜é‡ï¼Œç”¨ RDD è®¾è®¡ä¼°è®¡\"ä¼ªæ•ˆåº”\"\n",
    "2. å¦‚æœåå˜é‡è¿ç»­ï¼Œä¼ªæ•ˆåº”åº”æ¥è¿‘ 0\n",
    "\n",
    "**ç¤ºä¾‹åå˜é‡**ï¼š\n",
    "- ç”¨æˆ·å¹´é¾„\n",
    "- æ³¨å†Œæ—¶é•¿\n",
    "- å†å²æ¶ˆè´¹æ°´å¹³\n",
    "- åœ°ç†ä½ç½®\n",
    "\n",
    "### 5.3 Placebo æ£€éªŒ\n",
    "\n",
    "**ç›®çš„**ï¼šæ£€éªŒåœ¨ä¸åº”è¯¥æœ‰æ•ˆåº”çš„åœ°æ–¹æ˜¯å¦ä¹Ÿæ£€æµ‹åˆ°äº†æ•ˆåº”ã€‚\n",
    "\n",
    "#### (a) ä¼ªé—¨æ§›æ£€éªŒ\n",
    "- åœ¨çœŸå®é—¨æ§›å·¦å³ä¸¤ä¾§é€‰æ‹©ä¼ªé—¨æ§›ï¼ˆå¦‚ c - 20, c + 20ï¼‰\n",
    "- ä¼°è®¡ä¼ªé—¨æ§›å¤„çš„\"æ•ˆåº”\"\n",
    "- é¢„æœŸï¼šä¼ªæ•ˆåº”åº”è¯¥ä¸æ˜¾è‘—\n",
    "\n",
    "#### (b) ä¼ªç»“æœæ£€éªŒ\n",
    "- ä½¿ç”¨ä¸åº”è¯¥å—å¤„ç†å½±å“çš„ç»“æœå˜é‡ï¼ˆå¦‚ç”¨æˆ·æ€§åˆ«ã€æ³¨å†Œæ¸ é“ï¼‰\n",
    "- ä¼°è®¡å¤„ç†å¯¹ä¼ªç»“æœçš„\"æ•ˆåº”\"\n",
    "- é¢„æœŸï¼šä¼ªæ•ˆåº”åº”è¯¥ä¸æ˜¾è‘—\n",
    "\n",
    "### 5.4 æ£€éªŒæ±‡æ€»è¡¨\n",
    "\n",
    "| æ£€éªŒç±»å‹ | æ£€éªŒå†…å®¹ | é›¶å‡è®¾ | æœŸæœ›ç»“æœ |\n",
    "|----------|----------|--------|----------|\n",
    "| McCrary å¯†åº¦ | é©±åŠ¨å˜é‡å¯†åº¦è¿ç»­ | å¯†åº¦æ— è·³è·ƒ | ä¸æ‹’ç» H0 |\n",
    "| åå˜é‡è¿ç»­æ€§ | åŸºçº¿ç‰¹å¾å¹³æ»‘ | åå˜é‡æ— è·³è·ƒ | ä¸æ‹’ç» H0 |\n",
    "| ä¼ªé—¨æ§› | éé—¨æ§›å¤„æ— æ•ˆåº” | ä¼ªæ•ˆåº” = 0 | ä¸æ‹’ç» H0 |\n",
    "| ä¼ªç»“æœ | ä¸ç›¸å…³ç»“æœæ— æ•ˆåº” | ä¼ªæ•ˆåº” = 0 | ä¸æ‹’ç» H0 |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€éªŒ 1: McCrary å¯†åº¦æ£€éªŒ\n",
    "\n",
    "def mccrary_test(X, cutoff, bins=30):\n",
    "    \"\"\"\n",
    "    McCrary (2008) å¯†åº¦æ£€éªŒ\n",
    "    \n",
    "    è¿”å›:\n",
    "        theta: log å¯†åº¦å·®\n",
    "        se: æ ‡å‡†è¯¯\n",
    "        p_value: p å€¼\n",
    "    \"\"\"\n",
    "    # åˆ†ç®±\n",
    "    bin_edges = np.linspace(X.min(), X.max(), bins + 1)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    counts, _ = np.histogram(X, bins=bin_edges)\n",
    "    \n",
    "    # å¯†åº¦ä¼°è®¡ï¼ˆé¢‘æ•° / æ€»æ•° / ç®±å®½ï¼‰\n",
    "    bin_width = bin_edges[1] - bin_edges[0]\n",
    "    density = counts / (len(X) * bin_width)\n",
    "    \n",
    "    # æ‰¾åˆ°é—¨æ§›æ‰€åœ¨çš„ç®±\n",
    "    cutoff_idx = np.searchsorted(bin_edges, cutoff) - 1\n",
    "    \n",
    "    # å·¦å³ä¸¤ä¾§çš„å¯†åº¦ï¼ˆç®€åŒ–ï¼šå–é—¨æ§›å·¦å³çš„å¹³å‡å¯†åº¦ï¼‰\n",
    "    left_density = density[:cutoff_idx].mean()\n",
    "    right_density = density[cutoff_idx:].mean()\n",
    "    \n",
    "    # Log å¯†åº¦å·®\n",
    "    theta = np.log(right_density) - np.log(left_density)\n",
    "    \n",
    "    # æ ‡å‡†è¯¯ï¼ˆç®€åŒ–ä¼°è®¡ï¼‰\n",
    "    se = np.sqrt(1/counts[:cutoff_idx].sum() + 1/counts[cutoff_idx:].sum())\n",
    "    \n",
    "    # p å€¼\n",
    "    z_stat = theta / se\n",
    "    p_value = 2 * (1 - stats.norm.cdf(np.abs(z_stat)))\n",
    "    \n",
    "    return theta, se, p_value, bin_centers, density\n",
    "\n",
    "# æ‰§è¡Œ McCrary æ£€éªŒ\n",
    "theta, se, p_value, bin_centers, density = mccrary_test(df['spending'].values, cutoff=200)\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=bin_centers,\n",
    "    y=density,\n",
    "    marker_color=COLORS['primary'],\n",
    "    opacity=0.7,\n",
    "    name='å¯†åº¦'\n",
    "))\n",
    "\n",
    "fig.add_vline(x=200, line_dash=\"dash\", line_color=\"black\",\n",
    "              annotation_text=\"é—¨æ§›: 200 å…ƒ\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'McCrary å¯†åº¦æ£€éªŒ (Î¸ = {theta:.3f}, p = {p_value:.3f})',\n",
    "    xaxis_title='æ¶ˆè´¹é‡‘é¢ (å…ƒ)',\n",
    "    yaxis_title='å¯†åº¦',\n",
    "    template='plotly_white',\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"McCrary å¯†åº¦æ£€éªŒ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Log å¯†åº¦å·® (Î¸):     {theta:.4f}\")\n",
    "print(f\"æ ‡å‡†è¯¯ (SE):        {se:.4f}\")\n",
    "print(f\"p å€¼:              {p_value:.4f}\")\n",
    "print(\"-\"*60)\n",
    "if p_value > 0.05:\n",
    "    print(\"âœ… æ— æ³•æ‹’ç»å¯†åº¦è¿ç»­çš„é›¶å‡è®¾ â†’ æ— æ“çºµè¯æ®\")\n",
    "else:\n",
    "    print(\"âš ï¸  æ‹’ç»å¯†åº¦è¿ç»­çš„é›¶å‡è®¾ â†’ å¯èƒ½å­˜åœ¨æ“çºµ\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€éªŒ 2: åå˜é‡è¿ç»­æ€§æ£€éªŒ\n",
    "\n",
    "# ç”Ÿæˆå¸¦åå˜é‡çš„æ•°æ®\n",
    "np.random.seed(42)\n",
    "n = len(df)\n",
    "df['age'] = np.random.normal(35, 10, n)  # å¹´é¾„ï¼ˆä¸åº”è¯¥è·³è·ƒï¼‰\n",
    "df['tenure_days'] = np.random.exponential(365, n)  # æ³¨å†Œå¤©æ•°ï¼ˆä¸åº”è¯¥è·³è·ƒï¼‰\n",
    "df['avg_order_value'] = df['spending'] * 0.5 + np.random.normal(0, 20, n)  # å†å²è®¢å•é‡‘é¢ï¼ˆä¸åº”è¯¥è·³è·ƒï¼‰\n",
    "\n",
    "# å¯¹æ¯ä¸ªåå˜é‡è¿›è¡Œ RDD ä¼°è®¡\n",
    "covariates = ['age', 'tenure_days', 'avg_order_value']\n",
    "balance_results = []\n",
    "\n",
    "for covar in covariates:\n",
    "    rdd = SharpRDD(cutoff=200, bandwidth=50, polynomial_order=1)\n",
    "    rdd.fit(df['spending'], df[covar])\n",
    "    \n",
    "    z_stat = rdd.tau_ / rdd.se_\n",
    "    p_val = 2 * (1 - stats.norm.cdf(np.abs(z_stat)))\n",
    "    \n",
    "    balance_results.append({\n",
    "        'Covariate': covar,\n",
    "        'Estimate': rdd.tau_,\n",
    "        'SE': rdd.se_,\n",
    "        'p-value': p_val,\n",
    "        'Balanced': 'âœ…' if p_val > 0.05 else 'âŒ'\n",
    "    })\n",
    "\n",
    "balance_df = pd.DataFrame(balance_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"åå˜é‡è¿ç»­æ€§æ£€éªŒï¼ˆå¹³è¡¡æ€§æ£€éªŒï¼‰\")\n",
    "print(\"=\"*70)\n",
    "print(balance_df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ’¡ è§£é‡Š: å¦‚æœåå˜é‡åœ¨é—¨æ§›å¤„æœ‰æ˜¾è‘—è·³è·ƒï¼Œè¯´æ˜é—¨æ§›é™„è¿‘çš„ä¸ªä½“ä¸å¯æ¯”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ TODO 3: Placebo æ£€éªŒ\n",
    "\n",
    "è¯·å®Œæˆä¼ªé—¨æ§›æ£€éªŒï¼ŒéªŒè¯åœ¨éçœŸå®é—¨æ§›å¤„ä¸åº”è¯¥æœ‰æ•ˆåº”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================",
    "# TODO 3: Placebo æ£€éªŒ - ä¼ªé—¨æ§› - å®Œæ•´å®ç°",
    "# ===================================",
    "",
    "# çœŸå®é—¨æ§›: 200",
    "# ä¼ªé—¨æ§›: åœ¨çœŸå®é—¨æ§›é™„è¿‘ä½†ä¸åŒ…æ‹¬çœŸå®é—¨æ§›çš„ç‚¹",
    "placebo_cutoffs = [150, 170, 190, 210, 230, 250]",
    "",
    "placebo_results = []",
    "",
    "for cutoff_placebo in placebo_cutoffs:",
    "    # å¯¹æ¯ä¸ªä¼ªé—¨æ§›è¿›è¡Œ RDD ä¼°è®¡",
    "    rdd_placebo = SharpRDD(cutoff=cutoff_placebo, bandwidth=30, polynomial_order=1)",
    "    rdd_placebo.fit(df['score'].values, df['conversion'].values)",
    "    ",
    "    # è®¡ç®— p-value",
    "    t_stat = rdd_placebo.tau_ / rdd_placebo.se_",
    "    pvalue = 2 * (1 - stats.norm.cdf(abs(t_stat)))",
    "    ",
    "    placebo_results.append({",
    "        'cutoff': cutoff_placebo,",
    "        'effect': rdd_placebo.tau_,",
    "        'se': rdd_placebo.se_,",
    "        'pvalue': pvalue",
    "    })",
    "",
    "df_placebo = pd.DataFrame(placebo_results)",
    "",
    "# çœŸå®é—¨æ§›çš„ç»“æœ",
    "rdd_real = SharpRDD(cutoff=200, bandwidth=30, polynomial_order=1)",
    "rdd_real.fit(df['score'].values, df['conversion'].values)",
    "t_stat_real = rdd_real.tau_ / rdd_real.se_",
    "pvalue_real = 2 * (1 - stats.norm.cdf(abs(t_stat_real)))",
    "",
    "# æ‰“å°ç»“æœ",
    "print(\"=\" * 80)",
    "print(\"Placebo Test ç»“æœï¼ˆä¼ªé—¨æ§›æ£€éªŒï¼‰\")",
    "print(\"=\" * 80)",
    "print(f\"{'ä¼ªé—¨æ§›':>10s} {'æ•ˆåº”':>10s} {'æ ‡å‡†è¯¯':>10s} {'P-value':>10s} {'æ˜¾è‘—æ€§':>10s}\")",
    "print(\"-\" * 80)",
    "",
    "for _, row in df_placebo.iterrows():",
    "    sig = '***' if row['pvalue'] < 0.01 else ('**' if row['pvalue'] < 0.05 else ('*' if row['pvalue'] < 0.1 else ''))",
    "    print(f\"{row['cutoff']:10.0f} {row['effect']:10.4f} {row['se']:10.4f} {row['pvalue']:10.4f} {sig:>10s}\")",
    "",
    "# çœŸå®é—¨æ§›",
    "print(\"-\" * 80)",
    "sig_real = '***' if pvalue_real < 0.01 else ('**' if pvalue_real < 0.05 else ('*' if pvalue_real < 0.1 else ''))",
    "print(f\"{'200 (çœŸå®)':>10s} {rdd_real.tau_:10.4f} {rdd_real.se_:10.4f} {pvalue_real:10.4f} {sig_real:>10s}\")",
    "print(\"=\" * 80)",
    "",
    "# å¯è§†åŒ–",
    "fig = make_subplots(",
    "    rows=1, cols=2,",
    "    subplot_titles=('æ•ˆåº”ä¼°è®¡å€¼', 'P-value åˆ†å¸ƒ')",
    ")",
    "",
    "# å·¦å›¾ï¼šæ•ˆåº”ä¼°è®¡",
    "# ä¼ªé—¨æ§›",
    "fig.add_trace(",
    "    go.Scatter(",
    "        x=df_placebo['cutoff'],",
    "        y=df_placebo['effect'],",
    "        error_y=dict(",
    "            type='data',",
    "            array=1.96*df_placebo['se'],",
    "            visible=True",
    "        ),",
    "        mode='markers',",
    "        name='ä¼ªé—¨æ§›',",
    "        marker=dict(size=10, color=COLORS['synthetic']),",
    "    ),",
    "    row=1, col=1",
    ")",
    "",
    "# çœŸå®é—¨æ§›",
    "fig.add_trace(",
    "    go.Scatter(",
    "        x=[200],",
    "        y=[rdd_real.tau_],",
    "        error_y=dict(",
    "            type='data',",
    "            array=[1.96*rdd_real.se_],",
    "            visible=True",
    "        ),",
    "        mode='markers',",
    "        name='çœŸå®é—¨æ§›',",
    "        marker=dict(size=15, color=COLORS['treated'], symbol='diamond'),",
    "    ),",
    "    row=1, col=1",
    ")",
    "",
    "# é›¶çº¿",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", row=1, col=1)",
    "",
    "# çœŸå®æ•ˆåº”æ°´å¹³çº¿",
    "fig.add_hline(y=rdd_real.tau_, line_dash=\"dot\", line_color=COLORS['treated'], ",
    "              opacity=0.5, row=1, col=1)",
    "",
    "# å³å›¾ï¼šP-values",
    "fig.add_trace(",
    "    go.Scatter(",
    "        x=df_placebo['cutoff'],",
    "        y=df_placebo['pvalue'],",
    "        mode='lines+markers',",
    "        name='ä¼ªé—¨æ§›',",
    "        line=dict(color=COLORS['synthetic'], width=2),",
    "        marker=dict(size=10),",
    "        showlegend=False",
    "    ),",
    "    row=1, col=2",
    ")",
    "",
    "# çœŸå®é—¨æ§›çš„ p-value",
    "fig.add_trace(",
    "    go.Scatter(",
    "        x=[200],",
    "        y=[pvalue_real],",
    "        mode='markers',",
    "        name='çœŸå®é—¨æ§›',",
    "        marker=dict(size=15, color=COLORS['treated'], symbol='diamond'),",
    "        showlegend=False",
    "    ),",
    "    row=1, col=2",
    ")",
    "",
    "# æ˜¾è‘—æ€§æ°´å¹³çº¿",
    "fig.add_hline(y=0.05, line_dash=\"dash\", line_color=\"red\", ",
    "              annotation_text=\"Î±=0.05\", row=1, col=2)",
    "",
    "fig.update_xaxes(title_text=\"é—¨æ§›å€¼\", row=1, col=1)",
    "fig.update_xaxes(title_text=\"é—¨æ§›å€¼\", row=1, col=2)",
    "fig.update_yaxes(title_text=\"RDD ä¼°è®¡é‡\", row=1, col=1)",
    "fig.update_yaxes(title_text=\"P-value\", row=1, col=2)",
    "",
    "fig.update_layout(",
    "    title_text='Placebo Test: ä¼ªé—¨æ§›æ£€éªŒ',",
    "    template='plotly_white',",
    "    height=400,",
    "    showlegend=True",
    ")",
    "",
    "fig.show()",
    "",
    "# ç»Ÿè®¡æ£€éªŒ",
    "n_sig_placebo = (df_placebo['pvalue'] < 0.05).sum()",
    "n_total_placebo = len(df_placebo)",
    "",
    "print(f\"\\nğŸ’¡ è§£è¯»:\")",
    "print(f\"  â€¢ åœ¨ {n_total_placebo} ä¸ªä¼ªé—¨æ§›ä¸­ï¼Œ{n_sig_placebo} ä¸ªåœ¨ 5% æ°´å¹³ä¸Šæ˜¾è‘—\")",
    "print(f\"  â€¢ ç†æƒ³æƒ…å†µï¼šä¼ªé—¨æ§›å¤„æ•ˆåº”ä¸æ˜¾è‘—ï¼Œåªæœ‰çœŸå®é—¨æ§›å¤„æ˜¾è‘—\")",
    "",
    "if n_sig_placebo == 0:",
    "    print(f\"  âœ“ æ‰€æœ‰ä¼ªé—¨æ§›å‡ä¸æ˜¾è‘—ï¼ŒPlacebo Test é€šè¿‡\")",
    "    print(f\"  âœ“ è¿™å¢å¼ºäº†æˆ‘ä»¬å¯¹çœŸå®æ•ˆåº”çš„ä¿¡å¿ƒ\")",
    "elif n_sig_placebo <= n_total_placebo * 0.05:",
    "    print(f\"  âœ“ å°‘æ•°ä¼ªé—¨æ§›æ˜¾è‘—ï¼ˆâ‰¤5%ï¼‰ï¼Œåœ¨é¢„æœŸèŒƒå›´å†…\")",
    "    print(f\"  âœ“ Placebo Test åŸºæœ¬é€šè¿‡\")",
    "else:",
    "    print(f\"  âš  è¾ƒå¤šä¼ªé—¨æ§›æ˜¾è‘—ï¼ˆ>{n_total_placebo * 0.05:.0f}ä¸ªï¼‰ï¼Œéœ€è¦è­¦æƒ•\")",
    "    print(f\"  âš  å¯èƒ½åŸå› :\")",
    "    print(f\"    1. å‡½æ•°å½¢å¼è®¾å®šé”™è¯¯ï¼ˆåº”è¯¥ç”¨æ›´é«˜é˜¶å¤šé¡¹å¼ï¼‰\")",
    "    print(f\"    2. å­˜åœ¨å…¶ä»–æœªè§‚æµ‹çš„è·³è·ƒç‚¹\")",
    "    print(f\"    3. æ•°æ®ä¸­å­˜åœ¨å…¶ä»–ç»“æ„æ€§å˜åŒ–\")",
    "",
    "print(f\"\\n  â€¢ çœŸå®é—¨æ§›å¤„ p-value = {pvalue_real:.4f}\")",
    "if pvalue_real < 0.05:",
    "    print(f\"  âœ“ çœŸå®é—¨æ§›å¤„æ•ˆåº”æ˜¾è‘—ï¼ˆp < 0.05ï¼‰\")",
    "else:",
    "    print(f\"  âœ— çœŸå®é—¨æ§›å¤„æ•ˆåº”ä¸æ˜¾è‘—ï¼ˆp >= 0.05ï¼‰\")",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: ä¸šåŠ¡æ¡ˆä¾‹\n",
    "\n",
    "### æ¡ˆä¾‹ 1: ä¼˜æƒ åˆ¸é—¨æ§›æ•ˆåº”ï¼ˆæ»¡å‡æ´»åŠ¨ï¼‰\n",
    "\n",
    "**èƒŒæ™¯**ï¼šç”µå•†å¹³å°æ¨å‡ºã€Œæ»¡ 200 å‡ 50ã€æ´»åŠ¨ï¼Œå¸Œæœ›è¯„ä¼°ä¼˜æƒ åˆ¸å¯¹ç”¨æˆ·å¤è´­çš„é•¿æœŸæ•ˆåº”ã€‚\n",
    "\n",
    "**æ•°æ®**ï¼š\n",
    "- é©±åŠ¨å˜é‡ï¼šé¦–å•æ¶ˆè´¹é‡‘é¢\n",
    "- å¤„ç†ï¼šæ˜¯å¦è·å¾— 50 å…ƒä¼˜æƒ åˆ¸\n",
    "- ç»“æœï¼š30 å¤©å†…å¤è´­ç‡\n",
    "\n",
    "**æŒ‘æˆ˜**ï¼š\n",
    "- ç”¨æˆ·å¯èƒ½ä¸ºäº†å‡‘å•è€Œåˆšå¥½è¶…è¿‡ 200 å…ƒï¼ˆæ“çºµï¼‰\n",
    "- éœ€è¦æ£€éªŒå¯†åº¦è¿ç»­æ€§\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¡ˆä¾‹ 1: ä¼˜æƒ åˆ¸é—¨æ§›æ•ˆåº”\n",
    "\n",
    "# æ¨¡æ‹ŸçœŸå®ä¸šåŠ¡æ•°æ®ï¼ˆè€ƒè™‘è½»å¾®æ“çºµï¼‰\n",
    "def simulate_coupon_case(n=2000):\n",
    "    np.random.seed(123)\n",
    "    \n",
    "    # è‡ªç„¶æ¶ˆè´¹ï¼ˆæ— æ“çºµï¼‰\n",
    "    natural_spending = np.random.gamma(shape=4, scale=50, size=int(n*0.9))\n",
    "    \n",
    "    # å‡‘å•æ¶ˆè´¹ï¼ˆè½»å¾®æ“çºµï¼Œé›†ä¸­åœ¨ 200-210 ä¹‹é—´ï¼‰\n",
    "    manipulated_spending = np.random.uniform(200, 210, int(n*0.1))\n",
    "    \n",
    "    spending = np.concatenate([natural_spending, manipulated_spending])\n",
    "    spending = spending[(spending >= 100) & (spending <= 300)]  # è¿‡æ»¤æç«¯å€¼\n",
    "    \n",
    "    # å¤„ç†\n",
    "    coupon = (spending >= 200).astype(int)\n",
    "    \n",
    "    # åå˜é‡\n",
    "    age = np.random.normal(32, 8, len(spending))\n",
    "    is_member = np.random.binomial(1, 0.3, len(spending))\n",
    "    \n",
    "    # ç»“æœï¼ˆå¤è´­ç‡å—å¹´é¾„ã€ä¼šå‘˜ã€ä¼˜æƒ åˆ¸å½±å“ï¼‰\n",
    "    base_repurchase = 25 + 0.15 * (spending - 200) - 0.3 * age + 10 * is_member\n",
    "    treatment_effect = 12  # çœŸå®æ•ˆåº” 12%\n",
    "    \n",
    "    repurchase_rate = base_repurchase + treatment_effect * coupon + np.random.normal(0, 15, len(spending))\n",
    "    repurchase_rate = np.clip(repurchase_rate, 0, 100)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'spending': spending,\n",
    "        'coupon': coupon,\n",
    "        'repurchase_rate': repurchase_rate,\n",
    "        'age': age,\n",
    "        'is_member': is_member\n",
    "    })\n",
    "\n",
    "df_case1 = simulate_coupon_case(n=2000)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ¡ˆä¾‹ 1: ä¼˜æƒ åˆ¸é—¨æ§›æ•ˆåº”åˆ†æ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# æ­¥éª¤ 1: McCrary å¯†åº¦æ£€éªŒ\n",
    "print(\"\\n[æ­¥éª¤ 1] McCrary å¯†åº¦æ£€éªŒ\")\n",
    "theta, se, p_value, _, _ = mccrary_test(df_case1['spending'].values, cutoff=200)\n",
    "print(f\"  Log å¯†åº¦å·®: {theta:.4f} (p = {p_value:.4f})\")\n",
    "if p_value < 0.05:\n",
    "    print(\"  âš ï¸  æ£€æµ‹åˆ°å¯†åº¦è·³è·ƒï¼Œå¯èƒ½å­˜åœ¨å‡‘å•è¡Œä¸º\")\n",
    "else:\n",
    "    print(\"  âœ… å¯†åº¦è¿ç»­ï¼Œæ— æ˜æ˜¾æ“çºµ\")\n",
    "\n",
    "# æ­¥éª¤ 2: åå˜é‡å¹³è¡¡\n",
    "print(\"\\n[æ­¥éª¤ 2] åå˜é‡å¹³è¡¡æ€§æ£€éªŒ\")\n",
    "for covar in ['age', 'is_member']:\n",
    "    rdd = SharpRDD(cutoff=200, bandwidth=40)\n",
    "    rdd.fit(df_case1['spending'], df_case1[covar])\n",
    "    p = 2 * (1 - stats.norm.cdf(np.abs(rdd.tau_ / rdd.se_)))\n",
    "    status = \"âœ…\" if p > 0.05 else \"âŒ\"\n",
    "    print(f\"  {covar}: Ï„ = {rdd.tau_:.4f} (p = {p:.4f}) {status}\")\n",
    "\n",
    "# æ­¥éª¤ 3: RDD ä¼°è®¡\n",
    "print(\"\\n[æ­¥éª¤ 3] RDD æ•ˆåº”ä¼°è®¡\")\n",
    "rdd_main = SharpRDD(cutoff=200, bandwidth=None)  # è‡ªåŠ¨é€‰æ‹©å¸¦å®½\n",
    "rdd_main.fit(df_case1['spending'], df_case1['repurchase_rate'])\n",
    "results_case1 = rdd_main.summary()\n",
    "\n",
    "print(f\"\\nğŸ“Š ç»“è®º: ä¼˜æƒ åˆ¸ä½¿å¤è´­ç‡æå‡ {results_case1['tau']:.2f}% \")\n",
    "print(f\"         (95% CI: [{results_case1['ci'][0]:.2f}, {results_case1['ci'][1]:.2f}])\")\n",
    "print(f\"\\nğŸ’¡ ä¸šåŠ¡å»ºè®®: æ»¡å‡æ´»åŠ¨æœ‰æ•ˆï¼Œå¯è€ƒè™‘é•¿æœŸåŒ–æˆ–è°ƒæ•´é—¨æ§›\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ¡ˆä¾‹ 2: ä¼šå‘˜ç­‰çº§æ•ˆåº”\n",
    "\n",
    "**èƒŒæ™¯**ï¼šå¹³å°è®¾ç½®ä¼šå‘˜ç­‰çº§ï¼Œæ¶ˆè´¹æ»¡ 5000 å…ƒå‡çº§ä¸ºé‡‘å¡ä¼šå‘˜ï¼Œäº«å—ä¸“å±æƒç›Šã€‚è¯„ä¼°é‡‘å¡æƒç›Šå¯¹ç”¨æˆ·æ´»è·ƒåº¦çš„å½±å“ã€‚\n",
    "\n",
    "**æ•°æ®**ï¼š\n",
    "- é©±åŠ¨å˜é‡ï¼šå¹´åº¦ç´¯è®¡æ¶ˆè´¹\n",
    "- å¤„ç†ï¼šæ˜¯å¦ä¸ºé‡‘å¡ä¼šå‘˜\n",
    "- ç»“æœï¼šæ¬¡æœˆæ´»è·ƒå¤©æ•°\n",
    "\n",
    "**ç‰¹ç‚¹**ï¼š\n",
    "- Fuzzy RDDï¼ˆæœ‰äººè¾¾æ ‡ä½†æœªå‡çº§ï¼Œæœ‰äººæœªè¾¾æ ‡ä½†å®¢æœç‰¹æ‰¹ï¼‰\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¡ˆä¾‹ 2: ä¼šå‘˜ç­‰çº§æ•ˆåº”ï¼ˆFuzzy RDDï¼‰\n",
    "\n",
    "def simulate_membership_case(n=1500):\n",
    "    np.random.seed(456)\n",
    "    \n",
    "    # å¹´åº¦æ¶ˆè´¹\n",
    "    annual_spending = np.random.gamma(shape=3, scale=1500, size=n)\n",
    "    annual_spending = annual_spending[(annual_spending >= 2000) & (annual_spending <= 8000)]\n",
    "    \n",
    "    # æœ‰èµ„æ ¼å‡çº§ï¼ˆè¶…è¿‡ 5000ï¼‰\n",
    "    eligible = (annual_spending >= 5000).astype(int)\n",
    "    \n",
    "    # å®é™…å‡çº§ï¼ˆFuzzyï¼‰\n",
    "    # è¾¾æ ‡: 80% å‡çº§\n",
    "    # æœªè¾¾æ ‡: 15% ç‰¹æ‰¹å‡çº§\n",
    "    actual_upgrade = np.zeros(len(annual_spending))\n",
    "    actual_upgrade[eligible == 1] = np.random.binomial(1, 0.8, (eligible == 1).sum())\n",
    "    actual_upgrade[eligible == 0] = np.random.binomial(1, 0.15, (eligible == 0).sum())\n",
    "    \n",
    "    # ç»“æœï¼ˆæ´»è·ƒå¤©æ•°ï¼‰\n",
    "    base_activity = 10 + 0.002 * (annual_spending - 5000) + np.random.normal(0, 3, len(annual_spending))\n",
    "    treatment_effect = 5  # é‡‘å¡ä½¿æ´»è·ƒå¤©æ•°å¢åŠ  5 å¤©\n",
    "    \n",
    "    activity_days = base_activity + treatment_effect * actual_upgrade\n",
    "    activity_days = np.clip(activity_days, 0, 30)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'annual_spending': annual_spending,\n",
    "        'eligible': eligible,\n",
    "        'gold_member': actual_upgrade,\n",
    "        'activity_days': activity_days\n",
    "    })\n",
    "\n",
    "df_case2 = simulate_membership_case(n=1500)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ¡ˆä¾‹ 2: ä¼šå‘˜ç­‰çº§æ•ˆåº”åˆ†æ (Fuzzy RDD)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# æ£€æŸ¥å¤„ç†æ¦‚ç‡è·³è·ƒ\n",
    "bandwidth = 1500\n",
    "df_bw = df_case2[np.abs(df_case2['annual_spending'] - 5000) <= bandwidth].copy()\n",
    "\n",
    "left_treatment_prob = df_bw[df_bw['annual_spending'] < 5000]['gold_member'].mean()\n",
    "right_treatment_prob = df_bw[df_bw['annual_spending'] >= 5000]['gold_member'].mean()\n",
    "first_stage_jump = right_treatment_prob - left_treatment_prob\n",
    "\n",
    "print(f\"\\n[ç¬¬ä¸€é˜¶æ®µ] å¤„ç†æ¦‚ç‡è·³è·ƒ\")\n",
    "print(f\"  å·¦ä¾§å‡çº§ç‡: {left_treatment_prob:.3f}\")\n",
    "print(f\"  å³ä¾§å‡çº§ç‡: {right_treatment_prob:.3f}\")\n",
    "print(f\"  è·³è·ƒå¹…åº¦:   {first_stage_jump:.3f}\")\n",
    "\n",
    "# 2SLS ä¼°è®¡\n",
    "df_bw['X_centered'] = df_bw['annual_spending'] - 5000\n",
    "df_bw['Z_X'] = df_bw['eligible'] * df_bw['X_centered']\n",
    "\n",
    "# ç¬¬ä¸€é˜¶æ®µ\n",
    "X_first = df_bw[['eligible', 'X_centered', 'Z_X']].values\n",
    "D_bw = df_bw['gold_member'].values\n",
    "first_stage = LinearRegression().fit(X_first, D_bw)\n",
    "D_hat = first_stage.predict(X_first)\n",
    "\n",
    "# ç¬¬äºŒé˜¶æ®µ\n",
    "X_second = np.column_stack([D_hat, df_bw[['X_centered', 'Z_X']].values])\n",
    "Y_bw = df_bw['activity_days'].values\n",
    "second_stage = LinearRegression().fit(X_second, Y_bw)\n",
    "tau_2sls = second_stage.coef_[0]\n",
    "\n",
    "# æ ‡å‡†è¯¯ï¼ˆç®€åŒ–ï¼‰\n",
    "residuals = Y_bw - second_stage.predict(X_second)\n",
    "se_2sls = np.sqrt(np.sum(residuals**2) / (len(Y_bw) - 4)) / np.sqrt(len(Y_bw))\n",
    "\n",
    "print(f\"\\n[ç¬¬äºŒé˜¶æ®µ] 2SLS ä¼°è®¡\")\n",
    "print(f\"  LATE (é¡ºä»è€…æ•ˆåº”): {tau_2sls:.3f} å¤©\")\n",
    "print(f\"  æ ‡å‡†è¯¯:            {se_2sls:.3f}\")\n",
    "print(f\"  95% CI:           [{tau_2sls - 1.96*se_2sls:.3f}, {tau_2sls + 1.96*se_2sls:.3f}]\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ç»“è®º: é‡‘å¡ä¼šå‘˜ä½¿æ´»è·ƒå¤©æ•°å¢åŠ  {tau_2sls:.1f} å¤©ï¼ˆé’ˆå¯¹é¡ºä»è€…ï¼‰\")\n",
    "print(f\"\\nğŸ’¡ ä¸šåŠ¡è§£é‡Š: è¿™æ˜¯å¯¹'å› é‡‘å¡æƒç›Šè€Œå‡çº§çš„ç”¨æˆ·'çš„æ•ˆåº”ï¼Œä¸åŒ…æ‹¬æœ¬æ¥å°±å¾ˆæ´»è·ƒçš„ç”¨æˆ·\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ¡ˆä¾‹ 3: ä¿¡ç”¨è¯„åˆ†é—¨æ§›\n",
    "\n",
    "**èƒŒæ™¯**ï¼šé‡‘èå¹³å°è®¾ç½®ä¿¡ç”¨è¯„åˆ† 600 åˆ†ä¸ºé—¨æ§›ï¼Œ600 åˆ†ä»¥ä¸Šå¯äº«å—æ›´ä½åˆ©ç‡ã€‚è¯„ä¼°åˆ©ç‡ä¼˜æƒ å¯¹å€Ÿæ¬¾é‡‘é¢çš„å½±å“ã€‚\n",
    "\n",
    "**æ•°æ®**ï¼š\n",
    "- é©±åŠ¨å˜é‡ï¼šä¿¡ç”¨è¯„åˆ†ï¼ˆ590-610 åŒºé—´ï¼‰\n",
    "- å¤„ç†ï¼šæ˜¯å¦äº«å—ä½åˆ©ç‡\n",
    "- ç»“æœï¼šå€Ÿæ¬¾é‡‘é¢\n",
    "\n",
    "**è¦ç‚¹**ï¼š\n",
    "- çª„å¸¦å®½ï¼ˆä¿¡ç”¨è¯„åˆ†ç²¾ç¡®åº¦é«˜ï¼‰\n",
    "- éœ€è¦æ£€éªŒè¯„åˆ†æ“çºµï¼ˆå¦‚è™šå‡ä¿¡æ¯ï¼‰\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¡ˆä¾‹ 3: ä¿¡ç”¨è¯„åˆ†é—¨æ§›\n",
    "\n",
    "def simulate_credit_case(n=1000):\n",
    "    np.random.seed(789)\n",
    "    \n",
    "    # ä¿¡ç”¨è¯„åˆ†ï¼ˆé›†ä¸­åœ¨ 590-610 é™„è¿‘ï¼‰\n",
    "    credit_score = np.random.normal(600, 5, n)\n",
    "    credit_score = credit_score[(credit_score >= 590) & (credit_score <= 610)]\n",
    "    \n",
    "    # å¤„ç†ï¼ˆä½åˆ©ç‡ï¼‰\n",
    "    low_rate = (credit_score >= 600).astype(int)\n",
    "    \n",
    "    # ç»“æœï¼ˆå€Ÿæ¬¾é‡‘é¢ï¼Œä¸‡å…ƒï¼‰\n",
    "    base_loan = 20 + 0.5 * (credit_score - 600) + np.random.normal(0, 5, len(credit_score))\n",
    "    treatment_effect = 8  # ä½åˆ©ç‡ä½¿å€Ÿæ¬¾é‡‘é¢å¢åŠ  8 ä¸‡\n",
    "    \n",
    "    loan_amount = base_loan + treatment_effect * low_rate\n",
    "    loan_amount = np.clip(loan_amount, 5, 50)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'credit_score': credit_score,\n",
    "        'low_rate': low_rate,\n",
    "        'loan_amount': loan_amount\n",
    "    })\n",
    "\n",
    "df_case3 = simulate_credit_case(n=1000)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ¡ˆä¾‹ 3: ä¿¡ç”¨è¯„åˆ†é—¨æ§›æ•ˆåº”åˆ†æ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# RDD ä¼°è®¡ï¼ˆçª„å¸¦å®½ï¼‰\n",
    "rdd_case3 = SharpRDD(cutoff=600, bandwidth=5, polynomial_order=1)\n",
    "rdd_case3.fit(df_case3['credit_score'], df_case3['loan_amount'])\n",
    "results_case3 = rdd_case3.summary()\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_case3[df_case3['low_rate']==0]['credit_score'],\n",
    "    y=df_case3[df_case3['low_rate']==0]['loan_amount'],\n",
    "    mode='markers',\n",
    "    name='æ™®é€šåˆ©ç‡',\n",
    "    marker=dict(color=COLORS['danger'], size=5, opacity=0.6)\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_case3[df_case3['low_rate']==1]['credit_score'],\n",
    "    y=df_case3[df_case3['low_rate']==1]['loan_amount'],\n",
    "    mode='markers',\n",
    "    name='ä¼˜æƒ åˆ©ç‡',\n",
    "    marker=dict(color=COLORS['secondary'], size=5, opacity=0.6)\n",
    "))\n",
    "\n",
    "fig.add_vline(x=600, line_dash=\"dash\", line_color=\"black\",\n",
    "              annotation_text=\"é—¨æ§›: 600 åˆ†\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'ä¿¡ç”¨è¯„åˆ†é—¨æ§›æ•ˆåº”: {results_case3[\"tau\"]:.2f} ä¸‡å…ƒ',\n",
    "    xaxis_title='ä¿¡ç”¨è¯„åˆ†',\n",
    "    yaxis_title='å€Ÿæ¬¾é‡‘é¢ (ä¸‡å…ƒ)',\n",
    "    template='plotly_white',\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nğŸ“Š ç»“è®º: ä½åˆ©ç‡ä½¿å€Ÿæ¬¾é‡‘é¢å¢åŠ  {results_case3['tau']:.2f} ä¸‡å…ƒ\")\n",
    "print(f\"         (95% CI: [{results_case3['ci'][0]:.2f}, {results_case3['ci'][1]:.2f}])\")\n",
    "print(f\"\\nğŸ’¡ ä¸šåŠ¡å»ºè®®: åˆ©ç‡ä¼˜æƒ æœ‰æ•ˆåˆºæ¿€å€Ÿæ¬¾éœ€æ±‚ï¼Œå¯è€ƒè™‘åŠ¨æ€è°ƒæ•´é—¨æ§›\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç»ƒä¹ ä¸æ€è€ƒé¢˜\n",
    "\n",
    "### ç»ƒä¹  1: RDD ä¼°è®¡å™¨å¯¹æ¯”\n",
    "\n",
    "ä½¿ç”¨ `df` æ•°æ®ï¼Œå¯¹æ¯”ä»¥ä¸‹ä¼°è®¡å™¨çš„ç»“æœï¼š\n",
    "1. çº¿æ€§è§„èŒƒï¼ˆ`polynomial_order=1`ï¼‰\n",
    "2. äºŒæ¬¡è§„èŒƒï¼ˆ`polynomial_order=2`ï¼‰\n",
    "3. ä¸åŒå¸¦å®½ï¼ˆ20, 50, 100ï¼‰\n",
    "\n",
    "**é—®é¢˜**ï¼šå“ªç§è§„èŒƒæœ€ç¨³å¥ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "### ç»ƒä¹  2: Fuzzy RDD çš„ LATE è§£é‡Š\n",
    "\n",
    "åœ¨æ¡ˆä¾‹ 2ï¼ˆä¼šå‘˜ç­‰çº§ï¼‰ä¸­ï¼š\n",
    "1. è®¡ç®—é¡ºä»è€… (Compliers) çš„æ¯”ä¾‹\n",
    "2. ä¸ Always-takers å’Œ Never-takers çš„æ¯”ä¾‹å¯¹æ¯”\n",
    "3. è®¨è®ºï¼šLATE èƒ½å¦æ¨å¹¿åˆ°æ€»ä½“ï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "### ç»ƒä¹  3: å¸¦å®½é€‰æ‹©çš„å½±å“\n",
    "\n",
    "ç»˜åˆ¶å¸¦å®½ä» 10 åˆ° 100 çš„æ•æ„Ÿæ€§å›¾ï¼Œè§‚å¯Ÿï¼š\n",
    "1. ç‚¹ä¼°è®¡å¦‚ä½•å˜åŒ–\n",
    "2. ç½®ä¿¡åŒºé—´å¦‚ä½•å˜åŒ–\n",
    "3. åœ¨ä»€ä¹ˆå¸¦å®½ä¸‹ç»“æœæœ€ç¨³å®š\n",
    "\n",
    "---\n",
    "\n",
    "### æ€è€ƒé¢˜ 1: RDD çš„å±€é™æ€§\n",
    "\n",
    "**é—®é¢˜**ï¼šRDD åªèƒ½è¯†åˆ«é—¨æ§›å¤„çš„å±€éƒ¨æ•ˆåº” (LATE)ï¼Œæ— æ³•æ¨æ–­åˆ°è¿œç¦»é—¨æ§›çš„äººç¾¤ã€‚åœ¨ä¸šåŠ¡å†³ç­–ä¸­ï¼Œå¦‚ä½•åº”å¯¹è¿™ä¸€å±€é™ï¼Ÿ\n",
    "\n",
    "**æç¤º**ï¼šè€ƒè™‘å¤–éƒ¨æ•ˆåº¦ vs å†…éƒ¨æ•ˆåº¦çš„æƒè¡¡ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### æ€è€ƒé¢˜ 2: æ“çºµæ£€éªŒçš„é‡è¦æ€§\n",
    "\n",
    "**åœºæ™¯**ï¼šæŸæ•™è‚²å¹³å°è®¾ç½®\"è€ƒè¯• 60 åˆ†åŠæ ¼\"çš„é—¨æ§›ã€‚ä½ å‘ç°åœ¨ 60 åˆ†å¤„æœ‰æ˜æ˜¾çš„å¯†åº¦è·³è·ƒï¼ˆå¾ˆå¤šå­¦ç”Ÿåˆšå¥½ 60 åˆ†ï¼‰ã€‚\n",
    "\n",
    "**é—®é¢˜**ï¼š\n",
    "1. è¿™è¯´æ˜äº†ä»€ä¹ˆï¼Ÿ\n",
    "2. RDD è®¾è®¡è¿˜æœ‰æ•ˆå—ï¼Ÿ\n",
    "3. å¦‚ä½•è¡¥æ•‘æˆ–è°ƒæ•´åˆ†æç­–ç•¥ï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "### æ€è€ƒé¢˜ 3: RDD åœ¨ A/B æµ‹è¯•ä¸­çš„åº”ç”¨\n",
    "\n",
    "**åœºæ™¯**ï¼šä½ çš„ A/B æµ‹è¯•å› æŠ€æœ¯æ•…éšœï¼Œåªæœ‰éƒ¨åˆ†ç”¨æˆ·è¢«éšæœºåˆ†é…ï¼Œå…¶ä½™ç”¨æˆ·æ ¹æ®\"æ³¨å†Œæ—¶é—´è¶…è¿‡ 30 å¤©\"åˆ†é…åˆ°å¯¹ç…§ç»„ã€‚\n",
    "\n",
    "**é—®é¢˜**ï¼š\n",
    "1. èƒ½å¦ç”¨ RDD è¡¥æ•‘è¿™ä¸ªå®éªŒï¼Ÿ\n",
    "2. éœ€è¦æ»¡è¶³ä»€ä¹ˆå‡è®¾ï¼Ÿ\n",
    "3. å¦‚ä½•ä¸å®Œå…¨éšæœºçš„å­æ ·æœ¬ç»“åˆåˆ†æï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "## æ€»ç»“\n",
    "\n",
    "### RDD çš„æ ¸å¿ƒè¦ç‚¹\n",
    "\n",
    "1. **æ ¸å¿ƒæ€æƒ³**ï¼šåˆ©ç”¨æ”¿ç­–/è§„åˆ™äº§ç”Ÿçš„é—¨æ§›ï¼Œåœ¨æ–­ç‚¹å¤„è·å¾—å±€éƒ¨éšæœºåŒ–\n",
    "2. **å…³é”®å‡è®¾**ï¼šç»“æœå˜é‡åœ¨é—¨æ§›å¤„è¿ç»­ï¼ˆæ— å¤„ç†æ—¶ï¼‰\n",
    "3. **Sharp vs Fuzzy**ï¼šå®Œå…¨è·³è·ƒ vs æ¦‚ç‡è·³è·ƒï¼Œåè€…ç­‰ä»·äº IV\n",
    "4. **å¸¦å®½é€‰æ‹©**ï¼šå¹³è¡¡åå·®å’Œæ–¹å·®ï¼Œä½¿ç”¨ IK æˆ– CCT æ–¹æ³•\n",
    "5. **æœ‰æ•ˆæ€§æ£€éªŒ**ï¼šå¯†åº¦æ£€éªŒã€åå˜é‡å¹³è¡¡ã€Placebo æ£€éªŒ\n",
    "\n",
    "### å®è·µå»ºè®®\n",
    "\n",
    "1. **å¯è§†åŒ–ç¬¬ä¸€**ï¼šç”»å‡ºæ•°æ®å†ä¼°è®¡\n",
    "2. **å¤šé‡ç¨³å¥æ€§**ï¼šæŠ¥å‘Šä¸åŒå¸¦å®½ã€ä¸åŒè§„èŒƒçš„ç»“æœ\n",
    "3. **æ£€éªŒå‡è®¾**ï¼šä¸è¦è·³è¿‡æœ‰æ•ˆæ€§æ£€éªŒ\n",
    "4. **è°¨æ…å¤–æ¨**ï¼šRDD åªè¯†åˆ«é—¨æ§›å¤„çš„å±€éƒ¨æ•ˆåº”\n",
    "5. **ä¸šåŠ¡ç»“åˆ**ï¼šç†è§£é—¨æ§›çš„ä¸šåŠ¡å«ä¹‰ï¼Œåˆ¤æ–­å¯ä¿¡åº¦\n",
    "\n",
    "### å»¶ä¼¸é˜…è¯»\n",
    "\n",
    "- **Imbens & Lemieux (2008)**: \"Regression Discontinuity Designs: A Guide to Practice\"\n",
    "- **Lee & Lemieux (2010)**: \"Regression Discontinuity Designs in Economics\"\n",
    "- **Calonico, Cattaneo & Titiunik (2014)**: \"Robust Nonparametric Confidence Intervals for RDD\"\n",
    "- **Cattaneo, Idrobo & Titiunik (2019)**: *A Practical Introduction to RDD* (ä¹¦ç±)\n",
    "\n",
    "---\n",
    "\n",
    "**æ­å–œä½ å®Œæˆäº† RDD çš„å­¦ä¹ ï¼** ğŸ‰\n",
    "\n",
    "ä½ ç°åœ¨æŒæ¡äº†åˆ©ç”¨\"é—¨æ§›\"è¯†åˆ«å› æœæ•ˆåº”çš„å¼ºå¤§å·¥å…·ã€‚ä¸‹ä¸€æ­¥ï¼Œæˆ‘ä»¬å°†å­¦ä¹ **åˆæˆæ§åˆ¶æ³• (Synthetic Control)**ï¼Œåº”å¯¹æ²¡æœ‰æ˜ç¡®é—¨æ§›çš„åœºæ™¯ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}