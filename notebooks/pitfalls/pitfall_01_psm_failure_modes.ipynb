{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš¨ Pitfall 01: PSM å¸¸è§å¤±è´¥æ¨¡å¼ä¸æ’æŸ¥\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¬ çœŸå®åœºæ™¯ï¼šä¸€ä¸ªã€ŒæˆåŠŸã€çš„ PSM åˆ†æ\n",
    "\n",
    "å°å¼ åˆšå­¦å®Œ PSMï¼Œä¿¡å¿ƒæ»¡æ»¡åœ°åˆ†æå…¬å¸çš„ä¼šå‘˜æ•ˆæœï¼š\n",
    "\n",
    "```python\n",
    "# å°å¼ çš„ä»£ç \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# ä¼°è®¡å€¾å‘å¾—åˆ†\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, T)\n",
    "propensity = lr.predict_proba(X)[:, 1]\n",
    "\n",
    "# åŒ¹é…\n",
    "nn = NearestNeighbors(n_neighbors=1)\n",
    "nn.fit(propensity[T==0].reshape(-1, 1))\n",
    "matched_idx = nn.kneighbors(propensity[T==1].reshape(-1, 1))[1].flatten()\n",
    "\n",
    "# è®¡ç®—æ•ˆåº”\n",
    "ate = Y[T==1].mean() - Y[T==0][matched_idx].mean()\n",
    "print(f\"ä¼šå‘˜æ•ˆåº”: {ate:.2f}\")  # è¾“å‡º: ä¼šå‘˜æ•ˆåº”: 50.23\n",
    "```\n",
    "\n",
    "è€æ¿å¾ˆé«˜å…´ï¼šã€Œ50 å—çš„æ•ˆåº”ï¼å€¼å¾—æ¨å¹¿ï¼ã€\n",
    "\n",
    "**ä¸‰ä¸ªæœˆå...**\n",
    "\n",
    "æ¨å¹¿æ•ˆæœè¿œä¸å¦‚é¢„æœŸï¼Œå¤ç›˜å‘ç°ï¼š\n",
    "\n",
    "- âŒ ä»æ²¡æ£€æŸ¥è¿‡åŒ¹é…åçš„ **Balance**\n",
    "- âŒ åŒ¹é…ä¸¢å¤±äº† **30% çš„æ ·æœ¬**\n",
    "- âŒ å­˜åœ¨ä¸¥é‡çš„ **å…±åŒæ”¯æ’‘è¿èƒŒ**\n",
    "\n",
    "**è¿™ 50 å—æ ¹æœ¬ä¸å¯ä¿¡ï¼**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š æœ¬èŠ‚å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "å®Œæˆæœ¬ç»ƒä¹ åï¼Œä½ å°†èƒ½å¤Ÿï¼š\n",
    "\n",
    "1. ğŸ¯ è¯†åˆ« PSM åˆ†æä¸­çš„ **4 ç§å¸¸è§å¤±è´¥æ¨¡å¼**\n",
    "2. ğŸ¯ ä½¿ç”¨ **SMDï¼ˆæ ‡å‡†åŒ–å‡å€¼å·®ï¼‰** è¯„ä¼°åŒ¹é…è´¨é‡\n",
    "3. ğŸ¯ æ­£ç¡®å¤„ç† **å…±åŒæ”¯æ’‘è¿èƒŒ** é—®é¢˜\n",
    "4. ğŸ¯ æŒæ¡ **PSM è¯Šæ–­æ¸…å•**ï¼Œé¿å…è¸©å‘\n",
    "5. ğŸ¯ åœ¨é¢è¯•ä¸­å›ç­”ã€ŒPSM æœ‰ä»€ä¹ˆé—®é¢˜ã€\n",
    "\n",
    "> âš ï¸ **Pitfall ç³»åˆ—** ä¸“æ³¨äºå®é™…å·¥ä½œä¸­çš„å¸¸è§é”™è¯¯ï¼Œå¸®ä½ é¿å…è¸©å‘ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import stats\n",
    "from typing import Tuple, Dict, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style('whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæ¯•ï¼\")\n",
    "print(\"ğŸš¨ Pitfall ç³»åˆ—: ä»Šå¤©å­¦ä¹  PSM çš„å¸¸è§å¤±è´¥æ¨¡å¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”¬ Part 1: ç”Ÿæˆã€Œæœ‰é—®é¢˜ã€çš„æ•°æ®\n",
    "\n",
    "æˆ‘ä»¬æ•…æ„ç”Ÿæˆä¸€ä¸ªæœ‰å„ç§é—®é¢˜çš„æ•°æ®é›†ï¼Œæ¥æ¼”ç¤º PSM çš„å¤±è´¥æ¨¡å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_problematic_data(\n",
    "    n: int = 5000,\n",
    "    seed: int = 42\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆä¸€ä¸ªã€Œæœ‰é—®é¢˜ã€çš„æ•°æ®é›†\n",
    "    \n",
    "    é—®é¢˜ï¼š\n",
    "    1. å¤„ç†ç»„å’Œå¯¹ç…§ç»„çš„ç‰¹å¾åˆ†å¸ƒå·®å¼‚å¤§ï¼ˆå…±åŒæ”¯æ’‘å·®ï¼‰\n",
    "    2. å­˜åœ¨é€‰æ‹©åå·®\n",
    "    3. å¼‚è´¨æ€§æ•ˆåº”\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # ç‰¹å¾\n",
    "    age = np.random.normal(40, 15, n).clip(18, 80)\n",
    "    income = np.random.lognormal(10.5, 0.8, n)  # æ”¶å…¥ï¼Œåæ€åˆ†å¸ƒ\n",
    "    education = np.random.choice([1, 2, 3, 4], n, p=[0.2, 0.3, 0.35, 0.15])  # 1=é«˜ä¸­, 4=ç ”ç©¶ç”Ÿ\n",
    "    \n",
    "    X = np.column_stack([age, income, education])\n",
    "    feature_names = ['å¹´é¾„', 'æ”¶å…¥', 'æ•™è‚²æ°´å¹³']\n",
    "    \n",
    "    # å¤„ç†åˆ†é…ï¼šä¸¥é‡ä¾èµ–æ”¶å…¥å’Œæ•™è‚²\n",
    "    # é«˜æ”¶å…¥ã€é«˜æ•™è‚²æ›´å¯èƒ½æˆä¸ºä¼šå‘˜\n",
    "    propensity_logit = (\n",
    "        -3 +\n",
    "        0.00002 * income +      # æ”¶å…¥è¶Šé«˜è¶Šå¯èƒ½\n",
    "        0.5 * education +       # æ•™è‚²è¶Šé«˜è¶Šå¯èƒ½\n",
    "        0.01 * age              # å¹´é¾„æœ‰ä¸€ç‚¹å½±å“\n",
    "    )\n",
    "    true_propensity = 1 / (1 + np.exp(-propensity_logit))\n",
    "    T = np.random.binomial(1, true_propensity)\n",
    "    \n",
    "    # çœŸå®æ•ˆåº”ï¼šå¼‚è´¨æ€§\n",
    "    true_ate = 30  # å¹³å‡æ•ˆåº”\n",
    "    cate = (\n",
    "        true_ate +\n",
    "        0.0001 * income +       # é«˜æ”¶å…¥æ•ˆåº”æ›´å¤§\n",
    "        5 * education +         # é«˜æ•™è‚²æ•ˆåº”æ›´å¤§\n",
    "        np.random.randn(n) * 10\n",
    "    )\n",
    "    \n",
    "    # ç»“æœ\n",
    "    baseline = (\n",
    "        100 +\n",
    "        0.0005 * income +\n",
    "        10 * education +\n",
    "        0.5 * age +\n",
    "        np.random.randn(n) * 20\n",
    "    )\n",
    "    Y = baseline + T * cate\n",
    "    \n",
    "    # è®¡ç®—çœŸå®æ•ˆåº”\n",
    "    true_att = cate[T == 1].mean()\n",
    "    \n",
    "    info = {\n",
    "        'feature_names': feature_names,\n",
    "        'true_att': true_att,\n",
    "        'true_propensity': true_propensity,\n",
    "        'cate': cate\n",
    "    }\n",
    "    \n",
    "    print(f\"ğŸ“Š æ•°æ®ç”Ÿæˆå®Œæˆ\")\n",
    "    print(f\"=\" * 50)\n",
    "    print(f\"æ ·æœ¬é‡: {n}\")\n",
    "    print(f\"å¤„ç†ç»„: {T.sum()} ({T.mean():.1%})\")\n",
    "    print(f\"å¯¹ç…§ç»„: {(1-T).sum()} ({1-T.mean():.1%})\")\n",
    "    print(f\"çœŸå® ATT: {true_att:.2f}\")\n",
    "    \n",
    "    return X, T, Y, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆæ•°æ®\n",
    "X, T, Y, info = generate_problematic_data(n=5000)\n",
    "TRUE_ATT = info['true_att']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš¨ å¤±è´¥æ¨¡å¼ 1: æœªæ£€æŸ¥ Balance\n",
    "\n",
    "è¿™æ˜¯**æœ€å¸¸è§**çš„é”™è¯¯ï¼šåšå®ŒåŒ¹é…å°±ç›´æ¥è®¡ç®—æ•ˆåº”ï¼Œä»ä¸æ£€æŸ¥åŒ¹é…è´¨é‡ã€‚\n",
    "\n",
    "### ä»€ä¹ˆæ˜¯ Balanceï¼Ÿ\n",
    "\n",
    "Balance æŒ‡åŒ¹é…åå¤„ç†ç»„å’Œå¯¹ç…§ç»„çš„åå˜é‡åˆ†å¸ƒæ˜¯å¦ç›¸ä¼¼ã€‚\n",
    "\n",
    "### SMDï¼ˆæ ‡å‡†åŒ–å‡å€¼å·®ï¼‰\n",
    "\n",
    "$$SMD = \\frac{\\bar{X}_{treated} - \\bar{X}_{control}}{\\sqrt{(s^2_{treated} + s^2_{control})/2}}$$\n",
    "\n",
    "**åˆ¤æ–­æ ‡å‡†ï¼š**\n",
    "- SMD < 0.1: âœ… Balance å¥½\n",
    "- SMD 0.1-0.2: âš ï¸ å‹‰å¼ºæ¥å—\n",
    "- SMD > 0.2: âŒ Balance å·®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_smd(\n",
    "    X: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    feature_names: List[str] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    è®¡ç®—å„ç‰¹å¾çš„æ ‡å‡†åŒ–å‡å€¼å·® (SMD)\n",
    "    \"\"\"\n",
    "    if feature_names is None:\n",
    "        feature_names = [f'X{i}' for i in range(X.shape[1])]\n",
    "    \n",
    "    results = []\n",
    "    for i, name in enumerate(feature_names):\n",
    "        treated_mean = X[T == 1, i].mean()\n",
    "        control_mean = X[T == 0, i].mean()\n",
    "        treated_std = X[T == 1, i].std()\n",
    "        control_std = X[T == 0, i].std()\n",
    "        \n",
    "        pooled_std = np.sqrt((treated_std**2 + control_std**2) / 2)\n",
    "        smd = (treated_mean - control_mean) / pooled_std\n",
    "        \n",
    "        results.append({\n",
    "            'ç‰¹å¾': name,\n",
    "            'å¤„ç†ç»„å‡å€¼': treated_mean,\n",
    "            'å¯¹ç…§ç»„å‡å€¼': control_mean,\n",
    "            'SMD': smd,\n",
    "            '|SMD|': abs(smd),\n",
    "            'çŠ¶æ€': 'âœ…' if abs(smd) < 0.1 else ('âš ï¸' if abs(smd) < 0.2 else 'âŒ')\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥åŒ¹é…å‰çš„ Balance\n",
    "print(\"ğŸ“Š åŒ¹é…å‰çš„ Balance æ£€æŸ¥\")\n",
    "print(\"=\" * 60)\n",
    "smd_before = calculate_smd(X, T, info['feature_names'])\n",
    "display(smd_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–åŒ¹é…å‰çš„åˆ†å¸ƒå·®å¼‚\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, (ax, name) in enumerate(zip(axes, info['feature_names'])):\n",
    "    ax.hist(X[T==0, i], bins=30, alpha=0.5, label='å¯¹ç…§ç»„', color='steelblue', density=True)\n",
    "    ax.hist(X[T==1, i], bins=30, alpha=0.5, label='å¤„ç†ç»„', color='coral', density=True)\n",
    "    ax.set_xlabel(name, fontsize=12)\n",
    "    ax.set_ylabel('å¯†åº¦', fontsize=12)\n",
    "    ax.set_title(f'{name} åˆ†å¸ƒå¯¹æ¯”\\nSMD = {smd_before[\"SMD\"].iloc[i]:.3f}', fontsize=14)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâš ï¸ é—®é¢˜è¯Šæ–­:\")\n",
    "print(\"   - æ”¶å…¥å’Œæ•™è‚²æ°´å¹³çš„ SMD éƒ½å¾ˆå¤§\")\n",
    "print(\"   - å¤„ç†ç»„å’Œå¯¹ç…§ç»„çš„åˆ†å¸ƒå·®å¼‚æ˜æ˜¾\")\n",
    "print(\"   - å¦‚æœä¸è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ•ˆåº”ä¼°è®¡ä¼šæœ‰å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ã€Œé”™è¯¯ã€çš„ PSM åˆ†æï¼ˆä¸æ£€æŸ¥ Balanceï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_psm_analysis(X, T, Y):\n",
    "    \"\"\"\n",
    "    é”™è¯¯çš„ PSM åˆ†æï¼šä¸æ£€æŸ¥ Balance\n",
    "    \"\"\"\n",
    "    # ä¼°è®¡å€¾å‘å¾—åˆ†\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    lr.fit(X, T)\n",
    "    propensity = lr.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # æœ€è¿‘é‚»åŒ¹é…\n",
    "    treated_ps = propensity[T == 1].reshape(-1, 1)\n",
    "    control_ps = propensity[T == 0].reshape(-1, 1)\n",
    "    \n",
    "    nn = NearestNeighbors(n_neighbors=1)\n",
    "    nn.fit(control_ps)\n",
    "    distances, matched_idx = nn.kneighbors(treated_ps)\n",
    "    matched_idx = matched_idx.flatten()\n",
    "    \n",
    "    # ç›´æ¥è®¡ç®—æ•ˆåº”ï¼ˆé”™è¯¯åšæ³•ï¼ï¼‰\n",
    "    Y_treated = Y[T == 1]\n",
    "    Y_control_matched = Y[T == 0][matched_idx]\n",
    "    ate = Y_treated.mean() - Y_control_matched.mean()\n",
    "    \n",
    "    return {\n",
    "        'ate': ate,\n",
    "        'propensity': propensity,\n",
    "        'matched_idx': matched_idx,\n",
    "        'distances': distances.flatten()\n",
    "    }\n",
    "\n",
    "# è¿è¡Œé”™è¯¯çš„åˆ†æ\n",
    "bad_result = bad_psm_analysis(X, T, Y)\n",
    "\n",
    "print(\"âŒ é”™è¯¯çš„ PSM åˆ†æï¼ˆä¸æ£€æŸ¥ Balanceï¼‰\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"çœŸå® ATT: {TRUE_ATT:.2f}\")\n",
    "print(f\"ä¼°è®¡ ATT: {bad_result['ate']:.2f}\")\n",
    "print(f\"åå·®: {bad_result['ate'] - TRUE_ATT:+.2f}\")\n",
    "print(\"\\nâš ï¸ è¿™ä¸ªç»“æœçœ‹èµ·æ¥ã€Œæ­£å¸¸ã€ï¼Œä½†æˆ‘ä»¬è¿˜æ²¡æ£€æŸ¥ Balanceï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥åŒ¹é…åçš„ Balance\n",
    "treated_idx = np.where(T == 1)[0]\n",
    "control_idx = np.where(T == 0)[0][bad_result['matched_idx']]\n",
    "\n",
    "X_matched = np.vstack([X[treated_idx], X[control_idx]])\n",
    "T_matched = np.array([1] * len(treated_idx) + [0] * len(control_idx))\n",
    "\n",
    "print(\"ğŸ“Š åŒ¹é…åçš„ Balance æ£€æŸ¥\")\n",
    "print(\"=\" * 60)\n",
    "smd_after = calculate_smd(X_matched, T_matched, info['feature_names'])\n",
    "display(smd_after)\n",
    "\n",
    "print(\"\\nğŸ’¡ è§‚å¯Ÿ:\")\n",
    "print(\"   - SMD æœ‰æ‰€æ”¹å–„ï¼Œä½†ä»æœ‰é—®é¢˜\")\n",
    "print(\"   - è¿™è¯´æ˜åŒ¹é…è´¨é‡ä¸å¤Ÿå¥½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Love Plot: å¯è§†åŒ– SMD å˜åŒ–\n",
    "def love_plot(smd_before, smd_after, feature_names):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    y_pos = np.arange(len(feature_names))\n",
    "    \n",
    "    # åŒ¹é…å‰\n",
    "    ax.scatter(smd_before['|SMD|'], y_pos, s=100, marker='o', \n",
    "              label='åŒ¹é…å‰', color='red', alpha=0.7)\n",
    "    \n",
    "    # åŒ¹é…å\n",
    "    ax.scatter(smd_after['|SMD|'], y_pos, s=100, marker='s', \n",
    "              label='åŒ¹é…å', color='green', alpha=0.7)\n",
    "    \n",
    "    # è¿çº¿\n",
    "    for i in range(len(feature_names)):\n",
    "        ax.plot([smd_before['|SMD|'].iloc[i], smd_after['|SMD|'].iloc[i]], \n",
    "               [y_pos[i], y_pos[i]], 'gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # å‚è€ƒçº¿\n",
    "    ax.axvline(0.1, color='green', linestyle='--', linewidth=2, label='SMD=0.1')\n",
    "    ax.axvline(0.2, color='orange', linestyle='--', linewidth=2, label='SMD=0.2')\n",
    "    \n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(feature_names)\n",
    "    ax.set_xlabel('|SMD|', fontsize=12)\n",
    "    ax.set_title('Love Plot: åŒ¹é…å‰å SMD å¯¹æ¯”', fontsize=14)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_xlim([0, max(smd_before['|SMD|'].max() * 1.1, 0.5)])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "love_plot(smd_before, smd_after, info['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš¨ å¤±è´¥æ¨¡å¼ 2: å…±åŒæ”¯æ’‘è¿èƒŒ\n",
    "\n",
    "**å…±åŒæ”¯æ’‘ (Common Support / Overlap)**ï¼šå¤„ç†ç»„å’Œå¯¹ç…§ç»„çš„å€¾å‘å¾—åˆ†åˆ†å¸ƒåº”è¯¥æœ‰è¶³å¤Ÿçš„é‡å ã€‚\n",
    "\n",
    "å¦‚æœæŸäº›å¤„ç†ç»„æ ·æœ¬åœ¨å¯¹ç…§ç»„ä¸­æ‰¾ä¸åˆ°ã€Œç›¸ä¼¼ã€çš„åŒ¹é…å¯¹è±¡ï¼Œå¼ºè¡ŒåŒ¹é…ä¼šå¯¼è‡´åå·®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å…±åŒæ”¯æ’‘\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# å€¾å‘å¾—åˆ†åˆ†å¸ƒ\n",
    "propensity = bad_result['propensity']\n",
    "axes[0].hist(propensity[T==0], bins=50, alpha=0.5, label='å¯¹ç…§ç»„', color='steelblue', density=True)\n",
    "axes[0].hist(propensity[T==1], bins=50, alpha=0.5, label='å¤„ç†ç»„', color='coral', density=True)\n",
    "axes[0].set_xlabel('å€¾å‘å¾—åˆ†', fontsize=12)\n",
    "axes[0].set_ylabel('å¯†åº¦', fontsize=12)\n",
    "axes[0].set_title('å€¾å‘å¾—åˆ†åˆ†å¸ƒ', fontsize=14)\n",
    "axes[0].legend()\n",
    "\n",
    "# å…±åŒæ”¯æ’‘åŒºåŸŸ\n",
    "ps_min_treated = propensity[T==1].min()\n",
    "ps_max_treated = propensity[T==1].max()\n",
    "ps_min_control = propensity[T==0].min()\n",
    "ps_max_control = propensity[T==0].max()\n",
    "\n",
    "common_min = max(ps_min_treated, ps_min_control)\n",
    "common_max = min(ps_max_treated, ps_max_control)\n",
    "\n",
    "axes[1].hist(propensity[T==0], bins=50, alpha=0.5, label='å¯¹ç…§ç»„', color='steelblue', density=True)\n",
    "axes[1].hist(propensity[T==1], bins=50, alpha=0.5, label='å¤„ç†ç»„', color='coral', density=True)\n",
    "axes[1].axvline(common_min, color='green', linestyle='--', linewidth=2)\n",
    "axes[1].axvline(common_max, color='green', linestyle='--', linewidth=2)\n",
    "axes[1].axvspan(common_min, common_max, alpha=0.2, color='green', label='å…±åŒæ”¯æ’‘åŒºåŸŸ')\n",
    "axes[1].set_xlabel('å€¾å‘å¾—åˆ†', fontsize=12)\n",
    "axes[1].set_ylabel('å¯†åº¦', fontsize=12)\n",
    "axes[1].set_title('å…±åŒæ”¯æ’‘åŒºåŸŸ', fontsize=14)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ç»Ÿè®¡è¿èƒŒæƒ…å†µ\n",
    "n_treated_outside = ((propensity[T==1] < common_min) | (propensity[T==1] > common_max)).sum()\n",
    "n_control_outside = ((propensity[T==0] < common_min) | (propensity[T==0] > common_max)).sum()\n",
    "\n",
    "print(f\"ğŸ“Š å…±åŒæ”¯æ’‘æ£€æŸ¥\")\n",
    "print(f\"   å…±åŒæ”¯æ’‘åŒºåŸŸ: [{common_min:.4f}, {common_max:.4f}]\")\n",
    "print(f\"   å¤„ç†ç»„åœ¨åŒºåŸŸå¤–: {n_treated_outside} ({n_treated_outside/T.sum():.1%})\")\n",
    "print(f\"   å¯¹ç…§ç»„åœ¨åŒºåŸŸå¤–: {n_control_outside} ({n_control_outside/(1-T).sum():.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥åŒ¹é…è·ç¦»\n",
    "print(\"ğŸ“Š åŒ¹é…è·ç¦»ç»Ÿè®¡\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"æœ€å°è·ç¦»: {bad_result['distances'].min():.6f}\")\n",
    "print(f\"æœ€å¤§è·ç¦»: {bad_result['distances'].max():.6f}\")\n",
    "print(f\"å‡å€¼: {bad_result['distances'].mean():.6f}\")\n",
    "print(f\"ä¸­ä½æ•°: {np.median(bad_result['distances']):.6f}\")\n",
    "\n",
    "# å¤§è·ç¦»åŒ¹é…çš„æ¯”ä¾‹\n",
    "large_distance_pct = (bad_result['distances'] > 0.05).mean()\n",
    "print(f\"\\nè·ç¦» > 0.05 çš„æ¯”ä¾‹: {large_distance_pct:.1%}\")\n",
    "\n",
    "if large_distance_pct > 0.1:\n",
    "    print(\"\\nâš ï¸ è­¦å‘Š: æœ‰è¾ƒå¤šåŒ¹é…çš„è·ç¦»å¾ˆå¤§ï¼Œè´¨é‡å­˜ç–‘ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš¨ å¤±è´¥æ¨¡å¼ 3: æ ·æœ¬ä¸¢å¤±è¿‡å¤š\n",
    "\n",
    "å½“ä½¿ç”¨ caliperï¼ˆå¡å°ºï¼‰çº¦æŸæ—¶ï¼Œå¦‚æœä¸¢å¤±äº†å¤ªå¤šæ ·æœ¬ï¼Œä¼šå¯¼è‡´ï¼š\n",
    "1. ä¼°è®¡çš„ç›®æ ‡äººç¾¤æ”¹å˜\n",
    "2. ç»“æœçš„å¤–æ¨æ€§ä¸‹é™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psm_with_caliper(\n",
    "    X: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    caliper: float = 0.2\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    å¸¦å¡å°ºçº¦æŸçš„ PSM\n",
    "    \n",
    "    caliper: å€¾å‘å¾—åˆ†æ ‡å‡†å·®çš„å€æ•°\n",
    "    \"\"\"\n",
    "    # ä¼°è®¡å€¾å‘å¾—åˆ†\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    lr.fit(X, T)\n",
    "    propensity = lr.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # è®¡ç®—å¡å°ºé˜ˆå€¼\n",
    "    ps_std = propensity.std()\n",
    "    caliper_threshold = caliper * ps_std\n",
    "    \n",
    "    # åŒ¹é…\n",
    "    treated_ps = propensity[T == 1]\n",
    "    control_ps = propensity[T == 0]\n",
    "    treated_idx = np.where(T == 1)[0]\n",
    "    control_idx_all = np.where(T == 0)[0]\n",
    "    \n",
    "    matched_treated = []\n",
    "    matched_control = []\n",
    "    used_control = set()\n",
    "    \n",
    "    for i, (t_idx, t_ps) in enumerate(zip(treated_idx, treated_ps)):\n",
    "        # æ‰¾æœ€è¿‘çš„å¯¹ç…§ç»„\n",
    "        distances = np.abs(control_ps - t_ps)\n",
    "        \n",
    "        # æ’é™¤å·²ç”¨è¿‡çš„\n",
    "        for used in used_control:\n",
    "            distances[np.where(control_idx_all == used)[0]] = np.inf\n",
    "        \n",
    "        min_idx = np.argmin(distances)\n",
    "        min_dist = distances[min_idx]\n",
    "        \n",
    "        if min_dist <= caliper_threshold:\n",
    "            matched_treated.append(t_idx)\n",
    "            matched_control.append(control_idx_all[min_idx])\n",
    "            used_control.add(control_idx_all[min_idx])\n",
    "    \n",
    "    # è®¡ç®—æ•ˆåº”\n",
    "    if len(matched_treated) == 0:\n",
    "        return {'ate': np.nan, 'n_matched': 0, 'n_original': T.sum()}\n",
    "    \n",
    "    Y_treated = Y[matched_treated]\n",
    "    Y_control = Y[matched_control]\n",
    "    ate = Y_treated.mean() - Y_control.mean()\n",
    "    \n",
    "    return {\n",
    "        'ate': ate,\n",
    "        'n_matched': len(matched_treated),\n",
    "        'n_original': T.sum(),\n",
    "        'match_rate': len(matched_treated) / T.sum(),\n",
    "        'caliper_threshold': caliper_threshold,\n",
    "        'matched_treated_idx': matched_treated,\n",
    "        'matched_control_idx': matched_control\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹æ¯”ä¸åŒ caliper çš„æ•ˆæœ\n",
    "calipers = [0.05, 0.1, 0.2, 0.5, 1.0, None]\n",
    "results = []\n",
    "\n",
    "for caliper in calipers:\n",
    "    if caliper is None:\n",
    "        result = bad_psm_analysis(X, T, Y)\n",
    "        result['n_matched'] = T.sum()\n",
    "        result['match_rate'] = 1.0\n",
    "        caliper_str = 'æ— é™åˆ¶'\n",
    "    else:\n",
    "        result = psm_with_caliper(X, T, Y, caliper)\n",
    "        caliper_str = f'{caliper:.2f}Ïƒ'\n",
    "    \n",
    "    results.append({\n",
    "        'Caliper': caliper_str,\n",
    "        'åŒ¹é…æ ·æœ¬': result['n_matched'],\n",
    "        'åŒ¹é…ç‡': result.get('match_rate', 1.0),\n",
    "        'ATE': result['ate'],\n",
    "        'åå·®': result['ate'] - TRUE_ATT\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"ğŸ“Š ä¸åŒ Caliper çš„æ•ˆæœå¯¹æ¯”\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"çœŸå® ATT: {TRUE_ATT:.2f}\")\n",
    "print()\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# åŒ¹é…ç‡ vs Caliper\n",
    "caliper_numeric = [0.05, 0.1, 0.2, 0.5, 1.0, 1.5]\n",
    "match_rates = results_df['åŒ¹é…ç‡'].tolist()\n",
    "axes[0].plot(caliper_numeric, match_rates, 'bo-', markersize=10, linewidth=2)\n",
    "axes[0].axhline(0.9, color='green', linestyle='--', label='90% åŒ¹é…ç‡')\n",
    "axes[0].axhline(0.7, color='orange', linestyle='--', label='70% åŒ¹é…ç‡')\n",
    "axes[0].set_xlabel('Caliper (Ïƒ çš„å€æ•°)', fontsize=12)\n",
    "axes[0].set_ylabel('åŒ¹é…ç‡', fontsize=12)\n",
    "axes[0].set_title('Caliper å¯¹åŒ¹é…ç‡çš„å½±å“', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim([0, 1.05])\n",
    "\n",
    "# åå·® vs Caliper\n",
    "biases = results_df['åå·®'].tolist()\n",
    "axes[1].plot(caliper_numeric, biases, 'ro-', markersize=10, linewidth=2)\n",
    "axes[1].axhline(0, color='black', linestyle='-', linewidth=1)\n",
    "axes[1].set_xlabel('Caliper (Ïƒ çš„å€æ•°)', fontsize=12)\n",
    "axes[1].set_ylabel('åå·® (ä¼°è®¡ - çœŸå®)', fontsize=12)\n",
    "axes[1].set_title('Caliper å¯¹åå·®çš„å½±å“', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ å…³é”®å‘ç°:\")\n",
    "print(\"   1. Caliper å¤ªç´§ â†’ åŒ¹é…ç‡ä½ â†’ æ ·æœ¬ä¸¢å¤±\")\n",
    "print(\"   2. Caliper å¤ªæ¾ â†’ åŒ¹é…è´¨é‡å·® â†’ åå·®å¤§\")\n",
    "print(\"   3. éœ€è¦åœ¨ä¸¤è€…é—´æƒè¡¡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš¨ å¤±è´¥æ¨¡å¼ 4: éšå˜é‡é—æ¼\n",
    "\n",
    "å³ä½¿ Balance æ£€æŸ¥é€šè¿‡ï¼Œå¦‚æœå­˜åœ¨**æœªè§‚æµ‹çš„æ··æ·†å˜é‡**ï¼Œä¼°è®¡ä»ç„¶æœ‰åã€‚\n",
    "\n",
    "è¿™æ˜¯ PSMï¼ˆä»¥åŠæ‰€æœ‰è§‚æµ‹æ•°æ®æ–¹æ³•ï¼‰çš„æ ¹æœ¬å±€é™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡æ‹Ÿé—æ¼å˜é‡çš„æƒ…å†µ\n",
    "\n",
    "def generate_data_with_hidden_confounder(n=5000, seed=42):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆæœ‰éšå˜é‡çš„æ•°æ®\n",
    "    \n",
    "    éšå˜é‡ U åŒæ—¶å½±å“ T å’Œ Yï¼Œä½†æˆ‘ä»¬è§‚æµ‹ä¸åˆ°\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # è§‚æµ‹ç‰¹å¾\n",
    "    X1 = np.random.randn(n)\n",
    "    X2 = np.random.randn(n)\n",
    "    X = np.column_stack([X1, X2])\n",
    "    \n",
    "    # éšå˜é‡ Uï¼ˆæœªè§‚æµ‹ï¼‰\n",
    "    U = np.random.randn(n)\n",
    "    \n",
    "    # å¤„ç†åˆ†é…ï¼ˆä¾èµ– X å’Œ Uï¼‰\n",
    "    propensity_logit = 0.5 * X1 + 0.3 * X2 + 0.8 * U  # U å½±å“ Tï¼\n",
    "    propensity = 1 / (1 + np.exp(-propensity_logit))\n",
    "    T = np.random.binomial(1, propensity)\n",
    "    \n",
    "    # ç»“æœï¼ˆä¾èµ– Xã€T å’Œ Uï¼‰\n",
    "    true_ate = 5.0\n",
    "    Y = 10 + true_ate * T + 2 * X1 + X2 + 3 * U + np.random.randn(n)  # U ä¹Ÿå½±å“ Yï¼\n",
    "    \n",
    "    return X, T, Y, U, true_ate\n",
    "\n",
    "# ç”Ÿæˆæ•°æ®\n",
    "X_hidden, T_hidden, Y_hidden, U, true_ate_hidden = generate_data_with_hidden_confounder()\n",
    "\n",
    "# ç”¨è§‚æµ‹å˜é‡åš PSM\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_hidden, T_hidden)\n",
    "ps_hidden = lr.predict_proba(X_hidden)[:, 1]\n",
    "\n",
    "# åŒ¹é…\n",
    "nn = NearestNeighbors(n_neighbors=1)\n",
    "nn.fit(ps_hidden[T_hidden==0].reshape(-1, 1))\n",
    "matched_idx = nn.kneighbors(ps_hidden[T_hidden==1].reshape(-1, 1))[1].flatten()\n",
    "\n",
    "ate_psm = Y_hidden[T_hidden==1].mean() - Y_hidden[T_hidden==0][matched_idx].mean()\n",
    "\n",
    "print(\"ğŸ“Š é—æ¼å˜é‡çš„å½±å“\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"çœŸå® ATE: {true_ate_hidden:.2f}\")\n",
    "print(f\"PSM ä¼°è®¡ (å¿½ç•¥ U): {ate_psm:.2f}\")\n",
    "print(f\"åå·®: {ate_psm - true_ate_hidden:+.2f}\")\n",
    "print(\"\\nâš ï¸ å³ä½¿ Balance æ£€æŸ¥å¯èƒ½é€šè¿‡ï¼Œä¼°è®¡ä»ç„¶æœ‰åï¼\")\n",
    "print(\"   å› ä¸º U æ˜¯æœªè§‚æµ‹çš„æ··æ·†å˜é‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Part 2: æ­£ç¡®çš„ PSM è¯Šæ–­æµç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_psm_analysis(\n",
    "    X: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    feature_names: List[str] = None,\n",
    "    caliper: float = 0.2,\n",
    "    verbose: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    å®Œæ•´çš„ PSM åˆ†ææµç¨‹\n",
    "    \n",
    "    åŒ…æ‹¬æ‰€æœ‰å¿…è¦çš„è¯Šæ–­æ­¥éª¤\n",
    "    \"\"\"\n",
    "    if feature_names is None:\n",
    "        feature_names = [f'X{i}' for i in range(X.shape[1])]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Step 1: åŒ¹é…å‰ Balance æ£€æŸ¥\n",
    "    if verbose:\n",
    "        print(\"=\" * 60)\n",
    "        print(\"Step 1: åŒ¹é…å‰ Balance æ£€æŸ¥\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    smd_before = calculate_smd(X, T, feature_names)\n",
    "    results['smd_before'] = smd_before\n",
    "    \n",
    "    if verbose:\n",
    "        display(smd_before[['ç‰¹å¾', '|SMD|', 'çŠ¶æ€']])\n",
    "        max_smd_before = smd_before['|SMD|'].max()\n",
    "        if max_smd_before > 0.2:\n",
    "            print(f\"\\nâš ï¸ æœ€å¤§ SMD = {max_smd_before:.3f} > 0.2ï¼ŒBalance è¾ƒå·®\")\n",
    "    \n",
    "    # Step 2: ä¼°è®¡å€¾å‘å¾—åˆ†\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Step 2: ä¼°è®¡å€¾å‘å¾—åˆ†\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    lr.fit(X, T)\n",
    "    propensity = lr.predict_proba(X)[:, 1]\n",
    "    results['propensity'] = propensity\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"å€¾å‘å¾—åˆ†èŒƒå›´: [{propensity.min():.4f}, {propensity.max():.4f}]\")\n",
    "        print(f\"å€¾å‘å¾—åˆ†å‡å€¼: {propensity.mean():.4f}\")\n",
    "    \n",
    "    # Step 3: å…±åŒæ”¯æ’‘æ£€æŸ¥\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Step 3: å…±åŒæ”¯æ’‘æ£€æŸ¥\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    common_min = max(propensity[T==1].min(), propensity[T==0].min())\n",
    "    common_max = min(propensity[T==1].max(), propensity[T==0].max())\n",
    "    results['common_support'] = (common_min, common_max)\n",
    "    \n",
    "    in_support = (propensity >= common_min) & (propensity <= common_max)\n",
    "    pct_in_support = in_support.mean()\n",
    "    results['pct_in_support'] = pct_in_support\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"å…±åŒæ”¯æ’‘åŒºåŸŸ: [{common_min:.4f}, {common_max:.4f}]\")\n",
    "        print(f\"åœ¨å…±åŒæ”¯æ’‘å†…çš„æ ·æœ¬: {pct_in_support:.1%}\")\n",
    "        if pct_in_support < 0.9:\n",
    "            print(\"\\nâš ï¸ å…±åŒæ”¯æ’‘è¦†ç›–ç‡ < 90%ï¼Œå­˜åœ¨å¤–æ¨é£é™©\")\n",
    "    \n",
    "    # Step 4: æ‰§è¡ŒåŒ¹é…\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Step 4: æ‰§è¡ŒåŒ¹é… (caliper = {caliper}Ïƒ)\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    match_result = psm_with_caliper(X, T, Y, caliper)\n",
    "    results['match_result'] = match_result\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"åŸå§‹å¤„ç†ç»„: {T.sum()}\")\n",
    "        print(f\"åŒ¹é…æˆåŠŸ: {match_result['n_matched']} ({match_result['match_rate']:.1%})\")\n",
    "        if match_result['match_rate'] < 0.8:\n",
    "            print(\"\\nâš ï¸ åŒ¹é…ç‡ < 80%ï¼Œå¯èƒ½éœ€è¦æ”¾å®½ caliper\")\n",
    "    \n",
    "    # Step 5: åŒ¹é…å Balance æ£€æŸ¥\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Step 5: åŒ¹é…å Balance æ£€æŸ¥\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    if match_result['n_matched'] > 0:\n",
    "        X_matched = np.vstack([\n",
    "            X[match_result['matched_treated_idx']],\n",
    "            X[match_result['matched_control_idx']]\n",
    "        ])\n",
    "        T_matched = np.array([1] * match_result['n_matched'] + [0] * match_result['n_matched'])\n",
    "        smd_after = calculate_smd(X_matched, T_matched, feature_names)\n",
    "        results['smd_after'] = smd_after\n",
    "        \n",
    "        if verbose:\n",
    "            display(smd_after[['ç‰¹å¾', '|SMD|', 'çŠ¶æ€']])\n",
    "            max_smd_after = smd_after['|SMD|'].max()\n",
    "            if max_smd_after > 0.1:\n",
    "                print(f\"\\nâš ï¸ åŒ¹é…åæœ€å¤§ SMD = {max_smd_after:.3f} > 0.1ï¼ŒBalance ä»ä¸å¤Ÿå¥½\")\n",
    "            else:\n",
    "                print(f\"\\nâœ… æ‰€æœ‰ç‰¹å¾ |SMD| < 0.1ï¼ŒBalance è‰¯å¥½\")\n",
    "    \n",
    "    # Step 6: è®¡ç®—æ•ˆåº”\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Step 6: ä¼°è®¡æ•ˆåº”\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    results['ate'] = match_result['ate']\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"ATT ä¼°è®¡: {match_result['ate']:.2f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œå®Œæ•´çš„ PSM åˆ†æ\n",
    "complete_result = complete_psm_analysis(X, T, Y, info['feature_names'], caliper=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‹ PSM è¯Šæ–­æ¸…å•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "ğŸ“‹ PSM è¯Šæ–­æ¸…å•\n",
    "================================================================================\n",
    "\n",
    "åœ¨æŠ¥å‘Š PSM ç»“æœä¹‹å‰ï¼Œå¿…é¡»æ£€æŸ¥ä»¥ä¸‹å†…å®¹ï¼š\n",
    "\n",
    "â–¡ 1. å€¾å‘å¾—åˆ†æ¨¡å‹æ‹Ÿåˆ\n",
    "   - æ¨¡å‹æ˜¯å¦æ”¶æ•›ï¼Ÿ\n",
    "   - AUC æ˜¯å¦åˆç†ï¼ˆä¸è¦å¤ªé«˜ä¹Ÿä¸è¦å¤ªä½ï¼‰ï¼Ÿ\n",
    "   \n",
    "â–¡ 2. å…±åŒæ”¯æ’‘æ£€æŸ¥\n",
    "   - ä¸¤ç»„å€¾å‘å¾—åˆ†åˆ†å¸ƒæ˜¯å¦æœ‰è¶³å¤Ÿé‡å ï¼Ÿ\n",
    "   - å¤šå°‘æ ·æœ¬åœ¨å…±åŒæ”¯æ’‘åŒºåŸŸå†…ï¼Ÿ\n",
    "   \n",
    "â–¡ 3. åŒ¹é…è´¨é‡ï¼ˆæœ€é‡è¦ï¼ï¼‰\n",
    "   - æ‰€æœ‰ç‰¹å¾çš„ |SMD| < 0.1ï¼Ÿ\n",
    "   - ä½¿ç”¨ Love Plot å¯è§†åŒ–\n",
    "   \n",
    "â–¡ 4. åŒ¹é…ç‡\n",
    "   - åŒ¹é…æˆåŠŸç‡æ˜¯å¤šå°‘ï¼Ÿ\n",
    "   - ä¸¢å¤±çš„æ ·æœ¬æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ\n",
    "   \n",
    "â–¡ 5. æ•æ„Ÿæ€§åˆ†æ\n",
    "   - æ”¹å˜ caliper ç»“æœæ˜¯å¦ç¨³å®šï¼Ÿ\n",
    "   - æ”¹å˜åŒ¹é…æ–¹æ³•ç»“æœæ˜¯å¦ç¨³å®šï¼Ÿ\n",
    "   \n",
    "â–¡ 6. éšå˜é‡è€ƒè™‘\n",
    "   - æ˜¯å¦å¯èƒ½å­˜åœ¨æœªè§‚æµ‹çš„æ··æ·†å˜é‡ï¼Ÿ\n",
    "   - å¦‚æœæœ‰ï¼Œåšæ•æ„Ÿæ€§åˆ†æï¼ˆå¦‚ E-valueï¼‰\n",
    "\n",
    "================================================================================\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¡ æ€è€ƒé¢˜\n",
    "\n",
    "### é—®é¢˜ 1: SMD çš„é˜ˆå€¼ 0.1 æ˜¯æ€ä¹ˆæ¥çš„ï¼Ÿæœ‰æ²¡æœ‰æ›´å¥½çš„åˆ¤æ–­æ ‡å‡†ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 2: å¦‚æœ Balance æ£€æŸ¥ä¸é€šè¿‡ï¼Œæœ‰å“ªäº›å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 3: PSM ä¸¢å¤±äº†å¾ˆå¤šæ ·æœ¬ï¼Œè¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿå¯¹ç»“æœè§£é‡Šæœ‰ä»€ä¹ˆå½±å“ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 4: åœ¨é¢è¯•ä¸­ï¼Œå¦‚æœé¢è¯•å®˜é—®ã€ŒPSM æœ‰ä»€ä¹ˆå±€é™æ€§ã€ï¼Œä½ æ€ä¹ˆå›ç­”ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‹ æ€»ç»“\n",
    "\n",
    "### PSM å››å¤§å¤±è´¥æ¨¡å¼\n",
    "\n",
    "| å¤±è´¥æ¨¡å¼ | ç—‡çŠ¶ | è¯Šæ–­æ–¹æ³• | è§£å†³æ–¹æ¡ˆ |\n",
    "|---------|------|---------|----------|\n",
    "| **æœªæ£€æŸ¥ Balance** | ä¼°è®¡åå·®å¤§ | è®¡ç®— SMDï¼Œç»˜åˆ¶ Love Plot | è°ƒæ•´åŒ¹é…æ–¹æ³•ï¼Œå¢åŠ åå˜é‡ |\n",
    "| **å…±åŒæ”¯æ’‘å·®** | æç«¯æƒé‡/ä¸¢å¤±æ ·æœ¬ | æ£€æŸ¥å€¾å‘å¾—åˆ†åˆ†å¸ƒé‡å  | Trimmingï¼Œæ”¹ç”¨å…¶ä»–æ–¹æ³• |\n",
    "| **æ ·æœ¬ä¸¢å¤±è¿‡å¤š** | ç›®æ ‡äººç¾¤æ”¹å˜ | æ£€æŸ¥åŒ¹é…ç‡ | æ”¾å®½ caliperï¼Œå¤šå¯¹ä¸€åŒ¹é… |\n",
    "| **éšå˜é‡é—æ¼** | å³ä½¿ Balance å¥½ä¹Ÿæœ‰åå·® | æ— æ³•ç›´æ¥æ£€æµ‹ | æ•æ„Ÿæ€§åˆ†æï¼Œå¯»æ‰¾ IV |\n",
    "\n",
    "### å…³é”®æŒ‡æ ‡\n",
    "\n",
    "- **SMD (æ ‡å‡†åŒ–å‡å€¼å·®)**: |SMD| < 0.1 ä¸ºå¥½\n",
    "- **å…±åŒæ”¯æ’‘è¦†ç›–ç‡**: > 90% ä¸ºå¥½\n",
    "- **åŒ¹é…ç‡**: > 80% ä¸ºå¥½\n",
    "\n",
    "### æœ€ä½³å®è·µ\n",
    "\n",
    "1. **å…ˆè¯Šæ–­ï¼Œåä¼°è®¡**: æ°¸è¿œå…ˆæ£€æŸ¥ Balance\n",
    "2. **å¯è§†åŒ–æ˜¯å¿…é¡»çš„**: Love Plotã€å€¾å‘å¾—åˆ†åˆ†å¸ƒå›¾\n",
    "3. **æ•æ„Ÿæ€§åˆ†æ**: æ”¹å˜å‚æ•°çœ‹ç»“æœç¨³å®šæ€§\n",
    "4. **æŠ¥å‘Šé€æ˜**: æŠŠè¯Šæ–­ç»“æœä¹ŸæŠ¥å‘Šå‡ºæ¥\n",
    "\n",
    "---\n",
    "\n",
    "**ã€Œä¸æ£€æŸ¥ Balance çš„ PSMï¼Œå°±åƒä¸ç³»å®‰å…¨å¸¦å¼€è½¦â€”â€”çœ‹èµ·æ¥æ²¡é—®é¢˜ï¼Œç›´åˆ°å‡ºäº‹ã€‚ã€**\n",
    "\n",
    "ğŸ‰ æ­å–œå®Œæˆ Pitfall 01ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
