{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 Exercise 1: Meta-Learners - å› æœæ•ˆåº”ä¼°è®¡çš„ç‘å£«å†›åˆ€\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "1. ç†è§£ S-Learner å’Œ T-Learner çš„åŸç†\n",
    "2. å®ç°åŸºç¡€çš„ Meta-Learner ç®—æ³•\n",
    "3. ç†è§£ä¸åŒæ–¹æ³•çš„ä¼˜ç¼ºç‚¹\n",
    "4. æŒæ¡ CATE (æ¡ä»¶å¹³å‡å¤„ç†æ•ˆåº”) ä¼°è®¡å’Œè¯„ä¼°\n",
    "\n",
    "---\n",
    "\n",
    "## ä»€ä¹ˆæ˜¯ Meta-Learners?\n",
    "\n",
    "æƒ³è±¡ä½ æ˜¯ä¸€ä½åŒ»ç”Ÿï¼Œæƒ³çŸ¥é“æŸç§æ–°è¯å¯¹ä¸åŒç—…äººçš„æ•ˆæœã€‚é—®é¢˜æ˜¯ï¼šæ¯ä¸ªç—…äººåªèƒ½é€‰æ‹©åƒè¯æˆ–ä¸åƒè¯ä¸­çš„ä¸€ç§ï¼Œä½ æ°¸è¿œæ— æ³•åŒæ—¶è§‚å¯Ÿåˆ°ä¸¤ç§ç»“æœã€‚\n",
    "\n",
    "**Meta-Learners** å°±æ˜¯ç”¨ \"å…ƒå­¦ä¹ \" çš„æ€æƒ³æ¥è§£å†³è¿™ä¸ªé—®é¢˜â€”â€”å®ƒä»¬æŠŠå› æœæ•ˆåº”ä¼°è®¡è½¬åŒ–ä¸ºç›‘ç£å­¦ä¹ é—®é¢˜ï¼Œè®©æˆ‘ä»¬å¯ä»¥ç”¨ä»»ä½•æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚ Random Forestã€XGBoostï¼‰æ¥ä¼°è®¡å¤„ç†æ•ˆåº”ï¼\n",
    "\n",
    "è¿™å°±åƒæ˜¯ç»™ä½ ä¸€å¥—ä¸‡èƒ½å·¥å…·ï¼Œå¯ä»¥æŠŠå„ç§ ML æ¨¡å‹å˜æˆå› æœæ¨æ–­å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç”Ÿæ´»åŒ–ç±»æ¯”ï¼šé¤å…ä¼šå‘˜å¡çš„æ•ˆæœ\n",
    "\n",
    "å‡è®¾ä½ ç»è¥ä¸€å®¶é¤å…ï¼Œæ¨å‡ºäº†ä¼šå‘˜å¡ï¼ˆå¤„ç† Tï¼‰ï¼š\n",
    "- **å¤„ç†ç»„ (T=1)**ï¼šæ‹¿åˆ°ä¼šå‘˜å¡çš„é¡¾å®¢\n",
    "- **æ§åˆ¶ç»„ (T=0)**ï¼šæ²¡æœ‰ä¼šå‘˜å¡çš„é¡¾å®¢\n",
    "- **ç»“æœ Y**ï¼šæœˆæ¶ˆè´¹é‡‘é¢\n",
    "\n",
    "ä½ æƒ³çŸ¥é“ï¼š**ä¼šå‘˜å¡åˆ°åº•è®©é¡¾å®¢å¤šèŠ±äº†å¤šå°‘é’±ï¼Ÿ** è€Œä¸”æ›´è¿›ä¸€æ­¥ï¼š**å¯¹å“ªäº›é¡¾å®¢æ•ˆæœæœ€å¥½ï¼Ÿ**\n",
    "\n",
    "| é¡¾å®¢ç±»å‹ | åŸæœ¬æ¶ˆè´¹ | æœ‰ä¼šå‘˜å¡åæ¶ˆè´¹ | å¤„ç†æ•ˆåº” |\n",
    "|---------|---------|--------------|--------|\n",
    "| å­¦ç”Ÿå…š | 200 | 350 | **+150** (æ•ˆæœå¥½!) |\n",
    "| ä¸Šç­æ— | 500 | 520 | +20 (æ•ˆæœä¸€èˆ¬) |\n",
    "| åœŸè±ª | 2000 | 2010 | +10 (å‡ ä¹æ²¡æ•ˆæœ) |\n",
    "\n",
    "è¿™ç§ **å› äººè€Œå¼‚** çš„æ•ˆåº”å°±å«åš **CATE (Conditional Average Treatment Effect)**â€”â€”æ¡ä»¶å¹³å‡å¤„ç†æ•ˆåº”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from typing import Tuple\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"ç¯å¢ƒå‡†å¤‡å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: S-Learner (Single Model Learner)\n",
    "\n",
    "### æ ¸å¿ƒæ€æƒ³\n",
    "\n",
    "S-Learner æ˜¯æœ€ç®€å•çš„ Meta-Learnerï¼š\n",
    "\n",
    "**æŠŠå¤„ç† T å½“ä½œæ™®é€šç‰¹å¾ï¼Œè®­ç»ƒä¸€ä¸ªæ¨¡å‹åŒæ—¶é¢„æµ‹æ‰€æœ‰äººçš„ç»“æœ**\n",
    "\n",
    "$$\\hat{\\mu}(x, t) = \\hat{E}[Y | X=x, T=t]$$\n",
    "\n",
    "ç„¶åï¼ŒCATE å°±æ˜¯é¢„æµ‹å·®å€¼ï¼š\n",
    "\n",
    "$$\\hat{\\tau}(x) = \\hat{\\mu}(x, 1) - \\hat{\\mu}(x, 0)$$\n",
    "\n",
    "### ç±»æ¯”ï¼šä¸€ä¸ªç­çº§ï¼Œä¸€ä½è€å¸ˆ\n",
    "\n",
    "æƒ³è±¡ä¸€ä¸ªç­çº§é‡Œæœ‰ç”·ç”Ÿå’Œå¥³ç”Ÿï¼Œè€å¸ˆè¦é¢„æµ‹ä»–ä»¬çš„è€ƒè¯•æˆç»©ï¼š\n",
    "\n",
    "- **S-Learner æ–¹æ³•**ï¼šè€å¸ˆæŠŠ \"æ€§åˆ«\" ä½œä¸ºä¸€ä¸ªç‰¹å¾ï¼Œç”¨åŒä¸€å¥—æ¨¡å‹é¢„æµ‹æ‰€æœ‰å­¦ç”Ÿçš„æˆç»©\n",
    "- ç„¶åæ¯”è¾ƒï¼šå¦‚æœè¿™ä¸ªå­¦ç”Ÿæ˜¯ç”·ç”Ÿä¼šè€ƒå¤šå°‘åˆ†ï¼Ÿå¦‚æœæ˜¯å¥³ç”Ÿä¼šè€ƒå¤šå°‘åˆ†ï¼Ÿå·®å€¼å°±æ˜¯ \"æ€§åˆ«æ•ˆåº”\"\n",
    "\n",
    "### S-Learner çš„æµç¨‹å›¾\n",
    "\n",
    "```\n",
    "è®­ç»ƒé˜¶æ®µ:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  ç‰¹å¾ X + å¤„ç† T â”‚ â”€â”€â”€â–º â”‚  å•ä¸€æ¨¡å‹ f(X,T) â”‚ â”€â”€â”€â–º é¢„æµ‹ Y\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "é¢„æµ‹é˜¶æ®µ:\n",
    "                         â”Œâ”€ f(X, T=1) â”€â”\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”                 â”‚             â”‚    å‡æ³•\n",
    "â”‚ ç‰¹å¾ Xâ”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–º CATE\n",
    "â””â”€â”€â”€â”€â”€â”€â”˜                 â”‚             â”‚\n",
    "                         â””â”€ f(X, T=0) â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ============================================================\n# ğŸ¯ ç»ƒä¹  1.1: å®ç° S-Learner\n# ============================================================\n# ç›®æ ‡: å®ç° S-Learnerï¼Œå°†å¤„ç† T ä½œä¸ºç‰¹å¾ï¼Œè®­ç»ƒå•ä¸€æ¨¡å‹\n# æç¤º:\n#   1. fit() æ–¹æ³•: å°† T å’Œ X åˆå¹¶ä¸ºç‰¹å¾çŸ©é˜µï¼Œè®­ç»ƒæ¨¡å‹é¢„æµ‹ Y\n#   2. predict_cate() æ–¹æ³•: åˆ†åˆ«é¢„æµ‹ T=1 å’Œ T=0 çš„ç»“æœï¼Œè®¡ç®—å·®å€¼\n# ============================================================\n\nclass SimpleSLearner:\n    \"\"\"\n    S-Learner (Single Model Learner)\n    \n    æ ¸å¿ƒæ€æƒ³:\n    - å°†å¤„ç† T ä½œä¸ºä¸€ä¸ªç‰¹å¾\n    - è®­ç»ƒå•ä¸€æ¨¡å‹: Y = f(X, T)\n    - CATE ä¼°è®¡: tau(x) = f(x, 1) - f(x, 0)\n    \"\"\"\n    \n    def __init__(self):\n        # åˆå§‹åŒ–åŸºç¡€æ¨¡å‹ - ä½¿ç”¨éšæœºæ£®æ—\n        self.model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n    \n    def fit(self, X: np.ndarray, T: np.ndarray, Y: np.ndarray):\n        \"\"\"\n        è®­ç»ƒ S-Learner\n        \n        TODO: \n        1. å°† T å’Œ X åˆå¹¶ä¸ºç‰¹å¾çŸ©é˜µ (T ä½œä¸ºæœ€åä¸€åˆ—)\n        2. è®­ç»ƒæ¨¡å‹é¢„æµ‹ Y\n        \"\"\"\n        # === ä½ çš„ä»£ç å¼€å§‹ ===\n        \n        pass  # åˆ é™¤æ­¤è¡Œï¼Œå¡«å…¥ä½ çš„ä»£ç \n        \n        # === ä½ çš„ä»£ç ç»“æŸ ===\n        \n        return self\n    \n    def predict_cate(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        é¢„æµ‹ CATE (ä¸ªä½“å¤„ç†æ•ˆåº”)\n        \n        TODO:\n        1. æ„é€  T=1 çš„ç‰¹å¾: æŠŠ 1 æ·»åŠ åˆ° X åé¢\n        2. æ„é€  T=0 çš„ç‰¹å¾: æŠŠ 0 æ·»åŠ åˆ° X åé¢\n        3. åˆ†åˆ«é¢„æµ‹ Y(1) å’Œ Y(0)\n        4. è¿”å›å·®å€¼: Y(1) - Y(0)\n        \"\"\"\n        # === ä½ çš„ä»£ç å¼€å§‹ ===\n        \n        pass  # åˆ é™¤æ­¤è¡Œï¼Œå¡«å…¥ä½ çš„ä»£ç \n        \n        # === ä½ çš„ä»£ç ç»“æŸ ==="
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# ğŸ¯ ç»ƒä¹  1.2: å®ç° T-Learner\n# ============================================================\n# ç›®æ ‡: å®ç° T-Learnerï¼Œåˆ†åˆ«ä¸ºå¤„ç†ç»„å’Œæ§åˆ¶ç»„è®­ç»ƒä¸¤ä¸ªæ¨¡å‹\n# æç¤º:\n#   1. fit() æ–¹æ³•: æŒ‰ T åˆ†ç»„ï¼Œåˆ†åˆ«è®­ç»ƒä¸¤ä¸ªæ¨¡å‹\n#   2. predict_cate() æ–¹æ³•: ä½¿ç”¨ä¸¤ä¸ªæ¨¡å‹åˆ†åˆ«é¢„æµ‹ï¼Œè®¡ç®—å·®å€¼\n# ============================================================\n\nclass SimpleTLearner:\n    \"\"\"\n    T-Learner (Two Model Learner)\n    \n    æ ¸å¿ƒæ€æƒ³:\n    - åˆ†åˆ«ä¸ºå¤„ç†ç»„å’Œæ§åˆ¶ç»„è®­ç»ƒä¸¤ä¸ªæ¨¡å‹\n    - mu_0(x) = E[Y|X=x, T=0]  (æ§åˆ¶ç»„æ¨¡å‹)\n    - mu_1(x) = E[Y|X=x, T=1]  (å¤„ç†ç»„æ¨¡å‹)\n    - CATE ä¼°è®¡: tau(x) = mu_1(x) - mu_0(x)\n    \"\"\"\n    \n    def __init__(self):\n        # åˆå§‹åŒ–ä¸¤ä¸ªæ¨¡å‹\n        self.model_0 = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n        self.model_1 = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=43)\n    \n    def fit(self, X: np.ndarray, T: np.ndarray, Y: np.ndarray):\n        \"\"\"\n        è®­ç»ƒ T-Learner\n        \n        TODO:\n        1. å°†æ•°æ®æŒ‰ T åˆ†æˆä¸¤ç»„\n        2. ç”¨æ§åˆ¶ç»„æ•°æ®è®­ç»ƒ model_0\n        3. ç”¨å¤„ç†ç»„æ•°æ®è®­ç»ƒ model_1\n        \"\"\"\n        # === ä½ çš„ä»£ç å¼€å§‹ ===\n        \n        pass  # åˆ é™¤æ­¤è¡Œï¼Œå¡«å…¥ä½ çš„ä»£ç \n        \n        # === ä½ çš„ä»£ç ç»“æŸ ===\n        \n        return self\n    \n    def predict_cate(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        é¢„æµ‹ CATE\n        \n        TODO:\n        1. ä½¿ç”¨ model_1 é¢„æµ‹ Y(1)\n        2. ä½¿ç”¨ model_0 é¢„æµ‹ Y(0)\n        3. è¿”å›å·®å€¼ Y(1) - Y(0)\n        \"\"\"\n        # === ä½ çš„ä»£ç å¼€å§‹ ===\n        \n        pass  # åˆ é™¤æ­¤è¡Œï¼Œå¡«å…¥ä½ çš„ä»£ç \n        \n        # === ä½ çš„ä»£ç ç»“æŸ ==="
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ============================================================\n# ğŸ¯ ç»ƒä¹  1.3: ç”Ÿæˆ Uplift æ•°æ®\n# ============================================================\n# ç›®æ ‡: ç”ŸæˆåŒ…å«å¼‚è´¨æ€§å¤„ç†æ•ˆåº”çš„æ¨¡æ‹Ÿæ•°æ®\n# æç¤º:\n#   1. ç”Ÿæˆç‰¹å¾ X1, X2 (æ ‡å‡†æ­£æ€åˆ†å¸ƒ)\n#   2. éšæœºåˆ†é… T (ä¼¯åŠªåˆ©åˆ†å¸ƒ, p=0.5)\n#   3. è®¡ç®—çœŸå® CATE: å¦‚æœ heterogeneous=True, tau = 2 + X1 - 0.5*X2\n#   4. ç”Ÿæˆ Y0 = 5 + 2*X1 + X2 + noise\n#   5. ç”Ÿæˆ Y1 = Y0 + tau\n#   6. è§‚æµ‹ Y = T * Y1 + (1-T) * Y0\n# ============================================================\n\ndef generate_simple_uplift_data(\n    n: int = 1000,\n    heterogeneous: bool = True,\n    seed: int = 42\n) -> Tuple[pd.DataFrame, np.ndarray]:\n    \"\"\"\n    ç”Ÿæˆç®€å•çš„ Uplift æ•°æ®\n    \n    æ•°æ®ç”Ÿæˆè¿‡ç¨‹ (DGP):\n    - X1, X2 ~ N(0, 1)\n    - T ~ Bernoulli(0.5)  (éšæœºåˆ†é…)\n    - Y(0) = 5 + 2*X1 + X2 + noise\n    - Y(1) = Y(0) + tau(X)\n    \n    å…¶ä¸­:\n    - å¦‚æœ heterogeneous=True: tau(X) = 2 + X1 - 0.5*X2  (å¼‚è´¨æ€§æ•ˆåº”)\n    - å¦‚æœ heterogeneous=False: tau(X) = 2  (å¸¸æ•°æ•ˆåº”)\n    \n    Returns:\n        (DataFrame, true_cate)\n        DataFrame columns: X1, X2, T, Y\n        true_cate: çœŸå®çš„ä¸ªä½“å¤„ç†æ•ˆåº”\n    \"\"\"\n    # === ä½ çš„ä»£ç å¼€å§‹ ===\n    \n    pass  # åˆ é™¤æ­¤è¡Œï¼Œå¡«å…¥ä½ çš„ä»£ç \n    \n    # === ä½ çš„ä»£ç ç»“æŸ ===\n\n# æµ‹è¯•æ•°æ®ç”Ÿæˆ\ndf, true_cate = generate_simple_uplift_data(n=100)\nif df is not None and true_cate is not None:\n    print(f\"æ ·æœ¬é‡: {len(df)}\")\n    print(f\"çœŸå®å¹³å‡ CATE (ATE): {true_cate.mean():.4f}\")\n    print(f\"CATE èŒƒå›´: [{true_cate.min():.2f}, {true_cate.max():.2f}]\")\n    print(\"\\næ•°æ®é¢„è§ˆ:\")\n    print(df.head().to_string())\nelse:\n    print(\"[æœªå®Œæˆ] è¯·å®Œæˆ generate_simple_uplift_data å‡½æ•°\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: å¯è§†åŒ–ä¸è¯„ä¼°\n",
    "\n",
    "è®©æˆ‘ä»¬å®ç° CATE è¯„ä¼°æŒ‡æ ‡å’Œå¯è§†åŒ–æ•ˆæœï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# ğŸ¯ ç»ƒä¹  1.4: è¯„ä¼° CATE ä¼°è®¡\n# ============================================================\n# ç›®æ ‡: å®ç° CATE ä¼°è®¡è´¨é‡çš„è¯„ä¼°æŒ‡æ ‡\n# æç¤º:\n#   1. MSE: mean((true - pred)^2)\n#   2. MAE: mean(|true - pred|)\n#   3. Correlation: np.corrcoef(true, pred)[0, 1]\n#   4. PEHE: sqrt(MSE)\n# ============================================================\n\ndef evaluate_cate_estimation(\n    true_cate: np.ndarray,\n    predicted_cate: np.ndarray\n) -> dict:\n    \"\"\"\n    è¯„ä¼° CATE ä¼°è®¡çš„è´¨é‡\n    \n    è®¡ç®—ä»¥ä¸‹æŒ‡æ ‡:\n    1. MSE: å‡æ–¹è¯¯å·® = mean((true - pred)^2)\n    2. MAE: å¹³å‡ç»å¯¹è¯¯å·® = mean(|true - pred|)\n    3. Correlation: ä¸çœŸå® CATE çš„ç›¸å…³ç³»æ•°\n    4. PEHE: sqrt(MSE)\n    \n    Returns:\n        å­—å…¸åŒ…å«æ‰€æœ‰æŒ‡æ ‡\n    \"\"\"\n    # === ä½ çš„ä»£ç å¼€å§‹ ===\n    \n    pass  # åˆ é™¤æ­¤è¡Œï¼Œå¡«å…¥ä½ çš„ä»£ç \n    \n    # === ä½ çš„ä»£ç ç»“æŸ ===\n\n# æµ‹è¯•è¯„ä¼°å‡½æ•°\nif 'true_cate' in locals() and true_cate is not None:\n    # ç”¨ä¸€ä¸ªéšæœºé¢„æµ‹æµ‹è¯•\n    random_pred = np.random.randn(len(true_cate)) * 2 + 2\n    metrics = evaluate_cate_estimation(true_cate, random_pred)\n    if metrics and 'MSE' in metrics:\n        print(\"éšæœºé¢„æµ‹çš„è¯„ä¼°ç»“æœ:\")\n        for key, value in metrics.items():\n            print(f\"  {key}: {value:.4f}\")\n    else:\n        print(\"[æœªå®Œæˆ] è¯·å®Œæˆ evaluate_cate_estimation å‡½æ•°\")\nelse:\n    print(\"[æç¤º] è¯·å…ˆå®Œæˆç»ƒä¹  1.3 ç”Ÿæˆæ•°æ®\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## æ€»ç»“\n",
    "\n",
    "### ä»Šå¤©å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "| æ¦‚å¿µ | è¦ç‚¹ |\n",
    "|------|------|\n",
    "| **Meta-Learners** | æŠŠå› æœæ¨æ–­é—®é¢˜è½¬åŒ–ä¸ºç›‘ç£å­¦ä¹ é—®é¢˜çš„é€šç”¨æ–¹æ³• |\n",
    "| **S-Learner** | å•æ¨¡å‹ï¼ŒæŠŠ T å½“ç‰¹å¾ï¼Œç®€å•ä½†å¯èƒ½ä½ä¼°æ•ˆåº” |\n",
    "| **T-Learner** | åŒæ¨¡å‹ï¼Œåˆ†åˆ«å»ºæ¨¡ï¼Œçµæ´»ä½†å¯èƒ½æ–¹å·®å¤§ |\n",
    "| **CATE** | æ¡ä»¶å¹³å‡å¤„ç†æ•ˆåº”ï¼Œåæ˜ æ•ˆåº”çš„å¼‚è´¨æ€§ |\n",
    "| **PEHE** | è¯„ä¼° CATE ä¼°è®¡çš„é»„é‡‘æ ‡å‡† |\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "åœ¨ä¸‹ä¸€ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹  **Uplift Tree** â€”â€” ä¸€ç§ä¸“é—¨ä¸ºå› æœæ¨æ–­è®¾è®¡çš„å†³ç­–æ ‘ï¼\n",
    "\n",
    "---\n",
    "\n",
    "*æ­å–œä½ å®Œæˆäº† Meta-Learners çš„å­¦ä¹ ï¼* ğŸ‰"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# ğŸ¯ ç»ƒä¹  1.5: å¯¹æ¯” S-Learner å’Œ T-Learner\n# ============================================================\n# ç›®æ ‡: å®ç°å‡½æ•°æ¥å¯¹æ¯”ä¸¤ç§æ–¹æ³•çš„æ€§èƒ½\n# æç¤º:\n#   1. ç”Ÿæˆæ•°æ®\n#   2. è®­ç»ƒ S-Learner å¹¶é¢„æµ‹\n#   3. è®­ç»ƒ T-Learner å¹¶é¢„æµ‹\n#   4. è¯„ä¼°ä¸¤è€…ï¼Œè¿”å›å¯¹æ¯”ç»“æœ\n# ============================================================\n\ndef compare_s_and_t_learner(\n    n_samples: int = 2000,\n    heterogeneous: bool = True\n) -> Tuple[pd.DataFrame, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    æ¯”è¾ƒ S-Learner å’Œ T-Learner çš„æ€§èƒ½\n    \n    Returns:\n        (comparison_df, s_pred, t_pred, true_cate)\n    \"\"\"\n    # === ä½ çš„ä»£ç å¼€å§‹ ===\n    \n    pass  # åˆ é™¤æ­¤è¡Œï¼Œå¡«å…¥ä½ çš„ä»£ç \n    \n    # === ä½ çš„ä»£ç ç»“æŸ ===\n\n# è¿è¡Œå¯¹æ¯”å®éªŒ\nprint(\"=\" * 50)\nprint(\"åœºæ™¯ 1: å¼‚è´¨æ€§æ•ˆåº”\")\nprint(\"=\" * 50)\nresult = compare_s_and_t_learner(n_samples=1000, heterogeneous=True)\nif result and result[0] is not None:\n    comparison_df, s_pred, t_pred, true_cate = result\n    print(comparison_df.to_string())\nelse:\n    print(\"[æœªå®Œæˆ] è¯·å®Œæˆæ‰€æœ‰ç»ƒä¹ åé‡æ–°è¿è¡Œ\")\n\nprint(\"\\n\" + \"=\" * 50)\nprint(\"åœºæ™¯ 2: å¸¸æ•°æ•ˆåº”\")\nprint(\"=\" * 50)\nresult2 = compare_s_and_t_learner(n_samples=1000, heterogeneous=False)\nif result2 and result2[0] is not None:\n    print(result2[0].to_string())",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# å¯è§†åŒ– CATE ä¼°è®¡ç»“æœ\n\nif 'result' in locals() and result and result[0] is not None:\n    _, s_pred, t_pred, true_cate = result\n    \n    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n    \n    # å›¾1: çœŸå® vs S-Learner\n    axes[0].scatter(true_cate, s_pred, alpha=0.5, s=10)\n    axes[0].plot([true_cate.min(), true_cate.max()], \n                 [true_cate.min(), true_cate.max()], 'r--', lw=2)\n    axes[0].set_xlabel('True CATE')\n    axes[0].set_ylabel('Predicted CATE')\n    axes[0].set_title('S-Learner: True vs Predicted')\n    \n    # å›¾2: çœŸå® vs T-Learner\n    axes[1].scatter(true_cate, t_pred, alpha=0.5, s=10)\n    axes[1].plot([true_cate.min(), true_cate.max()], \n                 [true_cate.min(), true_cate.max()], 'r--', lw=2)\n    axes[1].set_xlabel('True CATE')\n    axes[1].set_ylabel('Predicted CATE')\n    axes[1].set_title('T-Learner: True vs Predicted')\n    \n    # å›¾3: CATE åˆ†å¸ƒå¯¹æ¯”\n    axes[2].hist(true_cate, bins='auto', alpha=0.5, label='True CATE', density=True)\n    axes[2].hist(s_pred, bins='auto', alpha=0.5, label='S-Learner', density=True)\n    axes[2].hist(t_pred, bins='auto', alpha=0.5, label='T-Learner', density=True)\n    axes[2].set_xlabel('CATE')\n    axes[2].set_ylabel('Density')\n    axes[2].set_title('CATE Distribution')\n    axes[2].legend()\n    \n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"è¯·å…ˆå®Œæˆä¸Šé¢çš„ç»ƒä¹ ï¼Œç”Ÿæˆé¢„æµ‹ç»“æœ\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### å‚è€ƒç­”æ¡ˆ: R-Learner å®ç°\n",
    "\n",
    "<details>\n",
    "<summary>ç‚¹å‡»æŸ¥çœ‹å‚è€ƒç­”æ¡ˆ</summary>\n",
    "\n",
    "```python\n",
    "class SimpleRLearner:\n",
    "    def __init__(self):\n",
    "        self.model_m = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        self.model_e = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        self.model_tau = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    def fit(self, X: np.ndarray, T: np.ndarray, Y: np.ndarray):\n",
    "        # Step 1: ä¼°è®¡ä¸»æ•ˆåº”\n",
    "        self.model_m.fit(X, Y)\n",
    "        self.model_e.fit(X, T)\n",
    "        \n",
    "        # Step 2: è®¡ç®—æ®‹å·®\n",
    "        Y_tilde = Y - self.model_m.predict(X)\n",
    "        T_tilde = T - self.model_e.predict(X)\n",
    "        \n",
    "        # Step 3: åŠ æƒå›å½’ä¼°è®¡ CATE\n",
    "        # ä½¿ç”¨ |T_tilde| ä½œä¸ºæƒé‡ï¼Œé¿å…è´Ÿæƒé‡\n",
    "        weights = np.abs(T_tilde) + 1e-6  # åŠ å°å¸¸æ•°é¿å…é›¶æƒé‡\n",
    "        self.model_tau.fit(X, Y_tilde / (T_tilde + 1e-6), sample_weight=weights)\n",
    "    \n",
    "    def predict_cate(self, X: np.ndarray) -> np.ndarray:\n",
    "        return self.model_tau.predict(X)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### å‚è€ƒç­”æ¡ˆ: S-Learner å’Œ T-Learner å®ç°\n",
    "\n",
    "<details>\n",
    "<summary>ç‚¹å‡»æŸ¥çœ‹å‚è€ƒç­”æ¡ˆ</summary>\n",
    "\n",
    "```python\n",
    "# S-Learner å‚è€ƒç­”æ¡ˆ\n",
    "class SimpleSLearner:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    def fit(self, X: np.ndarray, T: np.ndarray, Y: np.ndarray):\n",
    "        # åˆå¹¶ X å’Œ T\n",
    "        X_with_T = np.column_stack([X, T.reshape(-1, 1)])\n",
    "        self.model.fit(X_with_T, Y)\n",
    "    \n",
    "    def predict_cate(self, X: np.ndarray) -> np.ndarray:\n",
    "        n = X.shape[0]\n",
    "        # æ„é€  T=1 çš„ç‰¹å¾\n",
    "        X_with_T1 = np.column_stack([X, np.ones(n)])\n",
    "        # æ„é€  T=0 çš„ç‰¹å¾\n",
    "        X_with_T0 = np.column_stack([X, np.zeros(n)])\n",
    "        # é¢„æµ‹å¹¶è®¡ç®—å·®å€¼\n",
    "        Y1_pred = self.model.predict(X_with_T1)\n",
    "        Y0_pred = self.model.predict(X_with_T0)\n",
    "        return Y1_pred - Y0_pred\n",
    "\n",
    "# T-Learner å‚è€ƒç­”æ¡ˆ\n",
    "class SimpleTLearner:\n",
    "    def __init__(self):\n",
    "        self.model_0 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        self.model_1 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    def fit(self, X: np.ndarray, T: np.ndarray, Y: np.ndarray):\n",
    "        # æŒ‰ T åˆ†ç»„\n",
    "        mask_0 = (T == 0)\n",
    "        mask_1 = (T == 1)\n",
    "        # åˆ†åˆ«è®­ç»ƒ\n",
    "        self.model_0.fit(X[mask_0], Y[mask_0])\n",
    "        self.model_1.fit(X[mask_1], Y[mask_1])\n",
    "    \n",
    "    def predict_cate(self, X: np.ndarray) -> np.ndarray:\n",
    "        Y1_pred = self.model_1.predict(X)\n",
    "        Y0_pred = self.model_0.predict(X)\n",
    "        return Y1_pred - Y0_pred\n",
    "\n",
    "# æ•°æ®ç”Ÿæˆå‚è€ƒç­”æ¡ˆ\n",
    "def generate_simple_uplift_data(\n",
    "    n: int = 1000,\n",
    "    heterogeneous: bool = True,\n",
    "    seed: int = 42\n",
    ") -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    X1 = np.random.randn(n)\n",
    "    X2 = np.random.randn(n)\n",
    "    T = np.random.binomial(1, 0.5, n)\n",
    "    \n",
    "    if heterogeneous:\n",
    "        true_cate = 2 + X1 - 0.5 * X2\n",
    "    else:\n",
    "        true_cate = np.ones(n) * 2\n",
    "    \n",
    "    noise = np.random.randn(n) * 0.5\n",
    "    Y0 = 5 + 2 * X1 + X2 + noise\n",
    "    Y1 = Y0 + true_cate\n",
    "    Y = T * Y1 + (1 - T) * Y0\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'X1': X1,\n",
    "        'X2': X2,\n",
    "        'T': T,\n",
    "        'Y': Y\n",
    "    })\n",
    "    \n",
    "    return df, true_cate\n",
    "\n",
    "# è¯„ä¼°å‡½æ•°å‚è€ƒç­”æ¡ˆ\n",
    "def evaluate_cate_estimation(\n",
    "    true_cate: np.ndarray,\n",
    "    predicted_cate: np.ndarray\n",
    ") -> dict:\n",
    "    mse = np.mean((true_cate - predicted_cate)**2)\n",
    "    return {\n",
    "        'MSE': mse,\n",
    "        'MAE': np.mean(np.abs(true_cate - predicted_cate)),\n",
    "        'Correlation': np.corrcoef(true_cate, predicted_cate)[0, 1],\n",
    "        'PEHE': np.sqrt(mse)\n",
    "    }\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ============================================================\n# ğŸ¯ ç»ƒä¹  1.6: å®ç° R-Learner (è¿›é˜¶)\n# ============================================================\n# ç›®æ ‡: å®ç° R-Learnerï¼Œä½¿ç”¨åŒé‡å»åæ–¹æ³•ç›´æ¥ä¼˜åŒ– CATE\n# æç¤º:\n#   1. fit() æ–¹æ³•:\n#      - è®­ç»ƒ model_m é¢„æµ‹ E[Y|X]\n#      - è®­ç»ƒ model_e é¢„æµ‹ E[T|X]\n#      - è®¡ç®—æ®‹å·® Y_tilde å’Œ T_tilde\n#      - ä½¿ç”¨åŠ æƒå›å½’è®­ç»ƒ model_tau\n#   2. predict_cate() æ–¹æ³•: ç›´æ¥ä½¿ç”¨ model_tau é¢„æµ‹\n# ============================================================\n\nclass SimpleRLearner:\n    \"\"\"\n    R-Learner (Robinson Learner)\n    \n    æ ¸å¿ƒæ€æƒ³:\n    - Step 1: ä¼°è®¡ m(x) = E[Y|X] å’Œ e(x) = E[T|X]\n    - Step 2: è®¡ç®—æ®‹å·® Y_tilde = Y - m(X), T_tilde = T - e(X)\n    - Step 3: æœ€å°åŒ– (Y_tilde - T_tilde * tau(X))^2\n    \n    è¿™æ˜¯ä¸€ç§ã€ŒåŒé‡å»åã€çš„æ–¹æ³•ï¼Œç›´æ¥ä¼˜åŒ– CATE ä¼°è®¡\n    \"\"\"\n    \n    def __init__(self):\n        # åˆå§‹åŒ–ä¸‰ä¸ªæ¨¡å‹\n        self.model_m = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)  # E[Y|X]\n        self.model_e = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=43)  # E[T|X]\n        self.model_tau = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=44)  # tau(X)\n    \n    def fit(self, X: np.ndarray, T: np.ndarray, Y: np.ndarray):\n        \"\"\"\n        è®­ç»ƒ R-Learner\n        \n        TODO: å®ç° R-Learner çš„è®­ç»ƒè¿‡ç¨‹\n        \"\"\"\n        # === ä½ çš„ä»£ç å¼€å§‹ ===\n        \n        pass  # åˆ é™¤æ­¤è¡Œï¼Œå¡«å…¥ä½ çš„ä»£ç \n        \n        # === ä½ çš„ä»£ç ç»“æŸ ===\n        \n        return self\n    \n    def predict_cate(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        é¢„æµ‹ CATE\n        \n        TODO: ä½¿ç”¨ model_tau é¢„æµ‹\n        \"\"\"\n        # === ä½ çš„ä»£ç å¼€å§‹ ===\n        \n        pass  # åˆ é™¤æ­¤è¡Œï¼Œå¡«å…¥ä½ çš„ä»£ç \n        \n        # === ä½ çš„ä»£ç ç»“æŸ ==="
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: è¿›é˜¶ Meta-Learners (å¯é€‰)\n",
    "\n",
    "R-Learner å’Œ DR-Learner æ˜¯æ›´é«˜çº§çš„æ–¹æ³•ï¼Œå¦‚æœå®Œæˆäº†åŸºç¡€ç»ƒä¹ å¯ä»¥å°è¯•ï¼"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ============================================================\n# ğŸ¯ ç»ƒä¹  1.7: å®ç° DR-Learner (è¿›é˜¶)\n# ============================================================\n# ç›®æ ‡: å®ç° DR-Learnerï¼Œä½¿ç”¨åŒé‡ç¨³å¥æ–¹æ³•ä¼°è®¡ CATE\n# æç¤º:\n#   1. fit() æ–¹æ³•:\n#      - è®­ç»ƒ model_0 å’Œ model_1 åˆ†åˆ«é¢„æµ‹ä¸¤ç»„çš„ç»“æœ\n#      - è®­ç»ƒ model_e é¢„æµ‹å€¾å‘å¾—åˆ†\n#      - ä½¿ç”¨ AIPW å…¬å¼æ„é€ ä¼ªç»“æœ\n#      - è®­ç»ƒ model_tau é¢„æµ‹ä¼ªç»“æœ\n#   2. predict_cate() æ–¹æ³•: ä½¿ç”¨ model_tau é¢„æµ‹\n# ============================================================\n\nclass SimpleDRLearner:\n    \"\"\"\n    DR-Learner (Doubly Robust Learner)\n    \n    æ ¸å¿ƒæ€æƒ³:\n    - Step 1: åˆ†åˆ«ä¼°è®¡ Î¼â‚€(x), Î¼â‚(x), e(x)\n    - Step 2: æ„é€ ä¼ªç»“æœ (Pseudo-Outcome) ä½¿ç”¨ AIPW å…¬å¼\n    - Step 3: å°†ä¼ªç»“æœå›å½’åˆ° X ä¸Šå¾—åˆ° CATE\n    \n    è¿™ç§æ–¹æ³•å…·æœ‰ã€ŒåŒé‡ç¨³å¥æ€§ã€ï¼š\n    - å¦‚æœç»“æœæ¨¡å‹ (Î¼â‚€, Î¼â‚) æ­£ç¡®ï¼Œä¼°è®¡ä¸€è‡´\n    - å¦‚æœå€¾å‘å¾—åˆ†æ¨¡å‹ (e) æ­£ç¡®ï¼Œä¼°è®¡ä¹Ÿä¸€è‡´\n    \"\"\"\n    \n    def __init__(self):\n        # åˆå§‹åŒ–å››ä¸ªæ¨¡å‹\n        self.model_0 = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)  # Î¼â‚€(X)\n        self.model_1 = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=43)  # Î¼â‚(X)\n        self.model_e = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=44)  # e(X)\n        self.model_tau = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=45)  # Ï„(X)\n    \n    def fit(self, X: np.ndarray, T: np.ndarray, Y: np.ndarray):\n        \"\"\"\n        è®­ç»ƒ DR-Learner\n        \n        TODO: å®ç° DR-Learner çš„è®­ç»ƒè¿‡ç¨‹\n        \"\"\"\n        # === ä½ çš„ä»£ç å¼€å§‹ ===\n        \n        pass  # åˆ é™¤æ­¤è¡Œï¼Œå¡«å…¥ä½ çš„ä»£ç \n        \n        # === ä½ çš„ä»£ç ç»“æŸ ===\n        \n        return self\n    \n    def predict_cate(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        é¢„æµ‹ CATE\n        \n        TODO: ä½¿ç”¨ model_tau é¢„æµ‹\n        \"\"\"\n        # === ä½ çš„ä»£ç å¼€å§‹ ===\n        \n        pass  # åˆ é™¤æ­¤è¡Œï¼Œå¡«å…¥ä½ çš„ä»£ç \n        \n        # === ä½ çš„ä»£ç ç»“æŸ ===",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Meta-Learner é€‰æ‹©æŒ‡å—\n",
    "\n",
    "é¢å¯¹è¿™ä¹ˆå¤š Meta-Learnerï¼Œåº”è¯¥æ€ä¹ˆé€‰ï¼Ÿè¿™é‡Œæä¾›ä¸€ä¸ªå®ç”¨çš„å†³ç­–æ¡†æ¶ã€‚\n",
    "\n",
    "### æ–¹æ³•å¯¹æ¯”æ€»ç»“è¡¨\n",
    "\n",
    "| Meta-Learner | æ¨¡å‹æ•°é‡ | æ ¸å¿ƒæ€æƒ³ | ä¸»è¦ä¼˜åŠ¿ | ä¸»è¦åŠ£åŠ¿ | é€‚ç”¨åœºæ™¯ |\n",
    "|--------------|---------|---------|---------|---------|----------|\n",
    "| **S-Learner** | 1ä¸ª | å°† T ä½œä¸ºç‰¹å¾ | ç®€å•ï¼Œåˆ©ç”¨å…¨éƒ¨æ•°æ® | å¯èƒ½ä½ä¼°æ•ˆåº”ï¼ˆæ­£åˆ™åŒ–åå·®ï¼‰ | æ•ˆåº”å°ã€æ•°æ®å°‘ã€ä¸¤ç»„ç›¸ä¼¼ |\n",
    "| **T-Learner** | 2ä¸ª | åˆ†ç»„å»ºæ¨¡ | çµæ´»ï¼Œæ— æ­£åˆ™åŒ–åå·® | æ–¹å·®å¤§ï¼ˆç‰¹åˆ«æ˜¯ä¸å¹³è¡¡æ—¶ï¼‰ | æ•ˆåº”å¤§ã€ä¸¤ç»„å·®å¼‚å¤§ |\n",
    "| **X-Learner** | 4ä¸ª | äº¤å‰ä¼°è®¡ + å€¾å‘å¾—åˆ†åŠ æƒ | å¯¹ä¸å¹³è¡¡æ•°æ®å‹å¥½ | å¤æ‚ï¼Œéœ€è¦å€¾å‘å¾—åˆ† | æ ·æœ¬ä¸å¹³è¡¡ |\n",
    "| **R-Learner** | 3ä¸ª | åŒé‡å»åï¼Œç›´æ¥ä¼˜åŒ– CATE | ç†è®ºä¼˜é›…ï¼ŒDML æ¡†æ¶ | å®ç°å¤æ‚ | è¿½æ±‚ç†è®ºä¿è¯ |\n",
    "| **DR-Learner** | 4ä¸ª | åŒé‡ç¨³å¥ï¼Œä¼ªç»“æœ | åŒä¿é™©ï¼Œç¨³å¥æ€§å¼º | å®ç°æœ€å¤æ‚ | æ¨¡å‹ä¸ç¡®å®šæ€§å¤§ |\n",
    "\n",
    "### å†³ç­–æ ‘ï¼šåº”è¯¥ç”¨å“ªä¸ª Meta-Learnerï¼Ÿ\n",
    "\n",
    "```\n",
    "å¼€å§‹\n",
    "â”‚\n",
    "â”œâ”€ æ•°æ®é‡å¾ˆå° (n < 500) ?\n",
    "â”‚  â””â”€ æ˜¯ â†’ S-Learner (åˆ©ç”¨å…¨éƒ¨æ•°æ®)\n",
    "â”‚  â””â”€ å¦ â†’ ç»§ç»­\n",
    "â”‚\n",
    "â”œâ”€ å¤„ç†ç»„å’Œæ§åˆ¶ç»„ä¸¥é‡ä¸å¹³è¡¡ (æ¯”å¦‚ 90% vs 10%) ?\n",
    "â”‚  â””â”€ æ˜¯ â†’ X-Learner (å€¾å‘å¾—åˆ†åŠ æƒ)\n",
    "â”‚  â””â”€ å¦ â†’ ç»§ç»­\n",
    "â”‚\n",
    "â”œâ”€ æ‹…å¿ƒæ¨¡å‹è®¾å®šé”™è¯¯ï¼Ÿ\n",
    "â”‚  â””â”€ æ˜¯ â†’ DR-Learner (åŒé‡ç¨³å¥)\n",
    "â”‚  â””â”€ å¦ â†’ ç»§ç»­\n",
    "â”‚\n",
    "â”œâ”€ éœ€è¦ç†è®ºä¿è¯å’Œæ¨æ–­ï¼Ÿ\n",
    "â”‚  â””â”€ æ˜¯ â†’ R-Learner (DML æ¡†æ¶)\n",
    "â”‚  â””â”€ å¦ â†’ T-Learner (ç®€å•æœ‰æ•ˆ)\n",
    "```\n",
    "\n",
    "### å®è·µå»ºè®®\n",
    "\n",
    "#### 1. å¿«é€ŸåŸå‹é˜¶æ®µ\n",
    "\n",
    "**æ¨è: T-Learner**\n",
    "- åŸå› : å®ç°ç®€å•ï¼Œæ€§èƒ½ç¨³å®šï¼Œæ˜“äºç†è§£\n",
    "- ä½•æ—¶å‡çº§: å¦‚æœå‘ç°æ ·æœ¬ä¸å¹³è¡¡æˆ–æ•ˆåº”å¾ˆå°\n",
    "\n",
    "#### 2. ç”Ÿäº§ç¯å¢ƒ\n",
    "\n",
    "**æ¨èç­–ç•¥: ç»„åˆä½¿ç”¨**\n",
    "- åŒæ—¶è®­ç»ƒ T-Learner å’Œ DR-Learner\n",
    "- ç”¨éªŒè¯é›†é€‰æ‹©æ›´å¥½çš„\n",
    "- æˆ–è€…é›†æˆä¸¤è€…çš„é¢„æµ‹ (Ensemble)\n",
    "\n",
    "#### 3. ç ”ç©¶/è®ºæ–‡\n",
    "\n",
    "**æ¨è: R-Learner æˆ– DR-Learner**\n",
    "- åŸå› : æœ‰ç†è®ºä¿è¯ï¼Œå¯ä»¥åšç»Ÿè®¡æ¨æ–­\n",
    "- é…åˆ Cross-Fitting æé«˜ç¨³å¥æ€§\n",
    "\n",
    "### å…³é”®å› ç´ åˆ†æ\n",
    "\n",
    "#### å› ç´  1: æ ·æœ¬é‡\n",
    "\n",
    "| æ ·æœ¬é‡ | æ¨èæ–¹æ³• | ç†ç”± |\n",
    "|--------|---------|------|\n",
    "| n < 500 | S-Learner | éœ€è¦åˆ©ç”¨å…¨éƒ¨æ•°æ® |\n",
    "| 500 < n < 5000 | T-Learner | å¹³è¡¡ bias-variance |\n",
    "| n > 5000 | R/DR-Learner | å¯ä»¥æ‰¿å—æ›´å¤æ‚çš„æ¨¡å‹ |\n",
    "\n",
    "#### å› ç´  2: æ ·æœ¬å¹³è¡¡æ€§\n",
    "\n",
    "| å¤„ç†ç»„å æ¯” | æ¨èæ–¹æ³• | ç†ç”± |\n",
    "|-----------|---------|------|\n",
    "| 20% - 80% | T-Learner | ä¸¤ç»„æ ·æœ¬éƒ½è¶³å¤Ÿ |\n",
    "| 10% - 20% æˆ– 80% - 90% | X-Learner | éœ€è¦å€¾å‘å¾—åˆ†åŠ æƒ |\n",
    "| < 10% æˆ– > 90% | DR-Learner | åŒé‡ç¨³å¥æ€§é‡è¦ |\n",
    "\n",
    "#### å› ç´  3: æ•ˆåº”å¤§å°\n",
    "\n",
    "| æ•ˆåº”å¤§å° | æ¨èæ–¹æ³• | ç†ç”± |\n",
    "|---------|---------|------|\n",
    "| å¾ˆå° (< 5% æå‡) | S-Learner æˆ– DR-Learner | éœ€è¦ä½æ–¹å·® |\n",
    "| ä¸­ç­‰ (5-20%) | T-Learner | æ ‡å‡†é€‰æ‹© |\n",
    "| å¾ˆå¤§ (> 20%) | T-Learner | ä¸¤ç»„å·®å¼‚æ˜æ˜¾ |\n",
    "\n",
    "#### å› ç´  4: å¼‚è´¨æ€§ç¨‹åº¦\n",
    "\n",
    "| å¼‚è´¨æ€§ | æ¨èæ–¹æ³• | ç†ç”± |\n",
    "|--------|---------|------|\n",
    "| ä½ (CATE æ¥è¿‘å¸¸æ•°) | S-Learner | ä¸éœ€è¦å¤æ‚å»ºæ¨¡ |\n",
    "| ä¸­ | T-Learner | å¯ä»¥æ•æ‰éƒ¨åˆ†å¼‚è´¨æ€§ |\n",
    "| é«˜ (CATE å˜åŒ–å‰§çƒˆ) | R/DR-Learner + éçº¿æ€§æ¨¡å‹ | éœ€è¦çµæ´»æ€§ |\n",
    "\n",
    "### ç»„åˆç­–ç•¥ (Ensemble)\n",
    "\n",
    "ä¸ç¡®å®šç”¨å“ªä¸ªï¼Ÿå¯ä»¥ç»„åˆå¤šä¸ªï¼\n",
    "\n",
    "```python\n",
    "# ç®€å•å¹³å‡\n",
    "tau_ensemble = (tau_s + tau_t + tau_dr) / 3\n",
    "\n",
    "# åŠ æƒå¹³å‡ (ç”¨éªŒè¯é›†ç¡®å®šæƒé‡)\n",
    "tau_ensemble = w1 * tau_t + w2 * tau_dr\n",
    "\n",
    "# Stacking (ç”¨å¦ä¸€ä¸ªæ¨¡å‹å­¦ä¹ å¦‚ä½•ç»„åˆ)\n",
    "meta_model = RandomForestRegressor()\n",
    "meta_model.fit(\n",
    "    np.column_stack([tau_s, tau_t, tau_r, tau_dr]),\n",
    "    true_cate  # ä»…åœ¨æœ‰çœŸå®æ ‡ç­¾æ—¶\n",
    ")\n",
    "```\n",
    "\n",
    "### å¸¸è§è¯¯åŒº\n",
    "\n",
    "| è¯¯åŒº | æ­£ç¡®ç†è§£ |\n",
    "|------|----------|\n",
    "| \"DR-Learner æœ€å¥½ï¼Œåº”è¯¥æ€»æ˜¯ç”¨å®ƒ\" | DR-Learner å¤æ‚åº¦é«˜ï¼Œå°æ•°æ®å¯èƒ½è¿‡æ‹Ÿåˆ |\n",
    "| \"S-Learner å¤ªç®€å•ï¼Œä¸åº”è¯¥ç”¨\" | å°æ•°æ®æˆ–ä½å¼‚è´¨æ€§æ—¶ï¼ŒS-Learner å¯èƒ½æ›´å¥½ |\n",
    "| \"é€‰ä¸€ä¸ªæ–¹æ³•ä¸€åŠ³æ°¸é€¸\" | åº”è¯¥å¤šè¯•å‡ ä¸ªï¼Œç”¨éªŒè¯é›†é€‰æ‹© |\n",
    "| \"PEHE ä½å°±è¯´æ˜æ¨¡å‹å¥½\" | PEHE éœ€è¦çœŸå® CATEï¼Œå®é™…åº”ç”¨ä¸­æ²¡æœ‰ |\n",
    "\n",
    "### å®é™…åº”ç”¨ä¸­çš„éªŒè¯æ–¹æ³•\n",
    "\n",
    "å› ä¸ºå®é™…åº”ç”¨ä¸­æˆ‘ä»¬æ²¡æœ‰çœŸå®çš„ CATEï¼Œæ€ä¹ˆéªŒè¯ï¼Ÿ\n",
    "\n",
    "#### æ–¹æ³• 1: åˆ†ç»„ ATE ä¸€è‡´æ€§æ£€æŸ¥\n",
    "\n",
    "```python\n",
    "# æŒ‰é¢„æµ‹çš„ CATE åˆ†ç»„\n",
    "quartiles = pd.qcut(predicted_cate, q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "\n",
    "# æ¯ç»„è®¡ç®—å®é™… ATE\n",
    "for q in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "    mask = (quartiles == q)\n",
    "    ate = df[mask & (df['T']==1)]['Y'].mean() - df[mask & (df['T']==0)]['Y'].mean()\n",
    "    print(f\"{q}: Predicted CATE = {predicted_cate[mask].mean():.2f}, Actual ATE = {ate:.2f}\")\n",
    "    \n",
    "# æœŸæœ›: Q4 çš„ ATE > Q3 > Q2 > Q1 (å•è°ƒæ€§)\n",
    "```\n",
    "\n",
    "#### æ–¹æ³• 2: Qini æ›²çº¿ / Uplift æ›²çº¿\n",
    "\n",
    "è§ä¸‹ä¸€ä¸ªç»ƒä¹ : Uplift Evaluation\n",
    "\n",
    "#### æ–¹æ³• 3: ä¸šåŠ¡ A/B æµ‹è¯•éªŒè¯\n",
    "\n",
    "- åœ¨é¢„æµ‹ CATE é«˜çš„äººç¾¤ä¸Šåš A/B æµ‹è¯•\n",
    "- éªŒè¯æ•ˆåº”æ˜¯å¦ç¡®å®æ›´å¤§\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ¯ Meta-Learner é¢è¯•é«˜é¢‘é¢˜\n\n### Q1: S-Learner å’Œ T-Learner çš„æœ¬è´¨åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ\n\n**æ ‡å‡†ç­”æ¡ˆ**:\n\n**S-Learner**:\n- å•ä¸€æ¨¡å‹: $\\hat{\\mu}(x, t) = f(x, t)$\n- å°† T å½“ä½œæ™®é€šç‰¹å¾\n- é—®é¢˜: **æ­£åˆ™åŒ–åå·®** - å¤„ç†æ•ˆåº”å®¹æ˜“è¢«å‹ç¼©\n\n**T-Learner**:\n- ä¸¤ä¸ªç‹¬ç«‹æ¨¡å‹: $\\hat{\\mu}_0(x), \\hat{\\mu}_1(x)$\n- åˆ†åˆ«å»ºæ¨¡ä¸¤ç»„\n- é—®é¢˜: **é«˜æ–¹å·®** - $Var[\\hat{\\tau}] = Var[\\hat{\\mu}_1] + Var[\\hat{\\mu}_0]$\n\n**ä½•æ—¶é€‰æ‹©**:\n- S-Learner: æ•°æ®å°‘ã€æ•ˆåº”å°ã€ä¸¤ç»„ç›¸ä¼¼\n- T-Learner: æ•°æ®å¤šã€æ•ˆåº”å¤§ã€ä¸¤ç»„å·®å¼‚æ˜¾è‘—\n\n### Q2: X-Learner è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿ\n\n**æ ‡å‡†ç­”æ¡ˆ**:\n\nX-Learner ä¸»è¦è§£å†³ **æ ·æœ¬ä¸å¹³è¡¡** é—®é¢˜ (å¦‚ 90% vs 10%)ã€‚\n\n**æ ¸å¿ƒåˆ›æ–°**:\n1. è®¡ç®—ä¼ªæ•ˆåº” (imputed treatment effects)\n2. ç”¨å€¾å‘å¾—åˆ†åŠ æƒç»„åˆä¸¤ä¸ªä¼°è®¡\n\n**æ•°å­¦**:\n- å¤„ç†ç»„ä¼ªæ•ˆåº”: $D^1_i = Y_i - \\hat{\\mu}_0(X_i)$\n- æ§åˆ¶ç»„ä¼ªæ•ˆåº”: $D^0_j = \\hat{\\mu}_1(X_j) - Y_j$\n- æœ€ç»ˆä¼°è®¡: $\\hat{\\tau}(x) = e(x) \\cdot \\hat{\\tau}_0(x) + (1-e(x)) \\cdot \\hat{\\tau}_1(x)$\n\n**ç›´è§‰**: åœ¨æ ·æœ¬å¤šçš„ç»„ä¸Šï¼Œä¼°è®¡æ›´å¯é ï¼Œç»™äºˆæ›´é«˜æƒé‡ã€‚\n\n### Q3: R-Learner çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä»€ä¹ˆï¼Ÿ\n\n**æ ‡å‡†ç­”æ¡ˆ**:\n\nR-Learner çš„æ ¸å¿ƒæ˜¯ **åŒé‡å»å** (double residualization)ã€‚\n\n**Robinson åˆ†è§£**:\n$$Y = m(X) + (T - e(X)) \\cdot \\tau(X) + \\epsilon$$\n\n**ä¸¤æ­¥æ³•**:\n1. ä¼°è®¡å¹¶å»é™¤ä¸»æ•ˆåº”: $\\tilde{Y} = Y - \\hat{m}(X)$, $\\tilde{T} = T - \\hat{e}(X)$\n2. ç›´æ¥ä¼˜åŒ– CATE: $\\min_{\\tau} \\sum (\\tilde{Y}_i - \\tilde{T}_i \\cdot \\tau(X_i))^2$\n\n**ä¼˜åŠ¿**:\n- é¿å…æ­£åˆ™åŒ–åå·®\n- ç›´æ¥ä¼˜åŒ– CATE çš„ MSE\n- æœ‰ DML ç†è®ºä¿è¯ ($\\sqrt{n}$-ä¸€è‡´æ€§)\n\n### Q4: ä»€ä¹ˆæ˜¯ Honest Splittingï¼Ÿä¸ºä»€ä¹ˆå› æœæ£®æ—éœ€è¦å®ƒï¼Ÿ\n\n**æ ‡å‡†ç­”æ¡ˆ**:\n\n**Honest Splitting** æ˜¯å°†æ ·æœ¬åˆ†ä¸ºä¸¤éƒ¨åˆ†:\n- **åˆ†è£‚æ ·æœ¬** (50%): ç”¨äºæ„å»ºæ ‘ç»“æ„\n- **ä¼°è®¡æ ·æœ¬** (50%): ç”¨äºå¶èŠ‚ç‚¹çš„ CATE ä¼°è®¡\n\n**ä¸ºä»€ä¹ˆéœ€è¦**:\n1. **é¿å…è¿‡æ‹Ÿåˆ**: å¦‚æœç”¨åŒä¸€æ‰¹æ•°æ®æ—¢æ„å»ºæ ‘åˆä¼°è®¡ï¼Œä¼šè¿‡åº¦é€‚åº”æ•°æ®\n2. **ç»Ÿè®¡æ€§è´¨**: ä¿è¯æ¸è¿‘æ­£æ€æ€§ï¼Œä½¿ç½®ä¿¡åŒºé—´æœ‰æ•ˆ\n3. **æ— åä¼°è®¡**: åˆ†è£‚å’Œä¼°è®¡ç‹¬ç«‹ï¼Œæ¶ˆé™¤é€‰æ‹©åå·®\n\n**ç±»æ¯”**: å°±åƒå›æµ‹æŠ•èµ„ç­–ç•¥æ—¶ï¼Œä¸èƒ½ç”¨è®­ç»ƒæ•°æ®éªŒè¯æ•ˆæœã€‚\n\n### Q5: å¦‚ä½•è¯„ä¼° Uplift æ¨¡å‹ï¼ŸQini æ›²çº¿æ€ä¹ˆè§£è¯»ï¼Ÿ\n\n**æ ‡å‡†ç­”æ¡ˆ**:\n\n**Qini æ›²çº¿**:\n$$Qini(k) = Y_t(k) - Y_c(k) \\times \\frac{n_t(k)}{n_c(k)}$$\n\n**è§£è¯»**:\n- X è½´: å¹²é¢„æ¯”ä¾‹ (æŒ‰é¢„æµ‹ CATE ä»é«˜åˆ°ä½)\n- Y è½´: ç´¯ç§¯å¢é‡æ”¶ç›Š\n- æ›²çº¿è¶Šé«˜è¶Šå¥½\n\n**AUUC (Area Under Uplift Curve)**:\n- Qini æ›²çº¿ä¸‹çš„é¢ç§¯\n- ç±»ä¼¼ AUCï¼Œä½†é’ˆå¯¹ Uplift\n\n**å…¶ä»–è¯„ä¼°æ–¹æ³•**:\n1. **Uplift by Decile**: åˆ† 10 ç»„ï¼ŒéªŒè¯å•è°ƒæ€§\n2. **Top k% Uplift**: é«˜åˆ†ç»„çš„å®é™… uplift\n3. **A/B æµ‹è¯•éªŒè¯**: åœ¨é¢„æµ‹é«˜ CATE äººç¾¤ä¸Šå®éªŒ\n\n### Q6: DR-Learner çš„ã€ŒåŒé‡ç¨³å¥æ€§ã€æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ\n\n**æ ‡å‡†ç­”æ¡ˆ**:\n\n**åŒé‡ç¨³å¥æ€§** (Double Robustness): åªè¦ä»¥ä¸‹ä¹‹ä¸€æ­£ç¡®ï¼Œä¼°è®¡å°±æ˜¯ä¸€è‡´çš„:\n1. ç»“æœæ¨¡å‹æ­£ç¡®: $\\hat{\\mu}_0, \\hat{\\mu}_1$\n2. å€¾å‘å¾—åˆ†æ¨¡å‹æ­£ç¡®: $\\hat{e}(x)$\n\n**AIPW å…¬å¼**:\n$$\\tilde{\\tau}_i = \\frac{T_i(Y_i - \\hat{\\mu}_1(X_i))}{\\hat{e}(X_i)} - \\frac{(1-T_i)(Y_i - \\hat{\\mu}_0(X_i))}{1-\\hat{e}(X_i)} + \\hat{\\mu}_1(X_i) - \\hat{\\mu}_0(X_i)$$\n\n**ç›´è§‰**:\n- ç»“æœæ¨¡å‹æä¾›åŸºç¡€ä¼°è®¡\n- IPW ä¿®æ­£æä¾›åå·®æ ¡æ­£\n- ä¸¤è€…äº’è¡¥ï¼Œæä¾›\"åŒä¿é™©\"\n\n**å®è·µä»·å€¼**: å½“ä¸ç¡®å®šå“ªä¸ªæ¨¡å‹æ›´å¥½æ—¶ï¼ŒDR æ˜¯ç¨³å¥é€‰æ‹©ã€‚",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## æ›´æ–°åçš„æ€è€ƒé¢˜\n",
    "\n",
    "è¯·åœ¨ä¸‹é¢çš„ markdown å•å…ƒæ ¼ä¸­å†™ä¸‹ä½ çš„ç­”æ¡ˆï¼š\n",
    "\n",
    "### 1. R-Learner çš„ã€ŒåŒé‡å»åã€æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿä¸ºä»€ä¹ˆéœ€è¦å»åï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "\n",
    "### 2. DR-Learner çš„ã€ŒåŒé‡ç¨³å¥æ€§ã€æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿä¸ºä»€ä¹ˆè¯´å®ƒæ˜¯ã€ŒåŒä¿é™©ã€ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "\n",
    "### 3. å¦‚æœä½ æœ‰ 10000 ä¸ªæ ·æœ¬ï¼Œå¤„ç†ç»„å’Œæ§åˆ¶ç»„æ¯”ä¾‹æ˜¯ 50:50ï¼Œæ•ˆåº”å¤§å°æœªçŸ¥ï¼Œä½ ä¼šé€‰æ‹©å“ªä¸ª Meta-Learnerï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "\n",
    "### 4. R-Learner å’Œ T-Learner çš„ä¸»è¦åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "\n",
    "### 5. åœ¨å®é™…åº”ç”¨ä¸­ï¼ˆæ²¡æœ‰çœŸå® CATEï¼‰ï¼Œä½ å¦‚ä½•éªŒè¯ Meta-Learner çš„é¢„æµ‹è´¨é‡ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "\n",
    "### 6. (è¿›é˜¶) DR-Learner ä¸­çš„ä¼ªç»“æœ (Pseudo-Outcome) ä¸ºä»€ä¹ˆæ˜¯æ— åçš„ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}