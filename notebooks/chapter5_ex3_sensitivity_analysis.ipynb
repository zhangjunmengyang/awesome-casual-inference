{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ” Chapter 5 ç»ƒä¹  3: æ•æ„Ÿæ€§åˆ†æ - å› æœç»“è®ºçš„ã€Œå‹åŠ›æµ‹è¯•ã€\n",
    "\n",
    "## æ— æ··æ·†å‡è®¾èƒ½éªŒè¯å—ï¼Ÿ\n",
    "\n",
    "åœ¨å› æœæ¨æ–­ä¸­ï¼Œæœ‰ä¸€ä¸ªä»¤äººä¸å®‰çš„äº‹å®ï¼š\n",
    "\n",
    "> **æ— æ··æ·†å‡è®¾ (Unconfoundedness) æ— æ³•ä»æ•°æ®ä¸­éªŒè¯**\n",
    "\n",
    "æˆ‘ä»¬æ°¸è¿œä¸çŸ¥é“æ˜¯å¦é—æ¼äº†æŸä¸ªé‡è¦çš„æ··æ·†å› å­ï¼è¿™å°±åƒä½ æ°¸è¿œæ— æ³•è¯æ˜ã€Œæˆ¿é—´é‡Œæ²¡æœ‰éšå½¢çš„å¤§è±¡ã€ã€‚\n",
    "\n",
    "é‚£æ€ä¹ˆåŠå‘¢ï¼Ÿ**æ•æ„Ÿæ€§åˆ†æ (Sensitivity Analysis)** æ¥å¸®å¿™ï¼\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "1. ç†è§£æœªè§‚æµ‹æ··æ·†çš„å½±å“\n",
    "2. å®ç° Rosenbaum æ•æ„Ÿæ€§è¾¹ç•Œ\n",
    "3. è®¡ç®— E-value\n",
    "4. è¿›è¡Œ Placebo ç¨³å¥æ€§æ£€éªŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒŸ æ•æ„Ÿæ€§åˆ†æçš„ç›´è§‰\n",
    "\n",
    "### ç±»æ¯”ï¼šè¯ç‰©è¯•éªŒçš„ã€Œé­”é¬¼ä»£è¨€äººã€\n",
    "\n",
    "æƒ³è±¡ä½ æ˜¯ FDA çš„å®¡æŸ¥å‘˜ï¼Œåˆ¶è¯å…¬å¸å£°ç§°ä»–ä»¬çš„æ–°è¯æœ‰æ•ˆï¼š\n",
    "\n",
    "- **ä»–ä»¬è¯´**: ã€Œåƒè¯åï¼Œæ‚£è€…æ¢å¤ç‡é«˜äº† 20%ï¼ã€\n",
    "- **ä½ é—®**: ã€Œä¼šä¸ä¼šæ˜¯å› ä¸ºé€‰æ‹©åƒè¯çš„äººæœ¬æ¥å°±æ›´å¥åº·ï¼Ÿã€\n",
    "- **ä»–ä»¬è¯´**: ã€Œæˆ‘ä»¬å·²ç»æ§åˆ¶äº†æ‰€æœ‰è§‚æµ‹åˆ°çš„å› ç´ ï¼ã€\n",
    "- **ä½ é—®**: ã€Œä½†å¦‚æœæœ‰ä½ ä»¬æ²¡æµ‹é‡çš„å› ç´ å‘¢ï¼Ÿæ¯”å¦‚æ‚£è€…çš„ä¹è§‚ç¨‹åº¦ï¼Ÿã€\n",
    "\n",
    "æ•æ„Ÿæ€§åˆ†æå°±æ˜¯ç³»ç»Ÿåœ°é—®è¿™ä¸ªé—®é¢˜ï¼š\n",
    "\n",
    "> **ã€Œéœ€è¦å¤šå¼ºçš„æœªè§‚æµ‹æ··æ·†ï¼Œæ‰èƒ½æ¨ç¿»æˆ‘ä»¬çš„ç»“è®ºï¼Ÿã€**\n",
    "\n",
    "### ä¸¤ç§æ–¹æ³•\n",
    "\n",
    "1. **Rosenbaum æ•æ„Ÿæ€§è¾¹ç•Œ**: å‡è®¾å­˜åœ¨æœªè§‚æµ‹æ··æ·†ï¼Œçœ‹ç»“è®ºä½•æ—¶å˜å¾—ä¸æ˜¾è‘—\n",
    "2. **E-value**: è®¡ç®—èƒ½è§£é‡Šè§‚æµ‹å…³è”çš„æœ€å°æ··æ·†å¼ºåº¦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ æ ¸å¿ƒå…¬å¼\n",
    "\n",
    "### Rosenbaum æ•æ„Ÿæ€§å‚æ•° Î“\n",
    "\n",
    "å¯¹äºä¸¤ä¸ªåå˜é‡ç›¸åŒçš„ä¸ªä½“ i å’Œ jï¼š\n",
    "\n",
    "$$\\frac{1}{\\Gamma} \\leq \\frac{P(T_i=1|X)}{P(T_j=1|X)} \\leq \\Gamma$$\n",
    "\n",
    "- **Î“ = 1**: æ— æœªè§‚æµ‹æ··æ·†ï¼ˆå®Œç¾çš„éšæœºåŒ–ï¼‰\n",
    "- **Î“ = 2**: å€¾å‘å¾—åˆ†æœ€å¤šç›¸å·® 2 å€\n",
    "- **Î“ = 3**: å€¾å‘å¾—åˆ†æœ€å¤šç›¸å·® 3 å€\n",
    "\n",
    "### E-value å…¬å¼\n",
    "\n",
    "$$E = RR + \\sqrt{RR \\times (RR - 1)}$$\n",
    "\n",
    "å…¶ä¸­ RR æ˜¯é£é™©æ¯” (Risk Ratio)ã€‚\n",
    "\n",
    "E-value è¡¨ç¤ºï¼š**ä½¿è§‚æµ‹å…³è”å®Œå…¨è¢«æ··æ·†è§£é‡Šæ‰€éœ€çš„æœ€å°é£é™©æ¯”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯å¢ƒè®¾ç½®\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Dict\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "np.random.seed(42)\n",
    "\n",
    "# ç»˜å›¾è®¾ç½®\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"ç¯å¢ƒé…ç½®å®Œæˆ! ğŸ”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  3.1: æ¨¡æ‹Ÿæœªè§‚æµ‹æ··æ·†\n",
    "\n",
    "é¦–å…ˆï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæœ‰**æœªè§‚æµ‹æ··æ·†**çš„æ•°æ®é›†ï¼Œçœ‹çœ‹å®ƒå¦‚ä½•å½±å“å› æœä¼°è®¡ï¼\n",
    "\n",
    "### åœºæ™¯\n",
    "\n",
    "ç ”ç©¶ã€Œå‚åŠ åŸ¹è®­ã€å¯¹ã€Œè–ªèµ„ã€çš„å½±å“ï¼š\n",
    "- **X**: è§‚æµ‹åˆ°çš„èƒ½åŠ›æŒ‡æ ‡\n",
    "- **U**: æœªè§‚æµ‹çš„ã€ŒåŠ¨æœºã€å› ç´ ï¼ˆæˆ‘ä»¬å‡è£…çœ‹ä¸åˆ°ï¼‰\n",
    "- **T**: æ˜¯å¦å‚åŠ åŸ¹è®­ï¼ˆå— X å’Œ U å½±å“ï¼‰\n",
    "- **Y**: è–ªèµ„ï¼ˆå— Tã€Xã€U å½±å“ï¼‰\n",
    "\n",
    "é—®é¢˜ï¼šé«˜åŠ¨æœºçš„äººæ—¢æ›´å¯èƒ½å‚åŠ åŸ¹è®­ï¼Œä¹Ÿæ›´å¯èƒ½æœ‰é«˜è–ªèµ„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_unobserved_confounding(\n",
    "    n: int = 1000,\n",
    "    confounder_strength: float = 0.5,\n",
    "    seed: int = 42\n",
    ") -> Tuple[pd.DataFrame, np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    æ¨¡æ‹ŸåŒ…å«æœªè§‚æµ‹æ··æ·†çš„æ•°æ®\n",
    "    \n",
    "    æ•°æ®ç”Ÿæˆè¿‡ç¨‹:\n",
    "    - X ~ N(0, 1)  # è§‚æµ‹åå˜é‡ï¼ˆèƒ½åŠ›ï¼‰\n",
    "    - U ~ N(0, 1)  # æœªè§‚æµ‹æ··æ·†å› å­ï¼ˆåŠ¨æœºï¼‰\n",
    "    - P(T=1|X,U) = sigmoid(0.5*X + strength*U)\n",
    "    - Y = 10 + 2*T + 1.5*X + strength*2*U + noise\n",
    "    \n",
    "    çœŸå® ATE = 2.0\n",
    "    \n",
    "    Returns:\n",
    "        (df, U, params)\n",
    "        df: åŒ…å« X, T, Y çš„ DataFrame (ä¸åŒ…å« U!)\n",
    "        U: æœªè§‚æµ‹æ··æ·†å› å­\n",
    "        params: çœŸå®å‚æ•°\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆè§‚æµ‹åå˜é‡ X (èƒ½åŠ›)\n",
    "    X = None  # ä½ çš„ä»£ç : np.random.randn(n)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆæœªè§‚æµ‹æ··æ·†å› å­ U (åŠ¨æœº)\n",
    "    U = None  # ä½ çš„ä»£ç : np.random.randn(n)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆå¤„ç† T (å‚åŠ åŸ¹è®­)\n",
    "    # é«˜èƒ½åŠ›å’Œé«˜åŠ¨æœºçš„äººæ›´å¯èƒ½å‚åŠ åŸ¹è®­\n",
    "    # propensity_logit = 0.5*X + confounder_strength*U\n",
    "    # propensity = sigmoid(propensity_logit) = 1 / (1 + exp(-logit))\n",
    "    propensity_logit = None  # ä½ çš„ä»£ç \n",
    "    propensity = None  # ä½ çš„ä»£ç \n",
    "    T = None  # ä½ çš„ä»£ç : np.random.binomial(1, propensity)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆç»“æœ Y (è–ªèµ„)\n",
    "    # Y = 10 + 2*T + 1.5*X + confounder_strength*2*U + noise\n",
    "    # è§£è¯»: åŸ¹è®­çœŸæ­£å¢åŠ è–ªèµ„ 2ï¼Œèƒ½åŠ›å½±å“ 1.5ï¼ŒåŠ¨æœºå½±å“ confounder_strength*2\n",
    "    noise = np.random.randn(n) * 0.5\n",
    "    Y = None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    # åˆ›å»º DataFrame (å‡è£…æˆ‘ä»¬çœ‹ä¸åˆ° U!)\n",
    "    df = pd.DataFrame({\n",
    "        'X': X,\n",
    "        'T': T,\n",
    "        'Y': Y\n",
    "    })\n",
    "    \n",
    "    params = {\n",
    "        'true_ate': 2.0,\n",
    "        'confounder_strength': confounder_strength\n",
    "    }\n",
    "    \n",
    "    return df, U, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—ä¸åŒçš„ ATE ä¼°è®¡\n",
    "def compute_naive_ate(df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    æœ´ç´  ATE ä¼°è®¡: E[Y|T=1] - E[Y|T=0]\n",
    "    (å¿½ç•¥æ‰€æœ‰æ··æ·†)\n",
    "    \"\"\"\n",
    "    # TODO: è®¡ç®—æœ´ç´ ä¼°è®¡\n",
    "    # ä½ çš„ä»£ç \n",
    "    pass\n",
    "\n",
    "\n",
    "def compute_adjusted_ate(df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    è°ƒæ•´ X åçš„ ATE ä¼°è®¡\n",
    "    ä½¿ç”¨çº¿æ€§å›å½’: Y ~ T + X\n",
    "    \"\"\"\n",
    "    # TODO: ä½¿ç”¨å›å½’ä¼°è®¡ ATE\n",
    "    # 1. æ„å»ºç‰¹å¾çŸ©é˜µ [[T1, X1], [T2, X2], ...]\n",
    "    # 2. æ‹Ÿåˆçº¿æ€§å›å½’\n",
    "    # 3. è¿”å› T çš„ç³»æ•°\n",
    "    \n",
    "    # ä½ çš„ä»£ç \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•ä¸åŒæ··æ·†å¼ºåº¦\n",
    "print(\"=== æœªè§‚æµ‹æ··æ·†çš„å½±å“ ===\")\n",
    "print(f\"çœŸå® ATE = 2.0\\n\")\n",
    "\n",
    "strengths = [0.0, 0.3, 0.6, 1.0]\n",
    "results = []\n",
    "\n",
    "for strength in strengths:\n",
    "    df, U, params = simulate_unobserved_confounding(\n",
    "        n=2000,\n",
    "        confounder_strength=strength\n",
    "    )\n",
    "    \n",
    "    if df is not None and df['X'].iloc[0] is not None:\n",
    "        naive_ate = compute_naive_ate(df)\n",
    "        adjusted_ate = compute_adjusted_ate(df)\n",
    "        \n",
    "        if naive_ate is not None and adjusted_ate is not None:\n",
    "            results.append({\n",
    "                'Strength': strength,\n",
    "                'Naive ATE': naive_ate,\n",
    "                'Naive Bias': naive_ate - 2.0,\n",
    "                'Adjusted ATE': adjusted_ate,\n",
    "                'Adjusted Bias': adjusted_ate - 2.0\n",
    "            })\n",
    "\n",
    "if len(results) > 0:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    display(results_df.round(4))\n",
    "    \n",
    "    print(\"\\nè§£è¯»:\")\n",
    "    print(\"- æ··æ·†å¼ºåº¦ = 0: æ— æ··æ·†ï¼Œä¸¤ç§ä¼°è®¡éƒ½æ¥è¿‘çœŸå®å€¼\")\n",
    "    print(\"- æ··æ·†å¼ºåº¦å¢åŠ : æœ´ç´ ä¼°è®¡åå·®å¢å¤§ï¼ˆé«˜ä¼°æ•ˆåº”ï¼‰\")\n",
    "    print(\"- è°ƒæ•´ X å: ä»æœ‰åå·®ï¼Œå› ä¸º U æœªè¢«æ§åˆ¶ï¼\")\n",
    "else:\n",
    "    print(\"[TODO] è¯·å®Œæˆæ•°æ®ç”Ÿæˆå’Œä¼°è®¡å‡½æ•°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–æ··æ·†çš„å½±å“\n",
    "if len(results) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # ä¼°è®¡å€¼ vs æ··æ·†å¼ºåº¦\n",
    "    axes[0].plot(results_df['Strength'], results_df['Naive ATE'], \n",
    "                'bo-', label='æœ´ç´ ä¼°è®¡', linewidth=2, markersize=8)\n",
    "    axes[0].plot(results_df['Strength'], results_df['Adjusted ATE'], \n",
    "                'gs-', label='è°ƒæ•´ X å', linewidth=2, markersize=8)\n",
    "    axes[0].axhline(y=2.0, color='red', linestyle='--', label='çœŸå® ATE')\n",
    "    axes[0].set_xlabel('æœªè§‚æµ‹æ··æ·†å¼ºåº¦')\n",
    "    axes[0].set_ylabel('ATE ä¼°è®¡')\n",
    "    axes[0].set_title('ä¼°è®¡å€¼éšæ··æ·†å¼ºåº¦å˜åŒ–')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # åå·® vs æ··æ·†å¼ºåº¦\n",
    "    axes[1].bar(np.arange(len(strengths)) - 0.2, results_df['Naive Bias'], \n",
    "               0.35, label='æœ´ç´ ä¼°è®¡åå·®', color='#3498db')\n",
    "    axes[1].bar(np.arange(len(strengths)) + 0.2, results_df['Adjusted Bias'], \n",
    "               0.35, label='è°ƒæ•´ååå·®', color='#2ecc71')\n",
    "    axes[1].axhline(y=0, color='red', linestyle='--')\n",
    "    axes[1].set_xticks(np.arange(len(strengths)))\n",
    "    axes[1].set_xticklabels([f'{s:.1f}' for s in strengths])\n",
    "    axes[1].set_xlabel('æœªè§‚æµ‹æ··æ·†å¼ºåº¦')\n",
    "    axes[1].set_ylabel('åå·® (ä¼°è®¡ - çœŸå®)')\n",
    "    axes[1].set_title('åå·®éšæ··æ·†å¼ºåº¦å˜åŒ–')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  3.2: Rosenbaum æ•æ„Ÿæ€§è¾¹ç•Œ\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬å®ç° Rosenbaum æ•æ„Ÿæ€§åˆ†æï¼\n",
    "\n",
    "æ ¸å¿ƒé—®é¢˜ï¼š**å¦‚æœå­˜åœ¨æœªè§‚æµ‹æ··æ·†ï¼Œæˆ‘ä»¬çš„ç»“è®ºä¼šæœ‰å¤šè„†å¼±ï¼Ÿ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rosenbaum_bounds(\n",
    "    Y: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    gamma: float\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    è®¡ç®— Rosenbaum æ•æ„Ÿæ€§è¾¹ç•Œ\n",
    "    \n",
    "    Î“ å‚æ•°çš„å«ä¹‰:\n",
    "    - Î“ = 1: å‡è®¾æ— æœªè§‚æµ‹æ··æ·†\n",
    "    - Î“ > 1: å…è®¸å€¾å‘å¾—åˆ†æœ€å¤šç›¸å·® Î“ å€\n",
    "    \n",
    "    Args:\n",
    "        Y: ç»“æœå˜é‡\n",
    "        T: å¤„ç†å˜é‡\n",
    "        gamma: æ•æ„Ÿæ€§å‚æ•°\n",
    "    \n",
    "    Returns:\n",
    "        (lower_bound, upper_bound)\n",
    "    \"\"\"\n",
    "    # è§‚æµ‹çš„ ATE\n",
    "    ate_obs = Y[T == 1].mean() - Y[T == 0].mean()\n",
    "    \n",
    "    if gamma == 1.0:\n",
    "        # æ— æ··æ·†å‡è®¾ä¸‹ï¼Œè¾¹ç•Œå°±æ˜¯ç‚¹ä¼°è®¡\n",
    "        return ate_obs, ate_obs\n",
    "    \n",
    "    # TODO: è®¡ç®—æ•æ„Ÿæ€§è¾¹ç•Œ\n",
    "    # ç®€åŒ–ç‰ˆæœ¬: è¾¹ç•Œå®½åº¦ä¸ gamma å’Œæ ‡å‡†è¯¯ç›¸å…³\n",
    "    \n",
    "    # 1. è®¡ç®— ATE çš„æ ‡å‡†è¯¯å·®\n",
    "    n1 = (T == 1).sum()\n",
    "    n0 = (T == 0).sum()\n",
    "    var1 = Y[T == 1].var()\n",
    "    var0 = Y[T == 0].var()\n",
    "    \n",
    "    se = None  # ä½ çš„ä»£ç : np.sqrt(var1/n1 + var0/n0)\n",
    "    \n",
    "    # 2. è¾¹ç•Œå®½åº¦éš gamma å¢åŠ \n",
    "    # ç®€åŒ–å…¬å¼: bound_width = se * log(gamma) * 2\n",
    "    bound_width = None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    # 3. è®¡ç®—ä¸Šä¸‹ç•Œ\n",
    "    lower_bound = None  # ä½ çš„ä»£ç : ate_obs - bound_width\n",
    "    upper_bound = None  # ä½ çš„ä»£ç : ate_obs + bound_width\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_curve(\n",
    "    Y: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    gamma_range: np.ndarray,\n",
    "    true_ate: float = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    è®¡ç®—æ•æ„Ÿæ€§æ›²çº¿\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for gamma in gamma_range:\n",
    "        lower, upper = compute_rosenbaum_bounds(Y, T, gamma)\n",
    "        \n",
    "        row = {\n",
    "            'gamma': gamma,\n",
    "            'lower': lower,\n",
    "            'upper': upper\n",
    "        }\n",
    "        \n",
    "        if true_ate is not None:\n",
    "            row['true_ate'] = true_ate\n",
    "        \n",
    "        results.append(row)\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆæœ‰æ··æ·†çš„æ•°æ®\n",
    "df, U, params = simulate_unobserved_confounding(\n",
    "    n=2000,\n",
    "    confounder_strength=0.6\n",
    ")\n",
    "\n",
    "if df is not None and df['Y'].iloc[0] is not None:\n",
    "    # è®¡ç®—æ•æ„Ÿæ€§æ›²çº¿\n",
    "    gamma_range = np.linspace(1.0, 5.0, 30)\n",
    "    \n",
    "    try:\n",
    "        sens_df = sensitivity_curve(\n",
    "            df['Y'].values,\n",
    "            df['T'].values,\n",
    "            gamma_range,\n",
    "            true_ate=params['true_ate']\n",
    "        )\n",
    "        \n",
    "        if sens_df is not None and sens_df['lower'].iloc[0] is not None:\n",
    "            print(\"æ•æ„Ÿæ€§åˆ†æç»“æœ:\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"\\nè§‚æµ‹ ATE: {df['Y'][df['T']==1].mean() - df['Y'][df['T']==0].mean():.4f}\")\n",
    "            print(f\"çœŸå® ATE: {params['true_ate']:.4f}\")\n",
    "            \n",
    "            print(\"\\néƒ¨åˆ†ç»“æœ:\")\n",
    "            display(sens_df.iloc[::5].round(4))  # æ¯5è¡Œæ˜¾ç¤ºä¸€æ¬¡\n",
    "            \n",
    "            # æ‰¾åˆ°åŒ…å« 0 çš„æœ€å° gamma\n",
    "            includes_zero = (sens_df['lower'] <= 0) & (sens_df['upper'] >= 0)\n",
    "            if includes_zero.any():\n",
    "                gamma_threshold = sens_df.loc[includes_zero, 'gamma'].min()\n",
    "                print(f\"\\næ•æ„Ÿæ€§é˜ˆå€¼: Î“ = {gamma_threshold:.2f}\")\n",
    "                print(f\"è§£è¯»: å¦‚æœæœªè§‚æµ‹æ··æ·†ä½¿å€¾å‘å¾—åˆ†ç›¸å·® {gamma_threshold:.1f} å€ï¼Œ\")\n",
    "                print(f\"      æ•ˆåº”å¯èƒ½å˜ä¸ºé›¶ï¼ˆä¸æ˜¾è‘—ï¼‰\")\n",
    "            else:\n",
    "                print(f\"\\nåœ¨ Î“ â‰¤ {gamma_range.max():.1f} èŒƒå›´å†…ï¼Œæ•ˆåº”å§‹ç»ˆæ˜¾è‘—\")\n",
    "                print(\"ç»“è®ºç›¸å¯¹ç¨³å¥ï¼\")\n",
    "        else:\n",
    "            print(\"[TODO] è¯·å®Œæˆ compute_rosenbaum_bounds å‡½æ•°\")\n",
    "    except Exception as e:\n",
    "        print(f\"[é”™è¯¯] {e}\")\n",
    "else:\n",
    "    print(\"[TODO] è¯·å®Œæˆæ•°æ®ç”Ÿæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–æ•æ„Ÿæ€§åˆ†æ\n",
    "if 'sens_df' in dir() and sens_df is not None and sens_df['lower'].iloc[0] is not None:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # ç»˜åˆ¶è¾¹ç•Œ\n",
    "    ax.fill_between(\n",
    "        sens_df['gamma'], \n",
    "        sens_df['lower'], \n",
    "        sens_df['upper'],\n",
    "        alpha=0.3, color='#3498db', label='æ•æ„Ÿæ€§åŒºé—´'\n",
    "    )\n",
    "    ax.plot(sens_df['gamma'], sens_df['lower'], 'b-', linewidth=2, label='ä¸‹ç•Œ')\n",
    "    ax.plot(sens_df['gamma'], sens_df['upper'], 'b-', linewidth=2, label='ä¸Šç•Œ')\n",
    "    \n",
    "    # çœŸå® ATE\n",
    "    ax.axhline(y=params['true_ate'], color='green', linestyle='--', \n",
    "              linewidth=2, label=f'çœŸå® ATE = {params[\"true_ate\"]}')\n",
    "    \n",
    "    # é›¶çº¿\n",
    "    ax.axhline(y=0, color='red', linestyle='-', linewidth=1, label='é›¶æ•ˆåº”')\n",
    "    \n",
    "    # æ‰¾åˆ°äº¤å‰ç‚¹\n",
    "    includes_zero = (sens_df['lower'] <= 0) & (sens_df['upper'] >= 0)\n",
    "    if includes_zero.any():\n",
    "        gamma_threshold = sens_df.loc[includes_zero, 'gamma'].min()\n",
    "        ax.axvline(x=gamma_threshold, color='orange', linestyle=':', \n",
    "                  linewidth=2, label=f'æ•æ„Ÿæ€§é˜ˆå€¼ Î“={gamma_threshold:.2f}')\n",
    "    \n",
    "    ax.set_xlabel('Î“ (æ•æ„Ÿæ€§å‚æ•°)', fontsize=12)\n",
    "    ax.set_ylabel('ATE ä¼°è®¡', fontsize=12)\n",
    "    ax.set_title('Rosenbaum æ•æ„Ÿæ€§åˆ†æ\\n\"ç»“è®ºå¯¹æœªè§‚æµ‹æ··æ·†æœ‰å¤šè„†å¼±?\"', fontsize=14)\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nè§£è¯»æŒ‡å—:\")\n",
    "    print(\"- Î“ = 1: å‡è®¾æ— æœªè§‚æµ‹æ··æ·†\")\n",
    "    print(\"- éšç€ Î“ å¢åŠ ï¼Œå…è®¸æ›´å¼ºçš„æœªè§‚æµ‹æ··æ·†\")\n",
    "    print(\"- å½“åŒºé—´åŒ…å« 0 æ—¶ï¼Œç»“è®ºå˜å¾—ä¸ç¡®å®š\")\n",
    "    print(\"- æ•æ„Ÿæ€§é˜ˆå€¼è¶Šé«˜ï¼Œç»“è®ºè¶Šç¨³å¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  3.3: E-value\n",
    "\n",
    "E-value æ˜¯å¦ä¸€ç§æµè¡Œçš„æ•æ„Ÿæ€§åº¦é‡ï¼Œç”± VanderWeele & Ding (2017) æå‡ºã€‚\n",
    "\n",
    "**æ ¸å¿ƒé—®é¢˜**: éœ€è¦å¤šå¼ºçš„æœªè§‚æµ‹æ··æ·†ï¼Œæ‰èƒ½å®Œå…¨è§£é‡Šè§‚æµ‹åˆ°çš„å…³è”ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ate_to_risk_ratio(ate: float, baseline_mean: float) -> float:\n",
    "    \"\"\"\n",
    "    å°† ATE è½¬æ¢ä¸ºé£é™©æ¯” (Risk Ratio)\n",
    "    \n",
    "    RR = (baseline + ATE) / baseline\n",
    "    \n",
    "    TODO: è®¡ç®—é£é™©æ¯”\n",
    "    \"\"\"\n",
    "    # ä½ çš„ä»£ç \n",
    "    pass\n",
    "\n",
    "\n",
    "def compute_e_value(observed_rr: float, ci_lower: float = None) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    è®¡ç®— E-value\n",
    "    \n",
    "    E-value: ä½¿è§‚æµ‹å…³è”å®Œå…¨è¢«æ··æ·†è§£é‡Šæ‰€éœ€çš„æœ€å°é£é™©æ¯”\n",
    "    \n",
    "    å…¬å¼: E = RR + sqrt(RR * (RR - 1))  [å½“ RR >= 1]\n",
    "          E = 1/RR + sqrt(1/RR * (1/RR - 1))  [å½“ RR < 1]\n",
    "    \n",
    "    Args:\n",
    "        observed_rr: è§‚æµ‹åˆ°çš„é£é™©æ¯”\n",
    "        ci_lower: ç½®ä¿¡åŒºé—´ä¸‹ç•Œ (å¯é€‰)\n",
    "    \n",
    "    Returns:\n",
    "        {'e_value': ..., 'e_value_ci': ...}\n",
    "    \"\"\"\n",
    "    # ç¡®ä¿ RR >= 1 (å¦‚æœ < 1ï¼Œå–å€’æ•°)\n",
    "    if observed_rr < 1:\n",
    "        observed_rr = 1 / observed_rr\n",
    "    \n",
    "    # TODO: è®¡ç®— E-value\n",
    "    # E = RR + sqrt(RR * (RR - 1))\n",
    "    e_value = None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    result = {'e_value': e_value}\n",
    "    \n",
    "    # å¦‚æœæœ‰ç½®ä¿¡åŒºé—´ä¸‹ç•Œï¼Œä¹Ÿè®¡ç®—å…¶ E-value\n",
    "    if ci_lower is not None and ci_lower > 1:\n",
    "        e_value_ci = ci_lower + np.sqrt(ci_lower * (ci_lower - 1))\n",
    "        result['e_value_ci'] = e_value_ci\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯• E-value\n",
    "if df is not None and df['Y'].iloc[0] is not None:\n",
    "    try:\n",
    "        # è®¡ç®—è§‚æµ‹ ATE\n",
    "        naive_ate = df['Y'][df['T']==1].mean() - df['Y'][df['T']==0].mean()\n",
    "        baseline_mean = df.loc[df['T'] == 0, 'Y'].mean()\n",
    "        \n",
    "        # è½¬æ¢ä¸ºé£é™©æ¯”\n",
    "        rr = ate_to_risk_ratio(naive_ate, baseline_mean)\n",
    "        \n",
    "        if rr is not None:\n",
    "            # è®¡ç®— E-value\n",
    "            e_values = compute_e_value(rr)\n",
    "            \n",
    "            if e_values['e_value'] is not None:\n",
    "                print(\"E-value åˆ†æ:\")\n",
    "                print(\"=\"*50)\n",
    "                print(f\"\\nè§‚æµ‹ ATE: {naive_ate:.4f}\")\n",
    "                print(f\"åŸºçº¿å‡å€¼: {baseline_mean:.4f}\")\n",
    "                print(f\"é£é™©æ¯” (RR): {rr:.4f}\")\n",
    "                print(f\"\\nE-value: {e_values['e_value']:.4f}\")\n",
    "                \n",
    "                print(f\"\\nè§£è¯»:\")\n",
    "                print(f\"  éœ€è¦ä¸€ä¸ªä¸å¤„ç†å’Œç»“æœéƒ½æœ‰ RR â‰¥ {e_values['e_value']:.2f} å…³è”çš„\")\n",
    "                print(f\"  æœªè§‚æµ‹æ··æ·†å› å­ï¼Œæ‰èƒ½å®Œå…¨è§£é‡Šè§‚æµ‹åˆ°çš„æ•ˆåº”\")\n",
    "                \n",
    "                if e_values['e_value'] > 3:\n",
    "                    print(f\"\\n  è¯„ä»·: E-value è¾ƒé«˜ï¼Œç»“è®ºç›¸å¯¹ç¨³å¥\")\n",
    "                else:\n",
    "                    print(f\"\\n  è¯„ä»·: E-value è¾ƒä½ï¼Œç»“è®ºå¯èƒ½å¯¹æ··æ·†æ•æ„Ÿ\")\n",
    "            else:\n",
    "                print(\"[TODO] è¯·å®Œæˆ compute_e_value å‡½æ•°\")\n",
    "        else:\n",
    "            print(\"[TODO] è¯·å®Œæˆ ate_to_risk_ratio å‡½æ•°\")\n",
    "    except Exception as e:\n",
    "        print(f\"[é”™è¯¯] {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  3.4: Placebo ç¨³å¥æ€§æ£€éªŒ\n",
    "\n",
    "Placebo æµ‹è¯•æ˜¯ä¸€ç§ç®€å•ä½†å¼ºå¤§çš„ç¨³å¥æ€§æ£€éªŒï¼š\n",
    "\n",
    "**æ€è·¯**: å¦‚æœæˆ‘ä»¬çš„å› æœä¼°è®¡æ–¹æ³•æ˜¯æ­£ç¡®çš„ï¼Œé‚£ä¹ˆå¯¹äºã€Œä¸åº”å—å¤„ç†å½±å“çš„å˜é‡ã€ï¼Œæˆ‘ä»¬ä¸åº”è¯¥æ£€æµ‹åˆ°æ˜¾è‘—æ•ˆåº”ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼š\n",
    "- ç ”ç©¶ã€ŒåŸ¹è®­ã€å¯¹ã€Œè–ªèµ„ã€çš„å½±å“\n",
    "- Placebo å˜é‡ï¼šå‚åŠ åŸ¹è®­å‰çš„èº«é«˜ï¼ˆæ˜¾ç„¶åŸ¹è®­ä¸åº”è¯¥æ”¹å˜èº«é«˜ï¼‰\n",
    "- å¦‚æœæˆ‘ä»¬åœ¨èº«é«˜ä¸Šä¹Ÿå‘ç°äº†ã€Œæ•ˆåº”ã€ï¼Œè¯´æ˜å¯èƒ½æœ‰é—®é¢˜ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def placebo_test(\n",
    "    df: pd.DataFrame,\n",
    "    outcome_col: str = 'Y',\n",
    "    placebo_outcome_col: str = 'Y_placebo'\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Placebo æµ‹è¯•\n",
    "    \n",
    "    ä½¿ç”¨ä¸åº”å—å¤„ç†å½±å“çš„\"å‡\"ç»“æœå˜é‡è¿›è¡Œæµ‹è¯•\n",
    "    \n",
    "    Args:\n",
    "        df: åŒ…å« T, Y, Y_placebo çš„ DataFrame\n",
    "        outcome_col: çœŸå®ç»“æœåˆ—å\n",
    "        placebo_outcome_col: å‡ç»“æœåˆ—å\n",
    "    \n",
    "    Returns:\n",
    "        {'true_effect': ..., 'placebo_effect': ..., 'p_value_placebo': ...}\n",
    "    \"\"\"\n",
    "    T = df['T'].values\n",
    "    \n",
    "    # TODO: è®¡ç®—çœŸå®ç»“æœçš„æ•ˆåº”\n",
    "    Y = df[outcome_col].values\n",
    "    true_effect = None  # ä½ çš„ä»£ç : Y[T==1].mean() - Y[T==0].mean()\n",
    "    \n",
    "    # TODO: è®¡ç®—å‡ç»“æœçš„æ•ˆåº”\n",
    "    Y_placebo = df[placebo_outcome_col].values\n",
    "    placebo_effect = None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    # TODO: t æ£€éªŒæµ‹è¯•å‡ç»“æœæ•ˆåº”æ˜¯å¦æ˜¾è‘—\n",
    "    # ä½¿ç”¨ scipy.stats.ttest_ind\n",
    "    t_stat, p_value = None, None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    return {\n",
    "        'true_effect': true_effect,\n",
    "        'placebo_effect': placebo_effect,\n",
    "        'p_value_placebo': p_value\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯• Placebo æ£€éªŒ\n",
    "if df is not None and df['Y'].iloc[0] is not None:\n",
    "    # ç”Ÿæˆå‡ç»“æœå˜é‡ï¼ˆä¸åº”å— T å½±å“ï¼Œåªä¸ X ç›¸å…³ï¼‰\n",
    "    np.random.seed(123)\n",
    "    df['Y_placebo'] = df['X'] * 2 + np.random.randn(len(df)) * 0.5\n",
    "    \n",
    "    try:\n",
    "        placebo_results = placebo_test(df, 'Y', 'Y_placebo')\n",
    "        \n",
    "        if placebo_results['true_effect'] is not None:\n",
    "            print(\"Placebo æµ‹è¯•ç»“æœ:\")\n",
    "            print(\"=\"*50)\n",
    "            print(f\"\\nçœŸå®ç»“æœ (Y) çš„æ•ˆåº”: {placebo_results['true_effect']:.4f}\")\n",
    "            print(f\"å‡ç»“æœ (Y_placebo) çš„æ•ˆåº”: {placebo_results['placebo_effect']:.4f}\")\n",
    "            \n",
    "            if placebo_results['p_value_placebo'] is not None:\n",
    "                print(f\"å‡ç»“æœ p-value: {placebo_results['p_value_placebo']:.4f}\")\n",
    "                \n",
    "                print(\"\\nè§£è¯»:\")\n",
    "                if placebo_results['p_value_placebo'] < 0.05:\n",
    "                    print(\"  âš ï¸ è­¦å‘Š: å‡ç»“æœä¹Ÿæ˜¾ç¤ºæ˜¾è‘—æ•ˆåº”!\")\n",
    "                    print(\"  è¿™å¯èƒ½æ„å‘³ç€:\")\n",
    "                    print(\"  - å­˜åœ¨æœªæ§åˆ¶çš„æ··æ·†\")\n",
    "                    print(\"  - é€‰æ‹©åå·®é—®é¢˜\")\n",
    "                    print(\"  - æ¨¡å‹è®¾å®šé”™è¯¯\")\n",
    "                else:\n",
    "                    print(\"  âœ… å‡ç»“æœæ— æ˜¾è‘—æ•ˆåº”ï¼Œé€šè¿‡ Placebo æµ‹è¯•!\")\n",
    "                    print(\"  è¿™å¢å¼ºäº†æˆ‘ä»¬å¯¹å› æœä¼°è®¡çš„ä¿¡å¿ƒ\")\n",
    "        else:\n",
    "            print(\"[TODO] è¯·å®Œæˆ placebo_test å‡½æ•°\")\n",
    "    except Exception as e:\n",
    "        print(f\"[é”™è¯¯] {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹æ¯”æœ‰æ··æ·†å’Œæ— æ··æ·†æƒ…å†µä¸‹çš„ Placebo æµ‹è¯•\n",
    "print(\"å¯¹æ¯”ä¸åŒæ··æ·†å¼ºåº¦ä¸‹çš„ Placebo æµ‹è¯•:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "placebo_comparison = []\n",
    "\n",
    "for strength in [0.0, 0.3, 0.6, 1.0]:\n",
    "    df_temp, U_temp, params_temp = simulate_unobserved_confounding(\n",
    "        n=2000,\n",
    "        confounder_strength=strength\n",
    "    )\n",
    "    \n",
    "    if df_temp is not None and df_temp['Y'].iloc[0] is not None:\n",
    "        # ç”Ÿæˆä¾èµ–äº U çš„å‡ç»“æœï¼ˆå¦‚æœ U æ˜¯æ··æ·†ï¼Œè¿™ä¸ªä¹Ÿä¼šè¢«\"å½±å“\"ï¼‰\n",
    "        df_temp['Y_placebo'] = U_temp * 2 + np.random.randn(len(df_temp)) * 0.5\n",
    "        \n",
    "        results = placebo_test(df_temp, 'Y', 'Y_placebo')\n",
    "        \n",
    "        if results['placebo_effect'] is not None:\n",
    "            placebo_comparison.append({\n",
    "                'Strength': strength,\n",
    "                'True Effect': results['true_effect'],\n",
    "                'Placebo Effect': results['placebo_effect'],\n",
    "                'P-value': results['p_value_placebo']\n",
    "            })\n",
    "\n",
    "if len(placebo_comparison) > 0:\n",
    "    comp_df = pd.DataFrame(placebo_comparison)\n",
    "    display(comp_df.round(4))\n",
    "    \n",
    "    print(\"\\nè§£è¯»:\")\n",
    "    print(\"- å½“æ··æ·†å¼ºåº¦ä¸º 0 æ—¶ï¼ŒPlacebo æ•ˆåº”æ¥è¿‘ 0\")\n",
    "    print(\"- éšç€æ··æ·†å¼ºåº¦å¢åŠ ï¼ŒPlacebo æ•ˆåº”å˜å¾—æ˜¾è‘—\")\n",
    "    print(\"- è¿™è¯´æ˜ Placebo æµ‹è¯•å¯ä»¥å¸®åŠ©æ£€æµ‹æ··æ·†!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤” æ€è€ƒé¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 1: ä¸ºä»€ä¹ˆæ— æ··æ·†å‡è®¾æ— æ³•ä»æ•°æ®ä¸­éªŒè¯ï¼Ÿ\n",
    "\n",
    "answer_1 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 2: Rosenbaum Î“ = 2 æ„å‘³ç€ä»€ä¹ˆï¼Ÿåœ¨å®è·µä¸­è¿™ç®—å¼ºæ··æ·†è¿˜æ˜¯å¼±æ··æ·†ï¼Ÿ\n",
    "\n",
    "answer_2 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 3: E-value å’Œ Rosenbaum bounds æœ‰ä½•å¼‚åŒï¼Ÿ\n",
    "\n",
    "answer_3 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 4: åœ¨ä»€ä¹ˆæƒ…å†µä¸‹åº”è¯¥æŠ¥å‘Šæ•æ„Ÿæ€§åˆ†æç»“æœï¼Ÿ\n",
    "\n",
    "answer_4 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 5: å¦‚æœæ•æ„Ÿæ€§åˆ†ææ˜¾ç¤ºç»“è®ºå¯¹æœªè§‚æµ‹æ··æ·†å¾ˆæ•æ„Ÿï¼Œåº”è¯¥æ€ä¹ˆåŠï¼Ÿ\n",
    "\n",
    "answer_5 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 6: Placebo æµ‹è¯•çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿå®ƒèƒ½æ£€æµ‹å“ªç§ç±»å‹çš„åå·®ï¼Ÿ\n",
    "\n",
    "answer_6 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ€»ç»“\n",
    "\n",
    "### æ•æ„Ÿæ€§åˆ†ææ–¹æ³•å¯¹æ¯”\n",
    "\n",
    "| æ–¹æ³• | å›ç­”çš„é—®é¢˜ | ä¼˜ç‚¹ | ç¼ºç‚¹ |\n",
    "|------|------------|------|------|\n",
    "| Rosenbaum Bounds | å¤šå¼ºçš„æ··æ·†ä¼šæ¨ç¿»ç»“è®ºï¼Ÿ | ç›´è§‚ã€æœ‰ç†è®ºæ”¯æ’‘ | éœ€è¦åŒ¹é… |\n",
    "| E-value | è§£é‡Šæ•ˆåº”éœ€è¦å¤šå¼ºçš„æ··æ·†ï¼Ÿ | ç®€å•è®¡ç®—ã€å¹¿æ³›é€‚ç”¨ | å‡è®¾è¾ƒå¼º |\n",
    "| Placebo Test | æ–¹æ³•æ˜¯å¦å¯é ï¼Ÿ | ç›´æ¥æ£€éªŒå‡è®¾ | éœ€è¦å¥½çš„ placebo å˜é‡ |\n",
    "\n",
    "### ä½•æ—¶ä½¿ç”¨æ•æ„Ÿæ€§åˆ†æï¼Ÿ\n",
    "\n",
    "âœ… **æ€»æ˜¯åº”è¯¥åš**:\n",
    "- è§‚å¯Ÿæ€§ç ”ç©¶\n",
    "- æ— æ³•éšæœºåŒ–çš„æƒ…å†µ\n",
    "- ç»“è®ºæœ‰é‡è¦æ”¿ç­–å«ä¹‰\n",
    "\n",
    "### å¦‚ä½•è§£è¯»ç»“æœï¼Ÿ\n",
    "\n",
    "| E-value / Î“ é˜ˆå€¼ | è§£è¯» |\n",
    "|------------------|------|\n",
    "| < 1.5 | ç»“è®ºéå¸¸è„†å¼± |\n",
    "| 1.5 - 2.5 | ä¸­ç­‰ç¨³å¥ |\n",
    "| 2.5 - 4.0 | è¾ƒä¸ºç¨³å¥ |\n",
    "| > 4.0 | éå¸¸ç¨³å¥ |\n",
    "\n",
    "### æœ€ä½³å®è·µ\n",
    "\n",
    "1. **æ€»æ˜¯æŠ¥å‘Šæ•æ„Ÿæ€§åˆ†æ**\n",
    "2. **ç»“åˆé¢†åŸŸçŸ¥è¯†**åˆ¤æ–­å‡è®¾çš„æ··æ·†æ˜¯å¦åˆç†\n",
    "3. **ä½¿ç”¨å¤šç§æ–¹æ³•**äº¤å‰éªŒè¯\n",
    "4. **è¯šå®åœ°è®¨è®ºå±€é™æ€§**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ” æ­å–œå®Œæˆæ•æ„Ÿæ€§åˆ†æç»ƒä¹ !\")\n",
    "print(\"\\nä½ å·²ç»å­¦ä¼šäº†:\")\n",
    "print(\"  âœ“ ç†è§£æœªè§‚æµ‹æ··æ·†çš„å½±å“\")\n",
    "print(\"  âœ“ Rosenbaum æ•æ„Ÿæ€§è¾¹ç•Œ\")\n",
    "print(\"  âœ“ E-value è®¡ç®—å’Œè§£è¯»\")\n",
    "print(\"  âœ“ Placebo ç¨³å¥æ€§æ£€éªŒ\")\n",
    "print(\"\\næ­å–œå®Œæˆ Chapter 5 æ‰€æœ‰ç»ƒä¹ !\")\n",
    "print(\"ä¸‹ä¸€æ­¥: Chapter 6 åº”ç”¨åœºæ™¯ - ä¼˜æƒ åˆ¸ä¼˜åŒ–!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
