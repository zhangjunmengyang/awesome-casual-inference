{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dive 02: DragonNet å¤šå¤„ç†æ‰©å±•\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "å®Œæˆæœ¬ notebook åï¼Œä½ å°†èƒ½å¤Ÿï¼š\n",
    "\n",
    "1. **æ·±å…¥ç†è§£** DragonNet çš„ç½‘ç»œæ¶æ„å’Œ Loss è®¾è®¡åŸç†\n",
    "2. **æŒæ¡** å¦‚ä½•å°†äºŒå…ƒå¤„ç†æ‰©å±•åˆ°å¤šå¤„ç†ï¼ˆMulti-Treatmentï¼‰åœºæ™¯\n",
    "3. **å®ç°** å®Œæ•´çš„ Multi-Treatment DragonNetï¼ˆä»é›¶å®ç°ï¼Œä¸è°ƒåŒ…ï¼‰\n",
    "4. **åº”ç”¨** åˆ°çœŸå®ä¸šåŠ¡åœºæ™¯ï¼šå¤šç§ä¼˜æƒ åˆ¸ç­–ç•¥é€‰æ‹©\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“– èƒŒæ™¯æ•…äº‹\n",
    "\n",
    "> **åœºæ™¯ï¼šç”µå•†å¹³å°ä¼˜æƒ åˆ¸ç­–ç•¥é€‰æ‹©**\n",
    ">\n",
    "> ä½ æ˜¯æŸç”µå•†å¹³å°çš„ç®—æ³•å·¥ç¨‹å¸ˆã€‚å¹³å°æœ‰å¤šç§ä¼˜æƒ åˆ¸ç±»å‹ï¼š\n",
    "> - **æ— åˆ¸ (T=0)**ï¼šä¸å‘åˆ¸\n",
    "> - **5æŠ˜åˆ¸ (T=1)**ï¼šå•†å“5æŠ˜ï¼Œæˆæœ¬é«˜ä½†å¸å¼•åŠ›å¤§\n",
    "> - **7æŠ˜åˆ¸ (T=2)**ï¼šå•†å“7æŠ˜ï¼Œæˆæœ¬ä¸­ç­‰\n",
    "> - **æ»¡100å‡20 (T=3)**ï¼šé—¨æ§›åˆ¸ï¼Œæé«˜å®¢å•ä»·\n",
    ">\n",
    "> ä¸šåŠ¡é—®é¢˜ï¼š**å¯¹äºæ¯ä¸ªç”¨æˆ·ï¼Œåº”è¯¥å‘å“ªç§åˆ¸ï¼Ÿ**\n",
    ">\n",
    "> ä½ å†³å®šç”¨ DragonNet æ¥ä¼°è®¡æ¯ç§åˆ¸å¯¹æ¯ä¸ªç”¨æˆ·çš„æ•ˆæœï¼ˆCATEï¼‰ï¼Œä½†å‘ç°åŸç‰ˆ DragonNet åªæ”¯æŒäºŒå…ƒå¤„ç†...\n",
    ">\n",
    "> **æœ¬ notebook å°±æ˜¯æ¥è§£å†³è¿™ä¸ªé—®é¢˜çš„ï¼**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: åŸå§‹ DragonNet æ¶æ„å›é¡¾\n",
    "\n",
    "åœ¨æ‰©å±•ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆå½»åº•ç†è§£åŸå§‹ DragonNet çš„è®¾è®¡ã€‚\n",
    "\n",
    "### 1.1 DragonNet æ ¸å¿ƒæ€æƒ³\n",
    "\n",
    "DragonNet (Shi et al., 2019) çš„æ ¸å¿ƒåˆ›æ–°æ˜¯**ç”¨ç¥ç»ç½‘ç»œåŒæ—¶å­¦ä¹ **ï¼š\n",
    "1. **è¡¨ç¤ºå­¦ä¹  (Representation)**: å­¦ä¹ åå˜é‡ X çš„è¡¨ç¤º Z = Ï†(X)\n",
    "2. **å€¾å‘å¾—åˆ†é¢„æµ‹ (Propensity Score)**: ä»è¡¨ç¤ºé¢„æµ‹å¤„ç†æ¦‚ç‡ P(T=1|X)\n",
    "3. **ç»“æœé¢„æµ‹ (Outcome)**: ä»è¡¨ç¤ºé¢„æµ‹æ½œåœ¨ç»“æœ Y(0), Y(1)\n",
    "\n",
    "**å…³é”®æ´è§**ï¼šå€¾å‘å¾—åˆ†é¢„æµ‹ä»»åŠ¡å¸®åŠ©è¡¨ç¤ºå±‚å­¦ä¹ åˆ°\"å¤„ç†åˆ†é…ç›¸å…³\"çš„ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾æ­£æ˜¯æ··æ·†å˜é‡çš„ä½“ç°ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 åŸå§‹ DragonNet ç½‘ç»œç»“æ„\n",
    "\n",
    "```\n",
    "        è¾“å…¥ X\n",
    "           â”‚\n",
    "           â–¼\n",
    "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "   â”‚   å…±äº«è¡¨ç¤ºå±‚   â”‚  Ï†(X) â†’ Z\n",
    "   â”‚ (Representation)â”‚\n",
    "   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚\n",
    "     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”\n",
    "     â”‚           â”‚\n",
    "     â–¼           â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ å€¾å‘å¾—åˆ† â”‚ â”‚ ç»“æœé¢„æµ‹ â”‚\n",
    "â”‚  å¤´ (Îµ)  â”‚ â”‚   å¤´    â”‚\n",
    "â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜\n",
    "     â”‚           â”‚\n",
    "     â–¼           â–¼\n",
    "  P(T=1|X)    â”Œâ”€â”€â”´â”€â”€â”\n",
    "              â”‚     â”‚\n",
    "              â–¼     â–¼\n",
    "           Î¼â‚€(X)  Î¼â‚(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 åŸå§‹ DragonNet Loss å‡½æ•°\n",
    "\n",
    "DragonNet çš„ Loss åŒ…å«ä¸‰éƒ¨åˆ†ï¼š\n",
    "\n",
    "$$\\mathcal{L} = \\mathcal{L}_{outcome} + \\alpha \\cdot \\mathcal{L}_{propensity} + \\beta \\cdot \\mathcal{L}_{targeted}$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "\n",
    "1. **Outcome Loss** (è§‚æµ‹ç»“æœæ‹Ÿåˆ):\n",
    "$$\\mathcal{L}_{outcome} = \\frac{1}{n}\\sum_{i} \\left[ T_i (Y_i - \\hat{\\mu}_1(X_i))^2 + (1-T_i)(Y_i - \\hat{\\mu}_0(X_i))^2 \\right]$$\n",
    "\n",
    "2. **Propensity Loss** (å€¾å‘å¾—åˆ†æ‹Ÿåˆ):\n",
    "$$\\mathcal{L}_{propensity} = -\\frac{1}{n}\\sum_{i} \\left[ T_i \\log \\hat{\\epsilon}(X_i) + (1-T_i) \\log(1-\\hat{\\epsilon}(X_i)) \\right]$$\n",
    "\n",
    "3. **Targeted Regularization** (Neyman æ­£äº¤åŒ–):\n",
    "$$\\mathcal{L}_{targeted} = \\frac{1}{n}\\sum_{i} \\left( \\hat{Y}_i - Y_i + \\frac{T_i - \\hat{\\epsilon}(X_i)}{\\hat{\\epsilon}(X_i)(1-\\hat{\\epsilon}(X_i))} (Y_i - \\hat{Y}_i) \\right)^2$$\n",
    "\n",
    "å…¶ä¸­ $\\hat{Y}_i = T_i \\hat{\\mu}_1(X_i) + (1-T_i) \\hat{\\mu}_0(X_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯å¢ƒå‡†å¤‡\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# è®¾ç½®ç»˜å›¾é£æ ¼\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['font.family'] = ['Arial Unicode MS', 'SimHei', 'sans-serif']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæˆ\")\n",
    "print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 åŸå§‹ DragonNet å®ç°ï¼ˆä¾›å‚è€ƒï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OriginalDragonNet(nn.Module):\n",
    "    \"\"\"\n",
    "    åŸå§‹ DragonNet - ä»…æ”¯æŒäºŒå…ƒå¤„ç†\n",
    "    ç”¨äºå¯¹æ¯”å’Œç†è§£\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims=[200, 100, 100]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # å…±äº«è¡¨ç¤ºå±‚\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, h_dim),\n",
    "                nn.ELU(),\n",
    "            ])\n",
    "            prev_dim = h_dim\n",
    "        self.representation = nn.Sequential(*layers)\n",
    "        \n",
    "        # å€¾å‘å¾—åˆ†å¤´ï¼ˆäºŒåˆ†ç±»ï¼‰\n",
    "        self.propensity_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[-1], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # ç»“æœé¢„æµ‹å¤´ï¼ˆä¸¤ä¸ªï¼šÎ¼â‚€ å’Œ Î¼â‚ï¼‰\n",
    "        self.mu0_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[-1], 100),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(100, 1)\n",
    "        )\n",
    "        self.mu1_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[-1], 100),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(100, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # å…±äº«è¡¨ç¤º\n",
    "        z = self.representation(x)\n",
    "        \n",
    "        # å€¾å‘å¾—åˆ†\n",
    "        propensity = self.propensity_head(z).squeeze(-1)  # P(T=1|X)\n",
    "        \n",
    "        # æ½œåœ¨ç»“æœ\n",
    "        mu0 = self.mu0_head(z).squeeze(-1)  # E[Y(0)|X]\n",
    "        mu1 = self.mu1_head(z).squeeze(-1)  # E[Y(1)|X]\n",
    "        \n",
    "        return propensity, mu0, mu1\n",
    "    \n",
    "    def predict_cate(self, x):\n",
    "        \"\"\"é¢„æµ‹ CATE = E[Y(1) - Y(0)|X]\"\"\"\n",
    "        _, mu0, mu1 = self.forward(x)\n",
    "        return mu1 - mu0\n",
    "\n",
    "print(\"âœ… åŸå§‹ DragonNet å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: å¤šå¤„ç†æ‰©å±•çš„æŒ‘æˆ˜\n",
    "\n",
    "### 2.1 ä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥ç”¨åŸç‰ˆ DragonNetï¼Ÿ\n",
    "\n",
    "åŸç‰ˆ DragonNet çš„é™åˆ¶ï¼š\n",
    "\n",
    "| ç»„ä»¶ | åŸç‰ˆè®¾è®¡ | å¤šå¤„ç†éœ€æ±‚ |\n",
    "|------|---------|----------|\n",
    "| å€¾å‘å¾—åˆ† | äºŒåˆ†ç±» Sigmoid | å¤šåˆ†ç±» Softmax |\n",
    "| ç»“æœé¢„æµ‹å¤´ | 2 ä¸ª (Î¼â‚€, Î¼â‚) | K ä¸ª (Î¼â‚€, ..., Î¼â‚–â‚‹â‚) |\n",
    "| Outcome Loss | äºŒé€‰ä¸€ | Ké€‰ä¸€ |\n",
    "| Targeted Reg | é’ˆå¯¹äºŒå…ƒå¤„ç†è®¾è®¡ | éœ€è¦æ³›åŒ– |\n",
    "\n",
    "### 2.2 è®¾è®¡å†³ç­–ç‚¹\n",
    "\n",
    "åœ¨æ‰©å±• DragonNet æ—¶ï¼Œæˆ‘ä»¬éœ€è¦åšå‡ºä»¥ä¸‹è®¾è®¡å†³ç­–ï¼š\n",
    "\n",
    "1. **å¤„ç†ç¼–ç æ–¹å¼**ï¼šOne-hot vs Embedding\n",
    "2. **ç»“æœé¢„æµ‹å¤´è®¾è®¡**ï¼šç‹¬ç«‹å¤´ vs å…±äº«åº•å±‚\n",
    "3. **Targeted Regularization æ³›åŒ–**ï¼šå¦‚ä½•å¤„ç†å¤šä¸ªå¤„ç†çš„æ­£äº¤åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Multi-Treatment DragonNet æ¶æ„è®¾è®¡\n",
    "\n",
    "### 3.1 ç½‘ç»œæ¶æ„\n",
    "\n",
    "```\n",
    "           è¾“å…¥ X\n",
    "              â”‚\n",
    "              â–¼\n",
    "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "      â”‚   å…±äº«è¡¨ç¤ºå±‚   â”‚  Ï†(X) â†’ Z\n",
    "      â”‚ (Representation)â”‚\n",
    "      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "              â”‚\n",
    "        â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”\n",
    "        â”‚           â”‚\n",
    "        â–¼           â–¼\n",
    "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "   â”‚ å€¾å‘å¾—åˆ† â”‚  â”‚    ç»“æœé¢„æµ‹å¤´        â”‚\n",
    "   â”‚  å¤šåˆ†ç±»  â”‚  â”‚ (æ¯ä¸ªå¤„ç†ä¸€ä¸ªå¤´)    â”‚\n",
    "   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜\n",
    "        â”‚            â”‚    â”‚    â”‚    â”‚\n",
    "        â–¼            â–¼    â–¼    â–¼    â–¼\n",
    "   P(T=k|X)       Î¼â‚€(X) Î¼â‚(X) Î¼â‚‚(X) Î¼â‚ƒ(X)\n",
    "   k=0,1,2,3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Loss å‡½æ•°è®¾è®¡\n",
    "\n",
    "#### 3.2.1 å¤šå¤„ç† Outcome Loss\n",
    "\n",
    "$$\\mathcal{L}_{outcome} = \\frac{1}{n}\\sum_{i} \\sum_{k=0}^{K-1} \\mathbb{1}[T_i = k] (Y_i - \\hat{\\mu}_k(X_i))^2$$\n",
    "\n",
    "å³ï¼šåªå¯¹è§‚æµ‹åˆ°çš„å¤„ç†è®¡ç®— MSEã€‚\n",
    "\n",
    "#### 3.2.2 å¤šåˆ†ç±» Propensity Loss\n",
    "\n",
    "$$\\mathcal{L}_{propensity} = -\\frac{1}{n}\\sum_{i} \\sum_{k=0}^{K-1} \\mathbb{1}[T_i = k] \\log \\hat{\\pi}_k(X_i)$$\n",
    "\n",
    "å³ï¼šæ ‡å‡†çš„å¤šåˆ†ç±»äº¤å‰ç†µã€‚\n",
    "\n",
    "#### 3.2.3 æ³›åŒ–çš„ Targeted Regularization\n",
    "\n",
    "å¯¹äºå¤šå¤„ç†ï¼Œæˆ‘ä»¬éœ€è¦æ³›åŒ– Targeted Regularizationã€‚æ ¸å¿ƒæ€æƒ³æ˜¯ä½¿ç”¨**å¹¿ä¹‰å€¾å‘å¾—åˆ†åŠ æƒ**ï¼š\n",
    "\n",
    "$$\\mathcal{L}_{targeted} = \\frac{1}{n}\\sum_{i} \\left( \\hat{Y}_i - Y_i + \\frac{\\mathbb{1}[T_i = k] - \\hat{\\pi}_k(X_i)}{\\hat{\\pi}_k(X_i)} (Y_i - \\hat{\\mu}_k(X_i)) \\right)^2$$\n",
    "\n",
    "å…¶ä¸­ $\\hat{Y}_i = \\sum_{k} \\mathbb{1}[T_i=k] \\hat{\\mu}_k(X_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: ä»é›¶å®ç° Multi-Treatment DragonNet\n",
    "\n",
    "### ğŸ§ª TODO ç»ƒä¹  1: å®ç° Multi-Treatment DragonNet\n",
    "\n",
    "ä¸‹é¢æ˜¯ Multi-Treatment DragonNet çš„æ¡†æ¶ï¼Œè¯·å®Œæˆ TODO éƒ¨åˆ†ã€‚\n",
    "\n",
    "**æç¤º**ï¼š\n",
    "1. å€¾å‘å¾—åˆ†å¤´ï¼šä½¿ç”¨ `nn.Linear(hidden_dim, num_treatments)` + `F.softmax`\n",
    "2. ç»“æœé¢„æµ‹å¤´ï¼šä½¿ç”¨ `nn.ModuleList` å­˜å‚¨ K ä¸ªç‹¬ç«‹çš„å¤´\n",
    "3. å‰å‘ä¼ æ’­ï¼šè¿”å› propensity scores å’Œæ‰€æœ‰ mu é¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class MultiTreatmentDragonNet(nn.Module):\n    \"\"\"\n    å¤šå¤„ç† DragonNet\n    æ”¯æŒ K ç§å¤„ç†ï¼ˆåŒ…æ‹¬ä¸å¤„ç†ï¼‰\n    \"\"\"\n    def __init__(self, input_dim, num_treatments, hidden_dims=[200, 100, 100], outcome_hidden=100):\n        super().__init__()\n        \n        self.num_treatments = num_treatments\n        \n        # å®ç°å…±äº«è¡¨ç¤ºå±‚\n        layers = []\n        prev_dim = input_dim\n        for h_dim in hidden_dims:\n            layers.extend([\n                nn.Linear(prev_dim, h_dim),\n                nn.ELU()\n            ])\n            prev_dim = h_dim\n        self.representation = nn.Sequential(*layers)\n        \n        # å®ç°å€¾å‘å¾—åˆ†å¤´ï¼ˆå¤šåˆ†ç±»ï¼‰\n        self.propensity_head = nn.Linear(hidden_dims[-1], num_treatments)\n        \n        # å®ç°ç»“æœé¢„æµ‹å¤´ï¼ˆæ¯ä¸ªå¤„ç†ä¸€ä¸ªï¼‰\n        self.outcome_heads = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(hidden_dims[-1], outcome_hidden),\n                nn.ELU(),\n                nn.Linear(outcome_hidden, 1)\n            )\n            for _ in range(num_treatments)\n        ])\n    \n    def forward(self, x):\n        \"\"\"\n        å‰å‘ä¼ æ’­\n        \n        Returns:\n            propensity: (batch_size, num_treatments) - æ¯ç§å¤„ç†çš„æ¦‚ç‡\n            mus: (batch_size, num_treatments) - æ¯ç§å¤„ç†ä¸‹çš„é¢„æµ‹ç»“æœ\n        \"\"\"\n        # å®ç°å‰å‘ä¼ æ’­\n        # 1. è·å–å…±äº«è¡¨ç¤º\n        z = self.representation(x)\n        \n        # 2. è®¡ç®—å€¾å‘å¾—åˆ†\n        propensity = F.softmax(self.propensity_head(z), dim=-1)\n        \n        # 3. è®¡ç®—æ¯ä¸ªå¤„ç†çš„é¢„æµ‹ç»“æœ\n        mus = torch.cat([head(z) for head in self.outcome_heads], dim=-1)\n        \n        return propensity, mus\n    \n    def predict_cate(self, x, reference_treatment=0):\n        \"\"\"\n        é¢„æµ‹ CATE\n        CATE_k = E[Y(k) - Y(reference)|X]\n        \n        Args:\n            x: è¾“å…¥ç‰¹å¾\n            reference_treatment: å‚ç…§ç»„ï¼ˆé€šå¸¸æ˜¯ä¸å¤„ç†ï¼Œå³ T=0ï¼‰\n            \n        Returns:\n            cate: (batch_size, num_treatments - 1) - æ¯ç§å¤„ç†ç›¸å¯¹å‚ç…§ç»„çš„ CATE\n        \"\"\"\n        _, mus = self.forward(x)\n        mu_ref = mus[:, reference_treatment:reference_treatment+1]\n        # è®¡ç®—ç›¸å¯¹äºå‚ç…§ç»„çš„ CATE\n        cate = mus - mu_ref\n        # ç§»é™¤å‚ç…§ç»„è‡ªèº«ï¼ˆCATE=0ï¼‰\n        mask = torch.ones(self.num_treatments, dtype=torch.bool)\n        mask[reference_treatment] = False\n        return cate[:, mask]\n\nprint(\"âœ… MultiTreatmentDragonNet ç±»å®šä¹‰å®Œæˆï¼ˆå·²å®Œæˆ TODO éƒ¨åˆ†ï¼‰\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ å‚è€ƒç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# å‚è€ƒç­”æ¡ˆï¼šMulti-Treatment DragonNet å®Œæ•´å®ç°\n",
    "# ============================================================\n",
    "\n",
    "class MultiTreatmentDragonNet(nn.Module):\n",
    "    \"\"\"\n",
    "    å¤šå¤„ç† DragonNet - å®Œæ•´å®ç°\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, num_treatments, hidden_dims=[200, 100, 100], outcome_hidden=100):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_treatments = num_treatments\n",
    "        \n",
    "        # å…±äº«è¡¨ç¤ºå±‚\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, h_dim),\n",
    "                nn.ELU(),\n",
    "            ])\n",
    "            prev_dim = h_dim\n",
    "        self.representation = nn.Sequential(*layers)\n",
    "        \n",
    "        # å€¾å‘å¾—åˆ†å¤´ï¼ˆå¤šåˆ†ç±»ï¼‰\n",
    "        self.propensity_head = nn.Linear(hidden_dims[-1], num_treatments)\n",
    "        \n",
    "        # ç»“æœé¢„æµ‹å¤´ï¼ˆæ¯ä¸ªå¤„ç†ä¸€ä¸ªï¼‰\n",
    "        self.outcome_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_dims[-1], outcome_hidden),\n",
    "                nn.ELU(),\n",
    "                nn.Linear(outcome_hidden, 1)\n",
    "            )\n",
    "            for _ in range(num_treatments)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # å…±äº«è¡¨ç¤º\n",
    "        z = self.representation(x)\n",
    "        \n",
    "        # å€¾å‘å¾—åˆ†ï¼ˆå¤šåˆ†ç±»ï¼‰\n",
    "        propensity = F.softmax(self.propensity_head(z), dim=-1)\n",
    "        \n",
    "        # æ¯ä¸ªå¤„ç†çš„é¢„æµ‹ç»“æœ\n",
    "        mus = torch.cat([head(z) for head in self.outcome_heads], dim=-1)\n",
    "        \n",
    "        return propensity, mus\n",
    "    \n",
    "    def predict_cate(self, x, reference_treatment=0):\n",
    "        \"\"\"é¢„æµ‹ç›¸å¯¹äºå‚ç…§ç»„çš„ CATE\"\"\"\n",
    "        _, mus = self.forward(x)\n",
    "        mu_ref = mus[:, reference_treatment:reference_treatment+1]\n",
    "        cate = mus - mu_ref\n",
    "        mask = torch.ones(self.num_treatments, dtype=torch.bool)\n",
    "        mask[reference_treatment] = False\n",
    "        return cate[:, mask]\n",
    "\n",
    "# æµ‹è¯•\n",
    "model = MultiTreatmentDragonNet(input_dim=10, num_treatments=4)\n",
    "x_test = torch.randn(5, 10)\n",
    "prop, mus = model(x_test)\n",
    "print(f\"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ\")\n",
    "print(f\"   è¾“å…¥ç»´åº¦: 10, å¤„ç†æ•°é‡: 4\")\n",
    "print(f\"   å€¾å‘å¾—åˆ†å½¢çŠ¶: {prop.shape}  # (batch_size, num_treatments)\")\n",
    "print(f\"   é¢„æµ‹ç»“æœå½¢çŠ¶: {mus.shape}  # (batch_size, num_treatments)\")\n",
    "print(f\"   å€¾å‘å¾—åˆ†å’Œ: {prop.sum(dim=1)}  # åº”è¯¥å…¨æ˜¯ 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: å®ç° Multi-Treatment Loss å‡½æ•°\n",
    "\n",
    "### ğŸ§ª TODO ç»ƒä¹  2: å®ç°å¤šå¤„ç† Loss\n",
    "\n",
    "è¯·å®ç°å®Œæ•´çš„ Multi-Treatment DragonNet Lossï¼ŒåŒ…æ‹¬ï¼š\n",
    "1. Outcome Lossï¼ˆåªå¯¹è§‚æµ‹åˆ°çš„å¤„ç†è®¡ç®—ï¼‰\n",
    "2. Propensity Lossï¼ˆå¤šåˆ†ç±»äº¤å‰ç†µï¼‰\n",
    "3. Targeted Regularizationï¼ˆæ³›åŒ–ç‰ˆæœ¬ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class MultiTreatmentDragonNetLoss(nn.Module):\n    \"\"\"\n    å¤šå¤„ç† DragonNet Loss å‡½æ•°\n    \"\"\"\n    def __init__(self, alpha=1.0, beta=1.0, eps=1e-6):\n        super().__init__()\n        self.alpha = alpha  # å€¾å‘å¾—åˆ† Loss æƒé‡\n        self.beta = beta    # Targeted Reg æƒé‡\n        self.eps = eps      # æ•°å€¼ç¨³å®šæ€§\n    \n    def forward(self, propensity, mus, treatment, outcome):\n        \"\"\"\n        Args:\n            propensity: (batch_size, num_treatments) - é¢„æµ‹çš„å€¾å‘å¾—åˆ†\n            mus: (batch_size, num_treatments) - é¢„æµ‹çš„æ½œåœ¨ç»“æœ\n            treatment: (batch_size,) - å®é™…å¤„ç†ï¼ˆæ•´æ•° 0, 1, ..., K-1ï¼‰\n            outcome: (batch_size,) - å®é™…ç»“æœ\n        \"\"\"\n        batch_size = treatment.shape[0]\n        num_treatments = propensity.shape[1]\n        \n        # å®ç° Outcome Loss\n        # ä½¿ç”¨ gather é€‰æ‹©å¯¹åº”å¤„ç†çš„é¢„æµ‹å€¼\n        mu_observed = mus.gather(1, treatment.unsqueeze(1)).squeeze(1)\n        outcome_loss = F.mse_loss(mu_observed, outcome)\n        \n        # å®ç° Propensity Loss\n        # ä½¿ç”¨ F.cross_entropy\n        propensity_loss = F.cross_entropy(propensity + self.eps, treatment)\n        \n        # å®ç° Targeted Regularization\n        # 1. è·å–è§‚æµ‹å¤„ç†çš„å€¾å‘å¾—åˆ† pi_t\n        pi_observed = propensity.gather(1, treatment.unsqueeze(1)).squeeze(1)\n        pi_observed = torch.clamp(pi_observed, min=self.eps)  # æ•°å€¼ç¨³å®š\n        \n        # 2. è®¡ç®— correction term\n        correction = (1.0 - pi_observed) / pi_observed * (outcome - mu_observed)\n        \n        # 3. Targeted regularization term\n        targeted_term = mu_observed - outcome + correction\n        targeted_loss = (targeted_term ** 2).mean()\n        \n        total_loss = outcome_loss + self.alpha * propensity_loss + self.beta * targeted_loss\n        \n        return total_loss, {\n            'outcome_loss': outcome_loss.item(),\n            'propensity_loss': propensity_loss.item(),\n            'targeted_loss': targeted_loss.item(),\n            'total_loss': total_loss.item()\n        }\n\nprint(\"âœ… MultiTreatmentDragonNetLoss ç±»å®šä¹‰å®Œæˆï¼ˆå·²å®Œæˆ TODO éƒ¨åˆ†ï¼‰\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ å‚è€ƒç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# å‚è€ƒç­”æ¡ˆï¼šMulti-Treatment DragonNet Loss å®Œæ•´å®ç°\n",
    "# ============================================================\n",
    "\n",
    "class MultiTreatmentDragonNetLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    å¤šå¤„ç† DragonNet Loss å‡½æ•° - å®Œæ•´å®ç°\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1.0, beta=1.0, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.eps = eps  # æ•°å€¼ç¨³å®šæ€§\n",
    "    \n",
    "    def forward(self, propensity, mus, treatment, outcome):\n",
    "        batch_size = treatment.shape[0]\n",
    "        num_treatments = propensity.shape[1]\n",
    "        \n",
    "        # 1. Outcome Loss: åªå¯¹è§‚æµ‹åˆ°çš„å¤„ç†è®¡ç®— MSE\n",
    "        mu_observed = mus.gather(1, treatment.unsqueeze(1)).squeeze(1)\n",
    "        outcome_loss = F.mse_loss(mu_observed, outcome)\n",
    "        \n",
    "        # 2. Propensity Loss: å¤šåˆ†ç±»äº¤å‰ç†µ\n",
    "        propensity_loss = F.cross_entropy(propensity + self.eps, treatment)\n",
    "        \n",
    "        # 3. Targeted Regularization (æ³›åŒ–ç‰ˆ)\n",
    "        # è·å–è§‚æµ‹å¤„ç†çš„å€¾å‘å¾—åˆ†\n",
    "        pi_observed = propensity.gather(1, treatment.unsqueeze(1)).squeeze(1)\n",
    "        pi_observed = torch.clamp(pi_observed, min=self.eps)  # æ•°å€¼ç¨³å®š\n",
    "        \n",
    "        # æ„å»ºæŒ‡ç¤ºå˜é‡ (1[T=k] = 1 å¯¹äºè§‚æµ‹åˆ°çš„å¤„ç†)\n",
    "        # è®¡ç®— correction term\n",
    "        correction = (1.0 - pi_observed) / pi_observed * (outcome - mu_observed)\n",
    "        \n",
    "        # Targeted regularization term\n",
    "        targeted_term = mu_observed - outcome + correction\n",
    "        targeted_loss = (targeted_term ** 2).mean()\n",
    "        \n",
    "        # æ€» Loss\n",
    "        total_loss = outcome_loss + self.alpha * propensity_loss + self.beta * targeted_loss\n",
    "        \n",
    "        return total_loss, {\n",
    "            'outcome_loss': outcome_loss.item(),\n",
    "            'propensity_loss': propensity_loss.item(),\n",
    "            'targeted_loss': targeted_loss.item(),\n",
    "            'total_loss': total_loss.item()\n",
    "        }\n",
    "\n",
    "# æµ‹è¯• Loss å‡½æ•°\n",
    "loss_fn = MultiTreatmentDragonNetLoss()\n",
    "propensity = torch.softmax(torch.randn(5, 4), dim=-1)\n",
    "mus = torch.randn(5, 4)\n",
    "treatment = torch.randint(0, 4, (5,))\n",
    "outcome = torch.randn(5)\n",
    "\n",
    "loss, loss_dict = loss_fn(propensity, mus, treatment, outcome)\n",
    "print(f\"âœ… Loss å‡½æ•°æµ‹è¯•æˆåŠŸ\")\n",
    "print(f\"   Outcome Loss: {loss_dict['outcome_loss']:.4f}\")\n",
    "print(f\"   Propensity Loss: {loss_dict['propensity_loss']:.4f}\")\n",
    "print(f\"   Targeted Loss: {loss_dict['targeted_loss']:.4f}\")\n",
    "print(f\"   Total Loss: {loss_dict['total_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: ç”Ÿæˆå¤šå¤„ç†æ¨¡æ‹Ÿæ•°æ®\n",
    "\n",
    "ä¸ºäº†æµ‹è¯•æˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ç”Ÿæˆä¸€ä¸ªçœŸå®çš„å¤šå¤„ç†åœºæ™¯æ•°æ®é›†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multi_treatment_data(n_samples=5000, seed=42):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆå¤šå¤„ç†æ¨¡æ‹Ÿæ•°æ®\n",
    "    \n",
    "    åœºæ™¯ï¼šç”µå•†ä¼˜æƒ åˆ¸\n",
    "    - T=0: ä¸å‘åˆ¸\n",
    "    - T=1: 5æŠ˜åˆ¸ï¼ˆé«˜æˆæœ¬ï¼Œé«˜æ•ˆæœï¼‰\n",
    "    - T=2: 7æŠ˜åˆ¸ï¼ˆä¸­æˆæœ¬ï¼Œä¸­æ•ˆæœï¼‰\n",
    "    - T=3: æ»¡100å‡20ï¼ˆä½æˆæœ¬ï¼Œæ•ˆæœä¾èµ–ç”¨æˆ·ç±»å‹ï¼‰\n",
    "    \n",
    "    ç”¨æˆ·ç‰¹å¾ï¼š\n",
    "    - X0: è´­ä¹°åŠ›ï¼ˆé«˜è´­ä¹°åŠ›ç”¨æˆ·æ›´å®¹æ˜“è¢«å‘åˆ¸ï¼‰\n",
    "    - X1: ä»·æ ¼æ•æ„Ÿåº¦ï¼ˆé«˜æ•æ„Ÿåº¦ç”¨æˆ·å¯¹æŠ˜æ‰£å“åº”æ›´å¤§ï¼‰\n",
    "    - X2: æ´»è·ƒåº¦ï¼ˆå½±å“åŸºç¡€è½¬åŒ–ç‡ï¼‰\n",
    "    - X3-X9: å…¶ä»–ç‰¹å¾\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # ç”¨æˆ·ç‰¹å¾\n",
    "    X = np.random.randn(n_samples, 10)\n",
    "    \n",
    "    # å…³é”®ç‰¹å¾\n",
    "    purchase_power = X[:, 0]      # è´­ä¹°åŠ›\n",
    "    price_sensitivity = X[:, 1]   # ä»·æ ¼æ•æ„Ÿåº¦\n",
    "    activity = X[:, 2]            # æ´»è·ƒåº¦\n",
    "    \n",
    "    # çœŸå®çš„å€¾å‘å¾—åˆ†ï¼ˆå¤„ç†åˆ†é…æœºåˆ¶ï¼‰\n",
    "    # é«˜è´­ä¹°åŠ›ç”¨æˆ·æ›´å®¹æ˜“è¢«å‘å¤§é¢åˆ¸\n",
    "    logits = np.zeros((n_samples, 4))\n",
    "    logits[:, 0] = 0  # åŸºå‡†ï¼šä¸å‘åˆ¸\n",
    "    logits[:, 1] = -1.0 + 1.5 * purchase_power + 0.3 * activity  # 5æŠ˜åˆ¸ï¼šç»™é«˜ä»·å€¼ç”¨æˆ·\n",
    "    logits[:, 2] = 0.5 + 0.5 * purchase_power + 0.5 * price_sensitivity  # 7æŠ˜åˆ¸ï¼šè¾ƒæ™®é\n",
    "    logits[:, 3] = 0.3 + 0.3 * purchase_power + 0.8 * activity  # æ»¡å‡åˆ¸ï¼šç»™æ´»è·ƒç”¨æˆ·\n",
    "    \n",
    "    # Softmax å¾—åˆ°æ¦‚ç‡\n",
    "    exp_logits = np.exp(logits - logits.max(axis=1, keepdims=True))\n",
    "    true_propensity = exp_logits / exp_logits.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # æ ¹æ®æ¦‚ç‡åˆ†é…å¤„ç†\n",
    "    treatment = np.array([np.random.choice(4, p=p) for p in true_propensity])\n",
    "    \n",
    "    # çœŸå®çš„æ½œåœ¨ç»“æœå‡½æ•°\n",
    "    def mu_0(X):  # ä¸å‘åˆ¸\n",
    "        return 10 + 3 * X[:, 2] + np.random.randn(len(X)) * 0.5\n",
    "    \n",
    "    def mu_1(X):  # 5æŠ˜åˆ¸ - å¯¹ä»·æ ¼æ•æ„Ÿç”¨æˆ·æ•ˆæœæ›´å¤§\n",
    "        base = mu_0(X)\n",
    "        treatment_effect = 8 + 4 * X[:, 1]  # ä»·æ ¼æ•æ„Ÿåº¦è¶Šé«˜ï¼Œæ•ˆæœè¶Šå¤§\n",
    "        return base + treatment_effect\n",
    "    \n",
    "    def mu_2(X):  # 7æŠ˜åˆ¸ - ä¸­ç­‰æ•ˆæœ\n",
    "        base = mu_0(X)\n",
    "        treatment_effect = 5 + 2 * X[:, 1]\n",
    "        return base + treatment_effect\n",
    "    \n",
    "    def mu_3(X):  # æ»¡å‡åˆ¸ - å¯¹æ´»è·ƒç”¨æˆ·æ•ˆæœæ›´å¤§\n",
    "        base = mu_0(X)\n",
    "        treatment_effect = 3 + 3 * X[:, 2]  # æ´»è·ƒåº¦è¶Šé«˜ï¼Œæ•ˆæœè¶Šå¤§\n",
    "        return base + treatment_effect\n",
    "    \n",
    "    # è®¡ç®—æ‰€æœ‰æ½œåœ¨ç»“æœï¼ˆç”¨äºè¯„ä¼°çœŸå® CATEï¼‰\n",
    "    mu_all = np.stack([mu_0(X), mu_1(X), mu_2(X), mu_3(X)], axis=1)\n",
    "    \n",
    "    # è§‚æµ‹ç»“æœ\n",
    "    outcome = np.array([mu_all[i, t] for i, t in enumerate(treatment)])\n",
    "    \n",
    "    # çœŸå® CATEï¼ˆç›¸å¯¹äºä¸å‘åˆ¸ï¼‰\n",
    "    true_cate = mu_all[:, 1:] - mu_all[:, 0:1]\n",
    "    \n",
    "    return {\n",
    "        'X': X,\n",
    "        'treatment': treatment,\n",
    "        'outcome': outcome,\n",
    "        'true_cate': true_cate,  # (n_samples, 3)\n",
    "        'true_mu': mu_all,\n",
    "        'true_propensity': true_propensity\n",
    "    }\n",
    "\n",
    "# ç”Ÿæˆæ•°æ®\n",
    "data = generate_multi_treatment_data(n_samples=8000)\n",
    "print(f\"âœ… æ•°æ®ç”Ÿæˆå®Œæˆ\")\n",
    "print(f\"   æ ·æœ¬æ•°: {len(data['X'])}\")\n",
    "print(f\"   ç‰¹å¾ç»´åº¦: {data['X'].shape[1]}\")\n",
    "print(f\"   å¤„ç†åˆ†å¸ƒ: {np.bincount(data['treatment'])}\")\n",
    "print(f\"   çœŸå® CATE å‡å€¼ (T=1,2,3 ç›¸å¯¹ T=0):\")\n",
    "print(f\"      5æŠ˜åˆ¸: {data['true_cate'][:, 0].mean():.2f}\")\n",
    "print(f\"      7æŠ˜åˆ¸: {data['true_cate'][:, 1].mean():.2f}\")\n",
    "print(f\"      æ»¡å‡åˆ¸: {data['true_cate'][:, 2].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–æ•°æ®åˆ†å¸ƒ\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# å¤„ç†åˆ†å¸ƒ\n",
    "ax1 = axes[0, 0]\n",
    "treatment_labels = ['ä¸å‘åˆ¸', '5æŠ˜åˆ¸', '7æŠ˜åˆ¸', 'æ»¡å‡åˆ¸']\n",
    "counts = np.bincount(data['treatment'])\n",
    "ax1.bar(treatment_labels, counts, color=['#95a5a6', '#e74c3c', '#3498db', '#2ecc71'])\n",
    "ax1.set_ylabel('æ ·æœ¬æ•°')\n",
    "ax1.set_title('å¤„ç†åˆ†å¸ƒ')\n",
    "\n",
    "# ç»“æœåˆ†å¸ƒï¼ˆæŒ‰å¤„ç†ï¼‰\n",
    "ax2 = axes[0, 1]\n",
    "for t in range(4):\n",
    "    mask = data['treatment'] == t\n",
    "    ax2.hist(data['outcome'][mask], bins=30, alpha=0.5, label=treatment_labels[t])\n",
    "ax2.set_xlabel('ç»“æœ (GMV)')\n",
    "ax2.set_ylabel('é¢‘æ•°')\n",
    "ax2.set_title('å„å¤„ç†ç»„ç»“æœåˆ†å¸ƒ')\n",
    "ax2.legend()\n",
    "\n",
    "# çœŸå® CATE åˆ†å¸ƒ\n",
    "ax3 = axes[1, 0]\n",
    "for i, label in enumerate(['5æŠ˜åˆ¸', '7æŠ˜åˆ¸', 'æ»¡å‡åˆ¸']):\n",
    "    ax3.hist(data['true_cate'][:, i], bins=30, alpha=0.5, label=label)\n",
    "ax3.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax3.set_xlabel('CATE (ç›¸å¯¹ä¸å‘åˆ¸)')\n",
    "ax3.set_ylabel('é¢‘æ•°')\n",
    "ax3.set_title('çœŸå® CATE åˆ†å¸ƒï¼ˆå¼‚è´¨æ€§æ•ˆåº”ï¼‰')\n",
    "ax3.legend()\n",
    "\n",
    "# ç‰¹å¾ä¸å¤„ç†çš„å…³ç³»\n",
    "ax4 = axes[1, 1]\n",
    "for t in range(4):\n",
    "    mask = data['treatment'] == t\n",
    "    ax4.scatter(data['X'][mask, 0], data['X'][mask, 1], \n",
    "               alpha=0.3, label=treatment_labels[t], s=10)\n",
    "ax4.set_xlabel('è´­ä¹°åŠ› (X0)')\n",
    "ax4.set_ylabel('ä»·æ ¼æ•æ„Ÿåº¦ (X1)')\n",
    "ax4.set_title('å¤„ç†åˆ†é…ä¸ç‰¹å¾å…³ç³»ï¼ˆå­˜åœ¨æ··æ·†ï¼‰')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nè§‚å¯Ÿï¼š\")\n",
    "print(\"1. å¤„ç†åˆ†å¸ƒä¸å‡åŒ€ï¼ˆæ¨¡æ‹ŸçœŸå®ä¸šåŠ¡åœºæ™¯ï¼‰\")\n",
    "print(\"2. å„å¤„ç†ç»„ç»“æœåˆ†å¸ƒæœ‰é‡å ä½†ä¸å®Œå…¨ç›¸åŒ\")\n",
    "print(\"3. CATE å­˜åœ¨å¼‚è´¨æ€§ï¼ˆä¸åŒç”¨æˆ·æ•ˆæœä¸åŒï¼‰\")\n",
    "print(\"4. å¤„ç†åˆ†é…ä¸ç”¨æˆ·ç‰¹å¾ç›¸å…³ï¼ˆå­˜åœ¨æ··æ·†åå·®ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: è®­ç»ƒ Multi-Treatment DragonNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multi_treatment_dragonnet(data, epochs=100, batch_size=256, lr=1e-3, \n",
    "                                     alpha=1.0, beta=1.0, verbose=True):\n",
    "    \"\"\"\n",
    "    è®­ç»ƒ Multi-Treatment DragonNet\n",
    "    \"\"\"\n",
    "    # æ•°æ®å‡†å¤‡\n",
    "    X_train, X_val, t_train, t_val, y_train, y_val = train_test_split(\n",
    "        data['X'], data['treatment'], data['outcome'], \n",
    "        test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # æ ‡å‡†åŒ–\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    # è½¬ä¸º Tensor\n",
    "    X_train_t = torch.FloatTensor(X_train)\n",
    "    t_train_t = torch.LongTensor(t_train)\n",
    "    y_train_t = torch.FloatTensor(y_train)\n",
    "    X_val_t = torch.FloatTensor(X_val)\n",
    "    t_val_t = torch.LongTensor(t_val)\n",
    "    y_val_t = torch.FloatTensor(y_val)\n",
    "    \n",
    "    # åˆ›å»º DataLoader\n",
    "    train_dataset = TensorDataset(X_train_t, t_train_t, y_train_t)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # åˆå§‹åŒ–æ¨¡å‹\n",
    "    model = MultiTreatmentDragonNet(\n",
    "        input_dim=X_train.shape[1],\n",
    "        num_treatments=4,\n",
    "        hidden_dims=[200, 100, 100]\n",
    "    )\n",
    "    \n",
    "    loss_fn = MultiTreatmentDragonNetLoss(alpha=alpha, beta=beta)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)\n",
    "    \n",
    "    # è®­ç»ƒå†å²\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'outcome_loss': [], 'propensity_loss': [], 'targeted_loss': []\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # è®­ç»ƒ\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        epoch_metrics = {'outcome_loss': [], 'propensity_loss': [], 'targeted_loss': []}\n",
    "        \n",
    "        for X_batch, t_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            propensity, mus = model(X_batch)\n",
    "            loss, metrics = loss_fn(propensity, mus, t_batch, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            for k, v in metrics.items():\n",
    "                if k in epoch_metrics:\n",
    "                    epoch_metrics[k].append(v)\n",
    "        \n",
    "        # éªŒè¯\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            propensity_val, mus_val = model(X_val_t)\n",
    "            val_loss, _ = loss_fn(propensity_val, mus_val, t_val_t, y_val_t)\n",
    "        \n",
    "        # è®°å½•å†å²\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(val_loss.item())\n",
    "        for k in epoch_metrics:\n",
    "            history[k].append(np.mean(epoch_metrics[k]))\n",
    "        \n",
    "        # å­¦ä¹ ç‡è°ƒåº¦\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        \n",
    "        if verbose and (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "                  f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss.item():.4f}\")\n",
    "    \n",
    "    # åŠ è½½æœ€ä½³æ¨¡å‹\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, scaler, history\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "print(\"å¼€å§‹è®­ç»ƒ Multi-Treatment DragonNet...\\n\")\n",
    "model, scaler, history = train_multi_treatment_dragonnet(\n",
    "    data, epochs=150, batch_size=256, lr=5e-4,\n",
    "    alpha=1.0, beta=1.0\n",
    ")\n",
    "print(\"\\nâœ… è®­ç»ƒå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# æ€» Loss\n",
    "ax1 = axes[0]\n",
    "ax1.plot(history['train_loss'], label='Train', alpha=0.8)\n",
    "ax1.plot(history['val_loss'], label='Validation', alpha=0.8)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('è®­ç»ƒè¿‡ç¨‹')\n",
    "ax1.legend()\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# å„éƒ¨åˆ† Loss\n",
    "ax2 = axes[1]\n",
    "ax2.plot(history['outcome_loss'], label='Outcome Loss', alpha=0.8)\n",
    "ax2.plot(history['propensity_loss'], label='Propensity Loss', alpha=0.8)\n",
    "ax2.plot(history['targeted_loss'], label='Targeted Reg', alpha=0.8)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('å„éƒ¨åˆ† Loss')\n",
    "ax2.legend()\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: è¯„ä¼°æ¨¡å‹æ€§èƒ½\n",
    "\n",
    "### 8.1 CATE é¢„æµ‹è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cate_prediction(model, scaler, data):\n",
    "    \"\"\"\n",
    "    è¯„ä¼° CATE é¢„æµ‹æ€§èƒ½\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    X_scaled = torch.FloatTensor(scaler.transform(data['X']))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # é¢„æµ‹ CATE\n",
    "        pred_cate = model.predict_cate(X_scaled, reference_treatment=0)\n",
    "        pred_cate = pred_cate.numpy()\n",
    "    \n",
    "    true_cate = data['true_cate']\n",
    "    \n",
    "    results = {}\n",
    "    treatment_names = ['5æŠ˜åˆ¸', '7æŠ˜åˆ¸', 'æ»¡å‡åˆ¸']\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"CATE é¢„æµ‹è¯„ä¼°ç»“æœ\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, name in enumerate(treatment_names):\n",
    "        # RMSE\n",
    "        rmse = np.sqrt(np.mean((pred_cate[:, i] - true_cate[:, i]) ** 2))\n",
    "        # MAE\n",
    "        mae = np.mean(np.abs(pred_cate[:, i] - true_cate[:, i]))\n",
    "        # ç›¸å…³ç³»æ•°\n",
    "        corr = np.corrcoef(pred_cate[:, i], true_cate[:, i])[0, 1]\n",
    "        # å‡å€¼åå·®\n",
    "        bias = np.mean(pred_cate[:, i]) - np.mean(true_cate[:, i])\n",
    "        \n",
    "        results[name] = {'rmse': rmse, 'mae': mae, 'corr': corr, 'bias': bias}\n",
    "        \n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  RMSE: {rmse:.3f}\")\n",
    "        print(f\"  MAE:  {mae:.3f}\")\n",
    "        print(f\"  ç›¸å…³ç³»æ•°: {corr:.3f}\")\n",
    "        print(f\"  å‡å€¼åå·®: {bias:.3f} (çœŸå®å‡å€¼: {np.mean(true_cate[:, i]):.3f})\")\n",
    "    \n",
    "    return pred_cate, results\n",
    "\n",
    "pred_cate, eval_results = evaluate_cate_prediction(model, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– CATE é¢„æµ‹ vs çœŸå®\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "treatment_names = ['5æŠ˜åˆ¸', '7æŠ˜åˆ¸', 'æ»¡å‡åˆ¸']\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
    "\n",
    "for i, (name, color) in enumerate(zip(treatment_names, colors)):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # æ•£ç‚¹å›¾\n",
    "    ax.scatter(data['true_cate'][:, i], pred_cate[:, i], \n",
    "              alpha=0.3, s=10, c=color)\n",
    "    \n",
    "    # å¯¹è§’çº¿\n",
    "    min_val = min(data['true_cate'][:, i].min(), pred_cate[:, i].min())\n",
    "    max_val = max(data['true_cate'][:, i].max(), pred_cate[:, i].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='å®Œç¾é¢„æµ‹')\n",
    "    \n",
    "    ax.set_xlabel('çœŸå® CATE')\n",
    "    ax.set_ylabel('é¢„æµ‹ CATE')\n",
    "    ax.set_title(f'{name}\\nCorr: {eval_results[name][\"corr\"]:.3f}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle('CATE é¢„æµ‹ vs çœŸå®', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 æœ€ä¼˜å¤„ç†é€‰æ‹©è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_optimal_treatment_selection(model, scaler, data):\n",
    "    \"\"\"\n",
    "    è¯„ä¼°æœ€ä¼˜å¤„ç†é€‰æ‹©æ€§èƒ½\n",
    "    \n",
    "    å…³é”®æŒ‡æ ‡ï¼š\n",
    "    - æœ€ä¼˜å¤„ç†é€‰æ‹©å‡†ç¡®ç‡\n",
    "    - Value å‡½æ•°æå‡ï¼ˆä½¿ç”¨æ¨¡å‹é€‰æ‹© vs éšæœº vs å…¨å‘ï¼‰\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    X_scaled = torch.FloatTensor(scaler.transform(data['X']))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, pred_mus = model(X_scaled)\n",
    "        pred_mus = pred_mus.numpy()\n",
    "    \n",
    "    # çœŸå®æ½œåœ¨ç»“æœ\n",
    "    true_mus = data['true_mu']\n",
    "    \n",
    "    # æ¨¡å‹æ¨èçš„æœ€ä¼˜å¤„ç†\n",
    "    pred_optimal = np.argmax(pred_mus, axis=1)\n",
    "    \n",
    "    # çœŸå®æœ€ä¼˜å¤„ç†\n",
    "    true_optimal = np.argmax(true_mus, axis=1)\n",
    "    \n",
    "    # æœ€ä¼˜å¤„ç†é€‰æ‹©å‡†ç¡®ç‡\n",
    "    accuracy = np.mean(pred_optimal == true_optimal)\n",
    "    \n",
    "    # Value å‡½æ•°è®¡ç®—\n",
    "    n_samples = len(true_mus)\n",
    "    \n",
    "    # 1. ä½¿ç”¨æ¨¡å‹æ¨è\n",
    "    value_model = np.mean([true_mus[i, pred_optimal[i]] for i in range(n_samples)])\n",
    "    \n",
    "    # 2. éšæœºé€‰æ‹©\n",
    "    np.random.seed(42)\n",
    "    random_treatment = np.random.randint(0, 4, n_samples)\n",
    "    value_random = np.mean([true_mus[i, random_treatment[i]] for i in range(n_samples)])\n",
    "    \n",
    "    # 3. å…¨éƒ¨ä¸å‘åˆ¸\n",
    "    value_no_treatment = np.mean(true_mus[:, 0])\n",
    "    \n",
    "    # 4. å…¨éƒ¨å‘5æŠ˜åˆ¸\n",
    "    value_all_50off = np.mean(true_mus[:, 1])\n",
    "    \n",
    "    # 5. Oracleï¼ˆçœŸå®æœ€ä¼˜ï¼‰\n",
    "    value_oracle = np.mean([true_mus[i, true_optimal[i]] for i in range(n_samples)])\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"æœ€ä¼˜å¤„ç†é€‰æ‹©è¯„ä¼°\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\næœ€ä¼˜å¤„ç†é€‰æ‹©å‡†ç¡®ç‡: {accuracy:.2%}\")\n",
    "    print(f\"\\nValue å‡½æ•°å¯¹æ¯” (æœŸæœ›ç»“æœ):\")\n",
    "    print(f\"  éšæœºé€‰æ‹©:      {value_random:.2f}\")\n",
    "    print(f\"  å…¨éƒ¨ä¸å‘åˆ¸:    {value_no_treatment:.2f}\")\n",
    "    print(f\"  å…¨å‘5æŠ˜åˆ¸:     {value_all_50off:.2f}\")\n",
    "    print(f\"  æ¨¡å‹æ¨è:      {value_model:.2f}\")\n",
    "    print(f\"  Oracle(æœ€ä¼˜): {value_oracle:.2f}\")\n",
    "    print(f\"\\næ¨¡å‹ vs éšæœº æå‡: {(value_model - value_random) / value_random:.1%}\")\n",
    "    print(f\"æ¨¡å‹ vs Oracle å·®è·: {(value_oracle - value_model) / value_oracle:.1%}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'value_model': value_model,\n",
    "        'value_random': value_random,\n",
    "        'value_no_treatment': value_no_treatment,\n",
    "        'value_all_50off': value_all_50off,\n",
    "        'value_oracle': value_oracle,\n",
    "        'pred_optimal': pred_optimal,\n",
    "        'true_optimal': true_optimal\n",
    "    }\n",
    "\n",
    "selection_results = evaluate_optimal_treatment_selection(model, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ç­–ç•¥å¯¹æ¯”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Value å‡½æ•°å¯¹æ¯”\n",
    "ax1 = axes[0]\n",
    "strategies = ['éšæœº', 'ä¸å‘åˆ¸', 'å…¨å‘5æŠ˜', 'æ¨¡å‹æ¨è', 'Oracle']\n",
    "values = [\n",
    "    selection_results['value_random'],\n",
    "    selection_results['value_no_treatment'],\n",
    "    selection_results['value_all_50off'],\n",
    "    selection_results['value_model'],\n",
    "    selection_results['value_oracle']\n",
    "]\n",
    "colors = ['#95a5a6', '#e74c3c', '#f39c12', '#2ecc71', '#9b59b6']\n",
    "bars = ax1.bar(strategies, values, color=colors)\n",
    "ax1.set_ylabel('æœŸæœ›ç»“æœ (GMV)')\n",
    "ax1.set_title('ä¸åŒç­–ç•¥çš„æœŸæœ›ç»“æœå¯¹æ¯”')\n",
    "ax1.axhline(y=selection_results['value_model'], color='#2ecc71', linestyle='--', alpha=0.5)\n",
    "\n",
    "# æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "for bar, val in zip(bars, values):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2, \n",
    "            f'{val:.1f}', ha='center', va='bottom')\n",
    "\n",
    "# æœ€ä¼˜å¤„ç†åˆ†å¸ƒå¯¹æ¯”\n",
    "ax2 = axes[1]\n",
    "treatment_names = ['ä¸å‘åˆ¸', '5æŠ˜åˆ¸', '7æŠ˜åˆ¸', 'æ»¡å‡åˆ¸']\n",
    "x = np.arange(4)\n",
    "width = 0.35\n",
    "\n",
    "true_dist = np.bincount(selection_results['true_optimal'], minlength=4) / len(selection_results['true_optimal'])\n",
    "pred_dist = np.bincount(selection_results['pred_optimal'], minlength=4) / len(selection_results['pred_optimal'])\n",
    "\n",
    "ax2.bar(x - width/2, true_dist, width, label='çœŸå®æœ€ä¼˜', color='#3498db', alpha=0.8)\n",
    "ax2.bar(x + width/2, pred_dist, width, label='æ¨¡å‹æ¨è', color='#e74c3c', alpha=0.8)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(treatment_names)\n",
    "ax2.set_ylabel('æ¯”ä¾‹')\n",
    "ax2.set_title('æœ€ä¼˜å¤„ç†åˆ†å¸ƒå¯¹æ¯”')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: é«˜çº§æŠ€å·§ï¼šå¤„ç†ç±»åˆ«ä¸å¹³è¡¡\n",
    "\n",
    "åœ¨å®é™…ä¸šåŠ¡ä¸­ï¼Œä¸åŒå¤„ç†çš„æ ·æœ¬é‡å¯èƒ½ä¸¥é‡ä¸å¹³è¡¡ã€‚ä¸‹é¢ä»‹ç»å‡ ç§å¤„ç†æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTreatmentDragonNetLossWithBalancing(nn.Module):\n",
    "    \"\"\"\n",
    "    å¸¦ç±»åˆ«å¹³è¡¡çš„ Multi-Treatment DragonNet Loss\n",
    "    \n",
    "    æ”¹è¿›ç‚¹ï¼š\n",
    "    1. å€¾å‘å¾—åˆ† Loss ä½¿ç”¨ç±»åˆ«æƒé‡\n",
    "    2. Outcome Loss ä½¿ç”¨å¤„ç†ç»„æƒé‡\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=1.0, beta=1.0, eps=1e-6, treatment_weights=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.eps = eps\n",
    "        self.treatment_weights = treatment_weights  # ç±»åˆ«æƒé‡\n",
    "    \n",
    "    def forward(self, propensity, mus, treatment, outcome):\n",
    "        batch_size = treatment.shape[0]\n",
    "        \n",
    "        # 1. Outcome Loss with balancing\n",
    "        mu_observed = mus.gather(1, treatment.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        if self.treatment_weights is not None:\n",
    "            # æ¯ä¸ªæ ·æœ¬æ ¹æ®å…¶å¤„ç†ç»„è·å¾—æƒé‡\n",
    "            sample_weights = self.treatment_weights[treatment]\n",
    "            outcome_loss = (sample_weights * (mu_observed - outcome) ** 2).mean()\n",
    "        else:\n",
    "            outcome_loss = F.mse_loss(mu_observed, outcome)\n",
    "        \n",
    "        # 2. Propensity Loss with class weights\n",
    "        if self.treatment_weights is not None:\n",
    "            propensity_loss = F.cross_entropy(\n",
    "                propensity + self.eps, treatment,\n",
    "                weight=self.treatment_weights\n",
    "            )\n",
    "        else:\n",
    "            propensity_loss = F.cross_entropy(propensity + self.eps, treatment)\n",
    "        \n",
    "        # 3. Targeted Regularization\n",
    "        pi_observed = propensity.gather(1, treatment.unsqueeze(1)).squeeze(1)\n",
    "        pi_observed = torch.clamp(pi_observed, min=self.eps)\n",
    "        correction = (1.0 - pi_observed) / pi_observed * (outcome - mu_observed)\n",
    "        targeted_term = mu_observed - outcome + correction\n",
    "        targeted_loss = (targeted_term ** 2).mean()\n",
    "        \n",
    "        total_loss = outcome_loss + self.alpha * propensity_loss + self.beta * targeted_loss\n",
    "        \n",
    "        return total_loss, {\n",
    "            'outcome_loss': outcome_loss.item(),\n",
    "            'propensity_loss': propensity_loss.item(),\n",
    "            'targeted_loss': targeted_loss.item(),\n",
    "            'total_loss': total_loss.item()\n",
    "        }\n",
    "\n",
    "# è®¡ç®—ç±»åˆ«æƒé‡ï¼ˆé€†é¢‘ç‡ï¼‰\n",
    "treatment_counts = np.bincount(data['treatment'])\n",
    "treatment_weights = torch.FloatTensor(1.0 / treatment_counts)\n",
    "treatment_weights = treatment_weights / treatment_weights.sum() * 4  # å½’ä¸€åŒ–\n",
    "\n",
    "print(\"å¤„ç†ç»„æ ·æœ¬åˆ†å¸ƒ:\")\n",
    "for i, (count, weight) in enumerate(zip(treatment_counts, treatment_weights.numpy())):\n",
    "    print(f\"  T={i}: {count} æ ·æœ¬, æƒé‡ = {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 10: ä¸å…¶ä»–æ–¹æ³•å¯¹æ¯”\n",
    "\n",
    "### ğŸ§ª TODO ç»ƒä¹  3: å®ç° Multi-Treatment T-Learner ä½œä¸ºåŸºçº¿\n",
    "\n",
    "ä¸ºäº†å¯¹æ¯”ï¼Œè¯·å®ç°ä¸€ä¸ªç®€å•çš„ Multi-Treatment T-Learnerã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.ensemble import GradientBoostingRegressor\n\ndef multi_treatment_t_learner(X, treatment, outcome, X_eval):\n    \"\"\"\n    Multi-Treatment T-Learner\n    \n    ä¸ºæ¯ç§å¤„ç†è®­ç»ƒä¸€ä¸ªç‹¬ç«‹æ¨¡å‹\n    \n    Args:\n        X: è®­ç»ƒç‰¹å¾\n        treatment: å¤„ç† (0, 1, 2, 3)\n        outcome: ç»“æœ\n        X_eval: è¯„ä¼°ç‰¹å¾\n        \n    Returns:\n        pred_mus: (n_eval, num_treatments) - æ¯ç§å¤„ç†çš„é¢„æµ‹ç»“æœ\n        pred_cate: (n_eval, num_treatments - 1) - ç›¸å¯¹ T=0 çš„ CATE\n    \"\"\"\n    # å®ç° T-Learner\n    num_treatments = 4\n    n_eval = len(X_eval)\n    pred_mus = np.zeros((n_eval, num_treatments))\n    \n    # ä¸ºæ¯ç§å¤„ç†ç­›é€‰æ ·æœ¬å¹¶è®­ç»ƒæ¨¡å‹\n    for k in range(num_treatments):\n        # 1. ä¸ºæ¯ç§å¤„ç†ç­›é€‰æ ·æœ¬: mask = (treatment == k)\n        mask = (treatment == k)\n        \n        # 2. è®­ç»ƒæ¨¡å‹: model.fit(X[mask], outcome[mask])\n        model = GradientBoostingRegressor(n_estimators=100, max_depth=4, random_state=42)\n        model.fit(X[mask], outcome[mask])\n        \n        # 3. é¢„æµ‹: pred_mus[:, k] = model.predict(X_eval)\n        pred_mus[:, k] = model.predict(X_eval)\n    \n    # è®¡ç®— CATEï¼ˆç›¸å¯¹äº T=0ï¼‰\n    pred_cate = pred_mus[:, 1:] - pred_mus[:, 0:1]\n    \n    return pred_mus, pred_cate\n\nprint(\"âœ… multi_treatment_t_learner å‡½æ•°å®šä¹‰å®Œæˆï¼ˆå·²å®Œæˆ TODO éƒ¨åˆ†ï¼‰\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ å‚è€ƒç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# å‚è€ƒç­”æ¡ˆï¼šMulti-Treatment T-Learner\n",
    "# ============================================================\n",
    "\n",
    "def multi_treatment_t_learner(X, treatment, outcome, X_eval):\n",
    "    \"\"\"\n",
    "    Multi-Treatment T-Learner - å®Œæ•´å®ç°\n",
    "    \"\"\"\n",
    "    num_treatments = 4\n",
    "    n_eval = len(X_eval)\n",
    "    pred_mus = np.zeros((n_eval, num_treatments))\n",
    "    \n",
    "    for k in range(num_treatments):\n",
    "        mask = treatment == k\n",
    "        model = GradientBoostingRegressor(n_estimators=100, max_depth=4, random_state=42)\n",
    "        model.fit(X[mask], outcome[mask])\n",
    "        pred_mus[:, k] = model.predict(X_eval)\n",
    "    \n",
    "    pred_cate = pred_mus[:, 1:] - pred_mus[:, 0:1]\n",
    "    \n",
    "    return pred_mus, pred_cate\n",
    "\n",
    "# è¿è¡Œ T-Learner\n",
    "print(\"è®­ç»ƒ T-Learner...\")\n",
    "t_learner_mus, t_learner_cate = multi_treatment_t_learner(\n",
    "    data['X'], data['treatment'], data['outcome'], data['X']\n",
    ")\n",
    "print(\"âœ… T-Learner è®­ç»ƒå®Œæˆ\")\n",
    "\n",
    "# å¯¹æ¯”\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"æ–¹æ³•å¯¹æ¯”: DragonNet vs T-Learner\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "treatment_names = ['5æŠ˜åˆ¸', '7æŠ˜åˆ¸', 'æ»¡å‡åˆ¸']\n",
    "\n",
    "print(f\"\\n{'æ–¹æ³•':<15} {'å¤„ç†':<10} {'RMSE':<10} {'ç›¸å…³ç³»æ•°':<10}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for i, name in enumerate(treatment_names):\n",
    "    # DragonNet\n",
    "    rmse_dn = np.sqrt(np.mean((pred_cate[:, i] - data['true_cate'][:, i]) ** 2))\n",
    "    corr_dn = np.corrcoef(pred_cate[:, i], data['true_cate'][:, i])[0, 1]\n",
    "    \n",
    "    # T-Learner\n",
    "    rmse_tl = np.sqrt(np.mean((t_learner_cate[:, i] - data['true_cate'][:, i]) ** 2))\n",
    "    corr_tl = np.corrcoef(t_learner_cate[:, i], data['true_cate'][:, i])[0, 1]\n",
    "    \n",
    "    print(f\"{'DragonNet':<15} {name:<10} {rmse_dn:<10.3f} {corr_dn:<10.3f}\")\n",
    "    print(f\"{'T-Learner':<15} {name:<10} {rmse_tl:<10.3f} {corr_tl:<10.3f}\")\n",
    "    print(\"-\" * 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 11: ä¸šåŠ¡åº”ç”¨ï¼šæ™ºèƒ½å‘åˆ¸ç­–ç•¥\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬å°†æ¨¡å‹åº”ç”¨åˆ°å®é™…ä¸šåŠ¡åœºæ™¯ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coupon_strategy_report(model, scaler, data):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆæ™ºèƒ½å‘åˆ¸ç­–ç•¥æŠ¥å‘Š\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    X_scaled = torch.FloatTensor(scaler.transform(data['X']))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        propensity, pred_mus = model(X_scaled)\n",
    "        pred_cate = model.predict_cate(X_scaled, reference_treatment=0)\n",
    "        \n",
    "    pred_mus = pred_mus.numpy()\n",
    "    pred_cate = pred_cate.numpy()\n",
    "    \n",
    "    # æœ€ä¼˜ç­–ç•¥é€‰æ‹©\n",
    "    optimal_treatment = np.argmax(pred_mus, axis=1)\n",
    "    \n",
    "    # è®¡ç®—ç­–ç•¥æ”¶ç›Šï¼ˆè€ƒè™‘æˆæœ¬ï¼‰\n",
    "    # å‡è®¾æˆæœ¬ï¼š5æŠ˜åˆ¸æˆæœ¬5å…ƒï¼Œ7æŠ˜åˆ¸æˆæœ¬3å…ƒï¼Œæ»¡å‡åˆ¸æˆæœ¬2å…ƒ\n",
    "    costs = np.array([0, 5, 3, 2])\n",
    "    net_values = pred_mus - costs\n",
    "    optimal_with_cost = np.argmax(net_values, axis=1)\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"æ™ºèƒ½å‘åˆ¸ç­–ç•¥æŠ¥å‘Š\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\n1. ç­–ç•¥åˆ†å¸ƒï¼ˆä¸è€ƒè™‘æˆæœ¬ï¼‰:\")\n",
    "    for i, name in enumerate(['ä¸å‘åˆ¸', '5æŠ˜åˆ¸', '7æŠ˜åˆ¸', 'æ»¡å‡åˆ¸']):\n",
    "        count = np.sum(optimal_treatment == i)\n",
    "        pct = count / len(optimal_treatment) * 100\n",
    "        print(f\"   {name}: {count:5d} ({pct:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n2. ç­–ç•¥åˆ†å¸ƒï¼ˆè€ƒè™‘æˆæœ¬ï¼‰:\")\n",
    "    for i, name in enumerate(['ä¸å‘åˆ¸', '5æŠ˜åˆ¸', '7æŠ˜åˆ¸', 'æ»¡å‡åˆ¸']):\n",
    "        count = np.sum(optimal_with_cost == i)\n",
    "        pct = count / len(optimal_with_cost) * 100\n",
    "        print(f\"   {name}: {count:5d} ({pct:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n3. ç”¨æˆ·ç¾¤ä½“åˆ†æ:\")\n",
    "    # æŒ‰ä»·æ ¼æ•æ„Ÿåº¦åˆ†ç»„\n",
    "    price_sens = data['X'][:, 1]\n",
    "    low_sens = price_sens < np.percentile(price_sens, 33)\n",
    "    high_sens = price_sens > np.percentile(price_sens, 67)\n",
    "    \n",
    "    print(\"\\n   ä½ä»·æ ¼æ•æ„Ÿåº¦ç”¨æˆ·:\")\n",
    "    for i, name in enumerate(['ä¸å‘åˆ¸', '5æŠ˜åˆ¸', '7æŠ˜åˆ¸', 'æ»¡å‡åˆ¸']):\n",
    "        pct = np.sum(optimal_with_cost[low_sens] == i) / np.sum(low_sens) * 100\n",
    "        print(f\"      {name}: {pct:.1f}%\")\n",
    "    \n",
    "    print(\"\\n   é«˜ä»·æ ¼æ•æ„Ÿåº¦ç”¨æˆ·:\")\n",
    "    for i, name in enumerate(['ä¸å‘åˆ¸', '5æŠ˜åˆ¸', '7æŠ˜åˆ¸', 'æ»¡å‡åˆ¸']):\n",
    "        pct = np.sum(optimal_with_cost[high_sens] == i) / np.sum(high_sens) * 100\n",
    "        print(f\"      {name}: {pct:.1f}%\")\n",
    "    \n",
    "    print(\"\\n4. é¢„æœŸæ•ˆæœï¼ˆç›¸æ¯”éšæœºå‘åˆ¸ï¼‰:\")\n",
    "    value_model = np.mean([net_values[i, optimal_with_cost[i]] for i in range(len(net_values))])\n",
    "    value_random = np.mean([net_values[i, np.random.randint(4)] for i in range(len(net_values))])\n",
    "    print(f\"   æ¨¡å‹æ¨è: {value_model:.2f}\")\n",
    "    print(f\"   éšæœºå‘åˆ¸: {value_random:.2f}\")\n",
    "    print(f\"   æå‡: {(value_model - value_random):.2f} ({(value_model - value_random) / abs(value_random) * 100:.1f}%)\")\n",
    "    \n",
    "    return optimal_treatment, optimal_with_cost\n",
    "\n",
    "optimal_treatment, optimal_with_cost = generate_coupon_strategy_report(model, scaler, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ç­–ç•¥åˆ†å¸ƒä¸ç”¨æˆ·ç‰¹å¾çš„å…³ç³»\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ç­–ç•¥ä¸è´­ä¹°åŠ›çš„å…³ç³»\n",
    "ax1 = axes[0]\n",
    "for i, (name, color) in enumerate(zip(['ä¸å‘åˆ¸', '5æŠ˜åˆ¸', '7æŠ˜åˆ¸', 'æ»¡å‡åˆ¸'], \n",
    "                                      ['#95a5a6', '#e74c3c', '#3498db', '#2ecc71'])):\n",
    "    mask = optimal_with_cost == i\n",
    "    ax1.scatter(data['X'][mask, 0], data['X'][mask, 1], \n",
    "               alpha=0.4, s=10, c=color, label=name)\n",
    "ax1.set_xlabel('è´­ä¹°åŠ›')\n",
    "ax1.set_ylabel('ä»·æ ¼æ•æ„Ÿåº¦')\n",
    "ax1.set_title('æœ€ä¼˜å‘åˆ¸ç­–ç•¥åˆ†å¸ƒ')\n",
    "ax1.legend()\n",
    "\n",
    "# CATE çƒ­åŠ›å›¾ - 5æŠ˜åˆ¸\n",
    "ax2 = axes[1]\n",
    "# åˆ›å»ºç½‘æ ¼\n",
    "x_range = np.linspace(data['X'][:, 0].min(), data['X'][:, 0].max(), 50)\n",
    "y_range = np.linspace(data['X'][:, 1].min(), data['X'][:, 1].max(), 50)\n",
    "xx, yy = np.meshgrid(x_range, y_range)\n",
    "\n",
    "# ç”Ÿæˆé¢„æµ‹è¾“å…¥\n",
    "grid_X = np.zeros((len(x_range) * len(y_range), 10))\n",
    "grid_X[:, 0] = xx.ravel()\n",
    "grid_X[:, 1] = yy.ravel()\n",
    "\n",
    "# é¢„æµ‹ CATE\n",
    "model.eval()\n",
    "grid_X_scaled = torch.FloatTensor(scaler.transform(grid_X))\n",
    "with torch.no_grad():\n",
    "    grid_cate = model.predict_cate(grid_X_scaled, reference_treatment=0)\n",
    "grid_cate = grid_cate[:, 0].numpy().reshape(xx.shape)  # 5æŠ˜åˆ¸çš„ CATE\n",
    "\n",
    "im = ax2.contourf(xx, yy, grid_cate, levels=20, cmap='RdYlGn')\n",
    "plt.colorbar(im, ax=ax2, label='CATE (5æŠ˜åˆ¸ vs ä¸å‘åˆ¸)')\n",
    "ax2.set_xlabel('è´­ä¹°åŠ›')\n",
    "ax2.set_ylabel('ä»·æ ¼æ•æ„Ÿåº¦')\n",
    "ax2.set_title('5æŠ˜åˆ¸ CATE çƒ­åŠ›å›¾')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nè§‚å¯Ÿï¼š\")\n",
    "print(\"1. é«˜ä»·æ ¼æ•æ„Ÿåº¦ç”¨æˆ·å¯¹æŠ˜æ‰£åˆ¸å“åº”æ›´å¼º\")\n",
    "print(\"2. ä¸åŒç”¨æˆ·ç¾¤ä½“æœ€ä¼˜ç­–ç•¥ä¸åŒï¼Œä½“ç°äº†ç²¾ç»†åŒ–è¿è¥çš„ä»·å€¼\")\n",
    "print(\"3. CATE çƒ­åŠ›å›¾å±•ç¤ºäº†å¤„ç†æ•ˆæœçš„å¼‚è´¨æ€§\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¡ æ€è€ƒé¢˜\n",
    "\n",
    "1. **æ¶æ„è®¾è®¡**ï¼šå¦‚æœå¤„ç†æ•°é‡å¾ˆå¤šï¼ˆå¦‚ 100 ç§ï¼‰ï¼Œå¦‚ä½•æ”¹è¿›ç½‘ç»œæ¶æ„ï¼Ÿ\n",
    "   - æç¤ºï¼šè€ƒè™‘å¤„ç† Embeddingã€å‚æ•°å…±äº«\n",
    "\n",
    "2. **Loss è®¾è®¡**ï¼šå¦‚æœæŸäº›å¤„ç†çš„æ ·æœ¬é‡æå°‘ï¼ˆå¦‚ 1%ï¼‰ï¼Œå¦‚ä½•ä¿®æ”¹ Lossï¼Ÿ\n",
    "   - æç¤ºï¼šå‚è€ƒ Deep Dive 01 çš„ Focal Loss æ€è·¯\n",
    "\n",
    "3. **ä¸šåŠ¡çº¦æŸ**ï¼šå¦‚æœæœ‰é¢„ç®—çº¦æŸï¼ˆå¦‚æœ€å¤šç»™ 30% ç”¨æˆ·å‘åˆ¸ï¼‰ï¼Œå¦‚ä½•ä¿®æ”¹ç­–ç•¥ï¼Ÿ\n",
    "   - æç¤ºï¼šè€ƒè™‘å¸¦çº¦æŸçš„ä¼˜åŒ–é—®é¢˜\n",
    "\n",
    "4. **å› æœè¯†åˆ«**ï¼šå¦‚æœå­˜åœ¨æœªè§‚æµ‹æ··æ·†å˜é‡ï¼ŒDragonNet çš„ä¼°è®¡ä¼šæœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ\n",
    "   - æç¤ºï¼šæ— å¯å¿½ç•¥æ€§å‡è®¾\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ æ€»ç»“\n",
    "\n",
    "æœ¬ notebook æˆ‘ä»¬å­¦ä¹ äº†ï¼š\n",
    "\n",
    "1. **DragonNet åŸç†**ï¼šå…±äº«è¡¨ç¤ºå±‚ + å€¾å‘å¾—åˆ†å¤´ + ç»“æœé¢„æµ‹å¤´\n",
    "\n",
    "2. **å¤šå¤„ç†æ‰©å±•**ï¼š\n",
    "   - å€¾å‘å¾—åˆ†ï¼šäºŒåˆ†ç±» â†’ å¤šåˆ†ç±»\n",
    "   - ç»“æœé¢„æµ‹ï¼š2 ä¸ªå¤´ â†’ K ä¸ªå¤´\n",
    "   - Targeted Regï¼šæ³›åŒ–åˆ°å¤šå¤„ç†\n",
    "\n",
    "3. **å®ç°ç»†èŠ‚**ï¼š\n",
    "   - ä½¿ç”¨ `nn.ModuleList` ç®¡ç†å¤šä¸ªå¤´\n",
    "   - ä½¿ç”¨ `gather` é€‰æ‹©è§‚æµ‹å¤„ç†çš„é¢„æµ‹\n",
    "   - æ•°å€¼ç¨³å®šæ€§å¤„ç†ï¼ˆepsã€clampï¼‰\n",
    "\n",
    "4. **ä¸šåŠ¡åº”ç”¨**ï¼š\n",
    "   - æœ€ä¼˜å¤„ç†é€‰æ‹©\n",
    "   - è€ƒè™‘æˆæœ¬çš„ç­–ç•¥ä¼˜åŒ–\n",
    "   - ç”¨æˆ·ç¾¤ä½“åˆ†æ\n",
    "\n",
    "### é¢è¯•è¦ç‚¹\n",
    "\n",
    "- èƒ½è§£é‡Š DragonNet çš„è®¾è®¡åŠ¨æœºå’Œæ¶æ„\n",
    "- èƒ½æ‰‹å†™å¤šå¤„ç†æ‰©å±•çš„æ ¸å¿ƒä»£ç \n",
    "- ç†è§£ Targeted Regularization çš„ä½œç”¨\n",
    "- èƒ½è®¨è®ºå®é™…åº”ç”¨ä¸­çš„æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”— å‚è€ƒèµ„æ–™\n",
    "\n",
    "1. Shi, C., Blei, D. M., & Veitch, V. (2019). Adapting Neural Networks for the Estimation of Treatment Effects. NeurIPS.\n",
    "2. Johansson, F. D., Shalit, U., & Sontag, D. (2016). Learning Representations for Counterfactual Inference. ICML.\n",
    "3. Kunzel, S. R., et al. (2019). Metalearners for Estimating Heterogeneous Treatment Effects using Machine Learning. PNAS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}