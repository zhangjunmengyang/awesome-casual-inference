{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VCNet - 连续处理效应的深度学习方法\n",
    "\n",
    "---\n",
    "\n",
    "## 学习目标\n",
    "\n",
    "完成本练习后，你将能够：\n",
    "\n",
    "1. 理解连续处理 (Continuous Treatment) 与二元处理的本质区别\n",
    "2. 掌握剂量-响应曲线 (Dose-Response Curve) 的概念\n",
    "3. 理解 VCNet 的变系数网络设计\n",
    "4. 实现 VCNet 并估计连续处理效应\n",
    "5. 应用于真实业务场景：优惠券面额优化\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 真实场景：优惠券面额该发多少？\n",
    "\n",
    "### 场景描述\n",
    "\n",
    "你是某电商平台的增长负责人，手握 500 万优惠券预算。\n",
    "\n",
    "**传统做法**：\n",
    "- 要么发 10 元券，要么不发\n",
    "- 用 Uplift Modeling 区分「发」vs「不发」\n",
    "\n",
    "**新的问题**：\n",
    "> **发 5 元还是 10 元还是 20 元？不同用户的「最优面额」是多少？**\n",
    "\n",
    "这就是**连续处理效应 (Continuous Treatment Effect)** 问题！\n",
    "\n",
    "### 与二元处理的区别\n",
    "\n",
    "| 类型 | 二元处理 | 连续处理 |\n",
    "|------|---------|----------|\n",
    "| **处理变量** | T ∈ {0, 1} | T ∈ [0, ∞) 或 [t_min, t_max] |\n",
    "| **目标** | 估计 Y(1) - Y(0) | 估计整个 Y(t) 曲线 |\n",
    "| **业务问题** | 发不发券？ | 发多少面额？|\n",
    "| **倾向得分** | P(T=1|X) | f(T|X) 概率密度 |\n",
    "| **因果识别** | 更简单 | 需要更强假设 |\n",
    "\n",
    "### 生动比喻：调音量\n",
    "\n",
    "想象你在调音响的音量：\n",
    "\n",
    "- **二元处理**：音量只有「开」和「关」两档\n",
    "- **连续处理**：音量可以从 0 调到 100 任意值\n",
    "\n",
    "问题是：**每个人感觉舒适的音量不同，如何为每个人找到最优音量？**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 核心概念：剂量-响应曲线\n",
    "\n",
    "### 剂量-响应曲线 (Dose-Response Curve)\n",
    "\n",
    "对于个体 $i$，我们想估计：\n",
    "\n",
    "$$\\mu(t, x) = E[Y | T = t, X = x]$$\n",
    "\n",
    "这是一条**曲线**，描述了处理强度 $t$ 与结果 $Y$ 的关系。\n",
    "\n",
    "```\n",
    "    Y (结果)\n",
    "    │\n",
    "    │         ╭───────╮\n",
    "    │       ╭╯         ╲\n",
    "    │     ╭╯            ╲\n",
    "    │   ╭╯               ╲_____\n",
    "    │ ╭╯\n",
    "    │╭╯\n",
    "    └─────────────────────────── T (处理强度/剂量)\n",
    "         ↑       ↑         ↑\n",
    "      起效点   最优点    边际递减\n",
    "```\n",
    "\n",
    "### 连续处理效应\n",
    "\n",
    "**平均剂量-响应函数 (ADRF)**：\n",
    "$$\\mu(t) = E[Y(t)] = E_X[E[Y|T=t, X]]$$\n",
    "\n",
    "**边际处理效应 (Marginal Treatment Effect)**：\n",
    "$$\\frac{\\partial \\mu(t, x)}{\\partial t}$$\n",
    "\n",
    "**最优处理强度**：\n",
    "$$t^*(x) = \\arg\\max_t \\mu(t, x)$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 连续处理的因果识别\n",
    "\n",
    "### 广义倾向得分 (Generalized Propensity Score)\n",
    "\n",
    "对于连续处理，倾向得分变成**概率密度函数**：\n",
    "\n",
    "$$e(t|x) = f_{T|X}(t|x)$$\n",
    "\n",
    "### 识别假设\n",
    "\n",
    "1. **弱无混淆 (Weak Unconfoundedness)**：\n",
    "   $$Y(t) \\perp T | X, \\quad \\forall t$$\n",
    "\n",
    "2. **共同支撑 (Common Support)**：\n",
    "   $$0 < e(t|x) < \\infty, \\quad \\forall t, x$$\n",
    "\n",
    "3. **平滑性 (Smoothness)**：\n",
    "   $$\\mu(t, x) \\text{ 对 } t \\text{ 足够光滑}$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VCNet: Varying Coefficient Network\n",
    "\n",
    "### 核心创新：变系数设计\n",
    "\n",
    "VCNet 的核心思想是：**让神经网络的权重随处理强度变化**。\n",
    "\n",
    "传统神经网络：\n",
    "$$y = W \\cdot \\phi(x)$$\n",
    "\n",
    "VCNet：\n",
    "$$y = W(t) \\cdot \\phi(x)$$\n",
    "\n",
    "其中 $W(t)$ 是**处理强度 $t$ 的函数**！\n",
    "\n",
    "### 架构图解\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                        VCNet 架构                           │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│                                                             │\n",
    "│   输入 X ───→ [表示网络 Φ] ───→ φ(X)                        │\n",
    "│               (与 TARNet 类似)       ╲                      │\n",
    "│                                        ╲                    │\n",
    "│   输入 T ───→ [系数网络 ψ] ───→ W(T) ───→ 点乘 → Ŷ(T)       │\n",
    "│               (Spline 基函数)         ╱                     │\n",
    "│                                      ╱                      │\n",
    "│                                                             │\n",
    "│   关键: W(T) · φ(X) 实现了「处理-特征」的交互建模            │\n",
    "│                                                             │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### 为什么用样条基函数？\n",
    "\n",
    "为了让 $W(t)$ 对 $t$ 足够光滑，VCNet 使用**样条基函数 (Spline Basis)**：\n",
    "\n",
    "$$W(t) = \\sum_{k=1}^{K} \\alpha_k \\cdot B_k(t)$$\n",
    "\n",
    "其中 $B_k(t)$ 是第 $k$ 个样条基函数。\n",
    "\n",
    "这保证了剂量-响应曲线是**光滑**的，避免了 overfitting。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境准备\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.interpolate import BSpline\n",
    "from typing import Tuple, Dict, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 颜色方案\n",
    "COLORS = {\n",
    "    'primary': '#2D9CDB',\n",
    "    'success': '#27AE60',\n",
    "    'danger': '#EB5757',\n",
    "    'warning': '#F2994A',\n",
    "    'info': '#9B51E0',\n",
    "}\n",
    "\n",
    "print(f\"PyTorch 版本: {torch.__version__}\")\n",
    "print(\"环境准备完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: 数据生成\n",
    "\n",
    "### 场景：优惠券面额优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coupon_data(n_samples: int = 5000, seed: int = 42) -> Tuple:\n",
    "    \"\"\"\n",
    "    生成优惠券面额优化数据\n",
    "    \n",
    "    场景：\n",
    "    - X: 用户特征（购买力、活跃度、历史消费等）\n",
    "    - T: 优惠券面额（0-50 元）\n",
    "    - Y: 用户消费金额\n",
    "    \n",
    "    真实关系：\n",
    "    - 不同购买力的用户，最优面额不同\n",
    "    - 高购买力用户：边际递减快\n",
    "    - 低购买力用户：需要更大面额才能激活\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 用户特征 (5 维)\n",
    "    X = np.random.randn(n_samples, 5)\n",
    "    # X[:, 0]: 购买力（标准化）\n",
    "    # X[:, 1]: 活跃度\n",
    "    # X[:, 2]: 历史消费金额\n",
    "    # X[:, 3]: 价格敏感度\n",
    "    # X[:, 4]: 品类偏好\n",
    "    \n",
    "    # 模拟真实的优惠券分配（非随机）\n",
    "    # 活跃用户更可能收到优惠券，且面额更高\n",
    "    propensity_mean = 15 + 5 * X[:, 1] + 3 * X[:, 3]  # 倾向性影响面额\n",
    "    propensity_mean = np.clip(propensity_mean, 0, 50)\n",
    "    T = np.clip(propensity_mean + np.random.randn(n_samples) * 8, 0, 50)\n",
    "    \n",
    "    # 归一化到 [0, 1] 用于模型\n",
    "    T_normalized = T / 50.0\n",
    "    \n",
    "    # 真实的剂量-响应关系（复杂的非线性）\n",
    "    def true_dose_response(t, x):\n",
    "        \"\"\"\n",
    "        真实的剂量-响应函数\n",
    "        \n",
    "        - 基础消费取决于用户特征\n",
    "        - 优惠券效应有边际递减\n",
    "        - 不同用户的最优面额不同\n",
    "        \"\"\"\n",
    "        # 基础消费\n",
    "        base = 100 + 20 * x[:, 0] + 15 * x[:, 2]\n",
    "        \n",
    "        # 优惠券效应（对数函数 = 边际递减）\n",
    "        # 高价格敏感度用户对优惠券响应更大\n",
    "        sensitivity = 1 + 0.5 * x[:, 3]\n",
    "        coupon_effect = sensitivity * 30 * np.log1p(t * 5)\n",
    "        \n",
    "        # 低购买力用户需要更大面额才能激活（门槛效应）\n",
    "        threshold = np.maximum(0, -x[:, 0] * 0.3)\n",
    "        activation = 1 / (1 + np.exp(-10 * (t - threshold)))\n",
    "        \n",
    "        return base + coupon_effect * activation\n",
    "    \n",
    "    # 生成结果\n",
    "    noise = np.random.randn(n_samples) * 10\n",
    "    Y = true_dose_response(T_normalized, X) + noise\n",
    "    \n",
    "    return X, T, T_normalized, Y, true_dose_response\n",
    "\n",
    "\n",
    "# 生成数据\n",
    "X, T, T_norm, Y, true_dr = generate_coupon_data(n_samples=5000)\n",
    "\n",
    "print(\"数据生成完成！\")\n",
    "print(f\"样本数: {len(X)}\")\n",
    "print(f\"特征维度: {X.shape[1]}\")\n",
    "print(f\"\\n优惠券面额统计:\")\n",
    "print(f\"  范围: [{T.min():.1f}, {T.max():.1f}] 元\")\n",
    "print(f\"  均值: {T.mean():.1f} 元\")\n",
    "print(f\"  标准差: {T.std():.1f} 元\")\n",
    "print(f\"\\n消费金额统计:\")\n",
    "print(f\"  范围: [{Y.min():.1f}, {Y.max():.1f}] 元\")\n",
    "print(f\"  均值: {Y.mean():.1f} 元\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化真实的剂量-响应关系\n",
    "fig = make_subplots(rows=1, cols=2,\n",
    "                    subplot_titles=('优惠券面额分布', '不同用户的剂量-响应曲线'))\n",
    "\n",
    "# 面额分布\n",
    "fig.add_trace(go.Histogram(x=T, nbinsx=30, name='面额分布',\n",
    "                           marker_color=COLORS['primary']), row=1, col=1)\n",
    "\n",
    "# 剂量-响应曲线\n",
    "t_range = np.linspace(0, 1, 50)\n",
    "\n",
    "# 不同用户类型\n",
    "user_types = [\n",
    "    ('高购买力', np.array([[1.5, 0, 1, 0, 0]])),\n",
    "    ('中购买力', np.array([[0, 0, 0, 0, 0]])),\n",
    "    ('低购买力', np.array([[-1.5, 0, -1, 0.5, 0]])),\n",
    "]\n",
    "\n",
    "colors = [COLORS['success'], COLORS['warning'], COLORS['danger']]\n",
    "\n",
    "for (label, x), color in zip(user_types, colors):\n",
    "    x_repeat = np.repeat(x, len(t_range), axis=0)\n",
    "    y_curve = true_dr(t_range, x_repeat)\n",
    "    fig.add_trace(go.Scatter(x=t_range * 50, y=y_curve, name=label,\n",
    "                             line=dict(color=color, width=2)), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text='优惠券面额 (元)', row=1, col=1)\n",
    "fig.update_xaxes(title_text='优惠券面额 (元)', row=1, col=2)\n",
    "fig.update_yaxes(title_text='用户数', row=1, col=1)\n",
    "fig.update_yaxes(title_text='预期消费 (元)', row=1, col=2)\n",
    "\n",
    "fig.update_layout(height=400, template='plotly_white',\n",
    "                  title_text='优惠券数据探索')\n",
    "fig.show()\n",
    "\n",
    "print(\"\"\"\n",
    "📊 观察:\n",
    "1. 优惠券面额呈正态分布，集中在 10-20 元\n",
    "2. 不同用户的剂量-响应曲线形状不同\n",
    "3. 低购买力用户需要更大面额才能激活（有门槛）\n",
    "4. 所有曲线都呈现边际递减\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: VCNet 实现\n",
    "\n",
    "### 2.1 样条基函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruncatedBasis(nn.Module):\n",
    "    \"\"\"\n",
    "    截断幂基函数 (Truncated Power Basis)\n",
    "    \n",
    "    用于生成样条基函数，使得 W(t) 对 t 光滑\n",
    "    \n",
    "    B_k(t) = max(0, t - ξ_k)^p\n",
    "    \n",
    "    其中 ξ_k 是节点 (knots)，p 是多项式阶数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_knots: int = 5, degree: int = 2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_knots = num_knots\n",
    "        self.degree = degree\n",
    "        \n",
    "        # 均匀分布的节点\n",
    "        knots = torch.linspace(0, 1, num_knots + 2)[1:-1]  # 排除边界\n",
    "        self.register_buffer('knots', knots)\n",
    "    \n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        计算基函数值\n",
    "        \n",
    "        Args:\n",
    "            t: 处理强度，形状 (batch_size, 1)\n",
    "        \n",
    "        Returns:\n",
    "            basis: 基函数值，形状 (batch_size, num_knots + degree + 1)\n",
    "        \"\"\"\n",
    "        if len(t.shape) == 1:\n",
    "            t = t.unsqueeze(1)\n",
    "        \n",
    "        batch_size = t.shape[0]\n",
    "        \n",
    "        # 多项式项: 1, t, t^2, ..., t^p\n",
    "        poly_terms = [torch.ones(batch_size, 1, device=t.device)]\n",
    "        for d in range(1, self.degree + 1):\n",
    "            poly_terms.append(t ** d)\n",
    "        \n",
    "        # 截断幂项: max(0, t - ξ_k)^p\n",
    "        truncated_terms = []\n",
    "        for k in range(self.num_knots):\n",
    "            diff = t - self.knots[k]\n",
    "            truncated = torch.relu(diff) ** self.degree\n",
    "            truncated_terms.append(truncated)\n",
    "        \n",
    "        # 拼接所有基函数\n",
    "        basis = torch.cat(poly_terms + truncated_terms, dim=1)\n",
    "        \n",
    "        return basis\n",
    "\n",
    "\n",
    "# 测试基函数\n",
    "basis_fn = TruncatedBasis(num_knots=5, degree=2)\n",
    "t_test = torch.linspace(0, 1, 100).unsqueeze(1)\n",
    "basis_values = basis_fn(t_test)\n",
    "\n",
    "print(f\"基函数数量: {basis_values.shape[1]}\")\n",
    "print(f\"输入形状: {t_test.shape}\")\n",
    "print(f\"输出形状: {basis_values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化基函数\n",
    "fig = go.Figure()\n",
    "\n",
    "t_plot = t_test.numpy().squeeze()\n",
    "basis_plot = basis_values.detach().numpy()\n",
    "\n",
    "for i in range(basis_plot.shape[1]):\n",
    "    fig.add_trace(go.Scatter(x=t_plot, y=basis_plot[:, i],\n",
    "                             name=f'B_{i}', mode='lines'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='截断幂基函数',\n",
    "    xaxis_title='处理强度 t',\n",
    "    yaxis_title='基函数值',\n",
    "    template='plotly_white',\n",
    "    height=400\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"\"\"\n",
    "📊 基函数解释:\n",
    "- B_0 = 1 (常数项)\n",
    "- B_1 = t (线性项)\n",
    "- B_2 = t^2 (二次项)\n",
    "- B_3+ = max(0, t - ξ_k)^2 (截断幂项，在节点处开始非零)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 VCNet 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VCNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Varying Coefficient Network (VCNet)\n",
    "    \n",
    "    核心思想:\n",
    "    - 表示网络: 学习用户特征的表示 φ(X)\n",
    "    - 系数网络: 让权重随处理强度变化 W(t)\n",
    "    - 输出: Y = W(t) · φ(X)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int = 64,\n",
    "        repr_dim: int = 32,\n",
    "        num_knots: int = 5,\n",
    "        spline_degree: int = 2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.repr_dim = repr_dim\n",
    "        \n",
    "        # 表示网络 Φ(X)\n",
    "        self.representation = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim, repr_dim),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "        # 样条基函数\n",
    "        self.basis = TruncatedBasis(num_knots=num_knots, degree=spline_degree)\n",
    "        self.num_basis = num_knots + spline_degree + 1\n",
    "        \n",
    "        # 系数网络：从基函数值到变系数 W(t)\n",
    "        # W(t) 的形状是 (repr_dim,)，所以我们需要 repr_dim 组系数\n",
    "        self.coef_network = nn.Sequential(\n",
    "            nn.Linear(self.num_basis, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim, repr_dim),\n",
    "        )\n",
    "        \n",
    "        # 偏置项（也随 t 变化）\n",
    "        self.bias_network = nn.Sequential(\n",
    "            nn.Linear(self.num_basis, hidden_dim // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        \n",
    "        Args:\n",
    "            x: 用户特征，形状 (batch_size, input_dim)\n",
    "            t: 处理强度，形状 (batch_size,) 或 (batch_size, 1)\n",
    "        \n",
    "        Returns:\n",
    "            y: 预测结果，形状 (batch_size, 1)\n",
    "        \"\"\"\n",
    "        # 用户表示\n",
    "        phi = self.representation(x)  # (batch, repr_dim)\n",
    "        \n",
    "        # 基函数值\n",
    "        if len(t.shape) == 1:\n",
    "            t = t.unsqueeze(1)\n",
    "        basis = self.basis(t)  # (batch, num_basis)\n",
    "        \n",
    "        # 变系数 W(t)\n",
    "        W_t = self.coef_network(basis)  # (batch, repr_dim)\n",
    "        \n",
    "        # 偏置 b(t)\n",
    "        b_t = self.bias_network(basis)  # (batch, 1)\n",
    "        \n",
    "        # 输出: Y = W(t) · φ(X) + b(t)\n",
    "        y = torch.sum(W_t * phi, dim=1, keepdim=True) + b_t\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def predict_dose_response(self, x: torch.Tensor, t_values: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        预测完整的剂量-响应曲线\n",
    "        \n",
    "        Args:\n",
    "            x: 单个用户特征，形状 (1, input_dim)\n",
    "            t_values: 处理强度值列表，形状 (n_points,)\n",
    "        \n",
    "        Returns:\n",
    "            y_values: 对应的预测结果，形状 (n_points,)\n",
    "        \"\"\"\n",
    "        n_points = len(t_values)\n",
    "        x_repeat = x.repeat(n_points, 1)\n",
    "        y_values = self.forward(x_repeat, t_values)\n",
    "        return y_values.squeeze()\n",
    "\n",
    "\n",
    "# 测试模型\n",
    "vcnet = VCNet(input_dim=5, hidden_dim=64, repr_dim=32)\n",
    "X_test = torch.FloatTensor(X[:10])\n",
    "T_test = torch.FloatTensor(T_norm[:10])\n",
    "\n",
    "y_pred = vcnet(X_test, T_test)\n",
    "print(f\"VCNet 测试通过！\")\n",
    "print(f\"输入: X={X_test.shape}, T={T_test.shape}\")\n",
    "print(f\"输出: Y={y_pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: 训练 VCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vcnet(\n",
    "    model: VCNet,\n",
    "    X: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    n_epochs: int = 300,\n",
    "    batch_size: int = 128,\n",
    "    learning_rate: float = 1e-3,\n",
    "    weight_decay: float = 1e-4,\n",
    "    verbose: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    训练 VCNet\n",
    "    \"\"\"\n",
    "    # 数据准备\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    T_tensor = torch.FloatTensor(T)\n",
    "    Y_tensor = torch.FloatTensor(Y).unsqueeze(1)\n",
    "    \n",
    "    dataset = TensorDataset(X_tensor, T_tensor, Y_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 优化器\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "    \n",
    "    # 损失函数\n",
    "    mse_loss = nn.MSELoss()\n",
    "    \n",
    "    # 训练历史\n",
    "    history = {'loss': []}\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        n_batches = 0\n",
    "        \n",
    "        for batch_x, batch_t, batch_y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 前向传播\n",
    "            y_pred = model(batch_x, batch_t)\n",
    "            \n",
    "            # 损失\n",
    "            loss = mse_loss(y_pred, batch_y)\n",
    "            \n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            n_batches += 1\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        avg_loss = epoch_loss / n_batches\n",
    "        history['loss'].append(avg_loss)\n",
    "        \n",
    "        if verbose and (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "print(\"开始训练 VCNet...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vcnet_model = VCNet(input_dim=X.shape[1], hidden_dim=64, repr_dim=32, num_knots=5)\n",
    "history = train_vcnet(\n",
    "    vcnet_model, X, T_norm, Y,\n",
    "    n_epochs=300,\n",
    "    batch_size=128,\n",
    "    learning_rate=1e-3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"训练完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: 评估与可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估模型\n",
    "def evaluate_vcnet(model: VCNet, X: np.ndarray, T: np.ndarray, Y: np.ndarray,\n",
    "                   true_dr_func) -> Dict:\n",
    "    \"\"\"\n",
    "    评估 VCNet 性能\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_tensor = torch.FloatTensor(X)\n",
    "        T_tensor = torch.FloatTensor(T)\n",
    "        Y_pred = model(X_tensor, T_tensor).numpy().squeeze()\n",
    "    \n",
    "    # MSE\n",
    "    mse = np.mean((Y - Y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # 评估剂量-响应曲线的准确性\n",
    "    # 在多个 t 值上比较\n",
    "    t_eval = np.linspace(0, 1, 20)\n",
    "    dr_errors = []\n",
    "    \n",
    "    for i in range(min(100, len(X))):  # 抽样评估\n",
    "        x = X[i:i+1]\n",
    "        x_repeat = np.repeat(x, len(t_eval), axis=0)\n",
    "        \n",
    "        # 真实曲线\n",
    "        true_curve = true_dr_func(t_eval, x_repeat)\n",
    "        \n",
    "        # 预测曲线\n",
    "        with torch.no_grad():\n",
    "            pred_curve = model.predict_dose_response(\n",
    "                torch.FloatTensor(x), \n",
    "                torch.FloatTensor(t_eval)\n",
    "            ).numpy()\n",
    "        \n",
    "        dr_errors.append(np.mean((true_curve - pred_curve) ** 2))\n",
    "    \n",
    "    dr_mse = np.mean(dr_errors)\n",
    "    \n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "        'dr_mse': dr_mse,\n",
    "        'Y_pred': Y_pred\n",
    "    }\n",
    "\n",
    "\n",
    "metrics = evaluate_vcnet(vcnet_model, X, T_norm, Y, true_dr)\n",
    "\n",
    "print(\"VCNet 评估结果\")\n",
    "print(\"=\"*60)\n",
    "print(f\"预测 RMSE: {metrics['rmse']:.4f}\")\n",
    "print(f\"剂量-响应曲线 MSE: {metrics['dr_mse']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化剂量-响应曲线\n",
    "vcnet_model.eval()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=3,\n",
    "                    subplot_titles=('高购买力用户', '中购买力用户', '低购买力用户'))\n",
    "\n",
    "t_range = np.linspace(0, 1, 50)\n",
    "\n",
    "user_types = [\n",
    "    ('高购买力', np.array([[1.5, 0, 1, 0, 0]])),\n",
    "    ('中购买力', np.array([[0, 0, 0, 0, 0]])),\n",
    "    ('低购买力', np.array([[-1.5, 0, -1, 0.5, 0]])),\n",
    "]\n",
    "\n",
    "for col, (label, x) in enumerate(user_types, 1):\n",
    "    x_repeat = np.repeat(x, len(t_range), axis=0)\n",
    "    \n",
    "    # 真实曲线\n",
    "    true_curve = true_dr(t_range, x_repeat)\n",
    "    \n",
    "    # 预测曲线\n",
    "    with torch.no_grad():\n",
    "        pred_curve = vcnet_model.predict_dose_response(\n",
    "            torch.FloatTensor(x),\n",
    "            torch.FloatTensor(t_range)\n",
    "        ).numpy()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=t_range * 50, y=true_curve, name='真实',\n",
    "                             line=dict(color=COLORS['primary'], width=2),\n",
    "                             showlegend=(col==1)), row=1, col=col)\n",
    "    fig.add_trace(go.Scatter(x=t_range * 50, y=pred_curve, name='VCNet预测',\n",
    "                             line=dict(color=COLORS['danger'], width=2, dash='dash'),\n",
    "                             showlegend=(col==1)), row=1, col=col)\n",
    "\n",
    "fig.update_xaxes(title_text='优惠券面额 (元)')\n",
    "fig.update_yaxes(title_text='预期消费 (元)', row=1, col=1)\n",
    "\n",
    "fig.update_layout(height=400, template='plotly_white',\n",
    "                  title_text='VCNet 剂量-响应曲线预测 vs 真实')\n",
    "fig.show()\n",
    "\n",
    "print(\"\"\"\n",
    "📊 观察:\n",
    "1. VCNet 能够捕捉不同用户的剂量-响应曲线形状\n",
    "2. 边际递减效应被正确学习\n",
    "3. 低购买力用户的门槛效应也被捕捉到\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: 业务应用 - 最优面额推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_dosage(model: VCNet, x: np.ndarray, \n",
    "                         cost_per_unit: float = 1.0,\n",
    "                         t_range: Tuple[float, float] = (0, 1),\n",
    "                         n_points: int = 100) -> Dict:\n",
    "    \"\"\"\n",
    "    寻找用户的最优处理强度\n",
    "    \n",
    "    考虑 ROI：最大化 (响应 - 成本)\n",
    "    \n",
    "    Args:\n",
    "        cost_per_unit: 每单位处理的成本\n",
    "    \n",
    "    Returns:\n",
    "        最优处理强度和对应的预测响应\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    t_values = torch.linspace(t_range[0], t_range[1], n_points)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x_tensor = torch.FloatTensor(x)\n",
    "        y_pred = model.predict_dose_response(x_tensor, t_values).numpy()\n",
    "    \n",
    "    # 计算净收益 = 响应 - 成本\n",
    "    costs = t_values.numpy() * cost_per_unit * 50  # 转回实际面额\n",
    "    net_benefit = y_pred - costs\n",
    "    \n",
    "    # 找到最优点\n",
    "    optimal_idx = np.argmax(net_benefit)\n",
    "    optimal_t = t_values[optimal_idx].item()\n",
    "    optimal_y = y_pred[optimal_idx]\n",
    "    optimal_cost = costs[optimal_idx]\n",
    "    optimal_net = net_benefit[optimal_idx]\n",
    "    \n",
    "    return {\n",
    "        'optimal_t': optimal_t,\n",
    "        'optimal_amount': optimal_t * 50,\n",
    "        'expected_spending': optimal_y,\n",
    "        'cost': optimal_cost,\n",
    "        'net_benefit': optimal_net,\n",
    "        'roi': (optimal_y - optimal_cost) / optimal_cost if optimal_cost > 0 else float('inf'),\n",
    "        't_values': t_values.numpy(),\n",
    "        'y_values': y_pred,\n",
    "        'net_benefits': net_benefit\n",
    "    }\n",
    "\n",
    "\n",
    "# 为不同用户找最优面额\n",
    "print(\"为不同用户寻找最优优惠券面额...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for label, x in user_types:\n",
    "    result = find_optimal_dosage(vcnet_model, x, cost_per_unit=0.5)\n",
    "    \n",
    "    print(f\"\\n{label}:\")\n",
    "    print(f\"  最优面额: {result['optimal_amount']:.1f} 元\")\n",
    "    print(f\"  预期消费: {result['expected_spending']:.1f} 元\")\n",
    "    print(f\"  优惠券成本: {result['cost']:.1f} 元\")\n",
    "    print(f\"  净收益: {result['net_benefit']:.1f} 元\")\n",
    "    print(f\"  ROI: {result['roi']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化最优面额分析\n",
    "fig = make_subplots(rows=1, cols=3,\n",
    "                    subplot_titles=('高购买力', '中购买力', '低购买力'))\n",
    "\n",
    "for col, (label, x) in enumerate(user_types, 1):\n",
    "    result = find_optimal_dosage(vcnet_model, x, cost_per_unit=0.5)\n",
    "    \n",
    "    t_plot = result['t_values'] * 50\n",
    "    \n",
    "    # 预期消费\n",
    "    fig.add_trace(go.Scatter(x=t_plot, y=result['y_values'], name='预期消费',\n",
    "                             line=dict(color=COLORS['primary']),\n",
    "                             showlegend=(col==1)), row=1, col=col)\n",
    "    \n",
    "    # 净收益\n",
    "    fig.add_trace(go.Scatter(x=t_plot, y=result['net_benefits'], name='净收益',\n",
    "                             line=dict(color=COLORS['success']),\n",
    "                             showlegend=(col==1)), row=1, col=col)\n",
    "    \n",
    "    # 最优点\n",
    "    fig.add_trace(go.Scatter(x=[result['optimal_amount']], y=[result['net_benefit']],\n",
    "                             mode='markers', marker=dict(size=12, color=COLORS['danger']),\n",
    "                             name='最优点', showlegend=(col==1)), row=1, col=col)\n",
    "\n",
    "fig.update_xaxes(title_text='优惠券面额 (元)')\n",
    "fig.update_yaxes(title_text='金额 (元)', row=1, col=1)\n",
    "\n",
    "fig.update_layout(height=400, template='plotly_white',\n",
    "                  title_text='个性化最优优惠券面额')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 思考题\n",
    "\n",
    "### 基础理解\n",
    "\n",
    "1. **为什么 VCNet 用变系数设计而不是简单地把 T 作为特征输入？** 这有什么优势？\n",
    "\n",
    "2. **样条基函数的作用是什么？** 如果不用样条，直接让 W(t) = NN(t)，会有什么问题？\n",
    "\n",
    "### 深入分析\n",
    "\n",
    "3. **连续处理的共同支撑假设比二元处理更难满足吗？** 为什么？\n",
    "\n",
    "4. **如何处理处理强度分布不均匀的问题？** 例如，大部分用户收到 10 元券，很少用户收到 40 元券。\n",
    "\n",
    "### 实战应用\n",
    "\n",
    "5. **在优惠券场景中，如何设计 A/B 测试来收集训练数据？** 需要注意什么？\n",
    "\n",
    "6. **如果有预算约束，如何在整体上优化优惠券分配？** 这与 Part 6 的预算分配优化有什么联系？\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 思考题参考答案\n\n### 1. 为什么 VCNet 用变系数设计而不是简单地把 T 作为特征输入？\n\n**参考答案**:\n\n变系数设计 vs 简单拼接特征的本质区别在于**交互建模的方式**。\n\n**方法对比**:\n\n| 方法 | 架构 | 优势 | 劣势 |\n|------|------|------|------|\n| **简单拼接** | Y = NN([X, T]) | 简单易实现 | 难以学习复杂交互 |\n| **VCNet** | Y = W(T) · φ(X) | 显式建模T-X交互 | 架构更复杂 |\n\n**为什么简单拼接不够？**\n\n```python\n# 方法1: 简单拼接（不推荐）\nclass NaiveNet(nn.Module):\n    def forward(self, x, t):\n        # 直接拼接\n        concat = torch.cat([x, t.unsqueeze(1)], dim=1)\n        return self.network(concat)\n```\n\n**问题**:\n1. **有限的交互能力**: MLP虽然理论上可以逼近任何函数，但对于T和X的交互，需要非常深的网络\n2. **无光滑性保证**: 对于相近的t值，预测可能剧烈波动\n3. **样本效率低**: 每个t值的数据是独立学习的，无法利用相邻t值的信息\n\n**VCNet的优势**:\n\n```python\n# 方法2: VCNet\nclass VCNet(nn.Module):\n    def forward(self, x, t):\n        phi = self.representation(x)      # 学习特征表示\n        W_t = self.coef_network(t)        # t的系数函数\n        return torch.sum(W_t * phi, dim=1) + self.bias(t)\n```\n\n**优势**:\n\n1. **显式交互建模**:\n   - Y = W(t) · φ(x) 直接建模\"处理强度如何调制特征的影响\"\n   - 这是multiplicative interaction，比加性更强大\n\n2. **样条基函数的正则化**:\n   - W(t) = Σ α_k · B_k(t) 保证对t的光滑性\n   - 相近的t值自然有相近的权重\n   - 防止overfitting\n\n3. **可解释性**:\n   - W(t)的变化直接反映\"处理强度如何改变特征重要性\"\n   - 可以可视化W_k(t)曲线理解模型\n\n**数学直觉**:\n\n想象优惠券场景:\n- 用户特征 φ(X) = [购买力, 活跃度, 价格敏感度, ...]\n- 对于低面额券(t=0.1): 可能\"价格敏感度\"权重大 → W(0.1) = [0.1, 0.2, 0.8, ...]\n- 对于高面额券(t=0.8): 可能\"购买力\"权重大 → W(0.8) = [0.7, 0.3, 0.2, ...]\n\nVCNet通过W(t)自动学习这种\"不同处理强度下特征重要性的变化\"!\n\n**实验证据**:\n\n原论文实验显示VCNet在IHDP数据集上比简单拼接方法PEHE降低15-30%。\n\n**结论**: 变系数设计是VCNet的核心创新，它通过W(t) · φ(x)显式建模处理-特征交互，并通过样条基函数保证光滑性，这是简单拼接无法做到的。\n\n---\n\n### 2. 样条基函数的作用是什么？如果不用样条，直接让 W(t) = NN(t)，会有什么问题？\n\n**参考答案**:\n\n样条基函数的作用是**强制W(t)对t光滑，防止overfitting**。\n\n**样条 vs 神经网络对比**:\n\n| 方法 | W(t)的形式 | 光滑性 | 可控性 | 样本效率 |\n|------|-----------|--------|--------|---------|\n| **样条基函数** | Σ α_k · B_k(t) | ✅ 强制光滑 | ✅ 可调节(节点数) | ✅ 高 |\n| **MLP** | NN(t) | ❌ 无保证 | ❌ 黑盒 | ⚠️ 中等 |\n\n**样条基函数的数学形式**:\n\n$$W(t) = \\sum_{k=1}^{K} \\alpha_k \\cdot B_k(t)$$\n\n其中 $B_k(t)$ 是截断幂基函数:\n- $B_1(t) = 1$ (常数项)\n- $B_2(t) = t$ (线性项)\n- $B_3(t) = t^2$ (二次项)\n- $B_{3+k}(t) = \\max(0, t - \\xi_k)^2$ (截断幂项，在节点$\\xi_k$处激活)\n\n**为什么需要光滑性？**\n\n1. **物理合理性**: \n   - 剂量-响应曲线在真实世界中通常是光滑的\n   - 例如药物剂量从10mg到11mg，效果不会突变\n\n2. **样本效率**:\n   - 光滑性=归纳偏置\n   - 在t=0.5处的观测可以帮助预测t=0.51的效果\n   - 减少所需样本量\n\n3. **泛化能力**:\n   - 防止在数据稀疏的t区域overfitting\n   - 通过邻近节点插值\n\n**如果用NN(t)会怎样？**\n\n```python\n# 不推荐的做法\nclass BadVCNet(nn.Module):\n    def __init__(self, ...):\n        # 直接用MLP建模W(t)\n        self.coef_network = nn.Sequential(\n            nn.Linear(1, 64),  # 输入是标量t\n            nn.ReLU(),\n            nn.Linear(64, repr_dim)\n        )\n```\n\n**问题**:\n\n1. **过拟合风险**:\n   - MLP可以拟合任意函数，包括高频振荡\n   - 在数据稀疏区域可能产生不合理的W(t)\n\n2. **训练不稳定**:\n   - t是标量输入，信息量有限\n   - MLP可能陷入局部最优\n\n3. **无先验知识**:\n   - MLP从零学习，忽略了\"剂量响应应该光滑\"这一先验\n\n**可视化对比**:\n\n```\n样条基函数的W(t):\n      │     ╭──────╮\nW(t)  │   ╭╯        ╲╮\n      │ ╭╯            ╲___\n      └─────────────────────── t\n         光滑、可控\n\nMLP的W(t):\n      │  ╱╲╱╲   ╱╲\nW(t)  │ ╱    ╲╱╲╱  ╲╱╲\n      │╱              ╲\n      └─────────────────────── t\n         可能过拟合、抖动\n```\n\n**超参数控制**:\n\n样条基函数的光滑性可通过调节：\n- **节点数K**: K越大，曲线越灵活\n- **多项式阶数p**: p越高，连续性越强\n- 这比调MLP的层数/宽度更直观\n\n**最佳实践**:\n\n1. **默认选择**: 5-10个节点，2次多项式（原论文推荐）\n2. **数据量大**: 可以增加节点数\n3. **先验强**: 减少节点数（如已知单调性，可用3-5个节点）\n\n**结论**: 样条基函数通过有限的基函数组合保证W(t)的光滑性，这是一种强大的正则化，比直接用MLP更适合连续处理场景。\n\n---\n\n### 3. 连续处理的共同支撑假设比二元处理更难满足吗？为什么？\n\n**参考答案**:\n\n**是的，连续处理的共同支撑假设更难满足**，原因是\"连续\"带来的维度诅咒。\n\n**共同支撑假设对比**:\n\n| 处理类型 | 共同支撑要求 | 难度 |\n|---------|-------------|------|\n| **二元处理** | 0 < e(X) < 1, ∀X | 中等 |\n| **连续处理** | 0 < f(t\\\\|X) < ∞, ∀t,X | 困难 |\n\n**数学形式**:\n\n**二元处理**:\n$$0 < P(T=1 | X=x) < 1, \\quad \\forall x$$\n\n只需要每个X既能被处理也能不被处理。\n\n**连续处理**:\n$$0 < f_{T|X}(t | X=x) < \\infty, \\quad \\forall t \\in \\mathcal{T}, x$$\n\n需要**每个X在所有可能的t值上都有观测**！\n\n**为什么更难？**\n\n#### 原因1: 维度爆炸\n\n**二元**: 只需验证两个条件\n- P(T=0|X) > 0\n- P(T=1|X) > 0\n\n**连续**: 需验证无穷多个条件\n- f(t=0|X) > 0\n- f(t=0.01|X) > 0\n- f(t=0.02|X) > 0\n- ...\n- f(t=1|X) > 0\n\n**实践中的挑战**: 即使T的取值范围是[0,1]，也很难保证每个X都在整个区间有观测。\n\n#### 原因2: 数据稀疏性\n\n想象优惠券场景:\n\n```\n用户1 (高购买力):\n  观测到的券: 20元、25元、30元\n  缺失区域: 0-15元、35-50元\n\n用户2 (低购买力):\n  观测到的券: 5元、10元、15元  \n  缺失区域: 20-50元\n```\n\n对于用户1，我们能估计她在30元券的效果，但**无法**可靠估计5元券的效果（共同支撑违反！）\n\n#### 原因3: 非随机分配\n\n现实中处理强度往往不是随机的:\n- 活跃用户→高面额券\n- 新用户→低面额券\n\n导致**条件分布的支撑不重叠**:\n\n```\nf(T|X=高购买力) 集中在 [20,50]\nf(T|X=低购买力) 集中在 [0,20]\n           ↓\n在 [0,20] 区域，高购买力用户数据稀疏\n在 [20,50] 区域，低购买力用户数据稀疏\n```\n\n**检验方法**:\n\n```python\ndef check_common_support(X, T, n_bins=10):\n    \"\"\"\n    检验连续处理的共同支撑\n    \"\"\"\n    from sklearn.cluster import KMeans\n    \n    # 将X聚类成几个组\n    kmeans = KMeans(n_clusters=5).fit(X)\n    labels = kmeans.labels_\n    \n    # 将T分桶\n    t_bins = np.linspace(T.min(), T.max(), n_bins+1)\n    \n    # 对每个X组和T桶，检查样本数\n    for group in range(5):\n        for i in range(n_bins):\n            mask = (labels == group) & (T >= t_bins[i]) & (T < t_bins[i+1])\n            n_samples = mask.sum()\n            \n            if n_samples < 5:  # 阈值\n                print(f\"警告: 组{group}在区间[{t_bins[i]:.1f}, {t_bins[i+1]:.1f}]样本不足({n_samples})\")\n```\n\n**缓解策略**:\n\n1. **增强数据收集**:\n   - 设计**分层随机化**实验\n   - 确保每个X层在所有t区间都有足够样本\n\n2. **限制推断范围**:\n   - 只在有充分支撑的t区间做推断\n   - 例如只估计 t ∈ [0.2, 0.8] 的效应\n\n3. **外推 with caution**:\n   - 使用样条的光滑性外推到数据稀疏区域\n   - 但要报告不确定性（置信区间会很宽）\n\n4. **IPW重加权**:\n   - 广义倾向得分 GPS = f(T|X)\n   - 对稀疏区域上采样\n\n**实际建议**:\n\n在优惠券场景:\n- 收集数据时: 确保各种用户都尝试各种面额（至少在几个关键档位）\n- 建模时: 可以考虑离散化T（如5元、10元、20元、50元），降低维度\n- 推断时: 对于数据稀疏的(X, T)组合，报告\"不确定性高，建议做实验\"\n\n**结论**: 连续处理的共同支撑假设因维度爆炸和数据稀疏性更难满足，需要更仔细的实验设计和谨慎的外推。\n\n---\n\n### 4. 如何处理处理强度分布不均匀的问题？\n\n**参考答案**:\n\n处理强度分布不均匀是连续处理的常见问题，有多种策略：\n\n**问题示例**:\n\n```\n优惠券数据分布:\n  [0-10元):   ████████████████████ (40%)\n  [10-20元):  ████████████████████████ (50%)\n  [20-30元):  ████ (8%)\n  [30-50元):  █ (2%)\n```\n\n大部分数据集中在10-20元，高面额券数据稀疏。\n\n**策略1: 广义倾向得分加权 (GPS Weighting)**\n\n**原理**: 用 1/f(T|X) 加权，提升稀疏区域样本的权重\n\n```python\ndef train_with_gps_weighting(model, X, T, Y):\n    # 估计 GPS: f(T|X)\n    gps_model = GaussianProcessRegressor()  # 或其他密度估计\n    gps_model.fit(X, T)\n    \n    # 计算每个样本的GPS\n    gps = gps_model.pdf(T, X)  # 概率密度\n    \n    # 加权损失\n    weights = 1.0 / (gps + 1e-6)\n    weights = weights / weights.sum() * len(weights)  # 归一化\n    \n    loss = weighted_mse_loss(Y_pred, Y, weights)\n```\n\n**优点**: 理论上可以减少偏差\n**缺点**: GPS估计不准时会放大误差\n\n**策略2: 分层采样 (Stratified Sampling)**\n\n**实现**:\n\n```python\ndef stratified_batch_sampler(X, T, batch_size=128, n_strata=5):\n    \"\"\"\n    确保每个batch中T的分布均匀\n    \"\"\"\n    # 将T分层\n    t_quantiles = np.quantile(T, np.linspace(0, 1, n_strata+1))\n    strata = np.digitize(T, t_quantiles)\n    \n    # 从每层等量采样\n    batch_indices = []\n    per_stratum = batch_size // n_strata\n    \n    for s in range(1, n_strata+1):\n        stratum_indices = np.where(strata == s)[0]\n        sampled = np.random.choice(stratum_indices, per_stratum, replace=True)\n        batch_indices.extend(sampled)\n    \n    return batch_indices\n```\n\n**优点**: 简单有效，确保模型见到各种T值\n**缺点**: 如果某层样本极少，需要重复采样（可能过拟合）\n\n**策略3: 数据增强 (Data Augmentation)**\n\n**Mixup for T**:\n\n```python\ndef mixup_treatment(X, T, Y, alpha=0.2):\n    \"\"\"\n    在处理空间做插值，生成新样本\n    \"\"\"\n    lam = np.random.beta(alpha, alpha)\n    \n    # 随机配对\n    indices = np.random.permutation(len(X))\n    \n    X_mixed = lam * X + (1 - lam) * X[indices]\n    T_mixed = lam * T + (1 - lam) * T[indices]\n    Y_mixed = lam * Y + (1 - lam) * Y[indices]  # 假设线性混合合理\n    \n    return X_mixed, T_mixed, Y_mixed\n```\n\n**注意**: 只有当Y对T近似线性时才合理，否则可能引入bias\n\n**策略4: 限制推断范围**\n\n**最保守的方法**:\n\n```python\ndef get_reliable_t_range(T, X, min_samples=10):\n    \"\"\"\n    只在有足够数据的T区间做推断\n    \"\"\"\n    t_bins = np.linspace(T.min(), T.max(), 20)\n    \n    # 统计每个bin的样本数\n    hist, _ = np.histogram(T, bins=t_bins)\n    \n    # 找到充分支撑的区间\n    valid_bins = hist >= min_samples\n    \n    t_min = t_bins[np.argmax(valid_bins)]\n    t_max = t_bins[len(t_bins) - 1 - np.argmax(valid_bins[::-1])]\n    \n    return t_min, t_max\n\n# 使用\nt_min, t_max = get_reliable_t_range(T, X)\nprint(f\"只在 [{t_min:.1f}, {t_max:.1f}] 区间做可靠推断\")\n```\n\n**策略5: 主动学习 (Active Learning)**\n\n如果可以收集新数据，优先采集稀疏区域:\n\n```python\ndef select_samples_for_annotation(model, X_pool, T_grid, budget=100):\n    \"\"\"\n    选择对哪些(X, T)组合做实验\n    \"\"\"\n    # 计算不确定性（如果模型支持）\n    uncertainty_scores = []\n    \n    for x in X_pool:\n        # 评估在不同T下的不确定性\n        uncertainties = []\n        for t in T_grid:\n            # 如果有多次采样\n            samples = [model(x, t) for _ in range(10)]\n            uncertainty = np.std(samples)\n            uncertainties.append(uncertainty)\n        \n        # 选择最不确定的T\n        max_uncertainty = np.max(uncertainties)\n        uncertainty_scores.append(max_uncertainty)\n    \n    # 返回top-K不确定的样本\n    topk = np.argsort(uncertainty_scores)[-budget:]\n    \n    return X_pool[topk], T_grid[...]  # 对应的最优T\n```\n\n**策略6: 多任务学习**\n\n如果有相关任务（如预测点击率），联合训练可以缓解数据稀疏:\n\n```python\nclass MultiTaskVCNet(nn.Module):\n    def __init__(self, ...):\n        self.shared_repr = ...  # 共享表示\n        self.task1_head = ...   # 主任务: 预测消费\n        self.task2_head = ...   # 辅助任务: 预测点击\n    \n    def forward(self, x, t):\n        phi = self.shared_repr(x)\n        \n        # 两个任务共享表示，缓解数据稀疏\n        y1 = self.task1_head(phi, t)\n        y2 = self.task2_head(phi, t)\n        \n        return y1, y2\n```\n\n**实战组合策略**:\n\n在优惠券场景的推荐做法:\n1. **训练时**: 使用分层采样 + GPS加权\n2. **评估时**: 分别报告不同T区间的性能\n3. **推断时**: 对稀疏区域(t>30元)报告更宽的置信区间\n4. **业务建议**: 对高价值用户在稀疏区域做小规模RCT验证\n\n**监控指标**:\n\n```python\ndef analyze_treatment_distribution(T, X):\n    print(\"处理强度分布分析:\")\n    print(f\"  均值: {T.mean():.2f}\")\n    print(f\"  标准差: {T.std():.2f}\")\n    print(f\"  偏度: {scipy.stats.skew(T):.2f}\")  # >0表示右偏\n    \n    # 各quartile的样本数\n    for q in [0.25, 0.5, 0.75]:\n        t_q = np.quantile(T, q)\n        print(f\"  {int(q*100)}%分位数: {t_q:.1f}\")\n    \n    # 稀疏性警告\n    t_bins = np.linspace(T.min(), T.max(), 10)\n    hist, _ = np.histogram(T, bins=t_bins)\n    sparse_bins = np.where(hist < len(T) * 0.01)[0]  # <1%的bin\n    \n    if len(sparse_bins) > 0:\n        print(f\"  警告: {len(sparse_bins)}个区间样本稀疏(<1%)\")\n```\n\n**结论**: 处理分布不均匀需要组合多种策略——训练时加权/采样，推断时限制范围，长期通过主动学习补充数据。\n\n---\n\n### 5. 在优惠券场景中，如何设计 A/B 测试来收集训练数据？\n\n**参考答案**:\n\n为连续处理（优惠券面额）设计A/B测试比二元处理复杂，需要在**探索-利用**之间权衡。\n\n**挑战**:\n\n1. **无限维的处理空间**: 面额可以是0-50元任意值\n2. **成本约束**: 不能无限制地发券\n3. **时效性**: 需要快速迭代，不能永远只探索\n\n**策略1: 分层随机化 (Stratified Randomization)**\n\n**设计**:\n\n```\n用户群体划分:\n- 高价值用户 (LTV > 1000)\n- 中价值用户 (500 < LTV ≤ 1000)\n- 低价值用户 (LTV ≤ 500)\n\n每个群体内随机分配:\n群体1: 均匀分配 t ~ Uniform([20, 50])\n群体2: 均匀分配 t ~ Uniform([10, 30])\n群体3: 均匀分配 t ~ Uniform([0, 20])\n```\n\n**优点**:\n- 确保每个X层在多个T值有数据\n- 满足共同支撑假设\n\n**实现**:\n\n```python\ndef stratified_treatment_assignment(users, strata_rules):\n    \"\"\"\n    分层随机分配处理强度\n    \n    Args:\n        users: 用户特征DataFrame\n        strata_rules: 每层的处理范围\n    \"\"\"\n    assignments = []\n    \n    for user in users:\n        # 确定用户所属层\n        stratum = assign_stratum(user)\n        \n        # 从该层的处理范围随机采样\n        t_min, t_max = strata_rules[stratum]\n        treatment = np.random.uniform(t_min, t_max)\n        \n        assignments.append({\n            'user_id': user.id,\n            'features': user.features,\n            'treatment': treatment,\n            'stratum': stratum\n        })\n    \n    return pd.DataFrame(assignments)\n```\n\n**策略2: 多臂老虎机 (Multi-Armed Bandit)**\n\n对于连续处理，使用**连续臂老虎机**（Continuous-Armed Bandit）\n\n**Gaussian Process Thompson Sampling**:\n\n```python\nclass GPBandit:\n    def __init__(self, t_range=(0, 50)):\n        self.t_range = t_range\n        self.gp = GaussianProcessRegressor()\n        self.observations = []\n    \n    def select_treatment(self, user_features, explore_prob=0.2):\n        \"\"\"\n        为用户选择优惠券面额\n        \"\"\"\n        if len(self.observations) < 10 or np.random.rand() < explore_prob:\n            # 探索: 随机采样\n            return np.random.uniform(*self.t_range)\n        else:\n            # 利用: 基于GP的后验采样\n            t_candidates = np.linspace(*self.t_range, 50)\n            \n            # 预测每个t的期望收益及不确定性\n            mu, sigma = self.gp.predict(\n                [[*user_features, t] for t in t_candidates],\n                return_std=True\n            )\n            \n            # Thompson Sampling: 从后验采样\n            samples = mu + np.random.randn(len(t_candidates)) * sigma\n            \n            return t_candidates[np.argmax(samples)]\n    \n    def update(self, user_features, treatment, reward):\n        \"\"\"\n        更新模型\n        \"\"\"\n        self.observations.append([*user_features, treatment, reward])\n        \n        # 重新训练GP\n        X = np.array([[*obs[:- 1]] for obs in self.observations])\n        y = np.array([obs[-1] for obs in self.observations])\n        self.gp.fit(X, y)\n```\n\n**优点**:\n- 自动平衡探索-利用\n- 数据高效\n\n**缺点**:\n- GP在高维特征下可能慢\n- 需要在线更新\n\n**策略3: 自适应实验设计 (Adaptive Design)**\n\n**阶段式实验**:\n\n```\n阶段1 (Week 1-2): 宽泛探索\n- 对所有用户，t ~ Uniform([0, 50])\n- 收集基础数据\n\n阶段2 (Week 3-4): 聚焦探索  \n- 基于Week 1-2数据，识别\"有希望\"的区域\n- 例如发现 t ∈ [15, 25] 最优\n- 增加此区间的采样密度: 70%流量在[15,25]，30%在其他\n\n阶段3 (Week 5+): 利用\n- 基于模型预测，给每个用户最优面额\n- 保留10%流量继续探索（防止模型过时）\n```\n\n**实现**:\n\n```python\ndef adaptive_experiment_design(week, model, users):\n    if week <= 2:\n        # 阶段1: 均匀探索\n        return np.random.uniform(0, 50, len(users))\n    \n    elif week <= 4:\n        # 阶段2: 聚焦探索\n        # 找到高回报区域\n        promising_range = find_promising_range(model)\n        \n        treatments = []\n        for user in users:\n            if np.random.rand() < 0.7:\n                # 70%在promising range\n                t = np.random.uniform(*promising_range)\n            else:\n                # 30%全局探索\n                t = np.random.uniform(0, 50)\n            treatments.append(t)\n        \n        return np.array(treatments)\n    \n    else:\n        # 阶段3: 主要利用\n        treatments = []\n        for user in users:\n            if np.random.rand() < 0.1:\n                # 10%探索\n                t = np.random.uniform(0, 50)\n            else:\n                # 90%利用\n                t = model.predict_optimal_treatment(user)\n            treatments.append(t)\n        \n        return np.array(treatments)\n```\n\n**策略4: 贝叶斯优化 (Bayesian Optimization)**\n\n将实验设计看作优化问题:\n\n$$\\max_{t} E[Y | X=x, T=t] \\quad \\text{s.t. 数据收集约束}$$\n\n```python\nfrom bayes_opt import BayesianOptimization\n\ndef design_next_batch(model, user_pool, batch_size=1000):\n    \"\"\"\n    选择下一批实验的(user, treatment)组合\n    \"\"\"\n    # 采集函数: Expected Improvement\n    def acquisition(user_idx, t):\n        user = user_pool[user_idx]\n        \n        # 当前最优值\n        current_best = model.predict(user, model.current_best_t)\n        \n        # 预测均值和方差\n        mu, sigma = model.predict_with_uncertainty(user, t)\n        \n        # EI = E[max(mu - current_best, 0)]\n        improvement = mu - current_best\n        z = improvement / (sigma + 1e-6)\n        ei = improvement * norm.cdf(z) + sigma * norm.pdf(z)\n        \n        return ei\n    \n    # 优化采集函数\n    selected_pairs = []\n    for _ in range(batch_size):\n        best_ei = -np.inf\n        best_pair = None\n        \n        for user_idx in range(len(user_pool)):\n            for t in np.linspace(0, 50, 20):\n                ei = acquisition(user_idx, t)\n                if ei > best_ei:\n                    best_ei = ei\n                    best_pair = (user_idx, t)\n        \n        selected_pairs.append(best_pair)\n    \n    return selected_pairs\n```\n\n**策略5: 分桶近似 (Discretization)**\n\n如果连续优化太复杂，可以离散化:\n\n```\n将面额离散为5档:\n- 0元 (控制组)\n- 10元\n- 20元\n- 30元\n- 50元\n\n然后做标准的5组A/B测试\n```\n\n**权衡**:\n- ✅ 简化设计和分析\n- ❌ 无法找到10-20元之间的最优点\n\n**最佳实践: 混合策略**\n\n```python\nclass HybridExperimentDesign:\n    \"\"\"\n    混合策略: 分层 + 自适应 + 离散化\n    \"\"\"\n    def __init__(self):\n        # 离散化为几个关键档位\n        self.key_amounts = [0, 5, 10, 15, 20, 30, 50]\n        \n        # 每个档位的探索概率（初始均匀，后续自适应）\n        self.probs = np.ones(len(self.key_amounts)) / len(self.key_amounts)\n    \n    def assign_treatment(self, user, week):\n        # 确定用户层\n        stratum = self.get_stratum(user)\n        \n        # 过滤适合该层的档位\n        if stratum == 'high_value':\n            valid_amounts = [t for t in self.key_amounts if t >= 15]\n        elif stratum == 'low_value':\n            valid_amounts = [t for t in self.key_amounts if t <= 20]\n        else:\n            valid_amounts = self.key_amounts\n        \n        # 基于当前概率采样\n        # (概率会根据观察到的收益自适应更新)\n        return np.random.choice(valid_amounts, p=self.probs_normalized(valid_amounts))\n    \n    def update_probs(self, observations):\n        \"\"\"\n        基于观察数据更新探索概率\n        \"\"\"\n        # 计算每个档位的平均回报\n        rewards_by_amount = {}\n        for amount in self.key_amounts:\n            mask = observations['treatment'] == amount\n            if mask.sum() > 0:\n                rewards_by_amount[amount] = observations.loc[mask, 'reward'].mean()\n        \n        # Softmax更新（温度参数控制探索-利用权衡）\n        temperature = max(0.1, 1.0 - week * 0.1)  # 逐渐降低温度\n        new_probs = softmax([rewards_by_amount.get(a, 0) / temperature \n                             for a in self.key_amounts])\n        \n        self.probs = new_probs\n```\n\n**监控指标**:\n\n```python\ndef experiment_health_check(data):\n    \"\"\"\n    检查实验数据质量\n    \"\"\"\n    print(\"=\"*60)\n    print(\"实验数据健康度检查\")\n    print(\"=\"*60)\n    \n    # 1. 处理分布\n    print(\"\\n1. 处理分布:\")\n    print(data['treatment'].describe())\n    \n    # 2. 各区间样本量\n    print(\"\\n2. 各面额区间样本量:\")\n    for t_min, t_max in [(0,10), (10,20), (20,30), (30,50)]:\n        mask = (data['treatment'] >= t_min) & (data['treatment'] < t_max)\n        print(f\"  [{t_min}-{t_max}元): {mask.sum()} ({mask.mean():.1%})\")\n    \n    # 3. 各层的覆盖度\n    print(\"\\n3. 用户层的处理覆盖:\")\n    for stratum in data['stratum'].unique():\n        stratum_data = data[data['stratum'] == stratum]\n        print(f\"  {stratum}:\")\n        print(f\"    样本数: {len(stratum_data)}\")\n        print(f\"    处理范围: [{stratum_data['treatment'].min():.1f}, \"\n              f\"{stratum_data['treatment'].max():.1f}]\")\n    \n    # 4. 时间趋势\n    data['week'] = pd.to_datetime(data['timestamp']).dt.isocalendar().week\n    print(\"\\n4. 每周数据量:\")\n    print(data.groupby('week').size())\n```\n\n**结论**: \n- **短期**(Week 1-2): 分层随机化，确保共同支撑\n- **中期**(Week 3-6): 自适应设计，聚焦高价值区域\n- **长期**: 利用为主(90%)，保留探索(10%)\n- 始终监控数据质量，避免某些区域样本过少\n\n---\n\n### 6. 如果有预算约束，如何在整体上优化优惠券分配？\n\n**参考答案**:\n\n这是一个**带约束的因果优化问题**，目标是在预算约束下最大化总收益。\n\n**问题形式化**:\n\n$$\\begin{align}\n\\max_{t_1, ..., t_N} \\quad & \\sum_{i=1}^{N} [E[Y_i | X_i, T_i=t_i] - c \\cdot t_i] \\\\\n\\text{s.t.} \\quad & \\sum_{i=1}^{N} t_i \\leq B \\\\\n& 0 \\leq t_i \\leq t_{max}, \\quad \\forall i\n\\end{align}$$\n\n其中:\n- $N$: 用户数\n- $t_i$: 给用户i的券面额\n- $E[Y_i | X_i, T_i=t_i]$: 预期消费（由VCNet预测）\n- $c$: 成本系数（通常=1）\n- $B$: 总预算\n\n**策略1: 贪心分配 (Greedy Allocation)**\n\n**核心思想**: 优先给边际收益最大的用户发券\n\n```python\ndef greedy_allocation(model, users, budget):\n    \"\"\"\n    贪心分配优惠券\n    \"\"\"\n    N = len(users)\n    allocations = np.zeros(N)\n    remaining_budget = budget\n    \n    # 对每个用户，找到最优面额\n    optimal_amounts = []\n    marginal_benefits = []\n    \n    for i, user in enumerate(users):\n        # 在[0, remaining_budget]范围内搜索最优t\n        t_values = np.linspace(0, min(50, remaining_budget), 100)\n        \n        # 预测净收益\n        net_benefits = []\n        for t in t_values:\n            y_pred = model.predict(user, t)\n            net_benefit = y_pred - t  # 收益 - 成本\n            net_benefits.append(net_benefit)\n        \n        optimal_idx = np.argmax(net_benefits)\n        optimal_t = t_values[optimal_idx]\n        optimal_benefit = net_benefits[optimal_idx]\n        \n        optimal_amounts.append(optimal_t)\n        marginal_benefits.append(optimal_benefit)\n    \n    # 按边际收益排序\n    sorted_indices = np.argsort(marginal_benefits)[::-1]\n    \n    # 贪心分配\n    for idx in sorted_indices:\n        if remaining_budget <= 0:\n            break\n        \n        t = min(optimal_amounts[idx], remaining_budget)\n        allocations[idx] = t\n        remaining_budget -= t\n    \n    return allocations\n```\n\n**复杂度**: O(N log N)\n**最优性**: 近似最优（无理论保证）\n\n**策略2: 线性规划 (Linear Programming)**\n\n如果剂量-响应曲线是**线性或分段线性**的，可以用LP求精确解。\n\n**分段线性近似**:\n\n```python\nfrom scipy.optimize import linprog\n\ndef lp_allocation(model, users, budget, n_segments=5):\n    \"\"\"\n    将非线性剂量-响应曲线分段线性化，然后用LP求解\n    \"\"\"\n    N = len(users)\n    \n    # 对每个用户，将[0, 50]分成n_segments段\n    t_breakpoints = np.linspace(0, 50, n_segments + 1)\n    \n    # 变量: t_ij 表示用户i在第j段的分配量\n    # 总变量数 = N * n_segments\n    \n    # 目标函数系数\n    c = []\n    for i, user in enumerate(users):\n        for j in range(n_segments):\n            t_start = t_breakpoints[j]\n            t_end = t_breakpoints[j+1]\n            t_mid = (t_start + t_end) / 2\n            \n            # 预测该段的平均收益\n            y_pred = model.predict(user, t_mid)\n            benefit_per_unit = (y_pred - t_mid) / (t_end - t_start)\n            \n            c.append(-benefit_per_unit)  # 负号因为linprog是最小化\n    \n    # 约束1: 预算约束\n    A_budget = np.zeros((1, N * n_segments))\n    for i in range(N):\n        for j in range(n_segments):\n            A_budget[0, i * n_segments + j] = t_breakpoints[j+1] - t_breakpoints[j]\n    b_budget = [budget]\n    \n    # 约束2: 每个用户的段分配量之和 ≤ 1 (归一化)\n    A_user = np.zeros((N, N * n_segments))\n    for i in range(N):\n        for j in range(n_segments):\n            A_user[i, i * n_segments + j] = 1\n    b_user = [1] * N\n    \n    # 变量界: 0 ≤ t_ij ≤ 1\n    bounds = [(0, 1)] * (N * n_segments)\n    \n    # 求解\n    result = linprog(c, A_ub=np.vstack([A_budget, A_user]),\n                     b_ub=b_budget + b_user, bounds=bounds, method='highs')\n    \n    # 恢复实际分配\n    allocations = np.zeros(N)\n    for i in range(N):\n        for j in range(n_segments):\n            segment_allocation = result.x[i * n_segments + j]\n            allocations[i] += segment_allocation * (t_breakpoints[j+1] - t_breakpoints[j])\n    \n    return allocations\n```\n\n**优点**: 精确最优（在分段线性近似下）\n**缺点**: 计算复杂，仅适合中小规模\n\n**策略3: 拉格朗日松弛 (Lagrangian Relaxation)**\n\n对于大规模问题，用拉格朗日乘子法:\n\n$$L(t_1, ..., t_N, \\lambda) = \\sum_{i=1}^{N} [E[Y_i|X_i, t_i] - t_i] - \\lambda \\left(\\sum_{i=1}^{N} t_i - B\\right)$$\n\n**算法**:\n\n```python\ndef lagrangian_allocation(model, users, budget, max_iter=100):\n    \"\"\"\n    拉格朗日松弛法求解\n    \"\"\"\n    N = len(users)\n    lambda_val = 0.1  # 初始拉格朗日乘子\n    \n    for iteration in range(max_iter):\n        allocations = np.zeros(N)\n        \n        # 对每个用户，独立优化\n        for i, user in enumerate(users):\n            # 最优化 E[Y_i|X_i, t_i] - t_i - lambda * t_i\n            #       = E[Y_i|X_i, t_i] - (1 + lambda) * t_i\n            \n            t_values = np.linspace(0, 50, 100)\n            objectives = []\n            \n            for t in t_values:\n                y_pred = model.predict(user, t)\n                obj = y_pred - (1 + lambda_val) * t\n                objectives.append(obj)\n            \n            optimal_t = t_values[np.argmax(objectives)]\n            allocations[i] = optimal_t\n        \n        # 检查约束\n        total_budget_used = allocations.sum()\n        \n        if abs(total_budget_used - budget) < 1:\n            break\n        \n        # 更新拉格朗日乘子\n        if total_budget_used > budget:\n            lambda_val += 0.01  # 增大lambda，减少分配\n        else:\n            lambda_val -= 0.01  # 减小lambda，增加分配\n        \n        lambda_val = max(0, lambda_val)  # 非负约束\n    \n    # 最终调整到精确预算\n    if allocations.sum() > budget:\n        # 按比例缩减\n        allocations *= budget / allocations.sum()\n    elif allocations.sum() < budget:\n        # 贪心补充\n        remaining = budget - allocations.sum()\n        # 给边际收益最大的用户补充\n        # ...\n    \n    return allocations\n```\n\n**策略4: 排名优化 (Ranking Optimization)**\n\n实践中常用的简化方法:\n\n```python\ndef ranking_allocation(model, users, budget):\n    \"\"\"\n    基于用户价值排名分配\n    \"\"\"\n    N = len(users)\n    \n    # 计算每个用户的\"uplift per dollar\"\n    uplift_efficiency = []\n    \n    for user in users:\n        # 比较发20元券 vs 不发\n        y_treat = model.predict(user, t=20/50)  # 归一化\n        y_control = model.predict(user, t=0)\n        \n        uplift = y_treat - y_control\n        efficiency = uplift / 20  # 每元券带来的uplift\n        \n        uplift_efficiency.append(efficiency)\n    \n    # 排名\n    ranked_indices = np.argsort(uplift_efficiency)[::-1]\n    \n    # 分配\n    allocations = np.zeros(N)\n    remaining_budget = budget\n    \n    for idx in ranked_indices:\n        if remaining_budget <= 0:\n            break\n        \n        # 给该用户发最优面额（在剩余预算内）\n        optimal_t = find_optimal_treatment(model, users[idx], \n                                            max_t=min(50, remaining_budget))\n        \n        allocations[idx] = optimal_t\n        remaining_budget -= optimal_t\n    \n    return allocations\n```\n\n**策略5: 强化学习 (Reinforcement Learning)**\n\n将预算分配看作序贯决策问题:\n\n```python\nclass BudgetAllocationMDP:\n    \"\"\"\n    将预算分配建模为MDP\n    \n    State: (当前用户特征, 剩余预算, 已服务用户数)\n    Action: 给当前用户的券面额\n    Reward: 净收益\n    \"\"\"\n    def __init__(self, model, users, total_budget):\n        self.model = model\n        self.users = users\n        self.total_budget = total_budget\n        \n        self.current_user_idx = 0\n        self.remaining_budget = total_budget\n    \n    def get_state(self):\n        if self.current_user_idx >= len(self.users):\n            return None  # 终止状态\n        \n        user_features = self.users[self.current_user_idx]\n        return {\n            'user_features': user_features,\n            'remaining_budget': self.remaining_budget,\n            'users_served': self.current_user_idx,\n            'total_users': len(self.users)\n        }\n    \n    def step(self, action_t):\n        \"\"\"\n        执行动作: 给当前用户分配面额t\n        \"\"\"\n        user = self.users[self.current_user_idx]\n        \n        # 计算奖励\n        y_pred = self.model.predict(user, action_t)\n        reward = y_pred - action_t\n        \n        # 更新状态\n        self.remaining_budget -= action_t\n        self.current_user_idx += 1\n        \n        next_state = self.get_state()\n        done = (next_state is None)\n        \n        return next_state, reward, done\n```\n\n然后用DQN/PPO等RL算法训练策略。\n\n**优点**: 能学习复杂的序贯决策策略\n**缺点**: 训练复杂，需要大量模拟\n\n**实战推荐: 两阶段方法**\n\n```python\nclass TwoStageAllocation:\n    \"\"\"\n    第一阶段: 用VCNet预测每个用户的最优面额\n    第二阶段: 在预算约束下优化总体分配\n    \"\"\"\n    def __init__(self, vcnet_model):\n        self.model = vcnet_model\n    \n    def allocate(self, users, budget):\n        N = len(users)\n        \n        # 阶段1: 计算无约束最优\n        unconstrained_optimal = np.zeros(N)\n        expected_benefits = np.zeros(N)\n        \n        for i, user in enumerate(users):\n            # 找到ROI最大的面额\n            result = find_optimal_dosage(self.model, user, cost_per_unit=1.0)\n            unconstrained_optimal[i] = result['optimal_amount']\n            expected_benefits[i] = result['net_benefit']\n        \n        total_needed = unconstrained_optimal.sum()\n        \n        if total_needed <= budget:\n            # 预算充足，直接分配\n            return unconstrained_optimal\n        else:\n            # 预算不足，需要优化\n            # 使用贪心 + 边际分析\n            return self._constrained_optimization(\n                users, budget, unconstrained_optimal, expected_benefits\n            )\n    \n    def _constrained_optimization(self, users, budget, optimal_t, benefits):\n        \"\"\"\n        预算约束下的优化\n        \"\"\"\n        N = len(users)\n        allocations = np.zeros(N)\n        \n        # 按边际收益排序\n        marginal_roi = benefits / (optimal_t + 1e-6)  # ROI\n        sorted_indices = np.argsort(marginal_roi)[::-1]\n        \n        remaining_budget = budget\n        \n        for idx in sorted_indices:\n            if remaining_budget <= 0:\n                break\n            \n            # 分配该用户的最优面额（不超过剩余预算）\n            t = min(optimal_t[idx], remaining_budget)\n            allocations[idx] = t\n            remaining_budget -= t\n        \n        return allocations\n```\n\n**监控与调整**:\n\n```python\ndef evaluate_allocation_strategy(allocations, users, model, actual_outcomes=None):\n    \"\"\"\n    评估分配策略\n    \"\"\"\n    # 预测指标\n    predicted_revenue = 0\n    total_cost = 0\n    \n    for i, (user, t) in enumerate(zip(users, allocations)):\n        y_pred = model.predict(user, t / 50)  # 归一化\n        predicted_revenue += y_pred\n        total_cost += t\n    \n    predicted_roi = (predicted_revenue - total_cost) / total_cost\n    \n    print(f\"预测总收入: {predicted_revenue:.2f}\")\n    print(f\"总成本: {total_cost:.2f}\")\n    print(f\"预测 ROI: {predicted_roi:.2%}\")\n    \n    # 如果有实际结果，计算真实ROI\n    if actual_outcomes is not None:\n        actual_revenue = actual_outcomes.sum()\n        actual_roi = (actual_revenue - total_cost) / total_cost\n        \n        print(f\"\\n实际总收入: {actual_revenue:.2f}\")\n        print(f\"实际 ROI: {actual_roi:.2%}\")\n        print(f\"预测偏差: {(predicted_revenue - actual_revenue) / actual_revenue:.2%}\")\n```\n\n**与 Part 6 的联系**:\n\n这个问题与Part 6的预算分配优化密切相关:\n- Part 5 (VCNet): 学习个体剂量-响应函数 μ(t, x)\n- Part 6: 在总体上优化预算分配策略\n\n结合使用:\n1. 用VCNet估计每个用户的最优处理\n2. 用Part 6的方法在预算约束下优化总体分配\n3. 迭代更新: 新数据→重训练VCNet→重新分配\n\n**结论**: \n预算约束下的优惠券分配是一个带约束的因果优化问题。实战中推荐:\n- **小规模** (<1000用户): LP精确求解\n- **中规模** (1000-10万): 贪心算法\n- **大规模** (>10万): 分层+贪心+并行计算\n- 始终监控实际ROI，迭代优化\n\n---\n\n*这些详细的答案展示了VCNet在真实业务中的应用深度！* 🎓",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "| 概念 | 定义 | 重要性 |\n",
    "|------|------|--------|\n",
    "| **连续处理** | T 取连续值而非 0/1 | 更真实的业务场景 |\n",
    "| **剂量-响应曲线** | Y(t) 关于 t 的函数 | 核心估计目标 |\n",
    "| **变系数网络** | W(t) · φ(X) | VCNet 核心创新 |\n",
    "| **样条基函数** | 保证曲线光滑 | 正则化作用 |\n",
    "| **最优剂量** | argmax_t μ(t, x) | 业务决策依据 |\n",
    "\n",
    "### 与其他方法的对比\n",
    "\n",
    "| 方法 | 处理类型 | 输出 | 适用场景 |\n",
    "|------|---------|------|----------|\n",
    "| TARNet/DragonNet | 二元 | μ₀(x), μ₁(x) | 发不发 |\n",
    "| GPS + 回归 | 连续 | μ(t, x) | 简单关系 |\n",
    "| VCNet | 连续 | μ(t, x) | 复杂非线性 |\n",
    "| DRNet | 连续 | μ(t, x) | 多剂量区间 |\n",
    "\n",
    "### 何时使用 VCNet？\n",
    "\n",
    "- ✅ 处理强度是连续的（面额、价格、时长）\n",
    "- ✅ 需要估计完整的剂量-响应曲线\n",
    "- ✅ 剂量-响应关系复杂非线性\n",
    "- ❌ 处理只有少数几个档位（用多处理方法）\n",
    "- ❌ 数据量很小\n",
    "\n",
    "---\n",
    "\n",
    "## 延伸阅读\n",
    "\n",
    "- **原论文**: Nie, L., Ye, M., Liu, Q., & Nicolae, D. (2021). VCNet and Functional Targeted Regularization For Learning Causal Effects of Continuous Treatments. ICLR 2021.\n",
    "- **相关工作**: DRNet, GPS, SCIGAN\n",
    "\n",
    "---\n",
    "\n",
    "*恭喜你完成了 VCNet 的学习！* 🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}