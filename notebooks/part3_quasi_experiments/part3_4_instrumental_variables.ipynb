{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å·¥å…·å˜é‡ (Instrumental Variables) - å¤„ç†å†…ç”Ÿæ€§é—®é¢˜\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œä½ å°†èƒ½å¤Ÿï¼š\n",
    "\n",
    "1. **ç†è§£å†…ç”Ÿæ€§é—®é¢˜**ï¼šæŒæ¡å†…ç”Ÿæ€§çš„æ¥æºåŠå…¶å¯¹å› æœæ¨æ–­çš„å½±å“\n",
    "2. **æŒæ¡ IV çš„ä¸‰ä¸ªæ ¸å¿ƒå‡è®¾**ï¼šç›¸å…³æ€§ã€æ’ä»–æ€§ã€å¤–ç”Ÿæ€§\n",
    "3. **å®ç° 2SLS ä¼°è®¡**ï¼šç†è§£ä¸¤é˜¶æ®µæœ€å°äºŒä¹˜çš„åŸç†å’Œå®ç°\n",
    "4. **è¯Šæ–­å·¥å…·å˜é‡è´¨é‡**ï¼šå­¦ä¼šæ£€éªŒå¼±å·¥å…·å˜é‡å’Œè¿‡åº¦è¯†åˆ«\n",
    "5. **æ­£ç¡®è§£é‡Š IV ä¼°è®¡**ï¼šç†è§£ LATE ä¸ ATE çš„åŒºåˆ«\n",
    "6. **åº”ç”¨äºä¸šåŠ¡åœºæ™¯**ï¼šä»·æ ¼å¼¹æ€§ã€å¹¿å‘Šæ•ˆæœã€æ•™è‚²å›æŠ¥ç­‰çœŸå®æ¡ˆä¾‹\n",
    "\n",
    "---\n",
    "\n",
    "## ä¸šåŠ¡åœºæ™¯å¼•å…¥\n",
    "\n",
    "### åœºæ™¯ 1ï¼šç”µå•†ä»·æ ¼å¼¹æ€§ä¼°è®¡\n",
    "\n",
    "ä½ æ˜¯æŸç”µå•†å¹³å°çš„æ•°æ®ç§‘å­¦å®¶ï¼Œè€æ¿æƒ³çŸ¥é“ï¼š**é™ä»· 10% èƒ½å¸¦æ¥å¤šå°‘é”€é‡æå‡ï¼Ÿ**\n",
    "\n",
    "ä½ çš„ç¬¬ä¸€ååº”å¯èƒ½æ˜¯ï¼šæ”¶é›†å†å²æ•°æ®ï¼Œå›å½’ `é”€é‡ ~ ä»·æ ¼`ï¼Œä¸å°±å¾—åˆ°ä»·æ ¼å¼¹æ€§äº†å—ï¼Ÿ\n",
    "\n",
    "**ä½†æ˜¯ï¼**è€æ¿æé†’ä½ ï¼š\n",
    "- ğŸ”´ **æ—ºå­£éœ€æ±‚é«˜ï¼Œå•†å®¶æ•¢æ¶¨ä»·** â†’ é«˜ä»·æ ¼å¯¹åº”é«˜é”€é‡\n",
    "- ğŸ”´ **æ»é”€å•†å“è¢«è¿«é™ä»·** â†’ ä½ä»·æ ¼å¯¹åº”ä½é”€é‡\n",
    "\n",
    "ç›´æ¥å›å½’ä¼šå¾—åˆ° **æ­£ç›¸å…³**ï¼Œè€ŒçœŸå®çš„ä»·æ ¼å¼¹æ€§åº”è¯¥æ˜¯ **è´Ÿç›¸å…³**ï¼è¿™å°±æ˜¯ **å†…ç”Ÿæ€§** é—®é¢˜ã€‚\n",
    "\n",
    "### åœºæ™¯ 2ï¼šæ•™è‚²å›æŠ¥ç‡ä¼°è®¡\n",
    "\n",
    "æ”¿åºœæƒ³çŸ¥é“ï¼š**å¤šè¯»ä¸€å¹´ä¹¦èƒ½æé«˜å¤šå°‘æ”¶å…¥ï¼Ÿ**\n",
    "\n",
    "ç›´æ¥å›å½’ `æ”¶å…¥ ~ æ•™è‚²å¹´é™` ä¹Ÿæœ‰é—®é¢˜ï¼š\n",
    "- ğŸ”´ **èƒ½åŠ›å¼ºçš„äººæ›´æ„¿æ„è¯»ä¹¦** â†’ æ”¶å…¥é«˜æ˜¯å› ä¸ºèƒ½åŠ›ï¼Œä¸æ˜¯æ•™è‚²\n",
    "- ğŸ”´ **å®¶åº­æ¡ä»¶å¥½çš„äººè¯»ä¹¦å¤š** â†’ æ”¶å…¥é«˜æ˜¯å› ä¸ºå®¶åº­èµ„æºï¼Œä¸æ˜¯æ•™è‚²\n",
    "\n",
    "### å·¥å…·å˜é‡çš„æ€æƒ³\n",
    "\n",
    "æ‰¾ä¸€ä¸ª **\"å¤–éƒ¨å†²å‡»\"**ï¼Œå®ƒï¼š\n",
    "1. âœ… **å½±å“å¤„ç†å˜é‡** (å¦‚ï¼šæˆæœ¬å½±å“ä»·æ ¼ï¼Œè·ç¦»å½±å“æ•™è‚²)\n",
    "2. âœ… **ä¸ç›´æ¥å½±å“ç»“æœ** (é™¤äº†é€šè¿‡å¤„ç†å˜é‡)\n",
    "3. âœ… **ä¸æ··æ·†å› ç´ æ— å…³** (å¤–ç”Ÿçš„)\n",
    "\n",
    "è¿™å°±æ˜¯ **å·¥å…·å˜é‡ (Instrumental Variable, IV)**ï¼\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: ä»€ä¹ˆæ˜¯å†…ç”Ÿæ€§\n",
    "\n",
    "### 1.1 å†…ç”Ÿæ€§çš„å®šä¹‰\n",
    "\n",
    "åœ¨å›å½’æ¨¡å‹ä¸­ï¼Œå¦‚æœè§£é‡Šå˜é‡ $X$ ä¸è¯¯å·®é¡¹ $\\epsilon$ ç›¸å…³ï¼Œå³ï¼š\n",
    "\n",
    "$$\n",
    "\\text{Cov}(X, \\epsilon) \\neq 0\n",
    "$$\n",
    "\n",
    "åˆ™ç§° $X$ æ˜¯ **å†…ç”Ÿçš„ (endogenous)**ã€‚\n",
    "\n",
    "### 1.2 å†…ç”Ÿæ€§çš„æ¥æº\n",
    "\n",
    "| æ¥æº | ä¾‹å­ | åæœ |\n",
    "|------|------|------|\n",
    "| **é—æ¼å˜é‡** | èƒ½åŠ›å½±å“æ•™è‚²å’Œæ”¶å…¥ï¼Œä½†èƒ½åŠ›ä¸å¯è§‚æµ‹ | ä¼°è®¡æœ‰å |\n",
    "| **æµ‹é‡è¯¯å·®** | ä»·æ ¼æ•°æ®è®°å½•é”™è¯¯ | ç³»æ•°å‘ 0 å |\n",
    "| **åå‘å› æœ** | æ”¶å…¥é«˜ â†’ æ•™è‚²æŠ•èµ„å¤š | ä¼°è®¡æœ‰å |\n",
    "| **åŒæ—¶æ€§** | ä¾›éœ€åŒæ—¶å†³å®šä»·æ ¼å’Œæ•°é‡ | ä¼°è®¡æœ‰å |\n",
    "\n",
    "### 1.3 ç”ŸåŠ¨æ¯”å–»\n",
    "\n",
    "**æ¯”å–»ï¼šè¯æ•ˆè¯„ä¼°**\n",
    "\n",
    "å‡è®¾ä½ æƒ³è¯„ä¼° \"åƒè¯\" å¯¹ \"ç—…æƒ…å¥½è½¬\" çš„æ•ˆæœï¼š\n",
    "\n",
    "- ğŸ”´ **é—®é¢˜**ï¼šç—…æƒ…è¶Šé‡çš„äººè¶Šåƒè¯ â†’ åƒè¯çš„äººç—…æƒ…åè€Œæ›´ä¸¥é‡\n",
    "- âœ… **è§£å†³**ï¼šæ‰¾ä¸€ä¸ª \"è¯æˆ¿è·ç¦»\" ä½œä¸ºå·¥å…·å˜é‡\n",
    "  - ç¦»è¯æˆ¿è¿‘çš„äººæ›´å¯èƒ½åƒè¯ (ç›¸å…³æ€§)\n",
    "  - è¯æˆ¿è·ç¦»ä¸å½±å“ç—…æƒ…æœ¬èº« (æ’ä»–æ€§)\n",
    "  - è¯æˆ¿è·ç¦»ä¸ç—…æƒ…ä¸¥é‡ç¨‹åº¦æ— å…³ (å¤–ç”Ÿæ€§)\n",
    "\n",
    "é€šè¿‡ \"è¯æˆ¿è·ç¦»\" å¼•èµ·çš„ \"åƒè¯\" å˜åŒ–ï¼Œæ¥ä¼°è®¡çœŸå®çš„è¯æ•ˆï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 æ¨¡æ‹Ÿå†…ç”Ÿæ€§é—®é¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_endogeneity(n=1000):\n",
    "    \"\"\"\n",
    "    æ¨¡æ‹Ÿå†…ç”Ÿæ€§é—®é¢˜ï¼šéœ€æ±‚å†²å‡»åŒæ—¶å½±å“ä»·æ ¼å’Œé”€é‡\n",
    "    \n",
    "    çœŸå®æ¨¡å‹:\n",
    "    - éœ€æ±‚: D = 100 - 2*P + Î¸  (Î¸ æ˜¯éœ€æ±‚å†²å‡»)\n",
    "    - ä¾›ç»™: S = 50 + 3*P\n",
    "    - å‡è¡¡: D = S => P = 10 + 0.2*Î¸\n",
    "    \n",
    "    çœŸå®ä»·æ ¼å¼¹æ€§ = -2\n",
    "    \"\"\"\n",
    "    # éœ€æ±‚å†²å‡» (ä¸å¯è§‚æµ‹çš„æ··æ·†å› ç´ )\n",
    "    demand_shock = np.random.normal(0, 10, n)\n",
    "    \n",
    "    # å‡è¡¡ä»·æ ¼ (å—éœ€æ±‚å†²å‡»å½±å“ -> å†…ç”Ÿ)\n",
    "    price = 10 + 0.2 * demand_shock + np.random.normal(0, 1, n)\n",
    "    \n",
    "    # å‡è¡¡é”€é‡\n",
    "    quantity = 100 - 2 * price + demand_shock + np.random.normal(0, 2, n)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'price': price,\n",
    "        'quantity': quantity,\n",
    "        'demand_shock': demand_shock  # å®é™…ä¸­ä¸å¯è§‚æµ‹\n",
    "    })\n",
    "\n",
    "# ç”Ÿæˆæ•°æ®\n",
    "df = simulate_endogeneity()\n",
    "\n",
    "# OLS ä¼°è®¡ (æœ‰å)\n",
    "X = df[['price']].values\n",
    "y = df['quantity'].values\n",
    "ols_model = LinearRegression().fit(X, y)\n",
    "ols_coef = ols_model.coef_[0]\n",
    "\n",
    "print(f\"çœŸå®ä»·æ ¼å¼¹æ€§: -2.0\")\n",
    "print(f\"OLS ä¼°è®¡å¼¹æ€§: {ols_coef:.2f}\")\n",
    "print(f\"\\nâŒ OLS ä¸¥é‡æœ‰åï¼ä¼°è®¡å‡ºæ­£ç›¸å…³ï¼Œè€ŒçœŸå®æ˜¯è´Ÿç›¸å…³ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å†…ç”Ÿæ€§é—®é¢˜\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('OLS ä¼°è®¡ (æœ‰å)', 'çœŸå®å…³ç³» (æ§åˆ¶éœ€æ±‚å†²å‡»)')\n",
    ")\n",
    "\n",
    "# å·¦å›¾ï¼šOLS å›å½’\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df['price'], \n",
    "        y=df['quantity'],\n",
    "        mode='markers',\n",
    "        marker=dict(color='lightblue', size=6, opacity=0.6),\n",
    "        name='è§‚æµ‹æ•°æ®'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "x_range = np.linspace(df['price'].min(), df['price'].max(), 100)\n",
    "y_pred = ols_model.predict(x_range.reshape(-1, 1))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_range,\n",
    "        y=y_pred,\n",
    "        mode='lines',\n",
    "        line=dict(color='red', width=3),\n",
    "        name=f'OLS: slope={ols_coef:.2f}'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# å³å›¾ï¼šæŒ‰éœ€æ±‚å†²å‡»åˆ†ç»„ï¼Œæ˜¾ç¤ºçœŸå®è´Ÿç›¸å…³\n",
    "df['shock_group'] = pd.qcut(df['demand_shock'], q=5, labels=['å¾ˆä½', 'ä½', 'ä¸­', 'é«˜', 'å¾ˆé«˜'])\n",
    "colors = px.colors.sequential.Blues_r\n",
    "\n",
    "for i, group in enumerate(['å¾ˆä½', 'ä½', 'ä¸­', 'é«˜', 'å¾ˆé«˜']):\n",
    "    group_data = df[df['shock_group'] == group]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=group_data['price'],\n",
    "            y=group_data['quantity'],\n",
    "            mode='markers',\n",
    "            marker=dict(color=colors[i], size=8, opacity=0.7),\n",
    "            name=f'éœ€æ±‚å†²å‡»: {group}'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# æ·»åŠ çœŸå®æ–œç‡çš„å‚è€ƒçº¿\n",
    "for group in ['å¾ˆä½', 'ä½', 'ä¸­', 'é«˜', 'å¾ˆé«˜']:\n",
    "    group_data = df[df['shock_group'] == group]\n",
    "    if len(group_data) > 0:\n",
    "        # æ‹Ÿåˆçº¿æ€§å›å½’\n",
    "        X_group = group_data[['price']].values\n",
    "        y_group = group_data['quantity'].values\n",
    "        model_group = LinearRegression().fit(X_group, y_group)\n",
    "        \n",
    "        x_line = np.linspace(group_data['price'].min(), group_data['price'].max(), 100)\n",
    "        y_line = model_group.predict(x_line.reshape(-1, 1))\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_line,\n",
    "                y=y_line,\n",
    "                mode='lines',\n",
    "                line=dict(color='gray', width=1, dash='dash'),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "fig.update_xaxes(title_text=\"ä»·æ ¼\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"ä»·æ ¼\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"é”€é‡\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"é”€é‡\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    title_text=\"å†…ç”Ÿæ€§é—®é¢˜ç¤ºä¾‹ï¼šéœ€æ±‚å†²å‡»å¯¼è‡´ OLS æœ‰å\",\n",
    "    showlegend=True,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"ğŸ“Š è§£è¯»ï¼š\")\n",
    "print(\"- å·¦å›¾ï¼šæ‰€æœ‰æ•°æ®æ··åœ¨ä¸€èµ·ï¼ŒOLS ä¼°è®¡å‡ºæ­£ç›¸å…³ (é”™è¯¯!)\")\n",
    "print(\"- å³å›¾ï¼šæ§åˆ¶éœ€æ±‚å†²å‡»åï¼Œæ¯ç»„å†…éƒ½æ˜¯è´Ÿç›¸å…³ (æ­£ç¡®!)\")\n",
    "print(\"- é—®é¢˜æ ¹æºï¼šéœ€æ±‚å†²å‡»åŒæ—¶å½±å“ä»·æ ¼å’Œé”€é‡ï¼Œå¯¼è‡´æ··æ·†åå·®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: å·¥å…·å˜é‡çš„ä¸‰ä¸ªå‡è®¾\n",
    "\n",
    "### 2.1 ç¬¦å·å®šä¹‰\n",
    "\n",
    "æˆ‘ä»¬æƒ³ä¼°è®¡ä»¥ä¸‹å› æœæ•ˆåº”ï¼š\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X + \\epsilon\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- $Y$: ç»“æœå˜é‡ (outcome, å¦‚é”€é‡ã€æ”¶å…¥)\n",
    "- $X$: å¤„ç†å˜é‡ (treatment, å¦‚ä»·æ ¼ã€æ•™è‚²å¹´é™)\n",
    "- $\\epsilon$: è¯¯å·®é¡¹ (åŒ…å«ä¸å¯è§‚æµ‹çš„æ··æ·†å› ç´ )\n",
    "- $Z$: å·¥å…·å˜é‡ (instrument)\n",
    "\n",
    "### 2.2 ä¸‰ä¸ªæ ¸å¿ƒå‡è®¾\n",
    "\n",
    "#### å‡è®¾ 1: ç›¸å…³æ€§ (Relevance)\n",
    "\n",
    "$$\n",
    "\\text{Cov}(Z, X) \\neq 0\n",
    "$$\n",
    "\n",
    "**å«ä¹‰**ï¼šå·¥å…·å˜é‡ $Z$ å¿…é¡»ä¸å¤„ç†å˜é‡ $X$ ç›¸å…³ã€‚\n",
    "\n",
    "**å¯æ£€éªŒæ€§**ï¼šâœ… å¯ä»¥é€šè¿‡ç¬¬ä¸€é˜¶æ®µå›å½’æ£€éªŒ (F ç»Ÿè®¡é‡ > 10)\n",
    "\n",
    "**ä¾‹å­**ï¼š\n",
    "- æˆæœ¬å½±å“ä»·æ ¼ âœ…\n",
    "- è·ç¦»å½±å“æ•™è‚²å¹´é™ âœ…\n",
    "- å¤©æ°”å½±å“å¹¿å‘Šæ›å…‰ âœ…\n",
    "\n",
    "#### å‡è®¾ 2: æ’ä»–æ€§ (Exclusion Restriction)\n",
    "\n",
    "$$\n",
    "Z \\text{ åªèƒ½é€šè¿‡ } X \\text{ å½±å“ } Y\n",
    "$$\n",
    "\n",
    "**å«ä¹‰**ï¼šå·¥å…·å˜é‡åªèƒ½é€šè¿‡å¤„ç†å˜é‡é—´æ¥å½±å“ç»“æœï¼Œä¸èƒ½æœ‰ç›´æ¥è·¯å¾„ã€‚\n",
    "\n",
    "**å¯æ£€éªŒæ€§**ï¼šâŒ ä¸å¯ç›´æ¥æ£€éªŒï¼Œéœ€è¦ç»æµå­¦é€»è¾‘æ”¯æ’‘\n",
    "\n",
    "**ä¾‹å­**ï¼š\n",
    "- æˆæœ¬å½±å“é”€é‡ï¼Œåªèƒ½é€šè¿‡ä»·æ ¼ âœ…\n",
    "- è·ç¦»å½±å“æ”¶å…¥ï¼Œåªèƒ½é€šè¿‡æ•™è‚² âœ… (å¦‚æœè·ç¦»è¿˜å½±å“å°±ä¸šæœºä¼šï¼Œåˆ™ä¸æ»¡è¶³ âŒ)\n",
    "\n",
    "#### å‡è®¾ 3: å¤–ç”Ÿæ€§ (Exogeneity)\n",
    "\n",
    "$$\n",
    "\\text{Cov}(Z, \\epsilon) = 0\n",
    "$$\n",
    "\n",
    "**å«ä¹‰**ï¼šå·¥å…·å˜é‡ä¸è¯¯å·®é¡¹ä¸ç›¸å…³ï¼Œå³ä¸ä¸å¯è§‚æµ‹çš„æ··æ·†å› ç´ æ— å…³ã€‚\n",
    "\n",
    "**å¯æ£€éªŒæ€§**ï¼šâŒ ä¸å¯ç›´æ¥æ£€éªŒï¼Œéœ€è¦åˆ¶åº¦èƒŒæ™¯æ”¯æ’‘\n",
    "\n",
    "**ä¾‹å­**ï¼š\n",
    "- åŸææ–™æˆæœ¬çš„å¤–ç”Ÿå†²å‡» (å¦‚è‡ªç„¶ç¾å®³) âœ…\n",
    "- å‡ºç”Ÿåœ°ä¸å­¦æ ¡çš„è·ç¦» (éšæœºçš„) âœ…\n",
    "- é™é›¨å½±å“å¿ƒæƒ…ï¼Œè¿›è€Œå½±å“æ¶ˆè´¹ (ä¸æ»¡è¶³) âŒ\n",
    "\n",
    "### 2.3 å› æœå›¾è¡¨ç¤º\n",
    "\n",
    "```\n",
    "æœ‰æ•ˆçš„ IV:\n",
    "      \n",
    "   Z (å·¥å…·å˜é‡)\n",
    "   |\n",
    "   v\n",
    "   X (å¤„ç†) --> Y (ç»“æœ)\n",
    "   ^              ^\n",
    "   |              |\n",
    "   +---- U -------+\n",
    "   (ä¸å¯è§‚æµ‹æ··æ·†)\n",
    "\n",
    "è¦æ±‚:\n",
    "1. Z -> X (ç›¸å…³æ€§)\n",
    "2. Z ä¸ç›´æ¥æŒ‡å‘ Y (æ’ä»–æ€§)\n",
    "3. Z ä¸ U æ— å…³ (å¤–ç”Ÿæ€§)\n",
    "```\n",
    "\n",
    "### 2.4 ç”ŸåŠ¨æ¯”å–»\n",
    "\n",
    "**æ¯”å–»ï¼šäº¤é€šé™è¡Œæ”¿ç­–è¯„ä¼°è½¦è¾†å¯¹ç©ºæ°”è´¨é‡çš„å½±å“**\n",
    "\n",
    "- **é—®é¢˜**ï¼šè½¦è¾†æ•° $X$ ä¸æ±¡æŸ“ $Y$ éƒ½å—ç»æµå‘å±• $U$ å½±å“ (å†…ç”Ÿ)\n",
    "- **å·¥å…·å˜é‡**ï¼šé™è¡Œæ”¿ç­– $Z$ (éšæœºåˆ†é…å•åŒå·)\n",
    "\n",
    "æ£€éªŒä¸‰ä¸ªå‡è®¾ï¼š\n",
    "1. âœ… **ç›¸å…³æ€§**ï¼šé™è¡Œç¡®å®å‡å°‘è½¦è¾†æ•°\n",
    "2. âœ… **æ’ä»–æ€§**ï¼šé™è¡Œåªèƒ½é€šè¿‡å‡å°‘è½¦è¾†æ¥æ”¹å–„ç©ºæ°” (å‡è®¾æ²¡æœ‰å¿ƒç†å®‰æ…°æ•ˆåº”)\n",
    "3. âœ… **å¤–ç”Ÿæ€§**ï¼šå•åŒå·æ˜¯éšæœºçš„ï¼Œä¸ç»æµå‘å±•æ— å…³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n# TODO 1: æ¨¡æ‹Ÿä¸€ä¸ªå¥½çš„å·¥å…·å˜é‡åœºæ™¯ - å®Œæ•´å®ç°\n# ===================================\n\ndef simulate_good_iv(n=1000):\n    \"\"\"\n    æ¨¡æ‹Ÿä¸€ä¸ªæ»¡è¶³ IV å‡è®¾çš„åœºæ™¯\n    \n    Z (æˆæœ¬å†²å‡») -> X (ä»·æ ¼) -> Y (é”€é‡)\n                      ^          ^\n                      |          |\n                      +--- U ----+\n                    (éœ€æ±‚å†²å‡»)\n    \"\"\"\n    # ä¸å¯è§‚æµ‹çš„éœ€æ±‚å†²å‡»ï¼ˆæ··æ·†å› å­ï¼‰\n    demand_shock = np.random.normal(0, 10, n)\n    \n    # åˆ›å»ºä¸€ä¸ªå¤–ç”Ÿçš„æˆæœ¬å†²å‡» Zï¼ˆä¸éœ€æ±‚å†²å‡»æ— å…³ï¼‰\n    cost_shock = np.random.normal(0, 5, n)\n    \n    # ä»·æ ¼å—æˆæœ¬å†²å‡»å’Œéœ€æ±‚å†²å‡»å½±å“\n    # å…¬å¼: P = 10 + 0.5*Z + 0.2*U + noise\n    price = 10 + 0.5 * cost_shock + 0.2 * demand_shock + np.random.normal(0, 1, n)\n    \n    # é”€é‡åªå—ä»·æ ¼å’Œéœ€æ±‚å†²å‡»å½±å“ï¼ˆæˆæœ¬ä¸ç›´æ¥å½±å“é”€é‡ï¼‰\n    # å…¬å¼: Q = 100 - 2*P + U + noise\n    # çœŸå®çš„å› æœæ•ˆåº”: âˆ‚Q/âˆ‚P = -2\n    quantity = 100 - 2 * price + demand_shock + np.random.normal(0, 2, n)\n    \n    return pd.DataFrame({\n        'cost_shock': cost_shock,\n        'price': price,\n        'quantity': quantity,\n        'demand_shock': demand_shock\n    })\n\n# ç”Ÿæˆæ•°æ®\nnp.random.seed(42)\ndf_iv = simulate_good_iv()\n\nprint(\"âœ… æ•°æ®ç”Ÿæˆå®Œæˆ\")\nprint(\"",
    "æ•°æ®é¢„è§ˆ:\")\nprint(df_iv.head())\n\nprint(\"",
    "å˜é‡å…³ç³»:\")\nprint(f\"  æˆæœ¬å†²å‡» â†’ ä»·æ ¼: {df_iv['cost_shock'].corr(df_iv['price']):.3f}\")\nprint(f\"  æˆæœ¬å†²å‡» â†’ é”€é‡: {df_iv['cost_shock'].corr(df_iv['quantity']):.3f}\")\nprint(f\"  ä»·æ ¼ â†’ é”€é‡: {df_iv['price'].corr(df_iv['quantity']):.3f}\")\nprint(f\"  éœ€æ±‚å†²å‡» â†’ ä»·æ ¼: {df_iv['demand_shock'].corr(df_iv['price']):.3f}\")\nprint(f\"  éœ€æ±‚å†²å‡» â†’ é”€é‡: {df_iv['demand_shock'].corr(df_iv['quantity']):.3f}\")\n\nprint(\"",
    "ğŸ’¡ IV å‡è®¾æ£€æŸ¥:\")\nprint(\"  1. ç›¸å…³æ€§ï¼ˆRelevanceï¼‰: æˆæœ¬å†²å‡» â†’ ä»·æ ¼ï¼Ÿ\")\nprint(f\"     Cor(Z, X) = {df_iv['cost_shock'].corr(df_iv['price']):.3f} âœ“ å¼ºç›¸å…³\")\n\nprint(\"  2. å¤–ç”Ÿæ€§ï¼ˆExclusionï¼‰: æˆæœ¬å†²å‡»åªé€šè¿‡ä»·æ ¼å½±å“é”€é‡ï¼Ÿ\")\nprint(f\"     Cor(Z, Y | X) â‰ˆ 0ï¼Ÿæ— æ³•ç›´æ¥æ£€éªŒï¼Œéœ€è¦ç†è®ºæ”¯æŒ\")\n\nprint(\"  3. æ’é™¤æ€§ï¼ˆExogeneityï¼‰: æˆæœ¬å†²å‡»ä¸éœ€æ±‚å†²å‡»æ— å…³ï¼Ÿ\")\nprint(f\"     Cor(Z, U) = {df_iv['cost_shock'].corr(df_iv['demand_shock']):.3f} âœ“ å‡ ä¹ä¸º 0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€éªŒä¸‰ä¸ªå‡è®¾\n",
    "def check_iv_assumptions(df):\n",
    "    \"\"\"\n",
    "    æ£€éªŒ IV çš„ä¸‰ä¸ªå‡è®¾\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"å·¥å…·å˜é‡å‡è®¾æ£€éªŒ\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # å‡è®¾ 1: ç›¸å…³æ€§ (å¯æ£€éªŒ)\n",
    "    corr_zx = df['cost_shock'].corr(df['price'])\n",
    "    print(f\"\\n1ï¸âƒ£  ç›¸å…³æ€§å‡è®¾: Corr(Z, X) = {corr_zx:.3f}\")\n",
    "    if abs(corr_zx) > 0.3:\n",
    "        print(\"   âœ… æ»¡è¶³! å·¥å…·å˜é‡ä¸å¤„ç†å˜é‡å¼ºç›¸å…³\")\n",
    "    else:\n",
    "        print(\"   âŒ ä¸æ»¡è¶³! å¼±å·¥å…·å˜é‡é—®é¢˜\")\n",
    "    \n",
    "    # å‡è®¾ 2: æ’ä»–æ€§ (ä¸å¯ç›´æ¥æ£€éªŒï¼Œä½†å¯ä»¥çœ‹ reduced form)\n",
    "    corr_zy = df['cost_shock'].corr(df['quantity'])\n",
    "    print(f\"\\n2ï¸âƒ£  æ’ä»–æ€§å‡è®¾: Corr(Z, Y) = {corr_zy:.3f}\")\n",
    "    print(\"   âš ï¸  ä¸å¯ç›´æ¥æ£€éªŒï¼Œéœ€è¦ç†è®ºæ”¯æ’‘\")\n",
    "    print(\"   (å¦‚æœ Z ä¸ Y å®Œå…¨ä¸ç›¸å…³ï¼Œå¯èƒ½è¿åç›¸å…³æ€§å‡è®¾)\")\n",
    "    \n",
    "    # å‡è®¾ 3: å¤–ç”Ÿæ€§ (ä¸å¯æ£€éªŒï¼Œä½†å¯ä»¥çœ‹ä¸æ··æ·†å› ç´ çš„ç›¸å…³æ€§)\n",
    "    corr_zu = df['cost_shock'].corr(df['demand_shock'])\n",
    "    print(f\"\\n3ï¸âƒ£  å¤–ç”Ÿæ€§å‡è®¾: Corr(Z, U) = {corr_zu:.3f}\")\n",
    "    if abs(corr_zu) < 0.1:\n",
    "        print(\"   âœ… æ»¡è¶³! å·¥å…·å˜é‡ä¸æ··æ·†å› ç´ åŸºæœ¬æ— å…³\")\n",
    "    else:\n",
    "        print(\"   âŒ ä¸æ»¡è¶³! å·¥å…·å˜é‡å¯èƒ½ä¸æ˜¯å¤–ç”Ÿçš„\")\n",
    "    print(\"   âš ï¸  å®é™…ä¸­ U ä¸å¯è§‚æµ‹ï¼Œæ— æ³•ç›´æ¥æ£€éªŒ\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "check_iv_assumptions(df_iv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: ä¸¤é˜¶æ®µæœ€å°äºŒä¹˜ (2SLS) ä¼°è®¡\n",
    "\n",
    "### 3.1 2SLS çš„ç›´è§‰\n",
    "\n",
    "æ—¢ç„¶ $X$ æ˜¯å†…ç”Ÿçš„ï¼Œæˆ‘ä»¬ä¸èƒ½ç›´æ¥å›å½’ã€‚2SLS çš„æ€è·¯æ˜¯ï¼š\n",
    "\n",
    "1. **ç¬¬ä¸€é˜¶æ®µ**ï¼šç”¨å·¥å…·å˜é‡ $Z$ é¢„æµ‹ $X$ï¼Œå¾—åˆ° \"å¤–ç”Ÿéƒ¨åˆ†\" $\\hat{X}$\n",
    "2. **ç¬¬äºŒé˜¶æ®µ**ï¼šç”¨ $\\hat{X}$ å»é¢„æµ‹ $Y$ï¼Œå¾—åˆ°æ— åä¼°è®¡\n",
    "\n",
    "### 3.2 æ•°å­¦æ¨å¯¼\n",
    "\n",
    "#### ç¬¬ä¸€é˜¶æ®µ (First Stage)\n",
    "\n",
    "$$\n",
    "X = \\pi_0 + \\pi_1 Z + \\nu\n",
    "$$\n",
    "\n",
    "å¾—åˆ°é¢„æµ‹å€¼ï¼š\n",
    "\n",
    "$$\n",
    "\\hat{X} = \\hat{\\pi}_0 + \\hat{\\pi}_1 Z\n",
    "$$\n",
    "\n",
    "**å…³é”®**ï¼š$\\hat{X}$ åªåŒ…å«ç”± $Z$ å¼•èµ·çš„ $X$ çš„å˜åŒ–ï¼Œè¿™éƒ¨åˆ†æ˜¯ **å¤–ç”Ÿçš„**ï¼\n",
    "\n",
    "#### ç¬¬äºŒé˜¶æ®µ (Second Stage)\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 \\hat{X} + \\epsilon\n",
    "$$\n",
    "\n",
    "å¾—åˆ° 2SLS ä¼°è®¡é‡ï¼š\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_{2SLS} = \\frac{\\text{Cov}(Z, Y)}{\\text{Cov}(Z, X)}\n",
    "$$\n",
    "\n",
    "è¿™ä¹Ÿè¢«ç§°ä¸º **Wald ä¼°è®¡é‡**ã€‚\n",
    "\n",
    "### 3.3 ç”ŸåŠ¨æ¯”å–»\n",
    "\n",
    "**æ¯”å–»ï¼šè¯æ•ˆè¯„ä¼°çš„éšæœºåˆ†é…**\n",
    "\n",
    "- **é—®é¢˜**ï¼šé‡ç—…æ‚£è€…æ›´å¯èƒ½åƒè¯ (å†…ç”Ÿ)\n",
    "- **è§£å†³**ï¼š\n",
    "  1. ç¬¬ä¸€é˜¶æ®µï¼šçœ‹ \"è¯æˆ¿è·ç¦»\" å¦‚ä½•å½±å“ \"åƒè¯æ¦‚ç‡\"\n",
    "  2. ç¬¬äºŒé˜¶æ®µï¼šç”¨ \"ç”±è·ç¦»å¼•èµ·çš„åƒè¯å˜åŒ–\" æ¥ä¼°è®¡è¯æ•ˆ\n",
    "\n",
    "è¿™æ ·ï¼Œæˆ‘ä»¬åªåˆ©ç”¨äº† \"å¤–ç”Ÿçš„ã€éšæœºçš„\" åƒè¯å˜åŒ–ï¼Œé¿å…äº†ç—…æƒ…ä¸¥é‡æ€§çš„æ··æ·†ï¼\n",
    "\n",
    "### 3.4 ç¬¦å·è¯´æ˜\n",
    "\n",
    "| ç¬¦å· | å«ä¹‰ |\n",
    "|------|------|\n",
    "| $Y$ | ç»“æœå˜é‡ (é”€é‡ã€æ”¶å…¥ç­‰) |\n",
    "| $X$ | å†…ç”Ÿå¤„ç†å˜é‡ (ä»·æ ¼ã€æ•™è‚²ç­‰) |\n",
    "| $Z$ | å·¥å…·å˜é‡ (æˆæœ¬ã€è·ç¦»ç­‰) |\n",
    "| $\\hat{X}$ | ç¬¬ä¸€é˜¶æ®µé¢„æµ‹çš„ $X$ (å¤–ç”Ÿéƒ¨åˆ†) |\n",
    "| $\\pi_1$ | ç¬¬ä¸€é˜¶æ®µç³»æ•° (å·¥å…·å˜é‡å¯¹å¤„ç†çš„å½±å“) |\n",
    "| $\\beta_1$ | å› æœæ•ˆåº” (å¤„ç†å¯¹ç»“æœçš„å½±å“) |\n",
    "| $\\hat{\\beta}_{2SLS}$ | 2SLS ä¼°è®¡é‡ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n# TODO 2: æ‰‹åŠ¨å®ç° 2SLS ä¼°è®¡ - å®Œæ•´å®ç°\n# ===================================\n\nfrom sklearn.linear_model import LinearRegression\n\ndef two_stage_least_squares(Z, X, Y):\n    \"\"\"\n    æ‰‹åŠ¨å®ç° 2SLS\n    \n    å‚æ•°:\n        Z: å·¥å…·å˜é‡ (n,)\n        X: å†…ç”Ÿå¤„ç†å˜é‡ (n,)\n        Y: ç»“æœå˜é‡ (n,)\n    \n    è¿”å›:\n        results: åŒ…å«ä¼°è®¡ç»“æœçš„å­—å…¸\n    \"\"\"\n    # ç¬¬ä¸€é˜¶æ®µ - å›å½’ X ~ Z\n    first_stage = LinearRegression()\n    first_stage.fit(Z.reshape(-1, 1), X)\n    \n    # è·å–é¢„æµ‹å€¼ X_hat\n    X_hat = first_stage.predict(Z.reshape(-1, 1))\n    \n    # æ£€æŸ¥ç¬¬ä¸€é˜¶æ®µ F ç»Ÿè®¡é‡\n    ss_res = np.sum((X - X_hat)**2)\n    ss_tot = np.sum((X - np.mean(X))**2)\n    r2_first = 1 - ss_res / ss_tot\n    n = len(X)\n    f_stat = (r2_first / (1 - r2_first)) * (n - 2)\n    \n    # ç¬¬äºŒé˜¶æ®µ - å›å½’ Y ~ X_hat\n    second_stage = LinearRegression()\n    second_stage.fit(X_hat.reshape(-1, 1), Y)\n    \n    # è·å– 2SLS ä¼°è®¡é‡\n    beta_2sls = second_stage.coef_[0]\n    \n    # æ–¹æ³• 2: ç”¨ Wald å…¬å¼è®¡ç®—ï¼ˆç†è®ºä¸Šç›¸åŒï¼‰\n    cov_zy = np.cov(Z, Y)[0, 1]\n    cov_zx = np.cov(Z, X)[0, 1]\n    beta_wald = cov_zy / cov_zx\n    \n    # è®¡ç®—æ ‡å‡†è¯¯ï¼ˆéœ€è¦è°ƒæ•´ï¼Œå› ä¸ºç¬¬ä¸€é˜¶æ®µæœ‰ä¸ç¡®å®šæ€§ï¼‰\n    # ç®€åŒ–ç‰ˆï¼šä½¿ç”¨ç¬¬äºŒé˜¶æ®µçš„æ®‹å·®ä¼°è®¡æ–¹å·®\n    y_pred = second_stage.predict(X_hat.reshape(-1, 1))\n    residuals = Y - y_pred\n    sigma2 = np.sum(residuals**2) / (n - 2)\n    \n    # 2SLS æ–¹å·®ï¼ˆç®€åŒ–å…¬å¼ï¼‰\n    var_x_hat = np.var(X_hat)\n    se_2sls = np.sqrt(sigma2 / (n * var_x_hat))\n    \n    return {\n        'beta_2sls': beta_2sls,\n        'beta_wald': beta_wald,\n        'se_2sls': se_2sls,\n        'first_stage_r2': r2_first,\n        'first_stage_f': f_stat,\n        'first_stage': first_stage,\n        'second_stage': second_stage,\n        'X_hat': X_hat,\n        'residuals': residuals\n    }\n\n# åº”ç”¨ 2SLS\nresults = two_stage_least_squares(\n    df_iv['cost_shock'].values,\n    df_iv['price'].values,\n    df_iv['quantity'].values\n)\n\nprint(\"=\" * 70)\nprint(\"2SLS ä¼°è®¡ç»“æœ\")\nprint(\"=\" * 70)\n\nprint(\"",
    "ã€ç¬¬ä¸€é˜¶æ®µã€‘ä»·æ ¼ ~ æˆæœ¬å†²å‡»\")\nprint(f\"  RÂ²: {results['first_stage_r2']:.4f}\")\nprint(f\"  F-ç»Ÿè®¡é‡: {results['first_stage_f']:.2f}\")\nif results['first_stage_f'] > 10:\n    print(f\"  âœ“ F > 10ï¼Œå·¥å…·å˜é‡å¼º\")\nelse:\n    print(f\"  âš  F < 10ï¼Œå­˜åœ¨å¼±å·¥å…·å˜é‡é—®é¢˜\")\n\nprint(\"",
    "ã€ç¬¬äºŒé˜¶æ®µã€‘é”€é‡ ~ é¢„æµ‹ä»·æ ¼\")\nprint(f\"  çœŸå®å› æœæ•ˆåº”: -2.0\")\nprint(f\"  2SLS ä¼°è®¡: {results['beta_2sls']:.4f}\")\nprint(f\"  Wald ä¼°è®¡: {results['beta_wald']:.4f}\")\nprint(f\"  æ ‡å‡†è¯¯: {results['se_2sls']:.4f}\")\nprint(f\"  95% CI: [{results['beta_2sls'] - 1.96*results['se_2sls']:.4f}, \"\n      f\"{results['beta_2sls'] + 1.96*results['se_2sls']:.4f}]\")\n\n# å¯¹æ¯” OLSï¼ˆæœ‰åï¼‰\nfrom sklearn.linear_model import LinearRegression\nols = LinearRegression()\nols.fit(df_iv['price'].values.reshape(-1, 1), df_iv['quantity'].values)\nbeta_ols = ols.coef_[0]\n\nprint(f\"",
    "ã€å¯¹æ¯” OLSã€‘\")\nprint(f\"  OLS ä¼°è®¡: {beta_ols:.4f} (æœ‰åï¼)\")\nprint(f\"  2SLS ä¼°è®¡: {results['beta_2sls']:.4f} (æ— å)\")\nprint(f\"  çœŸå®å€¼: -2.0\")\nprint(f\"  OLS åå·®: {abs(beta_ols - (-2.0)):.4f}\")\nprint(f\"  2SLS åå·®: {abs(results['beta_2sls'] - (-2.0)):.4f}\")\n\nprint(\"",
    "ğŸ’¡ è§£è¯»:\")\nprint(\"  â€¢ OLS ä¼°è®¡æœ‰åï¼Œå› ä¸ºä»·æ ¼å’Œéœ€æ±‚å†²å‡»ç›¸å…³ï¼ˆå†…ç”Ÿæ€§ï¼‰\")\nprint(\"  â€¢ 2SLS ä½¿ç”¨æˆæœ¬å†²å‡»ä½œä¸ºå·¥å…·å˜é‡ï¼Œæ¶ˆé™¤äº†å†…ç”Ÿæ€§\")\nprint(\"  â€¢ 2SLS ä¼°è®¡æ›´æ¥è¿‘çœŸå®çš„å› æœæ•ˆåº”\")\n\nprint(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– 2SLS ä¸¤ä¸ªé˜¶æ®µ\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('ç¬¬ä¸€é˜¶æ®µ: Z â†’ X', 'ç¬¬äºŒé˜¶æ®µ: XÌ‚ â†’ Y')\n",
    ")\n",
    "\n",
    "# ç¬¬ä¸€é˜¶æ®µ\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_iv['cost_shock'],\n",
    "        y=df_iv['price'],\n",
    "        mode='markers',\n",
    "        marker=dict(color='lightblue', size=6, opacity=0.6),\n",
    "        name='è§‚æµ‹æ•°æ®'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# ç¬¬ä¸€é˜¶æ®µæ‹Ÿåˆçº¿\n",
    "z_range = np.linspace(df_iv['cost_shock'].min(), df_iv['cost_shock'].max(), 100)\n",
    "x_pred = results['first_stage'].predict(z_range.reshape(-1, 1))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=z_range,\n",
    "        y=x_pred,\n",
    "        mode='lines',\n",
    "        line=dict(color='green', width=3),\n",
    "        name='ç¬¬ä¸€é˜¶æ®µæ‹Ÿåˆ'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# ç¬¬äºŒé˜¶æ®µ\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=results['X_hat'],\n",
    "        y=df_iv['quantity'],\n",
    "        mode='markers',\n",
    "        marker=dict(color='lightcoral', size=6, opacity=0.6),\n",
    "        name='é¢„æµ‹çš„ X'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# ç¬¬äºŒé˜¶æ®µæ‹Ÿåˆçº¿\n",
    "x_hat_range = np.linspace(results['X_hat'].min(), results['X_hat'].max(), 100)\n",
    "y_pred = results['second_stage'].predict(x_hat_range.reshape(-1, 1))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_hat_range,\n",
    "        y=y_pred,\n",
    "        mode='lines',\n",
    "        line=dict(color='red', width=3),\n",
    "        name=f'ç¬¬äºŒé˜¶æ®µæ‹Ÿåˆ (slope={results[\"beta_2sls\"]:.2f})'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"æˆæœ¬å†²å‡» (Z)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"é¢„æµ‹çš„ä»·æ ¼ (XÌ‚)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"ä»·æ ¼ (X)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"é”€é‡ (Y)\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    title_text=\"2SLS ä¸¤é˜¶æ®µä¼°è®¡è¿‡ç¨‹\",\n",
    "    showlegend=True,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"ğŸ“Š è§£è¯»ï¼š\")\n",
    "print(\"- ç¬¬ä¸€é˜¶æ®µï¼šæå–ä»·æ ¼ä¸­ç”±æˆæœ¬å†²å‡»å¼•èµ·çš„å¤–ç”Ÿå˜åŒ–\")\n",
    "print(\"- ç¬¬äºŒé˜¶æ®µï¼šç”¨å¤–ç”Ÿçš„ä»·æ ¼å˜åŒ–ä¼°è®¡å¯¹é”€é‡çš„å½±å“\")\n",
    "print(\"- å…³é”®ï¼šXÌ‚ æ˜¯å¤–ç”Ÿçš„ï¼Œä¸éœ€æ±‚å†²å‡»æ— å…³ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹æ¯” OLS å’Œ 2SLS\n",
    "def compare_ols_2sls(df):\n",
    "    \"\"\"\n",
    "    å¯¹æ¯” OLS å’Œ 2SLS çš„ä¼°è®¡ç»“æœ\n",
    "    \"\"\"\n",
    "    # OLS ä¼°è®¡\n",
    "    ols = LinearRegression()\n",
    "    ols.fit(df[['price']], df['quantity'])\n",
    "    beta_ols = ols.coef_[0]\n",
    "    \n",
    "    # 2SLS ä¼°è®¡\n",
    "    results_2sls = two_stage_least_squares(\n",
    "        df['cost_shock'].values,\n",
    "        df['price'].values,\n",
    "        df['quantity'].values\n",
    "    )\n",
    "    beta_2sls = results_2sls['beta_2sls']\n",
    "    \n",
    "    # ç»“æœå¯¹æ¯”\n",
    "    comparison = pd.DataFrame({\n",
    "        'ä¼°è®¡æ–¹æ³•': ['çœŸå®å€¼', 'OLS (æœ‰å)', '2SLS (æ— å)'],\n",
    "        'ä¼°è®¡å€¼': [-2.0, beta_ols, beta_2sls],\n",
    "        'åå·®': [0, beta_ols + 2.0, beta_2sls + 2.0]\n",
    "    })\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "comparison = compare_ols_2sls(df_iv)\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: å¼±å·¥å…·å˜é‡é—®é¢˜\n",
    "\n",
    "### 4.1 ä»€ä¹ˆæ˜¯å¼±å·¥å…·å˜é‡\n",
    "\n",
    "å¦‚æœå·¥å…·å˜é‡ $Z$ ä¸å¤„ç†å˜é‡ $X$ çš„ç›¸å…³æ€§å¾ˆå¼±ï¼Œå³ï¼š\n",
    "\n",
    "$$\n",
    "\\text{Cov}(Z, X) \\approx 0\n",
    "$$\n",
    "\n",
    "åˆ™ç§° $Z$ æ˜¯ **å¼±å·¥å…·å˜é‡ (weak instrument)**ã€‚\n",
    "\n",
    "### 4.2 å¼± IV çš„é—®é¢˜\n",
    "\n",
    "1. **æœ‰é™æ ·æœ¬åå·®**ï¼š2SLS ä¼°è®¡é‡ä¸å†æ˜¯æ— åçš„\n",
    "2. **æ¨æ–­å¤±æ•ˆ**ï¼šæ ‡å‡†è¯¯è¢«ä½ä¼°ï¼Œç½®ä¿¡åŒºé—´è¿‡çª„\n",
    "3. **æ”¾å¤§å†…ç”Ÿæ€§**ï¼šå³ä½¿ $Z$ ä¸ $\\epsilon$ åªæœ‰å¾®å°ç›¸å…³ï¼Œä¹Ÿä¼šå¯¼è‡´å¤§åå·®\n",
    "\n",
    "### 4.3 F ç»Ÿè®¡é‡æ£€éªŒ\n",
    "\n",
    "**ç»éªŒæ³•åˆ™**ï¼šç¬¬ä¸€é˜¶æ®µ F ç»Ÿè®¡é‡ > 10\n",
    "\n",
    "$$\n",
    "F = \\frac{(RSS_{restricted} - RSS_{unrestricted}) / q}{RSS_{unrestricted} / (n - k)}\n",
    "$$\n",
    "\n",
    "å¯¹äºå•ä¸ªå·¥å…·å˜é‡ï¼Œç®€åŒ–ä¸ºï¼š\n",
    "\n",
    "$$\n",
    "F = \\frac{\\hat{\\pi}_1^2}{\\text{Var}(\\hat{\\pi}_1)}\n",
    "$$\n",
    "\n",
    "### 4.4 ç”ŸåŠ¨æ¯”å–»\n",
    "\n",
    "**æ¯”å–»ï¼šç”¨æ¸©åº¦è®¡æµ‹ä½“é‡**\n",
    "\n",
    "å‡è®¾ä½ æƒ³ä¼°è®¡ \"è¿åŠ¨æ—¶é•¿\" å¯¹ \"ä½“é‡\" çš„å½±å“ï¼Œä½† \"è¿åŠ¨æ—¶é•¿\" æ˜¯å†…ç”Ÿçš„ (çˆ±è¿åŠ¨çš„äººæœ¬æ¥å°±ç˜¦)ã€‚\n",
    "\n",
    "- ä½ æ‰¾åˆ°ä¸€ä¸ªå·¥å…·å˜é‡ \"æ°”æ¸©\"ï¼šå¤©çƒ­æ—¶è¿åŠ¨æ—¶é•¿å¢åŠ \n",
    "- **é—®é¢˜**ï¼šæ°”æ¸©å¯¹è¿åŠ¨æ—¶é•¿çš„å½±å“å¾ˆå¼± (å¾ˆå¤šäººä¸ç®¡å¤©æ°”éƒ½ä¸è¿åŠ¨)\n",
    "- **åæœ**ï¼šå³ä½¿æ°”æ¸©ä¸ä½“é‡æœ‰ä¸€ç‚¹ç‚¹ç›´æ¥å…³ç³» (çƒ­å¤©é£Ÿæ¬²å·®)ï¼Œä¹Ÿä¼šå¯¼è‡´ä¼°è®¡ä¸¥é‡æœ‰å\n",
    "\n",
    "**ç»“è®º**ï¼šå¼±å·¥å…·å˜é‡ worse than no instrument!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡æ‹Ÿå¼±å·¥å…·å˜é‡é—®é¢˜\n",
    "def simulate_weak_iv(n=1000, iv_strength=0.1):\n",
    "    \"\"\"\n",
    "    æ¨¡æ‹Ÿå¼±å·¥å…·å˜é‡åœºæ™¯\n",
    "    \n",
    "    å‚æ•°:\n",
    "        iv_strength: å·¥å…·å˜é‡å¼ºåº¦ (0.1 = å¼±, 0.5 = å¼º)\n",
    "    \"\"\"\n",
    "    demand_shock = np.random.normal(0, 10, n)\n",
    "    cost_shock = np.random.normal(0, 5, n)\n",
    "    \n",
    "    # ä»·æ ¼åªå—åˆ°å¾ˆå°çš„æˆæœ¬å†²å‡»å½±å“ (å¼± IV)\n",
    "    price = 10 + iv_strength * cost_shock + 0.5 * demand_shock + np.random.normal(0, 1, n)\n",
    "    \n",
    "    # é”€é‡\n",
    "    quantity = 100 - 2 * price + demand_shock + np.random.normal(0, 2, n)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'cost_shock': cost_shock,\n",
    "        'price': price,\n",
    "        'quantity': quantity\n",
    "    })\n",
    "\n",
    "# æ¯”è¾ƒä¸åŒ IV å¼ºåº¦\n",
    "strengths = [0.05, 0.1, 0.3, 0.5, 1.0]\n",
    "results_by_strength = []\n",
    "\n",
    "for strength in strengths:\n",
    "    df_test = simulate_weak_iv(n=500, iv_strength=strength)\n",
    "    \n",
    "    # ç¬¬ä¸€é˜¶æ®µå›å½’\n",
    "    first_stage = LinearRegression()\n",
    "    first_stage.fit(df_test[['cost_shock']], df_test['price'])\n",
    "    \n",
    "    # è®¡ç®— F ç»Ÿè®¡é‡\n",
    "    y_pred = first_stage.predict(df_test[['cost_shock']])\n",
    "    y_true = df_test['price'].values\n",
    "    \n",
    "    # æ®‹å·®å¹³æ–¹å’Œ\n",
    "    rss = np.sum((y_true - y_pred) ** 2)\n",
    "    tss = np.sum((y_true - y_true.mean()) ** 2)\n",
    "    r2 = 1 - rss / tss\n",
    "    \n",
    "    n = len(df_test)\n",
    "    k = 1  # ä¸€ä¸ªå·¥å…·å˜é‡\n",
    "    f_stat = (r2 / k) / ((1 - r2) / (n - k - 1))\n",
    "    \n",
    "    # 2SLS ä¼°è®¡\n",
    "    results_2sls = two_stage_least_squares(\n",
    "        df_test['cost_shock'].values,\n",
    "        df_test['price'].values,\n",
    "        df_test['quantity'].values\n",
    "    )\n",
    "    \n",
    "    results_by_strength.append({\n",
    "        'IVå¼ºåº¦': strength,\n",
    "        'Fç»Ÿè®¡é‡': f_stat,\n",
    "        '2SLSä¼°è®¡': results_2sls['beta_2sls'],\n",
    "        'åå·®': abs(results_2sls['beta_2sls'] + 2.0)\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results_by_strength)\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "print(\"\\nğŸ“Š è§£è¯»ï¼š\")\n",
    "print(\"- F < 10: å¼±å·¥å…·å˜é‡ï¼Œä¼°è®¡æœ‰åä¸”ä¸ç¨³å®š\")\n",
    "print(\"- F > 10: å¼ºå·¥å…·å˜é‡ï¼Œä¼°è®¡æ¥è¿‘çœŸå®å€¼\")\n",
    "print(\"- ç»éªŒæ³•åˆ™ï¼šç¬¬ä¸€é˜¶æ®µ F ç»Ÿè®¡é‡è‡³å°‘è¦å¤§äº 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å¼± IV é—®é¢˜\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results['Fç»Ÿè®¡é‡'],\n",
    "    y=df_results['2SLSä¼°è®¡'],\n",
    "    mode='markers+lines',\n",
    "    marker=dict(size=12, color=df_results['Fç»Ÿè®¡é‡'], colorscale='Viridis', showscale=True),\n",
    "    line=dict(width=2, color='gray', dash='dash'),\n",
    "    text=[f\"IVå¼ºåº¦: {s}\" for s in df_results['IVå¼ºåº¦']],\n",
    "    name='2SLS ä¼°è®¡'\n",
    "))\n",
    "\n",
    "# çœŸå®å€¼å‚è€ƒçº¿\n",
    "fig.add_hline(y=-2.0, line_dash=\"dash\", line_color=\"red\", \n",
    "              annotation_text=\"çœŸå®å€¼ = -2.0\", annotation_position=\"right\")\n",
    "\n",
    "# F=10 å‚è€ƒçº¿\n",
    "fig.add_vline(x=10, line_dash=\"dash\", line_color=\"green\",\n",
    "              annotation_text=\"F = 10 (é˜ˆå€¼)\", annotation_position=\"top\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"å¼±å·¥å…·å˜é‡é—®é¢˜ï¼šF ç»Ÿè®¡é‡ä¸ä¼°è®¡åå·®\",\n",
    "    xaxis_title=\"ç¬¬ä¸€é˜¶æ®µ F ç»Ÿè®¡é‡\",\n",
    "    yaxis_title=\"2SLS ä¼°è®¡å€¼\",\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: è¿‡åº¦è¯†åˆ«æ£€éªŒ (Overidentification Test)\n",
    "\n",
    "### 5.1 ä»€ä¹ˆæ˜¯è¿‡åº¦è¯†åˆ«\n",
    "\n",
    "å¦‚æœæˆ‘ä»¬æœ‰ **å¤šä¸ªå·¥å…·å˜é‡**ï¼Œå³ï¼š\n",
    "\n",
    "$$\n",
    "\\text{å·¥å…·å˜é‡ä¸ªæ•°} > \\text{å†…ç”Ÿå˜é‡ä¸ªæ•°}\n",
    "$$\n",
    "\n",
    "åˆ™æ¨¡å‹æ˜¯ **è¿‡åº¦è¯†åˆ« (overidentified)** çš„ã€‚\n",
    "\n",
    "### 5.2 Hansen J æ£€éªŒ\n",
    "\n",
    "**åŸå‡è®¾** $H_0$: æ‰€æœ‰å·¥å…·å˜é‡éƒ½æ˜¯æœ‰æ•ˆçš„ (æ»¡è¶³æ’ä»–æ€§å‡è®¾)\n",
    "\n",
    "**æ£€éªŒç»Ÿè®¡é‡**:\n",
    "\n",
    "$$\n",
    "J = n \\cdot R^2_{\\text{residuals}}\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ $R^2_{\\text{residuals}}$ æ˜¯ 2SLS æ®‹å·®å¯¹æ‰€æœ‰å·¥å…·å˜é‡å›å½’çš„ $R^2$ã€‚\n",
    "\n",
    "åœ¨åŸå‡è®¾ä¸‹ï¼š\n",
    "\n",
    "$$\n",
    "J \\sim \\chi^2(m - k)\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ $m$ æ˜¯å·¥å…·å˜é‡ä¸ªæ•°ï¼Œ$k$ æ˜¯å†…ç”Ÿå˜é‡ä¸ªæ•°ã€‚\n",
    "\n",
    "### 5.3 æ³¨æ„äº‹é¡¹\n",
    "\n",
    "âš ï¸ **J æ£€éªŒçš„å±€é™æ€§**ï¼š\n",
    "- åªèƒ½æ£€éªŒ \"æ˜¯å¦è‡³å°‘æœ‰ä¸€ä¸ª IV æ— æ•ˆ\"\n",
    "- æ— æ³•å‘Šè¯‰ä½  \"å“ªä¸ª IV æœ‰é—®é¢˜\"\n",
    "- éœ€è¦è‡³å°‘ä¸€ä¸ª IV æ˜¯æœ‰æ•ˆçš„ (æ— æ³•æ£€éªŒæ‰€æœ‰ IV éƒ½æ— æ•ˆ)\n",
    "\n",
    "### 5.4 ç”ŸåŠ¨æ¯”å–»\n",
    "\n",
    "**æ¯”å–»ï¼šå¤šä¸ªè¯äººçš„å£ä¾›**\n",
    "\n",
    "å‡è®¾ä½ æœ‰ 3 ä¸ªè¯äºº (3 ä¸ª IV)ï¼Œä»–ä»¬çš„è¯è¯åº”è¯¥ä¸€è‡´ (éƒ½ä¼°è®¡å‡ºç›¸åŒçš„å› æœæ•ˆåº”)ã€‚\n",
    "\n",
    "- å¦‚æœè¯è¯çŸ›ç›¾ â†’ è‡³å°‘æœ‰ä¸€ä¸ªè¯äººè¯´è° (è‡³å°‘æœ‰ä¸€ä¸ª IV æ— æ•ˆ)\n",
    "- J æ£€éªŒå°±æ˜¯æ£€éªŒ \"è¯è¯æ˜¯å¦ä¸€è‡´\"\n",
    "- ä½†å®ƒæ— æ³•å‘Šè¯‰ä½  \"è°åœ¨è¯´è°\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n# TODO 3: å®ç° Hansen J æ£€éªŒ - å®Œæ•´å®ç°\n# ===================================\n\ndef hansen_j_test(Z_list, X, Y):\n    \"\"\"\n    Hansen J è¿‡åº¦è¯†åˆ«æ£€éªŒ\n    \n    å½“å·¥å…·å˜é‡ä¸ªæ•° > å†…ç”Ÿå˜é‡ä¸ªæ•°æ—¶ï¼Œå¯ä»¥æ£€éªŒå·¥å…·å˜é‡çš„æœ‰æ•ˆæ€§\n    \n    å‚æ•°:\n        Z_list: å¤šä¸ªå·¥å…·å˜é‡çš„åˆ—è¡¨ [(n,), (n,), ...]\n        X: å†…ç”Ÿå¤„ç†å˜é‡ (n,)\n        Y: ç»“æœå˜é‡ (n,)\n    \n    è¿”å›:\n        results: æ£€éªŒç»“æœå­—å…¸\n    \"\"\"\n    n = len(Y)\n    m = len(Z_list)  # å·¥å…·å˜é‡ä¸ªæ•°\n    k = 1  # å†…ç”Ÿå˜é‡ä¸ªæ•°\n    \n    if m <= k:\n        return {\n            'ç»“è®º': 'å·¥å…·å˜é‡ä¸ªæ•° â‰¤ å†…ç”Ÿå˜é‡ä¸ªæ•°ï¼Œæ— æ³•è¿›è¡Œè¿‡åº¦è¯†åˆ«æ£€éªŒ'\n        }\n    \n    # æ„é€ å·¥å…·å˜é‡çŸ©é˜µ Z\n    Z = np.column_stack(Z_list)\n    \n    # ç¬¬ä¸€é˜¶æ®µ - å›å½’ X ~ Z\n    first_stage = LinearRegression()\n    first_stage.fit(Z, X)\n    X_hat = first_stage.predict(Z)\n    \n    # ç¬¬äºŒé˜¶æ®µ - å›å½’ Y ~ X_hat\n    second_stage = LinearRegression()\n    second_stage.fit(X_hat.reshape(-1, 1), Y)\n    \n    # è®¡ç®— 2SLS æ®‹å·®\n    residuals = Y - second_stage.predict(X_hat.reshape(-1, 1))\n    \n    # å›å½’æ®‹å·®å¯¹æ‰€æœ‰ IV\n    residual_model = LinearRegression()\n    residual_model.fit(Z, residuals)\n    \n    # è®¡ç®— RÂ²\n    y_pred = residual_model.predict(Z)\n    ss_res = np.sum((residuals - y_pred) ** 2)\n    ss_tot = np.sum((residuals - residuals.mean()) ** 2)\n    r2 = 1 - ss_res / ss_tot\n    \n    # J ç»Ÿè®¡é‡\n    j_stat = n * r2\n    \n    # è‡ªç”±åº¦\n    df = m - k\n    \n    # p å€¼\n    p_value = 1 - stats.chi2.cdf(j_stat, df)\n    \n    return {\n        'Jç»Ÿè®¡é‡': j_stat,\n        'è‡ªç”±åº¦': df,\n        'på€¼': p_value,\n        'RÂ²': r2,\n        'å·¥å…·å˜é‡ä¸ªæ•°': m,\n        'å†…ç”Ÿå˜é‡ä¸ªæ•°': k,\n        'è¿‡åº¦è¯†åˆ«çº¦æŸ': df,\n        'ç»“è®º': 'æ‹’ç»åŸå‡è®¾ï¼Œè‡³å°‘æœ‰ä¸€ä¸ªIVæ— æ•ˆ' if p_value < 0.05 else 'æ— æ³•æ‹’ç»åŸå‡è®¾ï¼ŒIVå¯èƒ½éƒ½æœ‰æ•ˆ'\n    }\n\n# æ¨¡æ‹Ÿå¤šä¸ªå·¥å…·å˜é‡çš„åœºæ™¯\ndef simulate_multiple_iv(n=1000):\n    \"\"\"æ¨¡æ‹Ÿæœ‰ä¸¤ä¸ªå·¥å…·å˜é‡çš„åœºæ™¯\"\"\"\n    demand_shock = np.random.normal(0, 10, n)\n    \n    # ä¸¤ä¸ªæœ‰æ•ˆçš„å·¥å…·å˜é‡ï¼ˆéƒ½ä¸éœ€æ±‚å†²å‡»æ— å…³ï¼‰\n    cost_shock_1 = np.random.normal(0, 5, n)  # åŸææ–™æˆæœ¬\n    cost_shock_2 = np.random.normal(0, 5, n)  # è¿è¾“æˆæœ¬\n    \n    # ä»·æ ¼å—ä¸¤ä¸ªæˆæœ¬å†²å‡»å½±å“\n    price = 10 + 0.5 * cost_shock_1 + 0.3 * cost_shock_2 + 0.2 * demand_shock + np.random.normal(0, 1, n)\n    \n    # é”€é‡\n    quantity = 100 - 2 * price + demand_shock + np.random.normal(0, 2, n)\n    \n    return cost_shock_1, cost_shock_2, price, quantity\n\n# ç”Ÿæˆæ•°æ®\nnp.random.seed(123)\nZ1, Z2, X_multi, Y_multi = simulate_multiple_iv()\n\n# æ‰§è¡Œ J æ£€éªŒ\nj_results = hansen_j_test([Z1, Z2], X_multi, Y_multi)\n\nprint(\"=\" * 70)\nprint(\"Hansen J è¿‡åº¦è¯†åˆ«æ£€éªŒ\")\nprint(\"=\" * 70)\n\nfor key, value in j_results.items():\n    if isinstance(value, float):\n        print(f\"{key}: {value:.4f}\")\n    else:\n        print(f\"{key}: {value}\")\n\nprint(\"",
    "\" + \"=\" * 70)\n\nprint(\"",
    "ğŸ’¡ è§£è¯»:\")\nprint(f\"  â€¢ æˆ‘ä»¬æœ‰ {j_results['å·¥å…·å˜é‡ä¸ªæ•°']} ä¸ªå·¥å…·å˜é‡ï¼Œ{j_results['å†…ç”Ÿå˜é‡ä¸ªæ•°']} ä¸ªå†…ç”Ÿå˜é‡\")\nprint(f\"  â€¢ è¿‡åº¦è¯†åˆ«çº¦æŸ: {j_results['è¿‡åº¦è¯†åˆ«çº¦æŸ']} ä¸ª\")\nprint(f\"  â€¢ åŸå‡è®¾: æ‰€æœ‰å·¥å…·å˜é‡éƒ½æœ‰æ•ˆï¼ˆæ»¡è¶³æ’é™¤æ€§çº¦æŸï¼‰\")\n\nif j_results['på€¼'] >= 0.05:\n    print(f\"  â€¢ p-value = {j_results['på€¼']:.4f} â‰¥ 0.05\")\n    print(f\"  â€¢ âœ“ æ— æ³•æ‹’ç»åŸå‡è®¾ï¼Œå·¥å…·å˜é‡å¯èƒ½éƒ½æœ‰æ•ˆ\")\n    print(f\"  â€¢ âœ“ æ•°æ®ä¸\"æ‰€æœ‰IVéƒ½æœ‰æ•ˆ\"çš„å‡è®¾ä¸€è‡´\")\nelse:\n    print(f\"  â€¢ p-value = {j_results['på€¼']:.4f} < 0.05\")\n    print(f\"  â€¢ âœ— æ‹’ç»åŸå‡è®¾ï¼Œè‡³å°‘æœ‰ä¸€ä¸ªIVæ— æ•ˆ\")\n    print(f\"  â€¢ âš  æŸäº›IVå¯èƒ½è¿åæ’é™¤æ€§çº¦æŸï¼ˆç›´æ¥å½±å“ç»“æœå˜é‡ï¼‰\")\n\nprint(\"",
    "âš ï¸  æ³¨æ„:\")\nprint(\"  â€¢ J æ£€éªŒåªèƒ½æ£€éªŒ\"æŸäº›IVæ— æ•ˆ\"ï¼Œä¸èƒ½å‘Šè¯‰ä½ æ˜¯å“ªä¸€ä¸ª\")\nprint(\"  â€¢ å³ä½¿ J æ£€éªŒé€šè¿‡ï¼Œä¹Ÿä¸èƒ½è¯æ˜æ‰€æœ‰IVéƒ½æœ‰æ•ˆï¼ˆå¯èƒ½æ‰€æœ‰IVéƒ½æ— æ•ˆï¼‰\")\nprint(\"  â€¢ J æ£€éªŒä¾èµ–äº\"è‡³å°‘æœ‰ k ä¸ªIVæ˜¯æœ‰æ•ˆçš„\"è¿™ä¸ªå‡è®¾\")\n\nprint(\"=\" * 70)\n\n# æ¡ˆä¾‹ï¼šä¸€ä¸ªæ— æ•ˆçš„ IV\nprint(\"",
    "ã€æ¡ˆä¾‹ï¼šæ·»åŠ ä¸€ä¸ªæ— æ•ˆçš„å·¥å…·å˜é‡ã€‘\")\n\n# æ·»åŠ ä¸€ä¸ªæ— æ•ˆçš„ IVï¼ˆç›´æ¥å½±å“é”€é‡ï¼‰\nZ3_invalid = np.random.normal(0, 5, len(X_multi))\nY_invalid = Y_multi + 0.5 * Z3_invalid  # Z3 ç›´æ¥å½±å“ Yï¼ˆè¿åæ’é™¤æ€§ï¼‰\n\nj_results_invalid = hansen_j_test([Z1, Z2, Z3_invalid], X_multi, Y_invalid)\n\nprint(\"",
    "ç»“æœ:\")\nfor key, value in j_results_invalid.items():\n    if isinstance(value, float):\n        print(f\"{key}: {value:.4f}\")\n    else:\n        print(f\"{key}: {value}\")\n\nif j_results_invalid['på€¼'] < 0.05:\n    print(\"",
    "âœ“ J æ£€éªŒæˆåŠŸæ£€æµ‹å‡ºæ— æ•ˆçš„å·¥å…·å˜é‡ï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: LATE ä¸å¤–éƒ¨æ•ˆåº¦\n",
    "\n",
    "### 6.1 LATE çš„å®šä¹‰\n",
    "\n",
    "**å±€éƒ¨å¹³å‡å¤„ç†æ•ˆåº” (Local Average Treatment Effect, LATE)**ï¼š\n",
    "\n",
    "IV ä¼°è®¡çš„æ˜¯ **Compliers** çš„å¹³å‡å¤„ç†æ•ˆåº”ï¼Œå³é‚£äº› \"å› ä¸ºå·¥å…·å˜é‡å˜åŒ–è€Œæ”¹å˜å¤„ç†çŠ¶æ€\" çš„ä¸ªä½“ã€‚\n",
    "\n",
    "### 6.2 äººç¾¤åˆ†ç±»\n",
    "\n",
    "æ ¹æ®ä¸ªä½“å¯¹å·¥å…·å˜é‡çš„ååº”ï¼Œå¯ä»¥åˆ†ä¸º 4 ç±»ï¼š\n",
    "\n",
    "| ç±»å‹ | å®šä¹‰ | Z=0æ—¶ | Z=1æ—¶ |\n",
    "|------|------|--------|--------|\n",
    "| **Compliers** | æœä»å·¥å…·å˜é‡ | ä¸å¤„ç† | å¤„ç† |\n",
    "| **Always-takers** | æ€»æ˜¯å¤„ç† | å¤„ç† | å¤„ç† |\n",
    "| **Never-takers** | ä»ä¸å¤„ç† | ä¸å¤„ç† | ä¸å¤„ç† |\n",
    "| **Defiers** | è¿æŠ—å·¥å…·å˜é‡ | å¤„ç† | ä¸å¤„ç† |\n",
    "\n",
    "**å•è°ƒæ€§å‡è®¾ (Monotonicity)**ï¼šæ²¡æœ‰ Defiersã€‚\n",
    "\n",
    "### 6.3 LATE å…¬å¼\n",
    "\n",
    "$$\n",
    "\\text{LATE} = \\frac{E[Y|Z=1] - E[Y|Z=0]}{E[X|Z=1] - E[X|Z=0]}\n",
    "$$\n",
    "\n",
    "åˆ†å­ï¼šå·¥å…·å˜é‡å¯¹ç»“æœçš„ **Reduced Form** æ•ˆåº”  \n",
    "åˆ†æ¯ï¼šå·¥å…·å˜é‡å¯¹å¤„ç†çš„ **First Stage** æ•ˆåº”\n",
    "\n",
    "### 6.4 LATE vs ATE\n",
    "\n",
    "| æ•ˆåº” | ä¼°è®¡å¯¹è±¡ | å¤–éƒ¨æ•ˆåº¦ |\n",
    "|------|----------|----------|\n",
    "| **ATE** | å…¨ä½“äººç¾¤çš„å¹³å‡æ•ˆåº” | é«˜ |\n",
    "| **LATE** | Compliers çš„å¹³å‡æ•ˆåº” | ä½ |\n",
    "\n",
    "**å…³é”®é—®é¢˜**ï¼šCompliers æ˜¯è°ï¼Ÿä»–ä»¬æœ‰ä»£è¡¨æ€§å—ï¼Ÿ\n",
    "\n",
    "### 6.5 ç”ŸåŠ¨æ¯”å–»\n",
    "\n",
    "**æ¯”å–»ï¼šå¾å…µæŠ½ç­¾ä¸æœå…µå½¹çš„æ”¶å…¥æ•ˆåº”**\n",
    "\n",
    "- **é—®é¢˜**ï¼šæœå…µå½¹å¯¹æ”¶å…¥çš„å½±å“ï¼Ÿ\n",
    "- **å†…ç”Ÿæ€§**ï¼šçˆ±å›½è€…æ›´å¯èƒ½å‚å†›ï¼Œä¹Ÿå¯èƒ½æ›´åŠªåŠ›å·¥ä½œ\n",
    "- **å·¥å…·å˜é‡**ï¼šè¶Šæˆ˜æ—¶æœŸçš„å¾å…µæŠ½ç­¾ (éšæœº)\n",
    "\n",
    "äººç¾¤åˆ†ç±»ï¼š\n",
    "- **Compliers**ï¼šæŠ½ä¸­å°±å»ï¼Œæ²¡æŠ½ä¸­å°±ä¸å» (å¾å…µå¯¹è±¡)\n",
    "- **Always-takers**ï¼šæŠ½ä¸æŠ½ä¸­éƒ½ä¸»åŠ¨å‚å†› (å¿—æ„¿è€…)\n",
    "- **Never-takers**ï¼šæŠ½ä¸­ä¹Ÿé€ƒå…µå½¹ (é€ƒå…µ)\n",
    "\n",
    "**LATE ä¼°è®¡çš„æ˜¯ Compliers çš„æ•ˆåº”**ï¼Œä¸æ˜¯å…¨ä½“äººç¾¤çš„æ•ˆåº”ï¼\n",
    "\n",
    "### 6.6 å¤–éƒ¨æ•ˆåº¦è®¨è®º\n",
    "\n",
    "**ä½•æ—¶ LATE â‰ˆ ATEï¼Ÿ**\n",
    "1. Compliers å æ¯”å¾ˆå¤§\n",
    "2. å¤„ç†æ•ˆåº”å¯¹æ‰€æœ‰äººéƒ½ç›¸ä¼¼ (æ•ˆåº”åŒè´¨æ€§)\n",
    "\n",
    "**ä½•æ—¶ LATE å¤–éƒ¨æ•ˆåº¦å·®ï¼Ÿ**\n",
    "1. Compliers æ˜¯ç‰¹æ®Šç¾¤ä½“ (å¦‚è¾¹é™…äººç¾¤)\n",
    "2. å¤„ç†æ•ˆåº”å¼‚è´¨æ€§å¾ˆå¼º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡æ‹Ÿ LATE vs ATE\n",
    "def simulate_late_vs_ate(n=10000):\n",
    "    \"\"\"\n",
    "    æ¨¡æ‹Ÿ LATE ä¸ ATE çš„åŒºåˆ«\n",
    "    \n",
    "    åœºæ™¯: é¼“åŠ±ä½¿ç”¨å¥èº«APPå¯¹å‡é‡çš„æ•ˆæœ\n",
    "    - Z: æ˜¯å¦æ”¶åˆ°æ¨é€é€šçŸ¥ (å·¥å…·å˜é‡)\n",
    "    - X: æ˜¯å¦ä½¿ç”¨å¥èº«APP (å¤„ç†)\n",
    "    - Y: ä½“é‡å‡å°‘é‡ (ç»“æœ)\n",
    "    \"\"\"\n",
    "    # ä¸ªä½“ç‰¹å¾ï¼šè‡ªå¾‹ç¨‹åº¦ (0-1)\n",
    "    self_discipline = np.random.beta(2, 2, n)\n",
    "    \n",
    "    # éšæœºåˆ†é…æ¨é€é€šçŸ¥\n",
    "    Z = np.random.binomial(1, 0.5, n)\n",
    "    \n",
    "    # æ˜¯å¦ä½¿ç”¨APP (å—è‡ªå¾‹å’Œæ¨é€å½±å“)\n",
    "    # - é«˜è‡ªå¾‹è€…ï¼šæ€»æ˜¯ç”¨ (Always-takers)\n",
    "    # - ä½è‡ªå¾‹è€…ï¼šä»ä¸ç”¨ (Never-takers)\n",
    "    # - ä¸­ç­‰è‡ªå¾‹è€…ï¼šæ”¶åˆ°æ¨é€æ‰ç”¨ (Compliers)\n",
    "    prob_use = 0.2 + 0.6 * self_discipline + 0.3 * Z * (1 - self_discipline)\n",
    "    X = (np.random.random(n) < prob_use).astype(int)\n",
    "    \n",
    "    # å¤„ç†æ•ˆåº”å¼‚è´¨æ€§ï¼šè‡ªå¾‹ç¨‹åº¦è¶Šé«˜ï¼ŒAPPæ•ˆæœè¶Šå¥½\n",
    "    treatment_effect = 5 + 10 * self_discipline\n",
    "    \n",
    "    # ä½“é‡å‡å°‘é‡\n",
    "    Y0 = 2 + 3 * self_discipline + np.random.normal(0, 1, n)  # ä¸ç”¨APP\n",
    "    Y1 = Y0 + treatment_effect  # ç”¨APP\n",
    "    Y = X * Y1 + (1 - X) * Y0\n",
    "    \n",
    "    # è¯†åˆ«äººç¾¤ç±»å‹\n",
    "    # æ¨¡æ‹Ÿ Z=0 å’Œ Z=1 æ—¶çš„å¤„ç†é€‰æ‹©\n",
    "    prob_use_z0 = 0.2 + 0.6 * self_discipline\n",
    "    prob_use_z1 = 0.2 + 0.6 * self_discipline + 0.3 * (1 - self_discipline)\n",
    "    \n",
    "    X_z0 = (np.random.random(n) < prob_use_z0).astype(int)\n",
    "    X_z1 = (np.random.random(n) < prob_use_z1).astype(int)\n",
    "    \n",
    "    types = []\n",
    "    for i in range(n):\n",
    "        if X_z1[i] == 1 and X_z0[i] == 0:\n",
    "            types.append('Complier')\n",
    "        elif X_z1[i] == 1 and X_z0[i] == 1:\n",
    "            types.append('Always-taker')\n",
    "        elif X_z1[i] == 0 and X_z0[i] == 0:\n",
    "            types.append('Never-taker')\n",
    "        else:\n",
    "            types.append('Defier')\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Z': Z,\n",
    "        'X': X,\n",
    "        'Y': Y,\n",
    "        'self_discipline': self_discipline,\n",
    "        'treatment_effect': treatment_effect,\n",
    "        'type': types\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_late = simulate_late_vs_ate()\n",
    "\n",
    "# è®¡ç®—ä¸åŒæ•ˆåº”\n",
    "# ATE (å…¨ä½“äººç¾¤)\n",
    "ate = df_late['treatment_effect'].mean()\n",
    "\n",
    "# ATT (å·²å¤„ç†äººç¾¤)\n",
    "att = df_late[df_late['X'] == 1]['treatment_effect'].mean()\n",
    "\n",
    "# LATE (Compliers)\n",
    "late_true = df_late[df_late['type'] == 'Complier']['treatment_effect'].mean()\n",
    "\n",
    "# IV ä¼°è®¡çš„ LATE\n",
    "late_iv = (\n",
    "    (df_late[df_late['Z'] == 1]['Y'].mean() - df_late[df_late['Z'] == 0]['Y'].mean()) /\n",
    "    (df_late[df_late['Z'] == 1]['X'].mean() - df_late[df_late['Z'] == 0]['X'].mean())\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ä¸åŒå¤„ç†æ•ˆåº”çš„æ¯”è¾ƒ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ATE (å…¨ä½“äººç¾¤): {ate:.2f}\")\n",
    "print(f\"ATT (å·²å¤„ç†äººç¾¤): {att:.2f}\")\n",
    "print(f\"LATE (Compliers, çœŸå®): {late_true:.2f}\")\n",
    "print(f\"LATE (IV ä¼°è®¡): {late_iv:.2f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# äººç¾¤åˆ†å¸ƒ\n",
    "type_counts = df_late['type'].value_counts()\n",
    "print(\"\\näººç¾¤ç±»å‹åˆ†å¸ƒ:\")\n",
    "print(type_counts)\n",
    "print(f\"\\nCompliers å æ¯”: {type_counts.get('Complier', 0) / len(df_late) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– LATE vs ATE\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('äººç¾¤ç±»å‹åˆ†å¸ƒ', 'å¤„ç†æ•ˆåº”å¼‚è´¨æ€§')\n",
    ")\n",
    "\n",
    "# å·¦å›¾ï¼šäººç¾¤ç±»å‹\n",
    "type_colors = {'Complier': '#2D9CDB', 'Always-taker': '#27AE60', \n",
    "               'Never-taker': '#EB5757', 'Defier': '#F2994A'}\n",
    "\n",
    "for typ in type_counts.index:\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=[typ],\n",
    "            y=[type_counts[typ]],\n",
    "            name=typ,\n",
    "            marker_color=type_colors.get(typ, 'gray')\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# å³å›¾ï¼šå¤„ç†æ•ˆåº”åˆ†å¸ƒ\n",
    "for typ in ['Complier', 'Always-taker', 'Never-taker']:\n",
    "    if typ in df_late['type'].values:\n",
    "        data = df_late[df_late['type'] == typ]['treatment_effect']\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=data,\n",
    "                name=typ,\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                fillcolor=type_colors.get(typ, 'gray'),\n",
    "                opacity=0.6\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "# æ·»åŠ å‚è€ƒçº¿\n",
    "fig.add_hline(y=ate, line_dash=\"dash\", line_color=\"red\", \n",
    "              annotation_text=f\"ATE = {ate:.1f}\", \n",
    "              annotation_position=\"right\", row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"äººç¾¤ç±»å‹\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"äººç¾¤ç±»å‹\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"äººæ•°\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"å¤„ç†æ•ˆåº” (å‡é‡ kg)\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    title_text=\"LATE çš„å¤–éƒ¨æ•ˆåº¦é—®é¢˜ï¼šIV åªä¼°è®¡ Compliers çš„æ•ˆåº”\",\n",
    "    showlegend=True,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"ğŸ“Š è§£è¯»ï¼š\")\n",
    "print(\"- Compliers: å—æ¨é€å½±å“è€Œä½¿ç”¨APPçš„äºº (ä¸­ç­‰è‡ªå¾‹)\")\n",
    "print(\"- Always-takers: æ— è®ºå¦‚ä½•éƒ½ç”¨APPçš„äºº (é«˜è‡ªå¾‹)\")\n",
    "print(\"- Never-takers: æ— è®ºå¦‚ä½•éƒ½ä¸ç”¨APPçš„äºº (ä½è‡ªå¾‹)\")\n",
    "print(\"- IV ä¼°è®¡çš„æ˜¯ Compliers çš„æ•ˆåº”ï¼Œå¯èƒ½ä¸ ATE ä¸åŒï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: ä¸šåŠ¡æ¡ˆä¾‹\n",
    "\n",
    "### æ¡ˆä¾‹ 1: ç”µå•†ä»·æ ¼å¼¹æ€§ä¼°è®¡\n",
    "\n",
    "**èƒŒæ™¯**ï¼šæŸç”µå•†å¹³å°æƒ³çŸ¥é“é™ä»·å¯¹é”€é‡çš„å½±å“ã€‚\n",
    "\n",
    "**é—®é¢˜**ï¼š\n",
    "- éœ€æ±‚æ—ºç››æ—¶ï¼Œä»·æ ¼é«˜ä¸”é”€é‡é«˜\n",
    "- æ»é”€å•†å“è¢«è¿«é™ä»·ï¼Œä»·æ ¼ä½ä½†é”€é‡ä½\n",
    "- ç›´æ¥å›å½’ä¼šé«˜ä¼°ä»·æ ¼å¼¹æ€§ï¼ˆç”šè‡³å¾—åˆ°æ­£ç›¸å…³ï¼‰\n",
    "\n",
    "**å·¥å…·å˜é‡**ï¼šä¾›åº”å•†çš„åŸææ–™æˆæœ¬å†²å‡»\n",
    "- âœ… ç›¸å…³æ€§ï¼šæˆæœ¬å½±å“å®šä»·\n",
    "- âœ… æ’ä»–æ€§ï¼šæˆæœ¬ä¸ç›´æ¥å½±å“éœ€æ±‚\n",
    "- âœ… å¤–ç”Ÿæ€§ï¼šåŸææ–™ä»·æ ¼æ³¢åŠ¨æ˜¯å¤–ç”Ÿçš„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¡ˆä¾‹ 1: ä»·æ ¼å¼¹æ€§ä¼°è®¡\n",
    "def case_study_price_elasticity():\n",
    "    \"\"\"\n",
    "    ç”µå•†ä»·æ ¼å¼¹æ€§ä¼°è®¡\n",
    "    \"\"\"\n",
    "    np.random.seed(123)\n",
    "    n = 2000\n",
    "    \n",
    "    # éœ€æ±‚å†²å‡» (èŠ‚å‡æ—¥ã€ä¿ƒé”€å­£ç­‰)\n",
    "    demand_shock = np.random.normal(0, 20, n)\n",
    "    \n",
    "    # æˆæœ¬å†²å‡» (åŸææ–™ä»·æ ¼æ³¢åŠ¨)\n",
    "    cost_shock = np.random.normal(0, 10, n)\n",
    "    \n",
    "    # ä»·æ ¼: å—æˆæœ¬å’Œéœ€æ±‚å½±å“\n",
    "    base_price = 100\n",
    "    price = base_price + 0.8 * cost_shock + 0.4 * demand_shock + np.random.normal(0, 5, n)\n",
    "    \n",
    "    # é”€é‡: å—ä»·æ ¼(è´Ÿ)å’Œéœ€æ±‚(æ­£)å½±å“\n",
    "    # çœŸå®ä»·æ ¼å¼¹æ€§ = -1.5\n",
    "    base_quantity = 1000\n",
    "    quantity = base_quantity - 1.5 * (price - base_price) + 2 * demand_shock + np.random.normal(0, 50, n)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'cost_shock': cost_shock,\n",
    "        'price': price,\n",
    "        'quantity': quantity,\n",
    "        'demand_shock': demand_shock\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_case1 = case_study_price_elasticity()\n",
    "\n",
    "# OLS vs 2SLS\n",
    "# OLS (æœ‰å)\n",
    "ols = LinearRegression()\n",
    "ols.fit(df_case1[['price']], df_case1['quantity'])\n",
    "elasticity_ols = ols.coef_[0]\n",
    "\n",
    "# 2SLS (æ— å)\n",
    "results_2sls = two_stage_least_squares(\n",
    "    df_case1['cost_shock'].values,\n",
    "    df_case1['price'].values,\n",
    "    df_case1['quantity'].values\n",
    ")\n",
    "elasticity_2sls = results_2sls['beta_2sls']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"æ¡ˆä¾‹ 1: ç”µå•†ä»·æ ¼å¼¹æ€§ä¼°è®¡\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"çœŸå®ä»·æ ¼å¼¹æ€§: -1.50\")\n",
    "print(f\"OLS ä¼°è®¡: {elasticity_ols:.2f} âŒ (ä¸¥é‡é«˜ä¼°)\")\n",
    "print(f\"2SLS ä¼°è®¡: {elasticity_2sls:.2f} âœ… (æ¥è¿‘çœŸå®å€¼)\")\n",
    "print(\"\\nä¸šåŠ¡å«ä¹‰:\")\n",
    "print(f\"- ä»·æ ¼æ¯ä¸‹é™ 1 å…ƒï¼Œé”€é‡å¢åŠ  {abs(elasticity_2sls):.1f} ä»¶\")\n",
    "print(f\"- é™ä»· 10%ï¼Œé¢„è®¡é”€é‡æå‡ {abs(elasticity_2sls) * 10:.0f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ¡ˆä¾‹ 2: åœ¨çº¿å¹¿å‘Šæ•ˆæœè¯„ä¼°\n",
    "\n",
    "**èƒŒæ™¯**ï¼šè¯„ä¼°å¹¿å‘Šæ›å…‰å¯¹è´­ä¹°è½¬åŒ–çš„å½±å“ã€‚\n",
    "\n",
    "**é—®é¢˜**ï¼š\n",
    "- è´­ä¹°æ„æ„¿é«˜çš„ç”¨æˆ·æ›´å¯èƒ½çœ‹åˆ°å¹¿å‘Šï¼ˆæ¨èç®—æ³•ï¼‰\n",
    "- ç›´æ¥å›å½’ä¼šé«˜ä¼°å¹¿å‘Šæ•ˆæœ\n",
    "\n",
    "**å·¥å…·å˜é‡**ï¼šæœåŠ¡å™¨éšæœºæ•…éšœå¯¼è‡´çš„æ›å…‰ä¸­æ–­\n",
    "- âœ… ç›¸å…³æ€§ï¼šæ•…éšœå‡å°‘æ›å…‰\n",
    "- âœ… æ’ä»–æ€§ï¼šæ•…éšœä¸ç›´æ¥å½±å“è´­ä¹°æ„æ„¿\n",
    "- âœ… å¤–ç”Ÿæ€§ï¼šæ•…éšœæ˜¯éšæœºçš„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¡ˆä¾‹ 2: å¹¿å‘Šæ•ˆæœè¯„ä¼°\n",
    "def case_study_ad_effectiveness():\n",
    "    \"\"\"\n",
    "    åœ¨çº¿å¹¿å‘Šæ•ˆæœè¯„ä¼°\n",
    "    \"\"\"\n",
    "    np.random.seed(456)\n",
    "    n = 5000\n",
    "    \n",
    "    # ç”¨æˆ·è´­ä¹°æ„æ„¿ (ä¸å¯è§‚æµ‹)\n",
    "    purchase_intent = np.random.beta(2, 5, n)\n",
    "    \n",
    "    # æœåŠ¡å™¨æ•…éšœ (éšæœº)\n",
    "    server_failure = np.random.binomial(1, 0.3, n)\n",
    "    \n",
    "    # å¹¿å‘Šæ›å…‰ï¼šå—è´­ä¹°æ„æ„¿(æ¨èç®—æ³•)å’ŒæœåŠ¡å™¨æ•…éšœå½±å“\n",
    "    prob_ad = 0.6 * purchase_intent * (1 - 0.7 * server_failure)\n",
    "    ad_exposure = np.random.binomial(1, prob_ad)\n",
    "    \n",
    "    # è´­ä¹°è½¬åŒ–ï¼šå—å¹¿å‘Šå’Œè´­ä¹°æ„æ„¿å½±å“\n",
    "    # çœŸå®å¹¿å‘Šæ•ˆæœ = 0.15 (15ä¸ªç™¾åˆ†ç‚¹)\n",
    "    prob_purchase = 0.1 + 0.15 * ad_exposure + 0.4 * purchase_intent\n",
    "    purchase = np.random.binomial(1, prob_purchase)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'server_failure': server_failure,\n",
    "        'ad_exposure': ad_exposure,\n",
    "        'purchase': purchase,\n",
    "        'purchase_intent': purchase_intent\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_case2 = case_study_ad_effectiveness()\n",
    "\n",
    "# OLS (æœ‰å)\n",
    "ols = LinearRegression()\n",
    "ols.fit(df_case2[['ad_exposure']], df_case2['purchase'])\n",
    "effect_ols = ols.coef_[0]\n",
    "\n",
    "# 2SLS (æ— å)\n",
    "results_2sls = two_stage_least_squares(\n",
    "    df_case2['server_failure'].values,\n",
    "    df_case2['ad_exposure'].values,\n",
    "    df_case2['purchase'].values\n",
    ")\n",
    "effect_2sls = results_2sls['beta_2sls']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"æ¡ˆä¾‹ 2: åœ¨çº¿å¹¿å‘Šæ•ˆæœè¯„ä¼°\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"çœŸå®å¹¿å‘Šæ•ˆæœ: 0.15 (æå‡15ä¸ªç™¾åˆ†ç‚¹)\")\n",
    "print(f\"OLS ä¼°è®¡: {effect_ols:.3f} âŒ (é«˜ä¼°)\")\n",
    "print(f\"2SLS ä¼°è®¡: {effect_2sls:.3f} âœ…\")\n",
    "print(\"\\nä¸šåŠ¡å«ä¹‰:\")\n",
    "print(f\"- å¹¿å‘Šæ›å…‰ä½¿è´­ä¹°ç‡æå‡ {effect_2sls * 100:.1f} ä¸ªç™¾åˆ†ç‚¹\")\n",
    "print(f\"- å¦‚æœåŸºç¡€è½¬åŒ–ç‡ 10%ï¼Œå¹¿å‘Šä½¿è½¬åŒ–ç‡å˜ä¸º {(0.1 + effect_2sls) * 100:.1f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ¡ˆä¾‹ 3: æ•™è‚²å›æŠ¥ç‡ä¼°è®¡\n",
    "\n",
    "**èƒŒæ™¯**ï¼šè¯„ä¼°å¤šè¯»ä¸€å¹´ä¹¦å¯¹æ”¶å…¥çš„å½±å“ã€‚\n",
    "\n",
    "**é—®é¢˜**ï¼š\n",
    "- èƒ½åŠ›å¼ºçš„äººæ›´æ„¿æ„è¯»ä¹¦ï¼Œæ”¶å…¥ä¹Ÿæ›´é«˜\n",
    "- å®¶åº­æ¡ä»¶å¥½çš„äººè¯»ä¹¦å¤šï¼Œæ”¶å…¥ä¹Ÿé«˜\n",
    "- ç›´æ¥å›å½’ä¼šé«˜ä¼°æ•™è‚²å›æŠ¥ç‡\n",
    "\n",
    "**å·¥å…·å˜é‡**ï¼šå‡ºç”Ÿåœ°åˆ°æœ€è¿‘å¤§å­¦çš„è·ç¦»\n",
    "- âœ… ç›¸å…³æ€§ï¼šè·ç¦»å½±å“ä¸Šå¤§å­¦çš„æ¦‚ç‡\n",
    "- âœ… æ’ä»–æ€§ï¼šè·ç¦»ä¸ç›´æ¥å½±å“æ”¶å…¥ï¼ˆå‡è®¾æ²¡æœ‰åœ°åŒºå·¥èµ„å·®å¼‚ï¼‰\n",
    "- âœ… å¤–ç”Ÿæ€§ï¼šå‡ºç”Ÿåœ°æ˜¯å¤–ç”Ÿçš„\n",
    "\n",
    "**æ³¨æ„**ï¼šè¿™æ˜¯ç»å…¸çš„ Card (1995) ç ”ç©¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¡ˆä¾‹ 3: æ•™è‚²å›æŠ¥ç‡\n",
    "def case_study_education_return():\n",
    "    \"\"\"\n",
    "    æ•™è‚²å›æŠ¥ç‡ä¼°è®¡ (Card, 1995)\n",
    "    \"\"\"\n",
    "    np.random.seed(789)\n",
    "    n = 3000\n",
    "    \n",
    "    # èƒ½åŠ› (ä¸å¯è§‚æµ‹)\n",
    "    ability = np.random.normal(100, 15, n)\n",
    "    \n",
    "    # åˆ°å¤§å­¦çš„è·ç¦» (km)\n",
    "    distance = np.random.gamma(2, 20, n)\n",
    "    \n",
    "    # æ•™è‚²å¹´é™ï¼šå—èƒ½åŠ›å’Œè·ç¦»å½±å“\n",
    "    # è·ç¦»è¶Šè¿œï¼Œè¯»ä¹¦è¶Šå°‘\n",
    "    education = 12 + 0.05 * ability - 0.03 * distance + np.random.normal(0, 2, n)\n",
    "    education = np.clip(education, 8, 20)  # 8-20å¹´\n",
    "    \n",
    "    # å¹´æ”¶å…¥ (ä¸‡å…ƒ)ï¼šå—æ•™è‚²å’Œèƒ½åŠ›å½±å“\n",
    "    # çœŸå®æ•™è‚²å›æŠ¥ç‡ = 0.8 (æ¯å¤šè¯»ä¸€å¹´ï¼Œæ”¶å…¥å¢åŠ 0.8ä¸‡)\n",
    "    income = 5 + 0.8 * education + 0.2 * ability + np.random.normal(0, 3, n)\n",
    "    income = np.maximum(income, 3)  # æœ€ä½3ä¸‡\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'distance': distance,\n",
    "        'education': education,\n",
    "        'income': income,\n",
    "        'ability': ability\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_case3 = case_study_education_return()\n",
    "\n",
    "# OLS (æœ‰å)\n",
    "ols = LinearRegression()\n",
    "ols.fit(df_case3[['education']], df_case3['income'])\n",
    "return_ols = ols.coef_[0]\n",
    "\n",
    "# 2SLS (æ— å)\n",
    "results_2sls = two_stage_least_squares(\n",
    "    df_case3['distance'].values,\n",
    "    df_case3['education'].values,\n",
    "    df_case3['income'].values\n",
    ")\n",
    "return_2sls = results_2sls['beta_2sls']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"æ¡ˆä¾‹ 3: æ•™è‚²å›æŠ¥ç‡ä¼°è®¡ (Card, 1995)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"çœŸå®æ•™è‚²å›æŠ¥ç‡: 0.80 ä¸‡å…ƒ/å¹´\")\n",
    "print(f\"OLS ä¼°è®¡: {return_ols:.2f} ä¸‡å…ƒ/å¹´ âŒ (é«˜ä¼°)\")\n",
    "print(f\"2SLS ä¼°è®¡: {return_2sls:.2f} ä¸‡å…ƒ/å¹´ âœ…\")\n",
    "print(\"\\nä¸šåŠ¡å«ä¹‰:\")\n",
    "print(f\"- å¤šè¯»ä¸€å¹´ä¹¦ï¼Œå¹´æ”¶å…¥å¢åŠ  {return_2sls:.1f} ä¸‡å…ƒ\")\n",
    "print(f\"- å¤§å­¦4å¹´ï¼Œé¢„è®¡ç»ˆèº«æ”¶å…¥å¢åŠ  {return_2sls * 4 * 30:.0f} ä¸‡å…ƒ (å·¥ä½œ30å¹´)\")\n",
    "print(\"\\nâš ï¸  æ³¨æ„: è¿™æ˜¯ LATEï¼Œä¼°è®¡çš„æ˜¯ 'å› è·ç¦»è€Œæ”¾å¼ƒè¯»ä¹¦çš„è¾¹é™…äººç¾¤' çš„å›æŠ¥ç‡\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç»ƒä¹ ä¸æ€è€ƒé¢˜\n",
    "\n",
    "### ç»ƒä¹  1: è¯†åˆ«æœ‰æ•ˆçš„å·¥å…·å˜é‡\n",
    "\n",
    "å¯¹äºä»¥ä¸‹åœºæ™¯ï¼Œåˆ¤æ–­æè®®çš„å·¥å…·å˜é‡æ˜¯å¦æœ‰æ•ˆï¼Œå¹¶è¯´æ˜ç†ç”±ï¼š\n",
    "\n",
    "1. **ç ”ç©¶ç›®æ ‡**ï¼šå¸çƒŸå¯¹è‚ºç™Œçš„å½±å“  \n",
    "   **å·¥å…·å˜é‡**ï¼šé¦™çƒŸç¨  \n",
    "   **é—®é¢˜**ï¼šæ£€éªŒä¸‰ä¸ªå‡è®¾\n",
    "\n",
    "2. **ç ”ç©¶ç›®æ ‡**ï¼šè­¦å¯Ÿæ•°é‡å¯¹çŠ¯ç½ªç‡çš„å½±å“  \n",
    "   **å·¥å…·å˜é‡**ï¼šææ€–è¢­å‡»åçš„è­¦åŠ›å¢æ´¾  \n",
    "   **é—®é¢˜**ï¼šæ£€éªŒä¸‰ä¸ªå‡è®¾\n",
    "\n",
    "3. **ç ”ç©¶ç›®æ ‡**ï¼šå¥èº«æˆ¿ä¼šå‘˜å¯¹å¥åº·çš„å½±å“  \n",
    "   **å·¥å…·å˜é‡**ï¼šåˆ°å¥èº«æˆ¿çš„è·ç¦»  \n",
    "   **é—®é¢˜**ï¼šæ£€éªŒä¸‰ä¸ªå‡è®¾\n",
    "\n",
    "### ç»ƒä¹  2: å®ç°å¼± IV ç¨³å¥æ¨æ–­\n",
    "\n",
    "å½“é‡åˆ°å¼±å·¥å…·å˜é‡æ—¶ï¼Œæ ‡å‡†çš„ 2SLS æ¨æ–­å¤±æ•ˆã€‚å°è¯•å®ç° Anderson-Rubin æ£€éªŒï¼š\n",
    "\n",
    "```python\n",
    "def anderson_rubin_test(Z, X, Y, beta_null):\n",
    "    \"\"\"\n",
    "    Anderson-Rubin æ£€éªŒ (å¼± IV ç¨³å¥)\n",
    "    \n",
    "    åŸå‡è®¾: H0: beta = beta_null\n",
    "    \"\"\"\n",
    "    # TODO: å®ç° AR æ£€éªŒ\n",
    "    pass\n",
    "```\n",
    "\n",
    "### ç»ƒä¹  3: å¤šä¸ªå†…ç”Ÿå˜é‡çš„ IV\n",
    "\n",
    "è€ƒè™‘ä»¥ä¸‹æ¨¡å‹ï¼š\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ $X_1$ å’Œ $X_2$ éƒ½æ˜¯å†…ç”Ÿçš„ã€‚ä½ æœ‰ 3 ä¸ªå·¥å…·å˜é‡ $Z_1, Z_2, Z_3$ã€‚\n",
    "\n",
    "**ä»»åŠ¡**ï¼š\n",
    "1. æ¨¡æ‹Ÿæ•°æ®\n",
    "2. å®ç° 2SLS ä¼°è®¡\n",
    "3. æ£€éªŒå·¥å…·å˜é‡çš„æœ‰æ•ˆæ€§\n",
    "\n",
    "### æ€è€ƒé¢˜\n",
    "\n",
    "1. **å¼± IV æ‚–è®º**ï¼šä¸ºä»€ä¹ˆå¼±å·¥å…·å˜é‡æ¯”æ²¡æœ‰å·¥å…·å˜é‡æ›´ç³Ÿç³•ï¼Ÿ\n",
    "\n",
    "2. **LATE çš„å±€é™æ€§**ï¼šåœ¨ä»€ä¹ˆæƒ…å†µä¸‹ï¼ŒLATE çš„å¤–éƒ¨æ•ˆåº¦æœ€å·®ï¼Ÿå¦‚ä½•æ”¹è¿›ï¼Ÿ\n",
    "\n",
    "3. **å·¥å…·å˜é‡çš„å¯»æ‰¾**ï¼šåœ¨ä½ çš„ä¸šåŠ¡åœºæ™¯ä¸­ï¼Œèƒ½æ‰¾åˆ°å“ªäº›æ½œåœ¨çš„å·¥å…·å˜é‡ï¼Ÿå¦‚ä½•æ£€éªŒå®ƒä»¬çš„æœ‰æ•ˆæ€§ï¼Ÿ\n",
    "\n",
    "4. **è‡ªç„¶å®éªŒ**ï¼šæŸ¥æ‰¾æ–‡çŒ®ï¼Œæ‰¾å‡º 3 ä¸ªä½¿ç”¨è‡ªç„¶å®éªŒä½œä¸º IV çš„ç»å…¸ç ”ç©¶ï¼Œæ€»ç»“å®ƒä»¬çš„å·¥å…·å˜é‡è®¾è®¡ã€‚\n",
    "\n",
    "5. **å› æœæ¨æ–­æ–¹æ³•é€‰æ‹©**ï¼š\n",
    "   - ä»€ä¹ˆæ—¶å€™ç”¨ IVï¼Ÿ\n",
    "   - ä»€ä¹ˆæ—¶å€™ç”¨ RDDï¼Ÿ\n",
    "   - ä»€ä¹ˆæ—¶å€™ç”¨ DIDï¼Ÿ\n",
    "   - å®ƒä»¬æœ‰ä»€ä¹ˆå…±åŒç‚¹å’ŒåŒºåˆ«ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n# ç»ƒä¹ ç©ºé—´ - å®Œæ•´å®ç°\n# ===================================\n\nprint(\"=\" * 70)\nprint(\"ç»ƒä¹ é¢˜ç­”æ¡ˆ\")\nprint(\"=\" * 70)\n\n# ===================================\n# ç»ƒä¹  1: è¯†åˆ«æœ‰æ•ˆçš„å·¥å…·å˜é‡\n# ===================================\n\nprint(\"",
    "ã€ç»ƒä¹  1: è¯†åˆ«æœ‰æ•ˆçš„å·¥å…·å˜é‡ã€‘\")\nprint(\"-\" * 70)\n\nprint(\"",
    "åœºæ™¯ï¼šè¯„ä¼°æ•™è‚²å›æŠ¥ç‡\")\nprint(\"  Y = å·¥èµ„\")\nprint(\"  X = æ•™è‚²å¹´é™ï¼ˆå†…ç”Ÿï¼Œå› ä¸ºèƒ½åŠ›å½±å“æ•™è‚²å’Œå·¥èµ„ï¼‰\")\nprint(\"  U = èƒ½åŠ›ï¼ˆä¸å¯è§‚æµ‹ï¼‰\")\n\nprint(\"",
    "å€™é€‰å·¥å…·å˜é‡:\")\ncandidates = {\n    '1. çˆ¶æ¯æ•™è‚²æ°´å¹³': {\n        'relevance': 'å¼ºï¼ˆçˆ¶æ¯æ•™è‚²å½±å“å­å¥³æ•™è‚²ï¼‰',\n        'exclusion': 'å¼±ï¼ˆçˆ¶æ¯æ•™è‚²å¯èƒ½ç›´æ¥å½±å“å·¥èµ„ï¼Œå¦‚ç¤¾ä¼šèµ„æœ¬ï¼‰',\n        'exogeneity': 'å¼ºï¼ˆä¸ä¸ªäººèƒ½åŠ›ç›¸å…³æ€§è¾ƒå¼±ï¼‰',\n        'valid': False\n    },\n    '2. å­¦åŒºæˆ¿ä»·æ ¼': {\n        'relevance': 'å¼ºï¼ˆæˆ¿ä»·é«˜çš„å­¦åŒºæ•™è‚²è´¨é‡å¥½ï¼‰',\n        'exclusion': 'å¼±ï¼ˆå¯Œè£•å®¶åº­çš„å­©å­å¯èƒ½æœ‰å…¶ä»–ä¼˜åŠ¿ï¼‰',\n        'exogeneity': 'ä¸­ç­‰',\n        'valid': False\n    },\n    '3. å‡ºç”Ÿå­£åº¦': {\n        'relevance': 'ä¸­ç­‰ï¼ˆå½±å“å…¥å­¦å¹´é¾„ï¼Œè¿›è€Œå½±å“æ•™è‚²å¹´é™ï¼‰',\n        'exclusion': 'å¼ºï¼ˆå‡ºç”Ÿå­£åº¦ä¸å¤ªå¯èƒ½ç›´æ¥å½±å“å·¥èµ„ï¼‰',\n        'exogeneity': 'å¼ºï¼ˆå‡ºç”Ÿå­£åº¦æ˜¯éšæœºçš„ï¼‰',\n        'valid': True,\n        'note': 'Angrist & Krueger (1991) çš„ç»å…¸IV'\n    },\n    '4. å¾å…µæŠ½ç­¾ç»“æœ': {\n        'relevance': 'å¼ºï¼ˆè¢«å¾å…µä¼šä¸­æ–­æ•™è‚²ï¼‰',\n        'exclusion': 'å¼ºï¼ˆæŠ½ç­¾ç»“æœæœ¬èº«ä¸å½±å“å·¥èµ„ï¼‰',\n        'exogeneity': 'å¼ºï¼ˆæŠ½ç­¾æ˜¯éšæœºçš„ï¼‰',\n        'valid': True,\n        'note': 'Angrist (1990) çš„ç»å…¸IV'\n    }\n}\n\nfor iv, props in candidates.items():\n    print(f\"",
    "{iv}\")\n    print(f\"  ç›¸å…³æ€§: {props['relevance']}\")\n    print(f\"  æ’é™¤æ€§: {props['exclusion']}\")\n    print(f\"  å¤–ç”Ÿæ€§: {props['exogeneity']}\")\n    if 'note' in props:\n        print(f\"  ğŸ“š {props['note']}\")\n    print(f\"  âœ“ æœ‰æ•ˆ\" if props['valid'] else \"  âœ— å¯èƒ½æ— æ•ˆ\")\n\nprint(\"",
    "ğŸ’¡ å…³é”®ç»“è®º:\")\nprint(\"  â€¢ æœ€å¥½çš„ IV: å‡ºç”Ÿå­£åº¦ã€å¾å…µæŠ½ç­¾ï¼ˆéšæœºæ€§å¼ºï¼‰\")\nprint(\"  â€¢ éœ€è¦è­¦æƒ•çš„ IV: çˆ¶æ¯æ•™è‚²ã€å­¦åŒºæˆ¿ä»·ï¼ˆå¯èƒ½è¿åæ’é™¤æ€§ï¼‰\")\nprint(\"  â€¢ ç†æƒ³çš„ IV æ¥æº: è‡ªç„¶å®éªŒã€æ”¿ç­–å†²å‡»ã€éšæœºåŒ–\")\n\n# ===================================\n# ç»ƒä¹  2: Anderson-Rubin æ£€éªŒ\n# ===================================\n\nprint(\"",
    "\" + \"=\" * 70)\nprint(\"ã€ç»ƒä¹  2: Anderson-Rubin æ£€éªŒï¼ˆå¼±å·¥å…·å˜é‡ç¨³å¥æ£€éªŒï¼‰ã€‘\")\nprint(\"-\" * 70)\n\ndef anderson_rubin_test(Z, X, Y, beta_0):\n    \"\"\"\n    Anderson-Rubin æ£€éªŒï¼ˆåœ¨å¼±å·¥å…·å˜é‡ä¸‹ä»ç„¶æœ‰æ•ˆï¼‰\n    \n    åŸå‡è®¾: beta = beta_0\n    \n    æ€æƒ³: å¦‚æœ beta = beta_0ï¼Œé‚£ä¹ˆ\n          Y - beta_0 * X = epsilon\n          åº”è¯¥ä¸ Z æ— å…³\n    \"\"\"\n    n = len(Y)\n    \n    # è®¡ç®— reduced-form æ®‹å·®\n    Y_tilde = Y - beta_0 * X\n    \n    # å›å½’ Y_tilde ~ Z\n    Z_mat = Z.reshape(-1, 1)\n    model = LinearRegression()\n    model.fit(Z_mat, Y_tilde)\n    \n    # F ç»Ÿè®¡é‡\n    y_pred = model.predict(Z_mat)\n    ss_model = np.sum((y_pred - Y_tilde.mean())**2)\n    ss_resid = np.sum((Y_tilde - y_pred)**2)\n    \n    df1 = 1  # Z çš„ä¸ªæ•°\n    df2 = n - 2\n    \n    f_stat = (ss_model / df1) / (ss_resid / df2)\n    p_value = 1 - stats.f.cdf(f_stat, df1, df2)\n    \n    return {\n        'Fç»Ÿè®¡é‡': f_stat,\n        'på€¼': p_value,\n        'æ‹’ç»H0': p_value < 0.05\n    }\n\n# æµ‹è¯•ä¸åŒçš„ beta_0\nbeta_candidates = np.linspace(-3, -1, 21)\nar_pvalues = []\n\nfor beta_0 in beta_candidates:\n    ar_result = anderson_rubin_test(\n        df_iv['cost_shock'].values,\n        df_iv['price'].values,\n        df_iv['quantity'].values,\n        beta_0\n    )\n    ar_pvalues.append(ar_result['på€¼'])\n\n# æ‰¾ç½®ä¿¡åŒºé—´ï¼ˆp-value > 0.05 çš„åŒºåŸŸï¼‰\nci_mask = np.array(ar_pvalues) > 0.05\nif ci_mask.any():\n    ci_lower = beta_candidates[ci_mask][0]\n    ci_upper = beta_candidates[ci_mask][-1]\n    print(f\"",
    "Anderson-Rubin 95% ç½®ä¿¡åŒºé—´: [{ci_lower:.3f}, {ci_upper:.3f}]\")\n    print(f\"çœŸå®å€¼ -2.0 åœ¨ç½®ä¿¡åŒºé—´å†…: {ci_lower <= -2.0 <= ci_upper}\")\nelse:\n    print(\"",
    "æ— æ³•æ„é€ ç½®ä¿¡åŒºé—´\")\n\n# å¯è§†åŒ–\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=beta_candidates,\n    y=ar_pvalues,\n    mode='lines+markers',\n    name='AR p-value',\n    line=dict(color=COLORS['treated'], width=2)\n))\n\nfig.add_hline(y=0.05, line_dash=\"dash\", line_color=\"red\",\n              annotation_text=\"Î± = 0.05\")\nfig.add_vline(x=-2.0, line_dash=\"dot\", line_color=\"green\",\n              annotation_text=\"çœŸå®å€¼\")\n\nfig.update_layout(\n    title='Anderson-Rubin æ£€éªŒ: p-value vs å‡è®¾çš„ Î²',\n    xaxis_title='Î² (ä»·æ ¼å¯¹é”€é‡çš„æ•ˆåº”)',\n    yaxis_title='p-value',\n    template='plotly_white',\n    height=400\n)\n\nfig.show()\n\nprint(\"",
    "ğŸ’¡ AR æ£€éªŒçš„ä¼˜åŠ¿:\")\nprint(\"  â€¢ åœ¨å¼±å·¥å…·å˜é‡æƒ…å†µä¸‹ä»ç„¶æœ‰æ•ˆï¼ˆä¸ä¾èµ–æ¸è¿‘ç†è®ºï¼‰\")\nprint(\"  â€¢ å¯ä»¥æ„é€ ç½®ä¿¡åŒºé—´ï¼ˆåè½¬æ£€éªŒï¼‰\")\nprint(\"  â€¢ ç¼ºç‚¹ï¼šåŠŸæ•ˆè¾ƒä½ï¼ˆæ›´ä¿å®ˆï¼‰\")\n\n# ===================================\n# ç»ƒä¹  3: å¤šä¸ªå†…ç”Ÿå˜é‡\n# ===================================\n\nprint(\"",
    "\" + \"=\" * 70)\nprint(\"ã€ç»ƒä¹  3: å¤šä¸ªå†…ç”Ÿå˜é‡çš„ IV ä¼°è®¡ã€‘\")\nprint(\"-\" * 70)\n\nprint(\"",
    "åœºæ™¯ï¼šéœ€æ±‚å’Œä¾›ç»™çš„åŒæ—¶è¯†åˆ«\")\nprint(\"  éœ€æ±‚æ–¹ç¨‹: Q = Î±0 + Î±1*P + Î±2*Income + u_d\")\nprint(\"  ä¾›ç»™æ–¹ç¨‹: Q = Î²0 + Î²1*P + Î²2*Cost + u_s\")\nprint(\"  å†…ç”Ÿå˜é‡: P, Qï¼ˆåŒæ—¶å†³å®šï¼‰\")\nprint(\"  éœ€è¦è‡³å°‘ 2 ä¸ªå·¥å…·å˜é‡ï¼\")\n\n# æ¨¡æ‹Ÿæ•°æ®\nnp.random.seed(789)\nn = 1000\n\n# å¤–ç”Ÿå˜é‡\nincome = np.random.normal(50, 10, n)  # æ”¶å…¥ï¼ˆå½±å“éœ€æ±‚ï¼‰\ncost = np.random.normal(20, 5, n)     # æˆæœ¬ï¼ˆå½±å“ä¾›ç»™ï¼‰\n\n# éœ€æ±‚å’Œä¾›ç»™çš„å†²å‡»\nu_d = np.random.normal(0, 5, n)\nu_s = np.random.normal(0, 5, n)\n\n# è”ç«‹æ–¹ç¨‹æ±‚è§£\n# éœ€æ±‚: Q = 100 - 2*P + 0.5*Income + u_d\n# ä¾›ç»™: Q = 20 + 1.5*P - 0.3*Cost + u_s\n# å‡è¡¡: 100 - 2*P + 0.5*Income + u_d = 20 + 1.5*P - 0.3*Cost + u_s\n\n# æ±‚è§£ Pï¼ˆå‡è¡¡ä»·æ ¼ï¼‰\nprice_eq = (100 - 20 + 0.5*income + 0.3*cost + u_d - u_s) / (2 + 1.5)\n\n# æ±‚è§£ Qï¼ˆå‡è¡¡æ•°é‡ï¼‰\nquantity_eq = 100 - 2*price_eq + 0.5*income + u_d\n\n# ç”¨ IV ä¼°è®¡éœ€æ±‚æ–¹ç¨‹\n# å·¥å…·å˜é‡: Costï¼ˆåªå½±å“ä¾›ç»™ï¼Œä¸ç›´æ¥å½±å“éœ€æ±‚ï¼‰\nprint(\"",
    "ä¼°è®¡éœ€æ±‚æ–¹ç¨‹ï¼šQ ~ P + Income\")\nprint(\"å·¥å…·å˜é‡ï¼šCostï¼ˆç§»åŠ¨ä¾›ç»™æ›²çº¿ï¼Œè¯†åˆ«éœ€æ±‚æ›²çº¿ï¼‰\")\n\n# 2SLS for demand equation\nZ_demand = cost.reshape(-1, 1)\nX_demand = np.column_stack([price_eq, income])\nY_demand = quantity_eq\n\n# ç¬¬ä¸€é˜¶æ®µ: P ~ Cost + Income\nfirst_stage_demand = LinearRegression()\nfirst_stage_demand.fit(np.column_stack([cost, income]), price_eq)\nP_hat = first_stage_demand.predict(np.column_stack([cost, income]))\n\n# ç¬¬äºŒé˜¶æ®µ: Q ~ P_hat + Income\nsecond_stage_demand = LinearRegression()\nsecond_stage_demand.fit(np.column_stack([P_hat, income]), quantity_eq)\n\nprint(f\"",
    "éœ€æ±‚æ–¹ç¨‹ä¼°è®¡ç»“æœ:\")\nprint(f\"  çœŸå®å‚æ•°: Î±1 = -2.0 (ä»·æ ¼å¼¹æ€§), Î±2 = 0.5 (æ”¶å…¥æ•ˆåº”)\")\nprint(f\"  IV ä¼°è®¡: Î±1 = {second_stage_demand.coef_[0]:.3f}, Î±2 = {second_stage_demand.coef_[1]:.3f}\")\n\n# ç”¨ IV ä¼°è®¡ä¾›ç»™æ–¹ç¨‹\n# å·¥å…·å˜é‡: Incomeï¼ˆåªå½±å“éœ€æ±‚ï¼Œä¸ç›´æ¥å½±å“ä¾›ç»™ï¼‰\nprint(\"",
    "ä¼°è®¡ä¾›ç»™æ–¹ç¨‹ï¼šQ ~ P + Cost\")\nprint(\"å·¥å…·å˜é‡ï¼šIncomeï¼ˆç§»åŠ¨éœ€æ±‚æ›²çº¿ï¼Œè¯†åˆ«ä¾›ç»™æ›²çº¿ï¼‰\")\n\n# ç¬¬ä¸€é˜¶æ®µ: P ~ Income + Cost\nfirst_stage_supply = LinearRegression()\nfirst_stage_supply.fit(np.column_stack([income, cost]), price_eq)\nP_hat_supply = first_stage_supply.predict(np.column_stack([income, cost]))\n\n# ç¬¬äºŒé˜¶æ®µ: Q ~ P_hat + Cost\nsecond_stage_supply = LinearRegression()\nsecond_stage_supply.fit(np.column_stack([P_hat_supply, cost]), quantity_eq)\n\nprint(f\"",
    "ä¾›ç»™æ–¹ç¨‹ä¼°è®¡ç»“æœ:\")\nprint(f\"  çœŸå®å‚æ•°: Î²1 = 1.5 (ä»·æ ¼å¼¹æ€§), Î²2 = -0.3 (æˆæœ¬æ•ˆåº”)\")\nprint(f\"  IV ä¼°è®¡: Î²1 = {second_stage_supply.coef_[0]:.3f}, Î²2 = {second_stage_supply.coef_[1]:.3f}\")\n\nprint(\"",
    "ğŸ’¡ åŒæ—¶æ–¹ç¨‹çš„è¯†åˆ«:\")\nprint(\"  â€¢ éœ€æ±‚æ–¹ç¨‹ç”¨ä¾›ç»™ä¾§çš„å·¥å…·å˜é‡ï¼ˆCostï¼‰è¯†åˆ«\")\nprint(\"  â€¢ ä¾›ç»™æ–¹ç¨‹ç”¨éœ€æ±‚ä¾§çš„å·¥å…·å˜é‡ï¼ˆIncomeï¼‰è¯†åˆ«\")\nprint(\"  â€¢ è¿™æ˜¯ç»å…¸çš„ä¾›éœ€åˆ†ææ¡†æ¶\")\n\nprint(\"",
    "\" + \"=\" * 70)\nprint(\"âœ… æ‰€æœ‰ç»ƒä¹ å®Œæˆï¼\")\nprint(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## æ€»ç»“\n",
    "\n",
    "### æ ¸å¿ƒè¦ç‚¹\n",
    "\n",
    "1. **å†…ç”Ÿæ€§é—®é¢˜**\n",
    "   - é—æ¼å˜é‡ã€æµ‹é‡è¯¯å·®ã€åå‘å› æœã€åŒæ—¶æ€§\n",
    "   - OLS ä¼°è®¡æœ‰å\n",
    "\n",
    "2. **å·¥å…·å˜é‡çš„ä¸‰ä¸ªå‡è®¾**\n",
    "   - âœ… ç›¸å…³æ€§ï¼šå¯æ£€éªŒ (F > 10)\n",
    "   - âš ï¸ æ’ä»–æ€§ï¼šä¸å¯æ£€éªŒï¼Œéœ€è¦ç†è®ºæ”¯æ’‘\n",
    "   - âš ï¸ å¤–ç”Ÿæ€§ï¼šä¸å¯æ£€éªŒï¼Œéœ€è¦åˆ¶åº¦èƒŒæ™¯\n",
    "\n",
    "3. **2SLS ä¼°è®¡**\n",
    "   - ç¬¬ä¸€é˜¶æ®µï¼šæå–å¤–ç”Ÿå˜åŒ–\n",
    "   - ç¬¬äºŒé˜¶æ®µï¼šä¼°è®¡å› æœæ•ˆåº”\n",
    "   - Wald ä¼°è®¡é‡ï¼š$\\frac{\\text{Cov}(Z,Y)}{\\text{Cov}(Z,X)}$\n",
    "\n",
    "4. **å¼±å·¥å…·å˜é‡**\n",
    "   - F < 10ï¼šæœ‰é™æ ·æœ¬åå·®ã€æ¨æ–­å¤±æ•ˆ\n",
    "   - å¼± IV worse than no IV\n",
    "\n",
    "5. **LATE è§£é‡Š**\n",
    "   - IV ä¼°è®¡çš„æ˜¯ Compliers çš„æ•ˆåº”\n",
    "   - å¤–éƒ¨æ•ˆåº¦é—®é¢˜ï¼šLATE â‰  ATE\n",
    "\n",
    "### æ–¹æ³•å¯¹æ¯”\n",
    "\n",
    "| æ–¹æ³• | é€‚ç”¨åœºæ™¯ | å‡è®¾ | ä¼°è®¡å¯¹è±¡ |\n",
    "|------|----------|------|----------|\n",
    "| **RCT** | å¯ä»¥éšæœºåˆ†é… | æ— æ··æ·† | ATE |\n",
    "| **Matching** | æœ‰ä¸°å¯Œåå˜é‡ | å¯å¿½ç•¥æ€§ | ATT |\n",
    "| **RDD** | æœ‰è¿ç»­åˆ†é…å˜é‡ | æ–­ç‚¹é™„è¿‘å¯æ¯” | LATE |\n",
    "| **DID** | æœ‰æ—¶é—´ç»´åº¦ | å¹³è¡Œè¶‹åŠ¿ | ATT |\n",
    "| **IV** | æœ‰å¤–ç”Ÿå†²å‡» | ä¸‰ä¸ªå‡è®¾ | LATE |\n",
    "\n",
    "### å®è·µå»ºè®®\n",
    "\n",
    "1. **å¯»æ‰¾å¥½çš„ IV**ï¼š\n",
    "   - è‡ªç„¶å®éªŒ (æ”¿ç­–ã€ç¾å®³ã€éšæœºäº‹ä»¶)\n",
    "   - åˆ¶åº¦è§„åˆ™ (åˆ†æ•°çº¿ã€é…é¢ã€æŠ½ç­¾)\n",
    "   - æ—¶ç©ºå˜å¼‚ (è·ç¦»ã€æ—¶å·®ã€å¤©æ°”)\n",
    "\n",
    "2. **æ£€éªŒ IV æœ‰æ•ˆæ€§**ï¼š\n",
    "   - ç¬¬ä¸€é˜¶æ®µ F ç»Ÿè®¡é‡ > 10\n",
    "   - è¿‡åº¦è¯†åˆ«æ£€éªŒ (Hansen J)\n",
    "   - å®‰æ…°å‰‚æ£€éªŒ (placebo test)\n",
    "\n",
    "3. **è§£é‡Š LATE**ï¼š\n",
    "   - æ˜ç¡® Compliers æ˜¯è°\n",
    "   - è®¨è®ºå¤–éƒ¨æ•ˆåº¦\n",
    "   - ä¸å…¶ä»–æ–¹æ³•å¯¹æ¯”\n",
    "\n",
    "4. **ç¨³å¥æ€§æ£€éªŒ**ï¼š\n",
    "   - ä¸åŒ IV çš„ç»“æœæ˜¯å¦ä¸€è‡´\n",
    "   - å¼± IV ç¨³å¥æ¨æ–­ (AR, LM)\n",
    "   - å­æ ·æœ¬åˆ†æ\n",
    "\n",
    "### å»¶ä¼¸é˜…è¯»\n",
    "\n",
    "**ç»å…¸è®ºæ–‡**ï¼š\n",
    "- Angrist & Krueger (1991): Does Compulsory School Attendance Affect Schooling and Earnings?\n",
    "- Card (1995): Using Geographic Variation in College Proximity to Estimate the Return to Schooling\n",
    "- Angrist & Evans (1998): Children and Their Parents' Labor Supply\n",
    "\n",
    "**æ•™æ**ï¼š\n",
    "- Angrist & Pischke (2009): Mostly Harmless Econometrics\n",
    "- Wooldridge (2010): Econometric Analysis of Cross Section and Panel Data\n",
    "\n",
    "**Python åŒ…**ï¼š\n",
    "- `linearmodels`: IV regression\n",
    "- `statsmodels`: IV2SLS\n",
    "- `econml`: LATE estimation\n",
    "\n",
    "---\n",
    "\n",
    "## æ­å–œï¼\n",
    "\n",
    "ä½ å·²ç»æŒæ¡äº†å·¥å…·å˜é‡æ–¹æ³•ï¼Œè¿™æ˜¯å‡†å®éªŒæ–¹æ³•çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚\n",
    "\n",
    "ä¸‹ä¸€æ­¥ï¼Œæˆ‘ä»¬å°†å­¦ä¹  **åˆæˆæ§åˆ¶æ³• (Synthetic Control)**ï¼Œå¤„ç†æ€»ä½“å•ä½çš„å› æœæ¨æ–­é—®é¢˜ã€‚\n",
    "\n",
    "**è®°ä½**ï¼šå¥½çš„å·¥å…·å˜é‡æ˜¯å¯é‡ä¸å¯æ±‚çš„ï¼Œå¯»æ‰¾å’Œè®ºè¯å·¥å…·å˜é‡çš„æœ‰æ•ˆæ€§ï¼Œå¾€å¾€æ¯”ä¼°è®¡æœ¬èº«æ›´é‡è¦ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}