{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Part 5.2: TARNet 与 DragonNet - 深度因果推断的演进\n\n## 学习目标\n\n1. 理解 TARNet 的架构设计和 Factual Loss\n2. 掌握 DragonNet 的三头架构和倾向得分正则化\n3. 理解 Targeted Regularization 的原理\n4. 通过对比实验理解两者的区别\n5. 学会在实践中选择合适的模型\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共同背景：深度学习用于因果推断\n",
    "\n",
    "### 为什么需要深度学习？\n",
    "\n",
    "传统因果推断方法（如 IPW, Matching）面临的挑战：\n",
    "- **高维特征**: 现代应用中特征维度可能很高（图像、文本、用户行为）\n",
    "- **非线性关系**: 特征与结果之间的关系可能高度非线性\n",
    "- **表示学习**: 需要自动学习有效的特征表示\n",
    "\n",
    "### 核心问题：反事实无法观测\n",
    "\n",
    "对于每个样本 $i$:\n",
    "- 如果 $T_i=1$，我们只观测到 $Y_i(1)$，$Y_i(0)$ 是反事实\n",
    "- 如果 $T_i=0$，我们只观测到 $Y_i(0)$，$Y_i(1)$ 是反事实\n",
    "\n",
    "这就是**因果推断的根本挑战**！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 导入必要的库\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom typing import Tuple, Dict\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\n\n# 设置随机种子\nnp.random.seed(42)\ntorch.manual_seed(42)\n\n# 绘图设置\nplt.rcParams['figure.figsize'] = [10, 6]\nplt.rcParams['font.size'] = 12\n# 使用兼容的样式\ntry:\n    plt.style.use('seaborn-v0_8-whitegrid')\nexcept:\n    plt.style.use('seaborn-whitegrid' if 'seaborn-whitegrid' in plt.style.available else 'default')\n\nprint(f\"PyTorch 版本: {torch.__version__}\")\nprint(\"环境准备完成！\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: TARNet - 开山之作\n",
    "\n",
    "## TARNet: Treatment-Agnostic Representation Network\n",
    "\n",
    "TARNet 是 2017 年提出的开创性工作，首次将深度学习系统地应用于因果效应估计。\n",
    "\n",
    "### 核心设计\n",
    "\n",
    "1. **共享表示层**：学习对处理组和控制组都有用的特征表示\n",
    "2. **双头输出**：分别预测 Y(0) 和 Y(1)\n",
    "\n",
    "$$X \\xrightarrow{\\Phi} \\text{Representation} \\xrightarrow{\\begin{cases} h_0 \\to \\hat{Y}(0) \\\\ h_1 \\to \\hat{Y}(1) \\end{cases}}$$\n",
    "\n",
    "### 生活化类比：双语翻译官\n",
    "\n",
    "想象你是一个翻译官，需要翻译中文文章给两类读者：\n",
    "- **英语读者** (处理组)\n",
    "- **法语读者** (控制组)\n",
    "\n",
    "**传统方法 (T-Learner)**：\n",
    "- 雇佣两个独立的翻译官\n",
    "- 每个翻译官只懂一种语言\n",
    "- 效率低，且无法利用共同知识\n",
    "\n",
    "**TARNet 方法**：\n",
    "- 一个翻译官先理解文章核心含义 (共享表示)\n",
    "- 然后分别翻译成英语和法语 (双头输出)\n",
    "- 效率高，且能利用语言间的共同结构\n",
    "\n",
    "### TARNet 架构图\n",
    "\n",
    "```\n",
    "        ┌─────────────────────────────────────────┐\n",
    "        │         共享表示层 (Shared Repr)          │\n",
    "        │  X → [Hidden] → [Hidden] → Φ(X)         │\n",
    "        └─────────────────┬───────────────────────┘\n",
    "                          │\n",
    "            ┌─────────────┴─────────────┐\n",
    "            ▼                           ▼\n",
    "    ┌───────────────┐           ┌───────────────┐\n",
    "    │    Head 0     │           │    Head 1     │\n",
    "    │ Φ(X) → Ŷ(0)  │           │ Φ(X) → Ŷ(1)  │\n",
    "    └───────────────┘           └───────────────┘\n",
    "            │                           │\n",
    "            ▼                           ▼\n",
    "      控制组预测                    处理组预测\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Factual Loss: 关键训练策略\n\n### 核心挑战：反事实无法观测\n\n对于每个样本，我们只能观测到一个结果：\n- 如果 $T=1$，我们只观测到 $Y(1)$\n- 如果 $T=0$，我们只观测到 $Y(0)$\n\n所以我们只能在 **观测到的结果** 上计算损失！\n\n### Factual Loss 公式\n\n$$L_{\\text{factual}} = \\frac{1}{n}\\sum_{i=1}^{n} (Y_i - \\hat{Y}_i^{\\text{factual}})^2$$\n\n其中：\n$$\\hat{Y}_i^{\\text{factual}} = \\begin{cases} \\hat{Y}_i(1) & \\text{if } T_i = 1 \\\\ \\hat{Y}_i(0) & \\text{if } T_i = 0 \\end{cases}$$"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习 1.1: 理解 TARNet 架构\n",
    "\n",
    "class SimpleTARNet(nn.Module):\n",
    "    \"\"\"\n",
    "    简化版 TARNet\n",
    "    \n",
    "    架构:\n",
    "    X -> [Shared Representation] -> Phi(X)\n",
    "                                      |\n",
    "                    +----------------+----------------+\n",
    "                    |                                 |\n",
    "                [Head 0]                         [Head 1]\n",
    "                    |                                 |\n",
    "                  Y(0)                              Y(1)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int = 50,\n",
    "        repr_dim: int = 25\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 共享表示层\n",
    "        self.representation = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, repr_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # 控制组输出头 (Y0)\n",
    "        self.head0 = nn.Sequential(\n",
    "            nn.Linear(repr_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "        )\n",
    "        \n",
    "        # 处理组输出头 (Y1)\n",
    "        self.head1 = nn.Sequential(\n",
    "            nn.Linear(repr_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        \n",
    "        Returns:\n",
    "            (y0_pred, y1_pred, representation)\n",
    "        \"\"\"\n",
    "        phi = self.representation(x)\n",
    "        y0 = self.head0(phi)\n",
    "        y1 = self.head1(phi)\n",
    "        \n",
    "        return y0, y1, phi\n",
    "    \n",
    "    def predict_ite(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"预测个体处理效应 ITE = Y(1) - Y(0)\"\"\"\n",
    "        y0, y1, _ = self.forward(x)\n",
    "        return y1 - y0\n",
    "\n",
    "# 测试架构\n",
    "model = SimpleTARNet(input_dim=5)\n",
    "X_sample = torch.randn(10, 5)\n",
    "y0, y1, phi = model(X_sample)\n",
    "print(f\"TARNet 输出形状: Y0={y0.shape}, Y1={y1.shape}, Phi={phi.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习 1.2: Factual Loss\n",
    "\n",
    "def compute_factual_loss(\n",
    "    y_true: torch.Tensor,\n",
    "    t_true: torch.Tensor,\n",
    "    y0_pred: torch.Tensor,\n",
    "    y1_pred: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    计算 Factual Loss\n",
    "    \n",
    "    关键思想: 只在观测到的结果上计算损失\n",
    "    - 如果 T=1, 损失 = (Y - Y1_pred)^2\n",
    "    - 如果 T=0, 损失 = (Y - Y0_pred)^2\n",
    "    \"\"\"\n",
    "    # 根据处理状态选择预测值\n",
    "    t_expanded = t_true.unsqueeze(1) if len(t_true.shape) == 1 else t_true\n",
    "    y_pred = torch.where(t_expanded == 1, y1_pred, y0_pred)\n",
    "    \n",
    "    # 计算 MSE\n",
    "    y_true_expanded = y_true.unsqueeze(1) if len(y_true.shape) == 1 else y_true\n",
    "    loss = torch.mean((y_true_expanded - y_pred)**2)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# 测试\n",
    "y_true = torch.FloatTensor([1.0, 2.0, 3.0])\n",
    "t_true = torch.FloatTensor([1.0, 0.0, 1.0])\n",
    "y0_pred = torch.FloatTensor([[1.5], [2.0], [2.5]])\n",
    "y1_pred = torch.FloatTensor([[1.0], [2.5], [3.0]])\n",
    "\n",
    "loss = compute_factual_loss(y_true, t_true, y0_pred, y1_pred)\n",
    "print(f\"Factual Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: DragonNet - 三头龙的进化\n",
    "\n",
    "## 从 TARNet 到 DragonNet: 一个巧妙的升级\n",
    "\n",
    "如果翻译官同时还能**判断客户来自哪个国家**（倾向得分），翻译效果会不会更好呢？\n",
    "\n",
    "这就是 **DragonNet** 的核心思想！\n",
    "\n",
    "## DragonNet 的直觉: 三头龙的故事\n",
    "\n",
    "### 问题回顾\n",
    "\n",
    "在因果推断中，**混淆**是最大的敌人。想象你在研究「广告是否增加用户购买」：\n",
    "\n",
    "- 经常购物的用户**更容易看到广告**（算法推荐）\n",
    "- 经常购物的用户**本来就会买更多**\n",
    "\n",
    "这就是**选择偏差**：处理分配不是随机的，而是依赖于混淆因子。\n",
    "\n",
    "### TARNet 的局限\n",
    "\n",
    "TARNet 只学习「预测结果」，但不显式地理解「谁会被处理」。\n",
    "\n",
    "### DragonNet 的解决方案\n",
    "\n",
    "DragonNet 添加了**第三个头**——倾向得分头！\n",
    "\n",
    "```\n",
    "                       🧠 共享表示层\n",
    "                           |                    \n",
    "       +------------------+-------------------+\n",
    "       |                  |                   |\n",
    "    🎯 Y(0)头         🎯 Y(1)头          📊 倾向得分头\n",
    "       |                  |                   |\n",
    "  控制组结果预测    处理组结果预测      \"谁会被处理?\"\n",
    "```\n",
    "\n",
    "为什么叫「龙网」（DragonNet）？因为这三个头就像传说中的**三头龙**！\n",
    "\n",
    "### 关键洞察\n",
    "\n",
    "添加倾向得分头有什么好处？\n",
    "\n",
    "1. **正则化作用**: 强迫表示层同时学会「预测结果」和「预测处理」\n",
    "2. **平衡表示**: 让表示层捕获与**处理分配相关的信息**，这正是混淆因子！\n",
    "3. **Targeted Regularization**: 用倾向得分来调整损失函数，减少偏差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## DragonNet 核心公式\n\n### 架构\n\n$$\\Phi(X) = f_{\\text{repr}}(X) \\quad \\text{(共享表示)}$$\n\n$$\\hat{Y}(0) = h_0(\\Phi(X)), \\quad \\hat{Y}(1) = h_1(\\Phi(X)) \\quad \\text{(结果头)}$$\n\n$$\\hat{e}(X) = h_e(\\Phi(X)) \\quad \\text{(倾向得分头)}$$\n\n### 复合损失函数\n\n$$\\mathcal{L}_{\\text{DragonNet}} = \\mathcal{L}_{\\text{factual}} + \\alpha \\cdot \\mathcal{L}_{\\text{propensity}} + \\beta \\cdot \\mathcal{L}_{\\text{targeted}}$$\n\n其中：\n\n1. **Factual Loss** (和 TARNet 一样):\n$$\\mathcal{L}_{\\text{factual}} = \\frac{1}{N}\\sum_{i=1}^{N} \\left(Y_i - \\left[T_i \\cdot \\hat{Y}_i(1) + (1-T_i) \\cdot \\hat{Y}_i(0)\\right]\\right)^2$$\n\n2. **Propensity Loss** (二分类交叉熵):\n$$\\mathcal{L}_{\\text{propensity}} = -\\frac{1}{N}\\sum_{i=1}^{N} \\left[T_i \\log \\hat{e}_i + (1-T_i) \\log (1-\\hat{e}_i)\\right]$$\n\n3. **Targeted Regularization** (DragonNet 的创新):\n$$\\mathcal{L}_{\\text{targeted}} = \\frac{1}{N}\\sum_{i=1}^{N} \\left(Y_i - \\hat{Y}_i - \\epsilon \\cdot h_i\\right)^2$$\n\n其中：\n$$h_i = \\frac{T_i}{\\hat{e}(X_i)} - \\frac{1-T_i}{1-\\hat{e}(X_i)}$$"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeted Regularization: 魔法公式的直觉\n",
    "\n",
    "### 那个神秘的 h 是什么？\n",
    "\n",
    "$$h = \\frac{T}{e(X)} - \\frac{1-T}{1-e(X)}$$\n",
    "\n",
    "这个公式来自于**半参数效率理论**和 **TMLE（Targeted Maximum Likelihood Estimation）**。\n",
    "\n",
    "### 一个直觉解释\n",
    "\n",
    "想象你在做民意调查，但有些人群更难接触到（比如年轻人不爱接电话）：\n",
    "\n",
    "- **e(X)** = 某人被调查到的概率（倾向得分）\n",
    "- **T/e(X)**: 如果被调查到（T=1），用 1/e(X) 加权，相当于「少见的人更重要」\n",
    "- **-(1-T)/(1-e(X))**: 如果没被调查到（T=0），用反向权重\n",
    "\n",
    "这个 **h** 本质上是一个**双重鲁棒性**的调整项！\n",
    "\n",
    "### epsilon 的作用\n",
    "\n",
    "**epsilon (ε)** 是一个**可学习的标量参数**：\n",
    "\n",
    "- 它让模型自动学习「需要多少调整」\n",
    "- 如果模型已经很准，epsilon 会趋近于 0\n",
    "- 如果有偏差，epsilon 会学到一个非零值来修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习 2.1: DragonNet 架构\n",
    "\n",
    "class SimpleDragonNet(nn.Module):\n",
    "    \"\"\"\n",
    "    简化版 DragonNet - 三头龙网络\n",
    "    \n",
    "    与 TARNet 的区别:\n",
    "    1. 多了一个倾向得分头\n",
    "    2. 有一个可学习的 epsilon 参数\n",
    "    3. 使用 ELU 激活函数（原论文推荐）\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int = 50,\n",
    "        repr_dim: int = 25\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 共享表示层 (使用 ELU)\n",
    "        self.representation = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim, repr_dim),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "        # 控制组输出头 (Y0)\n",
    "        self.head0 = nn.Sequential(\n",
    "            nn.Linear(repr_dim, hidden_dim // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "        )\n",
    "        \n",
    "        # 处理组输出头 (Y1)\n",
    "        self.head1 = nn.Sequential(\n",
    "            nn.Linear(repr_dim, hidden_dim // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "        )\n",
    "        \n",
    "        # 倾向得分头 (这是关键！)\n",
    "        self.propensity_head = nn.Sequential(\n",
    "            nn.Linear(repr_dim, hidden_dim // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()  # 输出限制在 [0, 1]\n",
    "        )\n",
    "        \n",
    "        # epsilon 参数 (可学习的标量)\n",
    "        self.epsilon = nn.Parameter(torch.tensor(0.0))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple:\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        \n",
    "        Returns:\n",
    "            (y0_pred, y1_pred, propensity, epsilon, representation)\n",
    "        \"\"\"\n",
    "        phi = self.representation(x)\n",
    "        y0 = self.head0(phi)\n",
    "        y1 = self.head1(phi)\n",
    "        propensity = self.propensity_head(phi)\n",
    "        \n",
    "        return y0, y1, propensity, self.epsilon, phi\n",
    "    \n",
    "    def predict_ite(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"预测个体处理效应\"\"\"\n",
    "        y0, y1, _, _, _ = self.forward(x)\n",
    "        return y1 - y0\n",
    "\n",
    "# 测试 DragonNet 架构\n",
    "dragon_model = SimpleDragonNet(input_dim=5)\n",
    "X_sample = torch.randn(10, 5)\n",
    "y0, y1, prop, eps, phi = dragon_model(X_sample)\n",
    "\n",
    "print(\"DragonNet 架构测试通过! 🐉\")\n",
    "print(f\"\\n输出形状:\")\n",
    "print(f\"  Y0 预测: {y0.shape}\")\n",
    "print(f\"  Y1 预测: {y1.shape}\")\n",
    "print(f\"  倾向得分: {prop.shape}\")\n",
    "print(f\"  表示向量: {phi.shape}\")\n",
    "print(f\"\\n关键参数:\")\n",
    "print(f\"  Epsilon: {eps}\")\n",
    "print(f\"  倾向得分范围: [{prop.min():.4f}, {prop.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习 2.2: DragonNet 复合损失函数\n",
    "\n",
    "def dragonnet_loss(\n",
    "    y_true: torch.Tensor,\n",
    "    t_true: torch.Tensor,\n",
    "    y0_pred: torch.Tensor,\n",
    "    y1_pred: torch.Tensor,\n",
    "    propensity: torch.Tensor,\n",
    "    epsilon: torch.Tensor,\n",
    "    alpha: float = 1.0,\n",
    "    beta: float = 1.0\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    DragonNet 复合损失函数\n",
    "    \n",
    "    L = L_factual + alpha * L_propensity + beta * L_targeted\n",
    "    \"\"\"\n",
    "    # 确保形状正确\n",
    "    y0_pred = y0_pred.squeeze()\n",
    "    y1_pred = y1_pred.squeeze()\n",
    "    propensity = propensity.squeeze()\n",
    "    \n",
    "    # 1. Factual Loss\n",
    "    y_pred = t_true * y1_pred + (1 - t_true) * y0_pred\n",
    "    factual_loss = torch.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "    # 2. Propensity Loss (二分类交叉熵)\n",
    "    eps = 1e-8\n",
    "    propensity_loss = -torch.mean(\n",
    "        t_true * torch.log(propensity + eps) + \n",
    "        (1 - t_true) * torch.log(1 - propensity + eps)\n",
    "    )\n",
    "    \n",
    "    # 3. Targeted Regularization\n",
    "    h = t_true / (propensity + eps) - (1 - t_true) / (1 - propensity + eps)\n",
    "    targeted_reg = torch.mean((y_true - y_pred - epsilon * h) ** 2)\n",
    "    \n",
    "    # 总损失\n",
    "    total_loss = factual_loss + alpha * propensity_loss + beta * targeted_reg\n",
    "    \n",
    "    return {\n",
    "        'total': total_loss,\n",
    "        'factual': factual_loss,\n",
    "        'propensity': propensity_loss,\n",
    "        'targeted': targeted_reg\n",
    "    }\n",
    "\n",
    "# 测试损失函数\n",
    "y_true = torch.FloatTensor([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "t_true = torch.FloatTensor([1.0, 0.0, 1.0, 0.0, 1.0])\n",
    "y0_pred = torch.FloatTensor([1.5, 2.0, 2.5, 4.5, 4.0])\n",
    "y1_pred = torch.FloatTensor([2.0, 2.5, 3.0, 5.0, 5.5])\n",
    "propensity = torch.FloatTensor([0.7, 0.3, 0.6, 0.4, 0.8])\n",
    "epsilon = torch.tensor(0.1)\n",
    "\n",
    "losses = dragonnet_loss(\n",
    "    y_true, t_true, y0_pred, y1_pred,\n",
    "    propensity, epsilon, alpha=1.0, beta=1.0\n",
    ")\n",
    "\n",
    "print(\"损失函数测试通过! 🎉\")\n",
    "print(f\"\\n各损失项:\")\n",
    "print(f\"  Factual Loss: {losses['factual'].item():.4f}\")\n",
    "print(f\"  Propensity Loss: {losses['propensity'].item():.4f}\")\n",
    "print(f\"  Targeted Reg: {losses['targeted'].item():.4f}\")\n",
    "print(f\"  Total Loss: {losses['total'].item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: 数据生成与实验准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 练习 3.1: 生成强混淆数据\n\ndef generate_confounded_data(\n    n: int = 2000,\n    seed: int = 42\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    生成有强混淆的数据\n    \n    场景: 广告投放效果评估\n    - X: 用户特征（购物频率、平台活跃度、消费能力等）\n    - T: 是否看到广告（不是随机分配！高价值用户更容易看到）\n    - Y: 是否购买\n    \n    强混淆: 用户特征同时影响「是否看广告」和「是否购买」\n    \n    DGP (Data Generating Process):\n    1. 倾向得分: e(X) = sigmoid(1.0*X₀ + 0.8*X₁ + 0.6*X₂)\n    2. 控制组结果: Y(0) = 2.0 + 1.0*X₀ + 0.5*X₁ + ε\n    3. 处理效应: τ(X) = 2.0 + 0.5*X₀\n    4. 处理组结果: Y(1) = Y(0) + τ(X)\n    \"\"\"\n    np.random.seed(seed)\n    \n    # 用户特征 (5维)\n    X = np.random.randn(n, 5)\n    # X[:, 0]: 购物频率\n    # X[:, 1]: 平台活跃度\n    # X[:, 2]: 消费能力\n    # X[:, 3]: 浏览历史\n    # X[:, 4]: 点击率\n    \n    # 强混淆的处理分配（高价值用户更容易看到广告）\n    propensity = 1 / (1 + np.exp(-(\n        1.0 * X[:, 0] +   # 购物频率高 -> 更可能看广告\n        0.8 * X[:, 1] +   # 活跃度高 -> 更可能看广告\n        0.6 * X[:, 2]     # 消费能力高 -> 更可能看广告\n    )))\n    \n    T = np.random.binomial(1, propensity, n)\n    \n    # 生成潜在结果（结果也依赖于 X - 这是混淆！）\n    noise = np.random.randn(n) * 0.5\n    Y0 = 2.0 + 1.0 * X[:, 0] + 0.5 * X[:, 1] + noise  # 修正系数，与文档一致\n    \n    # 异质性处理效应\n    treatment_effect = 2.0 + 0.5 * X[:, 0]  # 基础效应 2, 加上与特征相关的部分\n    Y1 = Y0 + treatment_effect\n    \n    # 观测结果\n    Y = np.where(T == 1, Y1, Y0)\n    \n    return X, T, Y, Y0, Y1\n\n# 生成数据\nX, T, Y, Y0, Y1 = generate_confounded_data(n=2000)\n\nprint(\"数据生成成功! 🎉\")\nprint(f\"数据形状: X={X.shape}\")\nprint(f\"处理组比例: {T.mean():.2%}\")\nprint(f\"\\n真实因果效应:\")\nprint(f\"  真实 ATE: {np.mean(Y1 - Y0):.4f}\")\nprint(f\"  真实 ATT: {np.mean((Y1 - Y0)[T == 1]):.4f}\")\nprint(f\"\\n朴素估计（有偏！）:\")\nnaive_ate = Y[T == 1].mean() - Y[T == 0].mean()\nprint(f\"  朴素 ATE: {naive_ate:.4f}\")\nprint(f\"  偏差: {naive_ate - np.mean(Y1 - Y0):.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: 对比实验 - TARNet vs DragonNet\n",
    "\n",
    "现在让我们训练并对比两个模型的性能！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习 4.1: 统一训练函数\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    X: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    model_type: str = 'tarnet',  # 'tarnet' or 'dragonnet'\n",
    "    n_epochs: int = 200,\n",
    "    batch_size: int = 64,\n",
    "    learning_rate: float = 1e-3,\n",
    "    alpha: float = 1.0,\n",
    "    beta: float = 1.0,\n",
    "    verbose: bool = True\n",
    ") -> Tuple[nn.Module, dict]:\n",
    "    \"\"\"\n",
    "    统一的模型训练函数\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_type: 'tarnet' (只用 factual loss) 或 'dragonnet' (完整损失)\n",
    "    alpha: 倾向得分损失权重 (仅 dragonnet)\n",
    "    beta: targeted regularization 权重 (仅 dragonnet)\n",
    "    \"\"\"\n",
    "    # 数据准备\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    T_tensor = torch.FloatTensor(T)\n",
    "    Y_tensor = torch.FloatTensor(Y)\n",
    "    \n",
    "    dataset = TensorDataset(X_tensor, T_tensor, Y_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 优化器\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # 训练历史\n",
    "    history = {\n",
    "        'total_loss': [],\n",
    "        'factual_loss': [],\n",
    "        'propensity_loss': [],\n",
    "        'targeted_loss': [],\n",
    "        'epsilon': []\n",
    "    }\n",
    "    \n",
    "    # 训练循环\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_losses = {k: 0 for k in ['total_loss', 'factual_loss', 'propensity_loss', 'targeted_loss']}\n",
    "        n_batches = 0\n",
    "        \n",
    "        for batch_x, batch_t, batch_y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 前向传播\n",
    "            if model_type == 'dragonnet':\n",
    "                y0_pred, y1_pred, propensity, epsilon, _ = model(batch_x)\n",
    "                \n",
    "                # DragonNet 完整损失\n",
    "                losses = dragonnet_loss(\n",
    "                    batch_y, batch_t, y0_pred, y1_pred,\n",
    "                    propensity, epsilon, alpha=alpha, beta=beta\n",
    "                )\n",
    "                loss = losses['total']\n",
    "                \n",
    "                # 记录各项损失\n",
    "                epoch_losses['total_loss'] += loss.item()\n",
    "                epoch_losses['factual_loss'] += losses['factual'].item()\n",
    "                epoch_losses['propensity_loss'] += losses['propensity'].item()\n",
    "                epoch_losses['targeted_loss'] += losses['targeted'].item()\n",
    "            else:\n",
    "                # TARNet 只用 factual loss\n",
    "                y0_pred, y1_pred, _ = model(batch_x)\n",
    "                loss = compute_factual_loss(batch_y, batch_t, y0_pred, y1_pred)\n",
    "                \n",
    "                epoch_losses['total_loss'] += loss.item()\n",
    "                epoch_losses['factual_loss'] += loss.item()\n",
    "            \n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            n_batches += 1\n",
    "        \n",
    "        # 记录平均损失\n",
    "        for k in epoch_losses.keys():\n",
    "            history[k].append(epoch_losses[k] / n_batches)\n",
    "        \n",
    "        # 记录 epsilon (仅 dragonnet)\n",
    "        if model_type == 'dragonnet':\n",
    "            history['epsilon'].append(model.epsilon.item())\n",
    "        \n",
    "        if verbose and (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {history['total_loss'][-1]:.4f}\")\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习 4.2: 训练 TARNet\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"训练 TARNet (只用 Factual Loss)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tarnet_model = SimpleTARNet(input_dim=X.shape[1])\n",
    "tarnet_model, tarnet_history = train_model(\n",
    "    tarnet_model, X, T, Y,\n",
    "    model_type='tarnet',\n",
    "    n_epochs=200,\n",
    "    batch_size=64,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nTARNet 训练完成! 最终损失: {tarnet_history['total_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习 4.3: 训练 DragonNet\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"训练 DragonNet (完整损失)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dragonnet_model = SimpleDragonNet(input_dim=X.shape[1])\n",
    "dragonnet_model, dragonnet_history = train_model(\n",
    "    dragonnet_model, X, T, Y,\n",
    "    model_type='dragonnet',\n",
    "    n_epochs=200,\n",
    "    batch_size=64,\n",
    "    alpha=1.0,\n",
    "    beta=1.0,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nDragonNet 训练完成! 最终损失: {dragonnet_history['total_loss'][-1]:.4f}\")\n",
    "print(f\"最终 Epsilon: {dragonnet_history['epsilon'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习 4.4: 评估函数\n",
    "\n",
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    X: np.ndarray,\n",
    "    Y0: np.ndarray,\n",
    "    Y1: np.ndarray,\n",
    "    model_type: str = 'tarnet'\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    评估模型性能\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_tensor = torch.FloatTensor(X)\n",
    "        \n",
    "        if model_type == 'dragonnet':\n",
    "            y0_pred, y1_pred, _, _, _ = model(X_tensor)\n",
    "        else:\n",
    "            y0_pred, y1_pred, _ = model(X_tensor)\n",
    "        \n",
    "        y0_pred = y0_pred.numpy().squeeze()\n",
    "        y1_pred = y1_pred.numpy().squeeze()\n",
    "    \n",
    "    # 真实 ITE\n",
    "    ite_true = Y1 - Y0\n",
    "    ite_pred = y1_pred - y0_pred\n",
    "    \n",
    "    # PEHE (Precision in Estimation of Heterogeneous Effect)\n",
    "    pehe = np.sqrt(np.mean((ite_true - ite_pred) ** 2))\n",
    "    \n",
    "    # ATE 误差\n",
    "    ate_true = np.mean(ite_true)\n",
    "    ate_pred = np.mean(ite_pred)\n",
    "    ate_error = np.abs(ate_true - ate_pred)\n",
    "    \n",
    "    # ITE 相关性\n",
    "    ite_corr = np.corrcoef(ite_true.flatten(), ite_pred.flatten())[0, 1]\n",
    "    \n",
    "    return {\n",
    "        'pehe': pehe,\n",
    "        'ate_true': ate_true,\n",
    "        'ate_pred': ate_pred,\n",
    "        'ate_error': ate_error,\n",
    "        'ite_corr': ite_corr,\n",
    "        'ite_true': ite_true,\n",
    "        'ite_pred': ite_pred,\n",
    "        'y0_pred': y0_pred,\n",
    "        'y1_pred': y1_pred\n",
    "    }\n",
    "\n",
    "# 评估两个模型\n",
    "tarnet_metrics = evaluate_model(tarnet_model, X, Y0, Y1, model_type='tarnet')\n",
    "dragonnet_metrics = evaluate_model(dragonnet_model, X, Y0, Y1, model_type='dragonnet')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TARNet vs DragonNet 性能对比\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n{'模型':<15} {'PEHE':<15} {'ATE 误差':<15} {'ITE 相关性':<15}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'TARNet':<15} {tarnet_metrics['pehe']:<15.4f} {tarnet_metrics['ate_error']:<15.4f} {tarnet_metrics['ite_corr']:<15.4f}\")\n",
    "print(f\"{'DragonNet':<15} {dragonnet_metrics['pehe']:<15.4f} {dragonnet_metrics['ate_error']:<15.4f} {dragonnet_metrics['ite_corr']:<15.4f}\")\n",
    "\n",
    "# 计算改进\n",
    "pehe_improve = (tarnet_metrics['pehe'] - dragonnet_metrics['pehe']) / tarnet_metrics['pehe'] * 100\n",
    "ate_improve = (tarnet_metrics['ate_error'] - dragonnet_metrics['ate_error']) / tarnet_metrics['ate_error'] * 100\n",
    "\n",
    "print(f\"\\n改进:\")\n",
    "print(f\"  PEHE: {pehe_improve:+.1f}%\")\n",
    "print(f\"  ATE 误差: {ate_improve:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 可视化对比结果\n\nfig, axes = plt.subplots(2, 3, figsize=(18, 12))\n\n# 第一行: TARNet 结果\n# ITE 散点图\naxes[0, 0].scatter(tarnet_metrics['ite_true'], tarnet_metrics['ite_pred'], alpha=0.3, s=10, c='#3498db')\nmin_val = min(tarnet_metrics['ite_true'].min(), tarnet_metrics['ite_pred'].min())\nmax_val = max(tarnet_metrics['ite_true'].max(), tarnet_metrics['ite_pred'].max())\naxes[0, 0].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\naxes[0, 0].set_xlabel('True ITE', fontsize=12)\naxes[0, 0].set_ylabel('Predicted ITE', fontsize=12)\naxes[0, 0].set_title(f'TARNet: ITE Prediction (r={tarnet_metrics[\"ite_corr\"]:.3f})', fontsize=13, fontweight='bold')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# ITE 误差分布\nite_error_tarnet = tarnet_metrics['ite_pred'] - tarnet_metrics['ite_true']\nn_bins = min(50, max(20, len(ite_error_tarnet) // 40))  # 动态调整 bins\naxes[0, 1].hist(ite_error_tarnet, bins=n_bins, alpha=0.7, color='#3498db', edgecolor='black')\naxes[0, 1].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\naxes[0, 1].axvline(x=ite_error_tarnet.mean(), color='orange', linestyle='-', linewidth=2, \n                   label=f'Mean: {ite_error_tarnet.mean():.3f}')\naxes[0, 1].set_xlabel('ITE Prediction Error', fontsize=12)\naxes[0, 1].set_ylabel('Frequency', fontsize=12)\naxes[0, 1].set_title(f'TARNet: ITE Error Distribution (PEHE={tarnet_metrics[\"pehe\"]:.3f})', \n                     fontsize=13, fontweight='bold')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# 训练曲线\naxes[0, 2].plot(tarnet_history['total_loss'], 'b-', linewidth=2, label='Total Loss')\naxes[0, 2].set_xlabel('Epoch', fontsize=12)\naxes[0, 2].set_ylabel('Loss', fontsize=12)\naxes[0, 2].set_title('TARNet: Training Loss', fontsize=13, fontweight='bold')\naxes[0, 2].legend()\naxes[0, 2].grid(True, alpha=0.3)\n\n# 第二行: DragonNet 结果\n# ITE 散点图\naxes[1, 0].scatter(dragonnet_metrics['ite_true'], dragonnet_metrics['ite_pred'], alpha=0.3, s=10, c='#e74c3c')\nmin_val = min(dragonnet_metrics['ite_true'].min(), dragonnet_metrics['ite_pred'].min())\nmax_val = max(dragonnet_metrics['ite_true'].max(), dragonnet_metrics['ite_pred'].max())\naxes[1, 0].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\naxes[1, 0].set_xlabel('True ITE', fontsize=12)\naxes[1, 0].set_ylabel('Predicted ITE', fontsize=12)\naxes[1, 0].set_title(f'DragonNet: ITE Prediction (r={dragonnet_metrics[\"ite_corr\"]:.3f})', \n                     fontsize=13, fontweight='bold')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# ITE 误差分布\nite_error_dragon = dragonnet_metrics['ite_pred'] - dragonnet_metrics['ite_true']\nn_bins = min(50, max(20, len(ite_error_dragon) // 40))  # 动态调整 bins\naxes[1, 1].hist(ite_error_dragon, bins=n_bins, alpha=0.7, color='#e74c3c', edgecolor='black')\naxes[1, 1].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\naxes[1, 1].axvline(x=ite_error_dragon.mean(), color='orange', linestyle='-', linewidth=2, \n                   label=f'Mean: {ite_error_dragon.mean():.3f}')\naxes[1, 1].set_xlabel('ITE Prediction Error', fontsize=12)\naxes[1, 1].set_ylabel('Frequency', fontsize=12)\naxes[1, 1].set_title(f'DragonNet: ITE Error Distribution (PEHE={dragonnet_metrics[\"pehe\"]:.3f})', \n                     fontsize=13, fontweight='bold')\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\n# 损失组成\naxes[1, 2].plot(dragonnet_history['factual_loss'], 'g-', label='Factual', linewidth=2)\naxes[1, 2].plot(dragonnet_history['propensity_loss'], 'r-', label='Propensity', linewidth=2)\nif len(dragonnet_history['targeted_loss']) > 0 and any(dragonnet_history['targeted_loss']):\n    axes[1, 2].plot(dragonnet_history['targeted_loss'], 'purple', label='Targeted', linewidth=2)\naxes[1, 2].set_xlabel('Epoch', fontsize=12)\naxes[1, 2].set_ylabel('Loss', fontsize=12)\naxes[1, 2].set_title('DragonNet: Loss Components', fontsize=13, fontweight='bold')\naxes[1, 2].legend()\naxes[1, 2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 对比柱状图\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# PEHE 对比\nmodels = ['TARNet', 'DragonNet']\npehe_values = [tarnet_metrics['pehe'], dragonnet_metrics['pehe']]\ncolors = ['#3498db', '#e74c3c']\n\nbars1 = axes[0].bar(models, pehe_values, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\naxes[0].set_ylabel('PEHE', fontsize=12)\naxes[0].set_title('PEHE 对比 (越低越好)', fontsize=13, fontweight='bold')\naxes[0].grid(True, alpha=0.3, axis='y')\n\n# 添加数值标签\nfor bar, val in zip(bars1, pehe_values):\n    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n                f'{val:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n\n# ATE Error 对比\nate_errors = [tarnet_metrics['ate_error'], dragonnet_metrics['ate_error']]\n\nbars2 = axes[1].bar(models, ate_errors, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\naxes[1].set_ylabel('ATE Error', fontsize=12)\naxes[1].set_title('ATE 误差对比 (越低越好)', fontsize=13, fontweight='bold')\naxes[1].grid(True, alpha=0.3, axis='y')\n\n# 添加数值标签\nfor bar, val in zip(bars2, ate_errors):\n    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n                f'{val:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: 何时选择哪个模型？\n",
    "\n",
    "## 决策树\n",
    "\n",
    "```\n",
    "开始\n",
    "  |\n",
    "  v\n",
    "是否存在强混淆？\n",
    "  |\n",
    "  +-- 否 (RCT或弱混淆) --> TARNet\n",
    "  |                        - 更简单\n",
    "  |                        - 更快训练\n",
    "  |                        - 足够准确\n",
    "  |\n",
    "  +-- 是 (强混淆) --> 处理分配是否高度不平衡？\n",
    "                        |\n",
    "                        +-- 否 --> TARNet 或 DragonNet 都可\n",
    "                        |          (DragonNet 略好)\n",
    "                        |\n",
    "                        +-- 是 --> DragonNet\n",
    "                                   - 倾向得分头有帮助\n",
    "                                   - Targeted Reg 减少偏差\n",
    "```\n",
    "\n",
    "## 选择指南表\n",
    "\n",
    "| 场景 | 推荐模型 | 原因 |\n",
    "|------|----------|------|\n",
    "| **随机对照试验 (RCT)** | TARNet | 无混淆，无需倾向得分 |\n",
    "| **观察性数据 + 弱混淆** | TARNet | 简单有效，训练快 |\n",
    "| **观察性数据 + 强混淆** | DragonNet | 倾向得分正则化有帮助 |\n",
    "| **处理分配高度不平衡** | DragonNet | Targeted Reg 更稳健 |\n",
    "| **数据量很小 (< 500)** | TARNet | 避免过拟合 |\n",
    "| **高维特征 (图像/文本)** | DragonNet | 更好的表示学习 |\n",
    "\n",
    "## 超参数调优建议\n",
    "\n",
    "### TARNet\n",
    "- `hidden_dim`: 50-200\n",
    "- `repr_dim`: 25-100\n",
    "- `learning_rate`: 1e-4 ~ 1e-2\n",
    "- `batch_size`: 32-128\n",
    "\n",
    "### DragonNet\n",
    "- 基础参数同 TARNet\n",
    "- `alpha` (倾向得分权重): 0.5-2.0\n",
    "  - 混淆越强，alpha 越大\n",
    "  - 建议从 1.0 开始\n",
    "- `beta` (targeted reg 权重): 0.5-2.0\n",
    "  - 处理分配越不平衡，beta 越大\n",
    "  - 建议从 1.0 开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 思考题\n",
    "\n",
    "请在下面的单元格中写下你的答案："
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 思考题 1: 为什么 TARNet 需要共享表示层？为什么不给两个头分别的特征提取器？\n\n**TODO**: 请思考以下问题并写出你的答案\n- 提示：考虑样本效率、知识迁移、正则化等角度\n- 对比 TARNet 和 T-Learner 的区别\n\n<details>\n<summary>点击查看参考答案</summary>\n\n共享表示层的三大优势:\n\n1. **样本效率提升**:\n   - T=1的样本只能训练Y(1)头，T=0的样本只能训练Y(0)头\n   - 但共享层Φ(X)可以从所有样本中学习\n   - 相当于变相增加了训练数据\n\n2. **知识迁移**:\n   - Y(0)和Y(1)往往有共同的预测因子（比如用户基础特征）\n   - 共享表示允许两个头之间知识迁移\n   - 类似Multi-Task Learning的硬参数共享\n\n3. **正则化作用**:\n   - 强迫模型学习对两组都有用的通用特征\n   - 防止过拟合到某一组的噪声\n\n如果分别使用特征提取器（T-Learner）:\n- 数据利用率低（每个模型只用一半数据）\n- 容易过拟合\n- 但异质性建模更灵活（两个完全独立的模型）\n\n决策: 数据量小/特征多 → TARNet; 数据量大/异质性极强 → T-Learner\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 思考题 2: Factual Loss 和普通的监督学习损失有什么区别？\n\n**TODO**: 请思考并回答\n- 提示：考虑哪些样本参与损失计算？为什么不能用普通回归？\n\n<details>\n<summary>点击查看参考答案</summary>\n\n核心区别在于**哪些样本参与损失计算**:\n\n**普通监督学习**:\n- 所有样本都有标签Y\n- 损失 = MSE(Y_pred, Y_true)，对所有样本\n\n**Factual Loss**:\n- 每个样本只有一个观测结果（factual）\n- T=1的样本: 只在Y(1)头计算损失\n- T=0的样本: 只在Y(0)头计算损失\n- 损失是\"条件性的\"\n\n数学形式对比:\n\n普通监督:\n$$L = \\frac{1}{N} \\sum_i (Y_i - f(X_i, T_i))^2$$\n\nFactual Loss:\n$$L = \\frac{1}{N} \\sum_i (Y_i - [T_i \\cdot \\mu_1(X_i) + (1-T_i) \\cdot \\mu_0(X_i)])^2$$\n\n关键洞察:\n- Factual Loss实际上是**半监督学习**\n- Y(0)对于T=1的样本是\"缺失\"的\n- Y(1)对于T=0的样本是\"缺失\"的\n- 共享表示Φ(X)起到了知识迁移的作用\n\n为什么不能用普通监督学习?\n- 因为我们想估计Y(0)和Y(1)的差异（ITE）\n- 普通回归只给出Y = f(X, T)，无法分离反事实\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 思考题 3: DragonNet 的倾向得分头在模型中起什么作用？为什么不单独训练一个倾向得分模型？\n\n**TODO**: 请思考并回答\n- 提示：考虑联合训练的优势、多任务学习、梯度反向传播\n\n<details>\n<summary>点击查看参考答案</summary>\n\n倾向得分头的三大作用:\n\n1. **正则化共享表示**:\n   - 强迫Φ(X)同时学习\"预测Y\"和\"预测T\"\n   - 这意味着表示层必须捕获影响处理分配的因素\n   - 这些因素往往也是混淆因子!\n\n2. **信息共享与协同训练**:\n   - 联合训练让三个任务相互增强\n   - 倾向得分头的梯度也会更新共享表示\n   - 类似Multi-Task Learning的效果\n\n3. **Targeted Regularization的基础**:\n   - DragonNet的第三项损失需要倾向得分e(X)\n   - 如果单独训练，梯度无法反向传播\n   - 联合训练实现端到端优化\n\n为什么不单独训练倾向得分模型?\n\n**分离训练的问题**:\n- 倾向得分模型和结果模型各自优化，可能不一致\n- 无法端到端优化Targeted Regularization\n- 失去了多任务学习的正则化benefit\n\n**联合训练的优势**:\n- 共享表示Φ(X)被多个目标约束\n- 倾向得分头起到\"指导\"作用，告诉表示层什么是重要特征\n- 理论上更接近双重鲁棒性估计器\n\n类比: 像是在学习时同时做\"习题\"(预测Y)和\"知识点梳理\"(理解T的分配机制)，效果比单独做习题更好\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 思考题 4: Targeted Regularization 中的 h = T/e(X) - (1-T)/(1-e(X)) 的直觉是什么？\n\n**TODO**: 请思考并回答\n- 提示：考虑逆倾向加权(IPW)、双重鲁棒性、民意调查的类比\n\n<details>\n<summary>点击查看参考答案</summary>\n\n这个公式来自**逆倾向加权(IPW)**和 **双重鲁棒性**理论。\n\n直觉解释 - 民意调查的类比:\n\n想象你在做民意调查，但不同人群被调查到的概率不同:\n\n$$h = \\frac{T}{e(X)} - \\frac{1-T}{1-e(X)}$$\n\n**第一项 T/e(X)** (被处理组):\n- e(X)小的人 → 权重大\n- 意思: \"本来不太可能被处理，但实际被处理了\"的样本更重要\n- 类比: 不爱接电话的年轻人如果接了电话，他们的意见要加权\n\n**第二项 -(1-T)/(1-e(X))** (控制组):\n- e(X)大的人 → 权重大（取负号）\n- 意思: \"本来很可能被处理，但实际没被处理\"的样本更重要\n- 类比: 爱接电话的老年人如果没接电话，这个缺失更需要补偿\n\n**h的作用**:\n1. 平衡处理组和控制组的分布差异\n2. 给\"反常\"样本更大权重（高e(X)但T=0，或低e(X)但T=1）\n3. 本质是IPW的调整因子\n\n**为什么在Targeted Reg中使用**:\n\n$$L_{TR} = E[(Y - \\hat{Y} - \\epsilon \\cdot h)^2]$$\n\n- 如果模型预测$\\hat{Y}$已经很准，ε会学到0\n- 如果有系统性偏差，ε·h提供\"倾向得分方向\"的修正\n- 这实现了双重鲁棒性: 结果模型准 or 倾向得分模型准，任一个对，估计就无偏\n\n数学来源:\n这来自半参数效率理论中的Efficient Influence Function (EIF)。\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 思考题 5: epsilon 参数的作用是什么？为什么它是可学习的？\n\n**TODO**: 请思考并回答\n- 提示：考虑自适应修正、端到端优化、模型质量指标\n\n<details>\n<summary>点击查看参考答案</summary>\n\nepsilon (ε) 是Targeted Regularization中的**可学习标量参数**。\n\n作用:\n\n1. **自适应修正幅度**:\n   - ε控制倾向得分调整项h的强度\n   - $L_{TR} = E[(Y - \\hat{Y} - \\epsilon \\cdot h)^2]$\n   - ε大 → 更依赖倾向得分修正\n   - ε小 → 更依赖结果模型预测\n\n2. **双重鲁棒性的桥梁**:\n   - 如果结果模型$\\hat{Y}$已经很准 → ε会学到≈0\n   - 如果结果模型有偏差 → ε学到非零值，用h来补偿\n   - 自动平衡两种策略\n\n3. **模型选择指标**:\n   - 训练后ε的值反映模型质量\n   - ε≈0: 结果模型已经足够准\n   - ε较大: 需要倾向得分修正\n\n为什么是可学习的?\n\n**固定ε的问题**:\n- 不同数据集最优的ε不同\n- 混淆程度强 → 需要大ε\n- 混淆程度弱 → 需要小ε\n\n**可学习ε的优势**:\n- 端到端优化，自动找到最优修正强度\n- 适应不同的数据分布\n- 避免手动调参\n\n实现细节:\n```python\nclass DragonNet(nn.Module):\n    def __init__(self):\n        self.epsilon = nn.Parameter(torch.tensor(0.0))  # 初始化为0\n```\n\n训练过程:\n- 初始阶段: ε≈0，主要靠结果模型\n- 中期: ε开始学习，引入倾向得分修正\n- 后期: ε收敛到某个值，反映最优平衡点\n\n监控ε的变化可以理解模型的学习过程!\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 思考题 6: 在你的实验中，DragonNet 比 TARNet 效果好吗？为什么？\n\n**TODO**: 运行实验后，分析并回答\n- 比较PEHE、ATE误差等指标\n- 思考数据特性（混淆程度、样本量）对结果的影响\n\n<details>\n<summary>点击查看参考答案</summary>\n\n从实验结果看（运行你自己的实验后填写）:\n\nPEHE对比: TARNet = ____, DragonNet = ____\nATE误差对比: TARNet = ____, DragonNet = ____\n\n**如果DragonNet更好**:\n\n原因分析:\n1. 数据有强混淆 - 我们生成数据时特意设计了混淆\n2. 倾向得分头捕获了处理分配机制\n3. Targeted Regularization提供了额外的正则化\n\n**如果差不多**:\n\n可能原因:\n1. 数据量不够大，DragonNet的优势没体现出来\n2. 混淆不够强，TARNet已经足够\n3. 超参数α和β没调好\n\n**如果TARNet更好** (较少见):\n\n可能原因:\n1. DragonNet过拟合（参数更多）\n2. 倾向得分头学习失败（检查propensity_loss是否收敛）\n3. alpha和beta设置不合理\n\n**实验设计的洞察**:\n\n我们的数据生成过程:\n```python\n# 强混淆: X影响T的分配\npropensity = sigmoid(1.0*X[:,0] + 0.8*X[:,1] + 0.6*X[:,2])\n\n# X也影响Y\nY0 = 2.0 + 1.0*X[:,0] + 0.5*X[:,1] + noise\n```\n\n这是典型的\"X既是混淆因子又是预测因子\"场景 → DragonNet应该更好\n\n**进一步实验**:\n可以尝试调整:\n- 增大alpha（如2.0）→ 更强的倾向得分约束\n- 增大beta（如2.0）→ 更强的targeted reg\n- 观察epsilon的变化轨迹\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 思考题 7: 如果处理分配是完全随机的（RCT），DragonNet 还有优势吗？\n\n**TODO**: 请思考并回答\n- 提示：考虑RCT中的倾向得分特性、混淆因子的作用\n\n<details>\n<summary>点击查看参考答案</summary>\n\n在RCT（随机对照试验）中，**DragonNet的优势会大幅减弱，但不会完全消失**。\n\n**理论分析**:\n\nRCT意味着: $T \\perp X$ (处理分配与特征独立)\n\n此时:\n1. **无混淆** → 不需要倾向得分调整\n2. **e(X) = 常数** (比如0.5) → 倾向得分头学到的是常数\n3. **Targeted Reg中的h ≈ 0** → 第三项损失几乎不起作用\n\nDragonNet退化为:\n$$L = L_{\\text{factual}} + \\alpha \\cdot L_{\\text{propensity}}$$\n\n而$L_{\\text{propensity}}$在RCT中只是在拟合一个常数函数。\n\n**可能的小优势**:\n\n1. **正则化效果**:\n   - 即使在RCT，多任务学习的正则化仍然有用\n   - 倾向得分头可能帮助表示层学习更鲁棒的特征\n\n2. **平衡检验**:\n   - 如果倾向得分头学到e(X) ≠ 常数，说明可能有问题\n   - 可以用来检验随机化是否成功\n\n**实验验证**:\n\n生成RCT数据:\n```python\nT = np.random.binomial(1, 0.5, n)  # 完全随机\n```\n\n预期结果:\n- TARNet和DragonNet性能接近\n- DragonNet的epsilon ≈ 0\n- propensity_head学到≈0.5的常数\n\n**实践建议**:\n\nRCT场景:\n- 优先用TARNet（更简单）\n- 如果用DragonNet，设置较小的alpha和beta\n- 关注epsilon的值（应该接近0）\n\n观察性研究:\n- DragonNet更有优势\n- 倾向得分头捕获选择偏差\n- Targeted Reg减少偏差\n\n结论: DragonNet是为**混淆/选择偏差**设计的，RCT中其优势不明显。\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# 面试题模拟与深度剖析\n\n## 高频面试题集锦\n\n### 题目 1: TARNet 和普通神经网络回归有什么区别？\n\n**标准答案**:\n\nTARNet 与普通神经网络回归的核心区别在于:\n\n1. **架构设计**:\n   - 普通回归: X → NN → Y\n   - TARNet: X → 共享表示Φ(X) → 双头[μ₀, μ₁]\n\n2. **训练策略**:\n   - 普通回归: 直接用所有样本训练Y = f(X, T)\n   - TARNet: Factual Loss - 只在观测到的结果上计算损失\n\n3. **反事实推断**:\n   - 普通回归: 无法直接给出反事实\n   - TARNet: 同时预测Y(0)和Y(1)\n\n4. **样本效率**:\n   - 普通回归: 两组样本独立训练\n   - TARNet: 共享表示，提高样本效率\n\n**进阶回答** (加分项):\n\nTARNet的Factual Loss实际上是在做**半监督学习**:\n- 对于T=1的样本，我们只观测到Y(1)，Y(0)是\"缺失\"的\n- 共享表示Φ(X)允许两组之间的知识迁移\n- 这类似于Multi-Task Learning中的硬参数共享\n\n---\n\n### 题目 2: DragonNet 为什么要联合预测倾向得分？\n\n**标准答案**:\n\nDragonNet添加倾向得分头的三大原因:\n\n1. **正则化作用**:\n   - 强迫表示层Φ(X)同时学习\"预测Y\"和\"预测T\"\n   - 防止表示层只优化结果预测而忽略混淆因子\n\n2. **捕获混淆**:\n   - 倾向得分e(X) = P(T=1|X)反映了X中哪些因素影响处理分配\n   - 这些因素往往也是混淆因子\n\n3. **Targeted Regularization**:\n   - 利用倾向得分构造双重鲁棒性的调整项\n   - 理论上可以减少偏差(来自TMLE理论)\n\n**数学推导**:\n\n根据双重鲁棒性理论:\n\n$$\\tau = \\mathbb{E}\\left[\\frac{T \\cdot Y}{e(X)} - \\frac{(1-T) \\cdot Y}{1-e(X)}\\right]$$\n\nDragonNet的Targeted Regularization正是利用这个原理:\n\n$$h_i = \\frac{T_i}{\\hat{e}(X_i)} - \\frac{1-T_i}{1-\\hat{e}(X_i)}$$\n\n当结果模型μ₀, μ₁准确或倾向得分模型e(X)准确时，估计都是无偏的。\n\n**面试加分点**:\n- 提到TMLE (Targeted Maximum Likelihood Estimation)\n- 提到双重鲁棒性\n- 能画出DragonNet的三头架构图\n\n---\n\n### 题目 3: CEVAE 的核心假设是什么？\n\n**标准答案**:\n\nCEVAE依赖于**代理变量假设** (Proxy Variable Assumption):\n\n1. **假设内容**:\n   - 存在隐变量Z影响X、T、Y\n   - 观测到的X包含关于Z的\"足够信息\"\n   - 形式化: $p(Y(t) | X, Z) = p(Y(t) | X)$\n\n2. **识别条件**:\n   ```\n   Z → X (X是Z的代理)\n   Z → T (Z影响处理分配)\n   Z → Y (Z影响结果)\n   ```\n\n3. **与其他方法的对比**:\n   - IPW/PSM假设: 所有混淆都被观测 (Unconfoundedness)\n   - IV假设: Z ⊥ Y | T (Z不直接影响Y)\n   - CEVAE假设: Z部分观测(通过X)\n\n**为什么这个假设重要**:\n\n如果X完全不包含Z的信息，CEVAE会失败，因为:\n- 后验推断q(Z|X,T,Y)无法从X中\"还原\"Z\n- 这时CEVAE退化为盲目猜测\n\n**面试官追问**: \"如何验证这个假设？\"\n\n答: \n1. 领域知识: 确保X包含相关的代理指标\n2. 敏感性分析: 测试不同的隐变量维度\n3. 预测检验: 检查X的重构质量\n\n---\n\n### 题目 4: 深度学习因果模型的主要挑战是什么？\n\n**标准答案** (多维度回答):\n\n#### 1. 理论挑战\n\n- **识别性**: 深度模型的非凸优化使得识别条件难以验证\n- **过拟合**: 参数多，容易记住噪声而非因果关系\n- **可解释性**: 黑盒模型，难以理解学到了什么\n\n#### 2. 实践挑战\n\n- **超参数敏感**: 网络深度、宽度、学习率都会影响结果\n- **训练不稳定**: GAN-based方法(如GANITE)容易模式崩溃\n- **计算成本**: 比传统方法慢很多\n\n#### 3. 数据挑战\n\n- **样本需求**: 深度模型通常需要更多数据\n- **标签噪声**: 对Y的测量误差更敏感\n- **分布偏移**: 测试集和训练集分布不同时表现差\n\n#### 4. 方法论挑战\n\n- **评估困难**: 真实ITE无法观测，只能用PEHE等模拟指标\n- **基准缺失**: 没有统一的benchmark\n- **调参黑箱**: 不同任务需要重新调参\n\n**最佳实践建议**:\n\n1. 从简单模型开始(如TARNet)\n2. 使用交叉验证选择超参数\n3. 进行消融实验验证每个组件的作用\n4. 敏感性分析测试鲁棒性\n\n---\n\n## 进阶面试题\n\n### 题目 5: 如果你要设计一个新的深度因果模型，你会考虑什么？\n\n**答题思路** (展示思维过程):\n\n#### Step 1: 明确问题设定\n\n- 二值处理 vs 连续处理 vs 多值处理？\n- 观测数据 vs RCT？\n- 是否存在未观测混淆？\n\n#### Step 2: 选择基础架构\n\n- 共享表示 + 多头 (类似TARNet)\n- VAE框架 (类似CEVAE)\n- GAN框架 (类似GANITE)\n\n#### Step 3: 设计损失函数\n\n核心权衡:\n```\nL_total = L_prediction + α·L_balance + β·L_regularization\n```\n\n- L_prediction: Factual loss\n- L_balance: IPM (MMD/Wasserstein)\n- L_regularization: 领域知识约束\n\n#### Step 4: 创新点\n\n可能的方向:\n1. **注意力机制**: 自动学习哪些特征是混淆因子\n2. **元学习**: 快速适应新的因果任务\n3. **不确定性量化**: 贝叶斯深度学习\n4. **因果图发现**: 联合学习结构和参数\n\n**面试加分点**:\n- 引用最新论文 (ICML/NeurIPS)\n- 提到具体应用场景\n- 讨论trade-offs\n\n---\n\n### 题目 6: TARNet和T-Learner有什么区别？什么时候用哪个？\n\n**对比分析**:\n\n| 维度 | T-Learner | TARNet |\n|------|-----------|--------|\n| 参数共享 | 无 (两个独立模型) | 有 (共享表示层) |\n| 样本效率 | 低 (各用一半数据) | 高 (共享知识) |\n| 过拟合风险 | 高 | 中等 |\n| 实现复杂度 | 简单 | 中等 |\n| 异质性建模 | 灵活 | 受共享表示约束 |\n\n**决策树**:\n\n```\n数据量大 (>10k) ?\n├─ 是 → 异质性很强？\n│       ├─ 是 → T-Learner\n│       └─ 否 → TARNet\n└─ 否 → 特征维度高？\n        ├─ 是 → TARNet (需要正则化)\n        └─ 否 → T-Learner 或 TARNet都可\n```\n\n---\n\n## 核心数学推导\n\n### 推导 1: TARNet 的 Factual Loss\n\n**目标**: 最小化预测误差\n\n$$\\mathcal{L} = \\mathbb{E}[(Y - \\hat{Y})^2]$$\n\n**关键点**: 我们只观测到factual outcome\n\n$$\\hat{Y}^{factual} = \\begin{cases} \n\\mu_1(\\Phi(X)) & \\text{if } T = 1 \\\\\n\\mu_0(\\Phi(X)) & \\text{if } T = 0\n\\end{cases}$$\n\n**展开**:\n\n$$\\begin{align}\n\\mathcal{L} &= \\mathbb{E}_{T=1}[(Y - \\mu_1(\\Phi(X)))^2] \\cdot P(T=1) \\\\\n&\\quad + \\mathbb{E}_{T=0}[(Y - \\mu_0(\\Phi(X)))^2] \\cdot P(T=0)\n\\end{align}$$\n\n**实现**:\n\n```python\nloss = torch.where(T == 1, \n                   (Y - mu1)**2, \n                   (Y - mu0)**2).mean()\n```\n\n---\n\n### 推导 2: DragonNet 的 Targeted Regularization\n\n**来源**: TMLE理论\n\n**核心思想**: 利用倾向得分构造一阶无偏估计\n\n**推导**:\n\n1. 真实ATE的efficient influence function (EIF):\n\n$$\\psi(X, T, Y) = \\frac{T \\cdot (Y - \\mu_1(X))}{e(X)} - \\frac{(1-T) \\cdot (Y - \\mu_0(X))}{1 - e(X)} + \\mu_1(X) - \\mu_0(X)$$\n\n2. 一阶条件 (first-order condition):\n\n$$\\mathbb{E}[\\psi(X, T, Y)] = \\tau_{ATE}$$\n\n3. Targeted Regularization惩罚EIF的方差:\n\n$$\\mathcal{L}_{TR} = \\mathbb{E}\\left[\\left(Y - \\hat{\\mu} - \\epsilon \\cdot h(X, T)\\right)^2\\right]$$\n\n其中:\n$$h(X, T) = \\frac{T}{e(X)} - \\frac{1-T}{1-e(X)}$$\n\n**直觉**: \n- h(X,T)是倾向得分的\"修正项\"\n- ε是可学习的修正幅度\n- 这个损失鼓励模型在倾向得分边界附近更准确\n\n---\n\n### 推导 3: CEVAE 的 ELBO\n\n**目标**: 最大化边际对数似然\n\n$$\\log p_\\theta(X, T, Y) = \\log \\int p_\\theta(X, T, Y, Z) dZ$$\n\n**问题**: 积分intractable\n\n**解决**: 变分推断，引入q_φ(Z|X,T,Y)\n\n**Jensen不等式**:\n\n$$\\begin{align}\n\\log p_\\theta(X, T, Y) &= \\log \\mathbb{E}_{q_\\phi} \\left[\\frac{p_\\theta(X, T, Y, Z)}{q_\\phi(Z|X,T,Y)}\\right] \\\\\n&\\geq \\mathbb{E}_{q_\\phi} \\left[\\log \\frac{p_\\theta(X, T, Y, Z)}{q_\\phi(Z|X,T,Y)}\\right] \\\\\n&= \\mathbb{E}_{q_\\phi}[\\log p_\\theta(X|Z)] + \\mathbb{E}_{q_\\phi}[\\log p_\\theta(T|X,Z)] \\\\\n&\\quad + \\mathbb{E}_{q_\\phi}[\\log p_\\theta(Y|T,X,Z)] - KL(q_\\phi || p(Z))\n\\end{align}$$\n\n**ELBO**:\n\n$$\\mathcal{L}_{ELBO} = \\mathbb{E}_{q_\\phi}[\\log p(X,T,Y|Z)] - KL(q_\\phi(Z|X,T,Y) || p(Z))$$\n\n**各项解释**:\n\n1. $\\log p(X|Z)$: X的重构损失\n2. $\\log p(T|X,Z)$: T的分类损失\n3. $\\log p(Y|T,X,Z)$: Y的预测损失\n4. KL散度: 正则化项，防止后验崩溃\n\n---\n\n### 推导 4: GANITE 的对抗损失\n\n**Block 1: 反事实生成**\n\n**生成器目标**:\n\n$$\\min_{G_{cf}} \\mathbb{E}_{X,T,Y,Z}\\left[D_{cf}(X, T, Y, G_{cf}(X, T, Y, Z))\\right]$$\n\n**判别器目标**:\n\n$$\\max_{D_{cf}} \\mathbb{E}[D_{cf}(X, T, Y, Y_{cf}^{true})] + \\mathbb{E}[\\log(1 - D_{cf}(X, T, Y, Y_{cf}^{fake}))]$$\n\n**监督约束** (关键!):\n\n$$\\mathcal{L}_{sup} = \\mathbb{E}[(Y - G_{cf}(X, T, Y, Z))^2] \\quad \\text{when generating factual}$$\n\n**总损失**:\n\n$$\\mathcal{L}_{G_{cf}} = -\\mathbb{E}[\\log D_{cf}] + \\lambda \\cdot \\mathcal{L}_{sup}$$\n\n**Block 2: ITE估计**\n\n使用Block 1填补的完整潜在结果训练ITE生成器:\n\n$$\\hat{\\tau}(X) = G_{ITE}(X)$$\n\n约束: $\\hat{Y}(1) - \\hat{Y}(0) = \\hat{\\tau}(X)$\n\n---\n\n## 实战技巧总结\n\n### 调参经验\n\n| 超参数 | TARNet | DragonNet | CEVAE | GANITE |\n|--------|--------|-----------|-------|--------|\n| 学习率 | 1e-3 | 1e-3 | 1e-4 | 1e-4 (G), 1e-3 (D) |\n| 批大小 | 64-256 | 128-512 | 64-128 | 128-256 |\n| 隐藏层维度 | 100-300 | 200-400 | 200-500 | 64-128 |\n| 正则化权重α | - | 0.5-2.0 | - | - |\n| KL权重β | - | 0.5-2.0 | 0.1-1.0 | - |\n\n### 训练监控指标\n\n1. **收敛性**:\n   - Train/Val loss曲线\n   - 梯度范数\n\n2. **平衡性**:\n   - MMD或Wasserstein距离\n   - SMD (每个特征维度)\n\n3. **预测质量**:\n   - Factual预测的MSE\n   - 倾向得分的AUC (DragonNet)\n\n4. **反事实合理性** (如有真值):\n   - PEHE\n   - ATE误差\n\n---\n\n*恭喜你完成了深度因果模型的面试题和数学推导！* 🎓"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}