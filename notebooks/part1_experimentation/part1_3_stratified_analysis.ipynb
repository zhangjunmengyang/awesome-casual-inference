{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åˆ†å±‚åˆ†æ - æé«˜å®éªŒæ•ˆç‡ä¸ç²¾åº¦\n",
    "\n",
    "## æœ¬èŠ‚ç›®æ ‡\n",
    "\n",
    "åœ¨æœ¬èŠ‚ä¸­ï¼Œä½ å°†å­¦ä¹ ï¼š\n",
    "\n",
    "1. **ç†è§£åˆ†å±‚åˆ†æçš„åŸç†å’Œä¼˜åŠ¿** - ä¸ºä»€ä¹ˆåˆ†å±‚èƒ½æé«˜å®éªŒç²¾åº¦\n",
    "2. **æŒæ¡åˆ†å±‚éšæœºåŒ–è®¾è®¡** - å¦‚ä½•åœ¨å®éªŒè®¾è®¡é˜¶æ®µè¿›è¡Œåˆ†å±‚\n",
    "3. **å­¦ä¹ äº‹ååˆ†å±‚åˆ†ææ–¹æ³•** - å¦‚ä½•åœ¨å®éªŒåè¿›è¡Œåˆ†å±‚è°ƒæ•´\n",
    "4. **å®è·µä¸šåŠ¡æ¡ˆä¾‹** - åº”ç”¨åˆ°çœŸå®çš„ä¸šåŠ¡åœºæ™¯\n",
    "\n",
    "---\n",
    "\n",
    "## ä¸šåŠ¡åœºæ™¯å¼•å…¥\n",
    "\n",
    "æƒ³è±¡ä½ æ˜¯æŸç”µå•†å¹³å°çš„æ•°æ®ç§‘å­¦å®¶ï¼Œè´Ÿè´£è¯„ä¼°ä¸€ä¸ªæ–°çš„æ¨èç®—æ³•ã€‚ä½ å‘ç°ï¼š\n",
    "\n",
    "- **VIPç”¨æˆ·** çš„è´­ä¹°é‡‘é¢æœ¬èº«å°±æ¯”æ™®é€šç”¨æˆ·é«˜10å€\n",
    "- **æ–°ç”¨æˆ·** å’Œè€ç”¨æˆ·çš„è¡Œä¸ºæ¨¡å¼å®Œå…¨ä¸åŒ\n",
    "- **ä¸åŒåœ°åŒº** çš„ç”¨æˆ·æ¶ˆè´¹èƒ½åŠ›å·®å¼‚å·¨å¤§\n",
    "\n",
    "å¦‚æœç›´æ¥è¿›è¡Œç®€å•çš„A/Bæµ‹è¯•ï¼Œè¿™äº›**å·²çŸ¥çš„å·®å¼‚**ä¼šå¸¦æ¥å·¨å¤§çš„å™ªå£°ï¼Œå¯¼è‡´ï¼š\n",
    "\n",
    "âŒ éœ€è¦æ›´å¤§çš„æ ·æœ¬é‡  \n",
    "âŒ æ›´é•¿çš„å®éªŒæ—¶é—´  \n",
    "âŒ æ›´ä½çš„æ£€æµ‹åŠŸæ•ˆ  \n",
    "\n",
    "**åˆ†å±‚åˆ†æ**å°±æ˜¯è§£å†³è¿™ä¸ªé—®é¢˜çš„åˆ©å™¨ï¼\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotly é…ç½®\n",
    "COLORS = {\n",
    "    'primary': '#2D9CDB',\n",
    "    'secondary': '#27AE60',\n",
    "    'danger': '#EB5757',\n",
    "    'warning': '#F2994A',\n",
    "    'info': '#9B51E0'\n",
    "}\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: ä¸ºä»€ä¹ˆéœ€è¦åˆ†å±‚\n",
    "\n",
    "## 1.1 æ–¹å·®æ¥æºåˆ†æ\n",
    "\n",
    "åœ¨A/Bæµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°çš„æ€»æ–¹å·®æ¥è‡ªä¸¤ä¸ªéƒ¨åˆ†ï¼š\n",
    "\n",
    "$$\n",
    "\\text{Var}(Y) = \\underbrace{\\text{Var}(E[Y|X])}_{\\text{å¯è§£é‡Šæ–¹å·®}} + \\underbrace{E[\\text{Var}(Y|X)]}_{\\text{ä¸å¯è§£é‡Šæ–¹å·®}}\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- $Y$ æ˜¯ç»“æœå˜é‡ï¼ˆå¦‚è´­ä¹°é‡‘é¢ï¼‰\n",
    "- $X$ æ˜¯åˆ†å±‚å˜é‡ï¼ˆå¦‚ç”¨æˆ·ç­‰çº§ï¼‰\n",
    "\n",
    "### å…³é”®æ´å¯Ÿ\n",
    "\n",
    "å¦‚æœæˆ‘ä»¬èƒ½æ‰¾åˆ°ä¸€ä¸ªå¼ºç›¸å…³çš„åˆ†å±‚å˜é‡ $X$ï¼š\n",
    "- **å¯è§£é‡Šæ–¹å·®** éƒ¨åˆ†å¾ˆå¤§ â†’ åˆ†å±‚å†…éƒ¨æ›´åŠ åŒè´¨\n",
    "- **ä¼°è®¡é‡çš„æ–¹å·®** å°±ä¼šå¤§å¹…ä¸‹é™\n",
    "- ç›¸åŒæ ·æœ¬é‡ä¸‹ï¼Œ**æ£€æµ‹åŠŸæ•ˆ** æ˜¾è‘—æå‡\n",
    "\n",
    "---\n",
    "\n",
    "## 1.2 ç›´è§‚ç¤ºä¾‹ï¼šç”¨æˆ·ç­‰çº§åˆ†å±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stratified_data(n_per_group: int = 500) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ç”ŸæˆåŒ…å«ç”¨æˆ·ç­‰çº§çš„æ¨¡æ‹Ÿæ•°æ®\n",
    "    \n",
    "    ç”¨æˆ·ç­‰çº§ä¸è´­ä¹°é‡‘é¢é«˜åº¦ç›¸å…³ï¼š\n",
    "    - æ™®é€šç”¨æˆ·: å‡å€¼ 50, æ ‡å‡†å·® 20\n",
    "    - VIPç”¨æˆ·: å‡å€¼ 200, æ ‡å‡†å·® 50\n",
    "    - è¶…çº§VIP: å‡å€¼ 500, æ ‡å‡†å·® 100\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    # å®šä¹‰ä¸‰ä¸ªå±‚çº§\n",
    "    strata_config = [\n",
    "        {'tier': 'æ™®é€š', 'base_mean': 50, 'base_std': 20, 'treatment_effect': 8},\n",
    "        {'tier': 'VIP', 'base_mean': 200, 'base_std': 50, 'treatment_effect': 15},\n",
    "        {'tier': 'è¶…çº§VIP', 'base_mean': 500, 'base_std': 100, 'treatment_effect': 30},\n",
    "    ]\n",
    "    \n",
    "    for config in strata_config:\n",
    "        # æ§åˆ¶ç»„\n",
    "        control = pd.DataFrame({\n",
    "            'user_tier': config['tier'],\n",
    "            'treatment': 0,\n",
    "            'purchase_amount': np.random.normal(\n",
    "                config['base_mean'], \n",
    "                config['base_std'], \n",
    "                n_per_group\n",
    "            )\n",
    "        })\n",
    "        \n",
    "        # å®éªŒç»„ (æœ‰å¤„ç†æ•ˆåº”)\n",
    "        treatment = pd.DataFrame({\n",
    "            'user_tier': config['tier'],\n",
    "            'treatment': 1,\n",
    "            'purchase_amount': np.random.normal(\n",
    "                config['base_mean'] + config['treatment_effect'], \n",
    "                config['base_std'], \n",
    "                n_per_group\n",
    "            )\n",
    "        })\n",
    "        \n",
    "        data.append(control)\n",
    "        data.append(treatment)\n",
    "    \n",
    "    df = pd.concat(data, ignore_index=True)\n",
    "    df['purchase_amount'] = df['purchase_amount'].clip(lower=0)  # é‡‘é¢ä¸èƒ½ä¸ºè´Ÿ\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ç”Ÿæˆæ•°æ®\n",
    "df = generate_stratified_data(n_per_group=500)\n",
    "\n",
    "print(f\"æ•°æ®é›†å¤§å°: {len(df)}\")\n",
    "print(f\"\\nå„å±‚æ ·æœ¬åˆ†å¸ƒ:\")\n",
    "print(df.groupby(['user_tier', 'treatment']).size())\n",
    "print(f\"\\nå„å±‚å‡å€¼:\")\n",
    "print(df.groupby(['user_tier', 'treatment'])['purchase_amount'].mean().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ï¼šåˆ†å±‚å¸¦æ¥çš„æ–¹å·®å·®å¼‚\n",
    "def plot_variance_decomposition(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    å¯è§†åŒ–åˆ†å±‚å‰åçš„æ–¹å·®åˆ†è§£\n",
    "    \"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=(\n",
    "            'ä¸åˆ†å±‚: æ–¹å·®å·¨å¤§',\n",
    "            'åˆ†å±‚å: æ¯å±‚å†…éƒ¨æ–¹å·®å°'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # å·¦å›¾ï¼šä¸åˆ†å±‚ï¼Œæ‰€æœ‰æ•°æ®æ··åœ¨ä¸€èµ·\n",
    "    for treatment in [0, 1]:\n",
    "        data = df[df['treatment'] == treatment]['purchase_amount']\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=data,\n",
    "                name=f\"{'å®éªŒç»„' if treatment else 'å¯¹ç…§ç»„'}\",\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                marker_color=COLORS['primary'] if treatment else COLORS['danger'],\n",
    "                showlegend=True\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # å³å›¾ï¼šåˆ†å±‚å\n",
    "    colors_map = {'æ™®é€š': COLORS['info'], 'VIP': COLORS['warning'], 'è¶…çº§VIP': COLORS['secondary']}\n",
    "    \n",
    "    for tier in df['user_tier'].unique():\n",
    "        for treatment in [0, 1]:\n",
    "            data = df[(df['user_tier'] == tier) & (df['treatment'] == treatment)]['purchase_amount']\n",
    "            fig.add_trace(\n",
    "                go.Violin(\n",
    "                    y=data,\n",
    "                    name=f\"{tier}-{'T' if treatment else 'C'}\",\n",
    "                    box_visible=True,\n",
    "                    meanline_visible=True,\n",
    "                    marker_color=colors_map[tier],\n",
    "                    opacity=0.7 if treatment == 0 else 1.0,\n",
    "                    showlegend=True\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=500,\n",
    "        title_text=\"åˆ†å±‚çš„æ ¸å¿ƒä¼˜åŠ¿: å‡å°‘ç»„å†…æ–¹å·®\",\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"è´­ä¹°é‡‘é¢ (å…ƒ)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"è´­ä¹°é‡‘é¢ (å…ƒ)\", row=1, col=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = plot_variance_decomposition(df)\n",
    "fig.show()\n",
    "\n",
    "# è®¡ç®—æ–¹å·®å¯¹æ¯”\n",
    "total_var = df['purchase_amount'].var()\n",
    "within_strata_var = df.groupby('user_tier')['purchase_amount'].var().mean()\n",
    "\n",
    "print(f\"\\nğŸ“Š æ–¹å·®å¯¹æ¯”:\")\n",
    "print(f\"  ä¸åˆ†å±‚æ€»æ–¹å·®: {total_var:.2f}\")\n",
    "print(f\"  åˆ†å±‚åå¹³å‡ç»„å†…æ–¹å·®: {within_strata_var:.2f}\")\n",
    "print(f\"  æ–¹å·®ç¼©å‡æ¯”ä¾‹: {(1 - within_strata_var/total_var)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ å…³é”®æ´å¯Ÿ\n",
    "\n",
    "ä»ä¸Šå›¾å¯ä»¥çœ‹åˆ°ï¼š\n",
    "\n",
    "1. **ä¸åˆ†å±‚æ—¶**ï¼šæ™®é€šç”¨æˆ·å’Œè¶…çº§VIPæ··åœ¨ä¸€èµ·ï¼Œæ–¹å·®å·¨å¤§\n",
    "2. **åˆ†å±‚å**ï¼šæ¯ä¸€å±‚å†…éƒ¨éƒ½å¾ˆåŒè´¨ï¼Œæ–¹å·®æ˜¾è‘—é™ä½\n",
    "3. **æ–¹å·®ç¼©å‡** é€šå¸¸å¯è¾¾ 30%-70%ï¼Œæ„å‘³ç€éœ€è¦æ›´å°‘çš„æ ·æœ¬!\n",
    "\n",
    "---\n",
    "\n",
    "## 1.3 åˆ†å±‚ vs æ§åˆ¶å˜é‡\n",
    "\n",
    "### ç›¸åŒç‚¹\n",
    "- éƒ½æ˜¯åˆ©ç”¨åå˜é‡ä¿¡æ¯æ¥å‡å°‘ä¼°è®¡æ–¹å·®\n",
    "- éƒ½åŸºäº"ç›¸ä¼¼ä¸ªä½“æ›´å…·å¯æ¯”æ€§"çš„æ€æƒ³\n",
    "\n",
    "### ä¸åŒç‚¹\n",
    "\n",
    "| ç»´åº¦ | åˆ†å±‚ | å›å½’æ§åˆ¶å˜é‡ |\n",
    "|------|------|-------------|\n",
    "| **æ—¶æœº** | å®éªŒè®¾è®¡é˜¶æ®µ | äº‹ååˆ†æé˜¶æ®µ |\n",
    "| **éšæœºåŒ–** | åœ¨å±‚å†…éšæœºåŒ– | å…¨å±€éšæœºåŒ– |\n",
    "| **å‡è®¾** | ä¸éœ€è¦çº¿æ€§å‡è®¾ | éœ€è¦æ­£ç¡®çš„å‡½æ•°å½¢å¼ |\n",
    "| **è§£é‡Šæ€§** | æ¯å±‚æ•ˆåº”å¯å•ç‹¬è§£é‡Š | æ•´ä½“å¹³å‡æ•ˆåº” |\n",
    "| **é²æ£’æ€§** | æ›´é²æ£’ | å¯¹æ¨¡å‹è¯¯è®¾å®šæ•æ„Ÿ |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: åˆ†å±‚éšæœºåŒ–è®¾è®¡\n",
    "\n",
    "## 2.1 åˆ†å±‚éšæœºåŒ–çš„æµç¨‹\n",
    "\n",
    "**åˆ†å±‚éšæœºåŒ–** (Stratified Randomization) æ˜¯åœ¨å®éªŒè®¾è®¡é˜¶æ®µè¿›è¡Œçš„ï¼š\n",
    "\n",
    "```\n",
    "1. è¯†åˆ«åˆ†å±‚å˜é‡ X (å¦‚ç”¨æˆ·ç­‰çº§)\n",
    "2. å°†æ€»ä½“åˆ†æˆ H ä¸ªå±‚ (Strata)\n",
    "3. åœ¨æ¯ä¸€å±‚å†…ç‹¬ç«‹éšæœºåˆ†é…å¤„ç†\n",
    "4. ç¡®ä¿æ¯å±‚çš„å¤„ç†ç»„/å¯¹ç…§ç»„æ¯”ä¾‹ä¸€è‡´\n",
    "```\n",
    "\n",
    "### æ•°å­¦è¡¨ç¤º\n",
    "\n",
    "è®¾æœ‰ $H$ ä¸ªå±‚ï¼Œç¬¬ $h$ å±‚æœ‰ $N_h$ ä¸ªå•ä½ï¼š\n",
    "\n",
    "- **æ€»æ ·æœ¬**: $N = \\sum_{h=1}^H N_h$\n",
    "- **å±‚æƒé‡**: $W_h = N_h / N$\n",
    "- **å±‚å†…éšæœºåŒ–**: $P(T_i=1|h) = 0.5$ (æˆ–å…¶ä»–æ¯”ä¾‹)\n",
    "\n",
    "---\n",
    "\n",
    "## 2.2 åˆ†å±‚å˜é‡çš„é€‰æ‹©\n",
    "\n",
    "### âœ… å¥½çš„åˆ†å±‚å˜é‡\n",
    "\n",
    "1. **ä¸ç»“æœå˜é‡é«˜åº¦ç›¸å…³** - èƒ½è§£é‡Šå¤§éƒ¨åˆ†æ–¹å·®\n",
    "2. **å®éªŒå‰å¯è§‚æµ‹** - ä¸èƒ½æ˜¯å®éªŒåæ‰çŸ¥é“çš„å˜é‡\n",
    "3. **åˆ†ç±»æ¸…æ™°** - æ¯ä¸ªå•ä½æ˜ç¡®å±äºæŸä¸€å±‚\n",
    "4. **å±‚æ•°é€‚ä¸­** - å¤ªå¤šä¼šå¯¼è‡´æŸäº›å±‚æ ·æœ¬è¿‡å°‘\n",
    "\n",
    "### å¸¸è§çš„åˆ†å±‚å˜é‡\n",
    "\n",
    "- **ç”¨æˆ·å±æ€§**: ç­‰çº§ã€æ³¨å†Œæ—¶é•¿ã€åœ°ç†ä½ç½®\n",
    "- **å†å²è¡Œä¸º**: è¿‡å»30å¤©GMVã€æ´»è·ƒåº¦ã€è´­ä¹°é¢‘æ¬¡\n",
    "- **é¢„å¤„ç†ç»“æœ**: å€¾å‘å¾—åˆ†åˆ†ç»„ã€é¢„æµ‹å€¼åˆ†ç»„\n",
    "\n",
    "---\n",
    "\n",
    "## 2.3 å®ç°åˆ†å±‚éšæœºåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StratifiedRandomizer:\n",
    "    \"\"\"\n",
    "    åˆ†å±‚éšæœºåŒ–å·¥å…·ç±»\n",
    "    \"\"\"\n",
    "    def __init__(self, treatment_ratio: float = 0.5, random_state: int = 42):\n",
    "        \"\"\"\n",
    "        å‚æ•°:\n",
    "            treatment_ratio: å®éªŒç»„æ¯”ä¾‹ (é»˜è®¤ 0.5 å³ 1:1)\n",
    "            random_state: éšæœºç§å­\n",
    "        \"\"\"\n",
    "        self.treatment_ratio = treatment_ratio\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def randomize(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        strata_col: str\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        åœ¨æ¯ä¸ªå±‚å†…è¿›è¡ŒéšæœºåŒ–åˆ†é…\n",
    "        \n",
    "        å‚æ•°:\n",
    "            df: ç”¨æˆ·æ•°æ®\n",
    "            strata_col: åˆ†å±‚å˜é‡åˆ—å\n",
    "        \n",
    "        è¿”å›:\n",
    "            å¸¦æœ‰ treatment åˆ—çš„ DataFrame\n",
    "        \"\"\"\n",
    "        np.random.seed(self.random_state)\n",
    "        result = df.copy()\n",
    "        result['treatment'] = 0\n",
    "        \n",
    "        # åœ¨æ¯ä¸€å±‚å†…ç‹¬ç«‹éšæœºåŒ–\n",
    "        for stratum in result[strata_col].unique():\n",
    "            mask = result[strata_col] == stratum\n",
    "            n_stratum = mask.sum()\n",
    "            n_treatment = int(n_stratum * self.treatment_ratio)\n",
    "            \n",
    "            # éšæœºé€‰æ‹©å¤„ç†ç»„\n",
    "            indices = result[mask].index\n",
    "            treatment_indices = np.random.choice(\n",
    "                indices, \n",
    "                size=n_treatment, \n",
    "                replace=False\n",
    "            )\n",
    "            result.loc[treatment_indices, 'treatment'] = 1\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def check_balance(self, df: pd.DataFrame, strata_col: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        æ£€æŸ¥åˆ†å±‚åçš„å¹³è¡¡æ€§\n",
    "        \"\"\"\n",
    "        balance = df.groupby([strata_col, 'treatment']).size().unstack(fill_value=0)\n",
    "        balance['total'] = balance.sum(axis=1)\n",
    "        balance['treatment_ratio'] = balance[1] / balance['total']\n",
    "        return balance\n",
    "\n",
    "# ç¤ºä¾‹ï¼šå‡†å¤‡å¾…éšæœºåŒ–çš„ç”¨æˆ·æ± \n",
    "user_pool = pd.DataFrame({\n",
    "    'user_id': range(3000),\n",
    "    'user_tier': np.random.choice(\n",
    "        ['æ™®é€š', 'VIP', 'è¶…çº§VIP'], \n",
    "        size=3000, \n",
    "        p=[0.7, 0.2, 0.1]  # ä¸åŒå±‚çº§çš„çœŸå®å æ¯”\n",
    "    )\n",
    "})\n",
    "\n",
    "# æ‰§è¡Œåˆ†å±‚éšæœºåŒ–\n",
    "randomizer = StratifiedRandomizer(treatment_ratio=0.5, random_state=42)\n",
    "user_pool_assigned = randomizer.randomize(user_pool, strata_col='user_tier')\n",
    "\n",
    "# æ£€æŸ¥å¹³è¡¡æ€§\n",
    "balance = randomizer.check_balance(user_pool_assigned, strata_col='user_tier')\n",
    "print(\"âœ… åˆ†å±‚éšæœºåŒ–å®Œæˆ!\\n\")\n",
    "print(\"å„å±‚çš„å¤„ç†ç»„/å¯¹ç…§ç»„åˆ†å¸ƒ:\")\n",
    "print(balance)\n",
    "print(f\"\\nå…¨å±€å¤„ç†ç»„æ¯”ä¾‹: {user_pool_assigned['treatment'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ TODO ç»ƒä¹  1: å®ç°åŒºå—éšæœºåŒ–\n",
    "\n",
    "**åŒºå—éšæœºåŒ–** (Block Randomization) æ˜¯åˆ†å±‚éšæœºåŒ–çš„ä¸€ç§ç‰¹æ®Šå½¢å¼ï¼Œå¸¸ç”¨äºæ—¶é—´åºåˆ—å®éªŒã€‚\n",
    "\n",
    "åœºæ™¯ï¼šä½ è¦æµ‹è¯•æ–°çš„æ¨èç®—æ³•ï¼Œæ¯å¤©æ¥100ä¸ªæ–°ç”¨æˆ·ï¼Œå¸Œæœ›æ¯å¤©çš„å®éªŒç»„/å¯¹ç…§ç»„æ¯”ä¾‹éƒ½æ˜¯ 1:1ã€‚\n",
    "\n",
    "è¯·å®ç° `block_randomize` å‡½æ•°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_randomize(\n",
    "    n_users_per_day: int, \n",
    "    n_days: int, \n",
    "    block_size: int = 4\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    åŒºå—éšæœºåŒ–ï¼šåœ¨å›ºå®šå¤§å°çš„åŒºå—å†…ç¡®ä¿æ¯”ä¾‹\n",
    "    \n",
    "    å‚æ•°:\n",
    "        n_users_per_day: æ¯å¤©æ–°å¢ç”¨æˆ·æ•°\n",
    "        n_days: å®éªŒå¤©æ•°\n",
    "        block_size: åŒºå—å¤§å° (å¿…é¡»æ˜¯å¶æ•°)\n",
    "    \n",
    "    è¿”å›:\n",
    "        DataFrame with columns: user_id, day, treatment\n",
    "    \n",
    "    æç¤º:\n",
    "        1. æ¯ä¸ªåŒºå—å†…æœ‰ block_size/2 ä¸ªT, block_size/2 ä¸ªC\n",
    "        2. åŒºå—å†…éšæœºæ’åˆ—\n",
    "        3. å¤šä¸ªåŒºå—æ‹¼æ¥\n",
    "    \"\"\"\n",
    "    # TODO: ä½ çš„ä»£ç \n",
    "    pass\n",
    "\n",
    "# æµ‹è¯•\n",
    "# df_blocked = block_randomize(n_users_per_day=100, n_days=7, block_size=4)\n",
    "# print(df_blocked.groupby('day')['treatment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‚è€ƒç­”æ¡ˆ (å–æ¶ˆæ³¨é‡ŠæŸ¥çœ‹)\n",
    "\"\"\"\n",
    "def block_randomize(\n",
    "    n_users_per_day: int, \n",
    "    n_days: int, \n",
    "    block_size: int = 4\n",
    ") -> pd.DataFrame:\n",
    "    assert block_size % 2 == 0, \"block_size å¿…é¡»æ˜¯å¶æ•°\"\n",
    "    \n",
    "    data = []\n",
    "    user_id = 0\n",
    "    \n",
    "    for day in range(n_days):\n",
    "        n_users = n_users_per_day\n",
    "        treatments = []\n",
    "        \n",
    "        # ç”Ÿæˆè¶³å¤Ÿçš„åŒºå—\n",
    "        while len(treatments) < n_users:\n",
    "            # ä¸€ä¸ªåŒºå—: ä¸€åŠT, ä¸€åŠC, éšæœºæ’åˆ—\n",
    "            block = [1] * (block_size // 2) + [0] * (block_size // 2)\n",
    "            np.random.shuffle(block)\n",
    "            treatments.extend(block)\n",
    "        \n",
    "        # æˆªå–åˆ°éœ€è¦çš„ç”¨æˆ·æ•°\n",
    "        treatments = treatments[:n_users]\n",
    "        \n",
    "        for t in treatments:\n",
    "            data.append({\n",
    "                'user_id': user_id,\n",
    "                'day': day,\n",
    "                'treatment': t\n",
    "            })\n",
    "            user_id += 1\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: åˆ†å±‚ä¼°è®¡é‡\n",
    "\n",
    "## 3.1 Neyman åˆ†å±‚ä¼°è®¡é‡\n",
    "\n",
    "åœ¨åˆ†å±‚éšæœºåŒ–å®éªŒä¸­ï¼Œ**æœ€ä¼˜**çš„ä¼°è®¡é‡æ˜¯ **Neyman åˆ†å±‚ä¼°è®¡é‡**ï¼š\n",
    "\n",
    "$$\n",
    "\\hat{\\tau}_{\\text{strat}} = \\sum_{h=1}^{H} W_h \\hat{\\tau}_h\n",
    "$$\n",
    "\n",
    "å…¶ä¸­:\n",
    "- $W_h = N_h / N$ æ˜¯ç¬¬ $h$ å±‚çš„æƒé‡\n",
    "- $\\hat{\\tau}_h = \\bar{Y}_{h,T} - \\bar{Y}_{h,C}$ æ˜¯ç¬¬ $h$ å±‚çš„å¤„ç†æ•ˆåº”ä¼°è®¡\n",
    "- $\\bar{Y}_{h,T}$ æ˜¯ç¬¬ $h$ å±‚å®éªŒç»„çš„å¹³å‡ç»“æœ\n",
    "- $\\bar{Y}_{h,C}$ æ˜¯ç¬¬ $h$ å±‚å¯¹ç…§ç»„çš„å¹³å‡ç»“æœ\n",
    "\n",
    "### æ–¹å·®å…¬å¼\n",
    "\n",
    "$$\n",
    "\\text{Var}(\\hat{\\tau}_{\\text{strat}}) = \\sum_{h=1}^{H} W_h^2 \\left( \\frac{s_{h,T}^2}{n_{h,T}} + \\frac{s_{h,C}^2}{n_{h,C}} \\right)\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ $s_{h,T}^2$ æ˜¯ç¬¬ $h$ å±‚å®éªŒç»„çš„æ ·æœ¬æ–¹å·®ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 3.2 å®ç°åˆ†å±‚ä¼°è®¡é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class StratifiedEstimate:\n",
    "    \"\"\"åˆ†å±‚ä¼°è®¡ç»“æœ\"\"\"\n",
    "    ate: float  # å¹³å‡å¤„ç†æ•ˆåº”\n",
    "    se: float   # æ ‡å‡†è¯¯\n",
    "    ci_lower: float  # ç½®ä¿¡åŒºé—´ä¸‹ç•Œ\n",
    "    ci_upper: float  # ç½®ä¿¡åŒºé—´ä¸Šç•Œ\n",
    "    stratum_effects: Dict[str, float]  # å„å±‚æ•ˆåº”\n",
    "    stratum_weights: Dict[str, float]  # å„å±‚æƒé‡\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"\"\"åˆ†å±‚ä¼°è®¡ç»“æœ:\n",
    "  ATE: {self.ate:.2f}\n",
    "  SE: {self.se:.2f}\n",
    "  95% CI: [{self.ci_lower:.2f}, {self.ci_upper:.2f}]\n",
    "  \n",
    "  å„å±‚æ•ˆåº”:\n",
    "  {self._format_stratum_effects()}\n",
    "\"\"\"\n",
    "    \n",
    "    def _format_stratum_effects(self):\n",
    "        lines = []\n",
    "        for stratum, effect in self.stratum_effects.items():\n",
    "            weight = self.stratum_weights[stratum]\n",
    "            lines.append(f\"    {stratum}: {effect:.2f} (æƒé‡: {weight:.2%})\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def stratified_ate(\n",
    "    df: pd.DataFrame,\n",
    "    outcome_col: str,\n",
    "    treatment_col: str,\n",
    "    strata_col: str,\n",
    "    alpha: float = 0.05\n",
    ") -> StratifiedEstimate:\n",
    "    \"\"\"\n",
    "    è®¡ç®—åˆ†å±‚ ATE (Neyman ä¼°è®¡é‡)\n",
    "    \n",
    "    å‚æ•°:\n",
    "        df: å®éªŒæ•°æ®\n",
    "        outcome_col: ç»“æœå˜é‡åˆ—å\n",
    "        treatment_col: å¤„ç†å˜é‡åˆ—å\n",
    "        strata_col: åˆ†å±‚å˜é‡åˆ—å\n",
    "        alpha: æ˜¾è‘—æ€§æ°´å¹³\n",
    "    \"\"\"\n",
    "    strata = df[strata_col].unique()\n",
    "    n_total = len(df)\n",
    "    \n",
    "    stratum_effects = {}\n",
    "    stratum_weights = {}\n",
    "    stratum_vars = {}\n",
    "    \n",
    "    # è®¡ç®—æ¯å±‚çš„æ•ˆåº”å’Œæ–¹å·®\n",
    "    for stratum in strata:\n",
    "        df_stratum = df[df[strata_col] == stratum]\n",
    "        n_stratum = len(df_stratum)\n",
    "        weight = n_stratum / n_total\n",
    "        \n",
    "        # å±‚å†…å¤„ç†æ•ˆåº”\n",
    "        y_t = df_stratum[df_stratum[treatment_col] == 1][outcome_col]\n",
    "        y_c = df_stratum[df_stratum[treatment_col] == 0][outcome_col]\n",
    "        \n",
    "        tau_h = y_t.mean() - y_c.mean()\n",
    "        \n",
    "        # å±‚å†…æ–¹å·®\n",
    "        var_h = (y_t.var() / len(y_t)) + (y_c.var() / len(y_c))\n",
    "        \n",
    "        stratum_effects[stratum] = tau_h\n",
    "        stratum_weights[stratum] = weight\n",
    "        stratum_vars[stratum] = var_h\n",
    "    \n",
    "    # åŠ æƒå¹³å‡å¾—åˆ°æ€»ä½“ ATE\n",
    "    ate = sum(w * stratum_effects[s] for s, w in stratum_weights.items())\n",
    "    \n",
    "    # æ€»æ–¹å·®\n",
    "    variance = sum(w**2 * stratum_vars[s] for s, w in stratum_weights.items())\n",
    "    se = np.sqrt(variance)\n",
    "    \n",
    "    # ç½®ä¿¡åŒºé—´\n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "    ci_lower = ate - z * se\n",
    "    ci_upper = ate + z * se\n",
    "    \n",
    "    return StratifiedEstimate(\n",
    "        ate=ate,\n",
    "        se=se,\n",
    "        ci_lower=ci_lower,\n",
    "        ci_upper=ci_upper,\n",
    "        stratum_effects=stratum_effects,\n",
    "        stratum_weights=stratum_weights\n",
    "    )\n",
    "\n",
    "\n",
    "# æµ‹è¯•ï¼šä½¿ç”¨å‰é¢ç”Ÿæˆçš„æ•°æ®\n",
    "result = stratified_ate(\n",
    "    df=df,\n",
    "    outcome_col='purchase_amount',\n",
    "    treatment_col='treatment',\n",
    "    strata_col='user_tier'\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.3 ä¸ç®€å•å·®åˆ†å¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_ate(df: pd.DataFrame, outcome_col: str, treatment_col: str, alpha: float = 0.05):\n",
    "    \"\"\"\n",
    "    ç®€å•çš„ä¸åˆ†å±‚ä¼°è®¡ (åŸºå‡†)\n",
    "    \"\"\"\n",
    "    y_t = df[df[treatment_col] == 1][outcome_col]\n",
    "    y_c = df[df[treatment_col] == 0][outcome_col]\n",
    "    \n",
    "    ate = y_t.mean() - y_c.mean()\n",
    "    se = np.sqrt(y_t.var()/len(y_t) + y_c.var()/len(y_c))\n",
    "    \n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "    ci_lower = ate - z * se\n",
    "    ci_upper = ate + z * se\n",
    "    \n",
    "    return {\n",
    "        'ate': ate,\n",
    "        'se': se,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper\n",
    "    }\n",
    "\n",
    "# å¯¹æ¯”\n",
    "simple = simple_ate(df, 'purchase_amount', 'treatment')\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"å¯¹æ¯”: åˆ†å±‚ vs ä¸åˆ†å±‚\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nä¸åˆ†å±‚ä¼°è®¡:\")\n",
    "print(f\"  ATE: {simple['ate']:.2f}\")\n",
    "print(f\"  SE: {simple['se']:.2f}\")\n",
    "print(f\"  95% CI: [{simple['ci_lower']:.2f}, {simple['ci_upper']:.2f}]\")\n",
    "print(f\"  CIå®½åº¦: {simple['ci_upper'] - simple['ci_lower']:.2f}\")\n",
    "\n",
    "print(f\"\\nåˆ†å±‚ä¼°è®¡:\")\n",
    "print(f\"  ATE: {result.ate:.2f}\")\n",
    "print(f\"  SE: {result.se:.2f}\")\n",
    "print(f\"  95% CI: [{result.ci_lower:.2f}, {result.ci_upper:.2f}]\")\n",
    "print(f\"  CIå®½åº¦: {result.ci_upper - result.ci_lower:.2f}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ æ•ˆç‡æå‡:\")\n",
    "print(f\"  æ ‡å‡†è¯¯é™ä½: {(1 - result.se/simple['se'])*100:.1f}%\")\n",
    "print(f\"  ç½®ä¿¡åŒºé—´ç¼©çª„: {(1 - (result.ci_upper-result.ci_lower)/(simple['ci_upper']-simple['ci_lower']))*100:.1f}%\")\n",
    "print(f\"  ç­‰æ•ˆæ ·æœ¬é‡å¢åŠ : {(simple['se']/result.se)**2:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ TODO ç»ƒä¹  2: æ¨¡æ‹Ÿåˆ†å±‚çš„åŠŸæ•ˆæå‡\n",
    "\n",
    "é€šè¿‡è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼ŒéªŒè¯åˆ†å±‚èƒ½æé«˜ç»Ÿè®¡åŠŸæ•ˆï¼ˆPowerï¼‰ã€‚\n",
    "\n",
    "ä»»åŠ¡ï¼š\n",
    "1. è®¾å®šçœŸå® ATE = 10\n",
    "2. è¿è¡Œ 1000 æ¬¡æ¨¡æ‹Ÿ\n",
    "3. è®¡ç®—åˆ†å±‚ vs ä¸åˆ†å±‚çš„ Power (æ£€æµ‹åˆ°æ˜¾è‘—æ•ˆåº”çš„æ¯”ä¾‹)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_power(\n",
    "    true_ate: float = 10,\n",
    "    n_per_group: int = 200,\n",
    "    n_simulations: int = 1000,\n",
    "    alpha: float = 0.05\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    æ¨¡æ‹Ÿå¯¹æ¯”åˆ†å±‚ vs ä¸åˆ†å±‚çš„ç»Ÿè®¡åŠŸæ•ˆ\n",
    "    \n",
    "    è¿”å›:\n",
    "        {'stratified_power': xxx, 'simple_power': xxx}\n",
    "    \n",
    "    æç¤º:\n",
    "        1. æ¯æ¬¡æ¨¡æ‹Ÿç”Ÿæˆæ•°æ® (ç”¨ generate_stratified_data)\n",
    "        2. è®¡ç®— p-value (å¯ç”¨ z-test)\n",
    "        3. ç»Ÿè®¡ p < alpha çš„æ¯”ä¾‹\n",
    "    \"\"\"\n",
    "    # TODO: ä½ çš„ä»£ç \n",
    "    pass\n",
    "\n",
    "# æµ‹è¯•\n",
    "# power_results = simulate_power(true_ate=10, n_per_group=200, n_simulations=1000)\n",
    "# print(f\"åˆ†å±‚åŠŸæ•ˆ: {power_results['stratified_power']:.1%}\")\n",
    "# print(f\"ä¸åˆ†å±‚åŠŸæ•ˆ: {power_results['simple_power']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‚è€ƒç­”æ¡ˆ (å–æ¶ˆæ³¨é‡ŠæŸ¥çœ‹)\n",
    "\"\"\"\n",
    "def simulate_power(\n",
    "    true_ate: float = 10,\n",
    "    n_per_group: int = 200,\n",
    "    n_simulations: int = 1000,\n",
    "    alpha: float = 0.05\n",
    ") -> Dict[str, float]:\n",
    "    stratified_rejections = 0\n",
    "    simple_rejections = 0\n",
    "    \n",
    "    for _ in range(n_simulations):\n",
    "        # ç”Ÿæˆæ•°æ®\n",
    "        df_sim = generate_stratified_data(n_per_group=n_per_group)\n",
    "        \n",
    "        # åˆ†å±‚ä¼°è®¡\n",
    "        result_strat = stratified_ate(df_sim, 'purchase_amount', 'treatment', 'user_tier', alpha)\n",
    "        z_strat = result_strat.ate / result_strat.se\n",
    "        p_strat = 2 * (1 - stats.norm.cdf(abs(z_strat)))\n",
    "        if p_strat < alpha:\n",
    "            stratified_rejections += 1\n",
    "        \n",
    "        # ä¸åˆ†å±‚ä¼°è®¡\n",
    "        result_simple = simple_ate(df_sim, 'purchase_amount', 'treatment', alpha)\n",
    "        z_simple = result_simple['ate'] / result_simple['se']\n",
    "        p_simple = 2 * (1 - stats.norm.cdf(abs(z_simple)))\n",
    "        if p_simple < alpha:\n",
    "            simple_rejections += 1\n",
    "    \n",
    "    return {\n",
    "        'stratified_power': stratified_rejections / n_simulations,\n",
    "        'simple_power': simple_rejections / n_simulations\n",
    "    }\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: äº‹ååˆ†å±‚ (Post-Stratification)\n",
    "\n",
    "## 4.1 ä¸åˆ†å±‚éšæœºåŒ–çš„åŒºåˆ«\n",
    "\n",
    "| ç»´åº¦ | åˆ†å±‚éšæœºåŒ– | äº‹ååˆ†å±‚ |\n",
    "|------|-----------|----------|\n",
    "| **æ—¶æœº** | å®éªŒè®¾è®¡æ—¶ | å®éªŒåˆ†ææ—¶ |\n",
    "| **éšæœºåŒ–** | å±‚å†…ç‹¬ç«‹éšæœº | å…¨å±€éšæœºåŒ– |\n",
    "| **å¹³è¡¡æ€§** | ä¸¥æ ¼ä¿è¯ | å¯èƒ½ä¸å¹³è¡¡ |\n",
    "| **é€‚ç”¨æ€§** | éœ€æå‰çŸ¥é“åˆ†å±‚å˜é‡ | å¯ç”¨ä»»ä½•äº‹åå˜é‡ |\n",
    "\n",
    "### ä»€ä¹ˆæ—¶å€™ç”¨äº‹ååˆ†å±‚ï¼Ÿ\n",
    "\n",
    "1. **å®éªŒå·²ç»å¼€å§‹**ï¼Œæ— æ³•é‡æ–°éšæœºåŒ–\n",
    "2. **æ ·æœ¬ä¸å¹³è¡¡** - æŸäº›å±‚è¢«è¿‡åº¦/ä¸è¶³æŠ½æ ·\n",
    "3. **å‘ç°æ–°çš„åˆ†å±‚å˜é‡** - å®éªŒåæ‰æ„è¯†åˆ°åº”è¯¥åˆ†å±‚\n",
    "\n",
    "---\n",
    "\n",
    "## 4.2 äº‹ååˆ†å±‚çš„ä¼°è®¡é‡\n",
    "\n",
    "å‡è®¾æ€»ä½“ä¸­ç¬¬ $h$ å±‚çš„çœŸå®æ¯”ä¾‹æ˜¯ $W_h^{\\text{pop}}$ï¼Œä½†æ ·æœ¬ä¸­çš„æ¯”ä¾‹æ˜¯ $W_h^{\\text{sample}}$ã€‚\n",
    "\n",
    "äº‹ååˆ†å±‚ä¼°è®¡é‡é€šè¿‡**é‡æ–°åŠ æƒ**æ¥çº æ­£:\n",
    "\n",
    "$$\n",
    "\\hat{\\tau}_{\\text{post-strat}} = \\sum_{h=1}^{H} W_h^{\\text{pop}} \\hat{\\tau}_h\n",
    "$$\n",
    "\n",
    "è€Œä¸æ˜¯ç”¨æ ·æœ¬æƒé‡ $W_h^{\\text{sample}}$ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 4.3 å®ç°äº‹ååˆ†å±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_stratified_ate(\n",
    "    df: pd.DataFrame,\n",
    "    outcome_col: str,\n",
    "    treatment_col: str,\n",
    "    strata_col: str,\n",
    "    population_weights: Dict[str, float],\n",
    "    alpha: float = 0.05\n",
    ") -> StratifiedEstimate:\n",
    "    \"\"\"\n",
    "    äº‹ååˆ†å±‚ä¼°è®¡ (ä½¿ç”¨æ€»ä½“æƒé‡)\n",
    "    \n",
    "    å‚æ•°:\n",
    "        df: å®éªŒæ•°æ®\n",
    "        outcome_col: ç»“æœå˜é‡\n",
    "        treatment_col: å¤„ç†å˜é‡\n",
    "        strata_col: åˆ†å±‚å˜é‡\n",
    "        population_weights: æ€»ä½“ä¸­å„å±‚çš„çœŸå®æ¯”ä¾‹ (Dict)\n",
    "        alpha: æ˜¾è‘—æ€§æ°´å¹³\n",
    "    \"\"\"\n",
    "    strata = df[strata_col].unique()\n",
    "    \n",
    "    stratum_effects = {}\n",
    "    stratum_vars = {}\n",
    "    \n",
    "    # è®¡ç®—æ¯å±‚çš„æ•ˆåº”\n",
    "    for stratum in strata:\n",
    "        df_stratum = df[df[strata_col] == stratum]\n",
    "        \n",
    "        y_t = df_stratum[df_stratum[treatment_col] == 1][outcome_col]\n",
    "        y_c = df_stratum[df_stratum[treatment_col] == 0][outcome_col]\n",
    "        \n",
    "        tau_h = y_t.mean() - y_c.mean()\n",
    "        var_h = (y_t.var() / len(y_t)) + (y_c.var() / len(y_c))\n",
    "        \n",
    "        stratum_effects[stratum] = tau_h\n",
    "        stratum_vars[stratum] = var_h\n",
    "    \n",
    "    # ä½¿ç”¨æ€»ä½“æƒé‡è€Œéæ ·æœ¬æƒé‡\n",
    "    ate = sum(population_weights[s] * stratum_effects[s] for s in strata)\n",
    "    variance = sum(population_weights[s]**2 * stratum_vars[s] for s in strata)\n",
    "    se = np.sqrt(variance)\n",
    "    \n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "    ci_lower = ate - z * se\n",
    "    ci_upper = ate + z * se\n",
    "    \n",
    "    return StratifiedEstimate(\n",
    "        ate=ate,\n",
    "        se=se,\n",
    "        ci_lower=ci_lower,\n",
    "        ci_upper=ci_upper,\n",
    "        stratum_effects=stratum_effects,\n",
    "        stratum_weights=population_weights\n",
    "    )\n",
    "\n",
    "\n",
    "# ç¤ºä¾‹ï¼šæ ·æœ¬ä¸å¹³è¡¡çš„æƒ…å†µ\n",
    "# å‡è®¾çœŸå®æ€»ä½“åˆ†å¸ƒ: æ™®é€š 70%, VIP 20%, è¶…çº§VIP 10%\n",
    "# ä½†æˆ‘ä»¬çš„æ ·æœ¬è¿‡åº¦æŠ½æ ·äº†è¶…çº§VIP\n",
    "\n",
    "df_imbalanced = pd.concat([\n",
    "    df[df['user_tier'] == 'æ™®é€š'].sample(500, random_state=42),\n",
    "    df[df['user_tier'] == 'VIP'].sample(500, random_state=42),\n",
    "    df[df['user_tier'] == 'è¶…çº§VIP'].sample(1000, random_state=42),  # è¿‡åº¦æŠ½æ ·!\n",
    "], ignore_index=True)\n",
    "\n",
    "print(\"æ ·æœ¬ä¸­çš„åˆ†å¸ƒ:\")\n",
    "print(df_imbalanced['user_tier'].value_counts(normalize=True))\n",
    "\n",
    "# å®šä¹‰æ€»ä½“çœŸå®åˆ†å¸ƒ\n",
    "population_weights = {\n",
    "    'æ™®é€š': 0.70,\n",
    "    'VIP': 0.20,\n",
    "    'è¶…çº§VIP': 0.10\n",
    "}\n",
    "\n",
    "# äº‹ååˆ†å±‚è°ƒæ•´\n",
    "result_post = post_stratified_ate(\n",
    "    df=df_imbalanced,\n",
    "    outcome_col='purchase_amount',\n",
    "    treatment_col='treatment',\n",
    "    strata_col='user_tier',\n",
    "    population_weights=population_weights\n",
    ")\n",
    "\n",
    "print(\"\\näº‹ååˆ†å±‚ç»“æœ (ä½¿ç”¨æ€»ä½“æƒé‡):\")\n",
    "print(result_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ å…³é”®ç‚¹\n",
    "\n",
    "äº‹ååˆ†å±‚çš„æ ¸å¿ƒæ˜¯**é‡æ–°åŠ æƒ**:\n",
    "- è¢«è¿‡åº¦æŠ½æ ·çš„å±‚ â†’ é™ä½æƒé‡\n",
    "- è¢«ä¸è¶³æŠ½æ ·çš„å±‚ â†’ æé«˜æƒé‡\n",
    "- æœ€ç»ˆå¾—åˆ°å¯¹æ€»ä½“çš„æ— åä¼°è®¡\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: å®è·µæ¡ˆä¾‹\n",
    "\n",
    "## æ¡ˆä¾‹ 1: æŒ‰ç”¨æˆ·ç­‰çº§åˆ†å±‚çš„ä¿ƒé”€å®éªŒ\n",
    "\n",
    "### èƒŒæ™¯\n",
    "\n",
    "æŸç”µå•†å¹³å°è¦æµ‹è¯•æ–°çš„ä¼˜æƒ åˆ¸ç­–ç•¥ï¼š\n",
    "- **å¯¹ç…§ç»„**: æ»¡100å‡10\n",
    "- **å®éªŒç»„**: æ»¡80å‡10 (æ›´å®¹æ˜“è§¦å‘)\n",
    "\n",
    "ç”¨æˆ·åˆ†ä¸ºä¸‰ä¸ªç­‰çº§ï¼Œæ¶ˆè´¹èƒ½åŠ›å·®å¼‚å·¨å¤§ã€‚æˆ‘ä»¬å¸Œæœ›ï¼š\n",
    "1. ä¼°è®¡æ•´ä½“ ATE\n",
    "2. åˆ†æä¸åŒç­‰çº§çš„å¼‚è´¨æ€§æ•ˆåº”\n",
    "3. ä¸ºä¸åŒç­‰çº§å®šåˆ¶ç­–ç•¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆä¿ƒé”€å®éªŒæ•°æ®\n",
    "def generate_coupon_experiment(n_per_tier: int = 1000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    æ¨¡æ‹Ÿä¼˜æƒ åˆ¸å®éªŒæ•°æ®\n",
    "    \n",
    "    å¼‚è´¨æ€§æ•ˆåº”:\n",
    "    - æ™®é€šç”¨æˆ·: æ•ˆåº”å¤§ (å› ä¸ºæ›´éœ€è¦ä¼˜æƒ )\n",
    "    - VIPç”¨æˆ·: æ•ˆåº”ä¸­ç­‰\n",
    "    - è¶…çº§VIP: æ•ˆåº”å° (æœ¬æ¥å°±ä¼šä¹°)\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    configs = [\n",
    "        {'tier': 'æ™®é€š', 'base_gmv': 120, 'std': 40, 'te': 25},  # æ•ˆåº”æœ€å¤§\n",
    "        {'tier': 'VIP', 'base_gmv': 300, 'std': 80, 'te': 15},   # ä¸­ç­‰\n",
    "        {'tier': 'è¶…çº§VIP', 'base_gmv': 600, 'std': 150, 'te': 5},  # æ•ˆåº”æœ€å°\n",
    "    ]\n",
    "    \n",
    "    for config in configs:\n",
    "        for treatment in [0, 1]:\n",
    "            gmv = np.random.normal(\n",
    "                config['base_gmv'] + treatment * config['te'],\n",
    "                config['std'],\n",
    "                n_per_tier\n",
    "            )\n",
    "            \n",
    "            df_tier = pd.DataFrame({\n",
    "                'user_tier': config['tier'],\n",
    "                'treatment': treatment,\n",
    "                'gmv': np.clip(gmv, 0, None)\n",
    "            })\n",
    "            data.append(df_tier)\n",
    "    \n",
    "    return pd.concat(data, ignore_index=True)\n",
    "\n",
    "df_coupon = generate_coupon_experiment(n_per_tier=1000)\n",
    "\n",
    "# åˆ†å±‚åˆ†æ\n",
    "result_coupon = stratified_ate(\n",
    "    df=df_coupon,\n",
    "    outcome_col='gmv',\n",
    "    treatment_col='treatment',\n",
    "    strata_col='user_tier'\n",
    ")\n",
    "\n",
    "print(\"ä¼˜æƒ åˆ¸å®éªŒ - åˆ†å±‚åˆ†æç»“æœ:\")\n",
    "print(result_coupon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å„å±‚çš„å¼‚è´¨æ€§æ•ˆåº”\n",
    "def plot_heterogeneous_effects(result: StratifiedEstimate):\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶å„å±‚çš„å¤„ç†æ•ˆåº”å¯¹æ¯”\n",
    "    \"\"\"\n",
    "    tiers = list(result.stratum_effects.keys())\n",
    "    effects = [result.stratum_effects[t] for t in tiers]\n",
    "    weights = [result.stratum_weights[t] for t in tiers]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # å„å±‚æ•ˆåº”\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=tiers,\n",
    "        y=effects,\n",
    "        text=[f\"{e:.1f}å…ƒ<br>æƒé‡: {w:.1%}\" for e, w in zip(effects, weights)],\n",
    "        textposition='outside',\n",
    "        marker_color=[COLORS['info'], COLORS['warning'], COLORS['secondary']],\n",
    "        name='å„å±‚æ•ˆåº”'\n",
    "    ))\n",
    "    \n",
    "    # æ€»ä½“ATEçº¿\n",
    "    fig.add_hline(\n",
    "        y=result.ate,\n",
    "        line_dash='dash',\n",
    "        line_color=COLORS['danger'],\n",
    "        annotation_text=f\"æ€»ä½“ATE: {result.ate:.1f}å…ƒ\",\n",
    "        annotation_position=\"right\"\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"å¼‚è´¨æ€§å¤„ç†æ•ˆåº” - ä¸åŒç”¨æˆ·ç­‰çº§å¯¹ä¼˜æƒ åˆ¸çš„ååº”\",\n",
    "        xaxis_title=\"ç”¨æˆ·ç­‰çº§\",\n",
    "        yaxis_title=\"å¤„ç†æ•ˆåº” (GMVæå‡, å…ƒ)\",\n",
    "        template='plotly_white',\n",
    "        height=500,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = plot_heterogeneous_effects(result_coupon)\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ ä¸šåŠ¡æ´å¯Ÿ:\")\n",
    "print(\"  1. æ™®é€šç”¨æˆ·å¯¹ä¼˜æƒ æœ€æ•æ„Ÿï¼Œå»ºè®®é‡ç‚¹æŠ•æ”¾\")\n",
    "print(\"  2. è¶…çº§VIPæ•ˆåº”å¾ˆå°ï¼Œå¯è€ƒè™‘å·®å¼‚åŒ–ç­–ç•¥\")\n",
    "print(\"  3. æ€»ä½“ATEæ˜¯åŠ æƒå¹³å‡ï¼Œè€ƒè™‘äº†å„å±‚å æ¯”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## æ¡ˆä¾‹ 2: æŒ‰åœ°åŒºåˆ†å±‚çš„å®šä»·å®éªŒ\n",
    "\n",
    "### èƒŒæ™¯\n",
    "\n",
    "æŸå¤–å–å¹³å°æµ‹è¯•é…é€è´¹ä¸Šè°ƒ 1 å…ƒå¯¹è®¢å•é‡çš„å½±å“ã€‚ä¸åŒåŸå¸‚çš„ç”¨æˆ·ä»·æ ¼æ•æ„Ÿåº¦ä¸åŒï¼š\n",
    "- **ä¸€çº¿åŸå¸‚**: ä»·æ ¼ä¸æ•æ„Ÿ\n",
    "- **äºŒçº¿åŸå¸‚**: ä¸­ç­‰æ•æ„Ÿ\n",
    "- **ä¸‰å››çº¿**: é«˜åº¦æ•æ„Ÿ\n",
    "\n",
    "æˆ‘ä»¬éœ€è¦æŒ‰åœ°åŒºåˆ†å±‚åˆ†æã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pricing_experiment(n_per_city: int = 800) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    æ¨¡æ‹Ÿå®šä»·å®éªŒæ•°æ®\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    configs = [\n",
    "        {'city_tier': 'ä¸€çº¿', 'base_orders': 50, 'std': 15, 'price_effect': -2},\n",
    "        {'city_tier': 'äºŒçº¿', 'base_orders': 35, 'std': 10, 'price_effect': -5},\n",
    "        {'city_tier': 'ä¸‰å››çº¿', 'base_orders': 25, 'std': 8, 'price_effect': -8},\n",
    "    ]\n",
    "    \n",
    "    for config in configs:\n",
    "        for treatment in [0, 1]:  # 0: åŸä»·, 1: æ¶¨ä»·\n",
    "            orders = np.random.normal(\n",
    "                config['base_orders'] + treatment * config['price_effect'],\n",
    "                config['std'],\n",
    "                n_per_city\n",
    "            )\n",
    "            \n",
    "            df_city = pd.DataFrame({\n",
    "                'city_tier': config['city_tier'],\n",
    "                'treatment': treatment,\n",
    "                'daily_orders': np.clip(orders, 0, None)\n",
    "            })\n",
    "            data.append(df_city)\n",
    "    \n",
    "    return pd.concat(data, ignore_index=True)\n",
    "\n",
    "df_pricing = generate_pricing_experiment(n_per_city=800)\n",
    "\n",
    "# åˆ†å±‚åˆ†æ\n",
    "result_pricing = stratified_ate(\n",
    "    df=df_pricing,\n",
    "    outcome_col='daily_orders',\n",
    "    treatment_col='treatment',\n",
    "    strata_col='city_tier'\n",
    ")\n",
    "\n",
    "print(\"å®šä»·å®éªŒ - åˆ†å±‚åˆ†æç»“æœ:\")\n",
    "print(result_pricing)\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig = plot_heterogeneous_effects(result_pricing)\n",
    "fig.update_layout(\n",
    "    title=\"å®šä»·æ•æ„Ÿåº¦ - ä¸åŒåŸå¸‚å¯¹æ¶¨ä»·çš„ååº”\",\n",
    "    yaxis_title=\"å¤„ç†æ•ˆåº” (è®¢å•é‡å˜åŒ–)\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ ä¸šåŠ¡å†³ç­–:\")\n",
    "print(\"  å¦‚æœå¹³å°ç›®æ ‡æ˜¯æœ€å¤§åŒ–è¥æ”¶ (è®¢å•é‡ Ã— ä»·æ ¼):\")\n",
    "print(\"  - ä¸€çº¿åŸå¸‚: æ¶¨ä»·å½±å“å°ï¼Œå¯ä»¥æ¶¨\")\n",
    "print(\"  - ä¸‰å››çº¿: æ¶¨ä»·æŸå¤±å¤§ï¼Œä¸å»ºè®®æ¶¨\")\n",
    "print(\"  - å¯ä»¥è€ƒè™‘å·®å¼‚åŒ–å®šä»·ç­–ç•¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¡ TODO ç»ƒä¹  3: è®¡ç®—æœ€ä¼˜æ ·æœ¬åˆ†é…\n",
    "\n",
    "åœ¨åˆ†å±‚å®éªŒä¸­ï¼Œå¦‚æœæˆ‘ä»¬å¯ä»¥è‡ªç”±å†³å®šå„å±‚çš„æ ·æœ¬é‡ï¼Œåº”è¯¥å¦‚ä½•åˆ†é…æ‰èƒ½æœ€å°åŒ–æ€»ä½“æ–¹å·®ï¼Ÿ\n",
    "\n",
    "**Neyman æœ€ä¼˜åˆ†é…** ç»™å‡ºç­”æ¡ˆ:\n",
    "\n",
    "$$\n",
    "n_h \\propto W_h \\sigma_h\n",
    "$$\n",
    "\n",
    "å³ï¼šç»™æ–¹å·®å¤§ã€å æ¯”é«˜çš„å±‚åˆ†é…æ›´å¤šæ ·æœ¬ã€‚\n",
    "\n",
    "ä»»åŠ¡ï¼šå®ç° `optimal_allocation` å‡½æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_allocation(\n",
    "    stratum_weights: Dict[str, float],  # å„å±‚å æ¯”\n",
    "    stratum_stds: Dict[str, float],     # å„å±‚æ ‡å‡†å·®\n",
    "    total_budget: int                    # æ€»æ ·æœ¬é‡\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    è®¡ç®— Neyman æœ€ä¼˜æ ·æœ¬åˆ†é…\n",
    "    \n",
    "    å‚æ•°:\n",
    "        stratum_weights: å„å±‚çš„æ€»ä½“å æ¯”\n",
    "        stratum_stds: å„å±‚çš„æ ‡å‡†å·®\n",
    "        total_budget: æ€»æ ·æœ¬é‡é¢„ç®—\n",
    "    \n",
    "    è¿”å›:\n",
    "        Dict[stratum_name, sample_size]\n",
    "    \n",
    "    æç¤º:\n",
    "        n_h = total_budget * (W_h * sigma_h) / sum(W_k * sigma_k)\n",
    "    \"\"\"\n",
    "    # TODO: ä½ çš„ä»£ç \n",
    "    pass\n",
    "\n",
    "# æµ‹è¯•\n",
    "# weights = {'æ™®é€š': 0.7, 'VIP': 0.2, 'è¶…çº§VIP': 0.1}\n",
    "# stds = {'æ™®é€š': 20, 'VIP': 50, 'è¶…çº§VIP': 100}\n",
    "# allocation = optimal_allocation(weights, stds, total_budget=3000)\n",
    "# print(allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‚è€ƒç­”æ¡ˆ (å–æ¶ˆæ³¨é‡ŠæŸ¥çœ‹)\n",
    "\"\"\"\n",
    "def optimal_allocation(\n",
    "    stratum_weights: Dict[str, float],\n",
    "    stratum_stds: Dict[str, float],\n",
    "    total_budget: int\n",
    ") -> Dict[str, int]:\n",
    "    strata = list(stratum_weights.keys())\n",
    "    \n",
    "    # è®¡ç®— W_h * sigma_h\n",
    "    products = {s: stratum_weights[s] * stratum_stds[s] for s in strata}\n",
    "    total_product = sum(products.values())\n",
    "    \n",
    "    # æŒ‰æ¯”ä¾‹åˆ†é…\n",
    "    allocation = {}\n",
    "    for s in strata:\n",
    "        allocation[s] = int(total_budget * products[s] / total_product)\n",
    "    \n",
    "    # ç¡®ä¿æ€»å’Œç­‰äº total_budget (å¤„ç†èˆå…¥è¯¯å·®)\n",
    "    diff = total_budget - sum(allocation.values())\n",
    "    if diff > 0:\n",
    "        # æŠŠå‰©ä½™çš„åˆ†é…ç»™æœ€å¤§å±‚\n",
    "        max_stratum = max(allocation, key=allocation.get)\n",
    "        allocation[max_stratum] += diff\n",
    "    \n",
    "    return allocation\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ç»ƒä¹ ä¸æ€è€ƒé¢˜\n",
    "\n",
    "## åŸºç¡€é¢˜\n",
    "\n",
    "1. **æ¦‚å¿µé¢˜**: åˆ†å±‚éšæœºåŒ–å’Œäº‹ååˆ†å±‚çš„æ ¸å¿ƒåŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿå„è‡ªé€‚ç”¨äºä»€ä¹ˆåœºæ™¯ï¼Ÿ\n",
    "\n",
    "2. **è®¡ç®—é¢˜**: å‡è®¾æœ‰ä¸¤å±‚ï¼Œç¬¬1å±‚ $N_1=1000, \\bar{Y}_{1T}=100, \\bar{Y}_{1C}=90$ï¼›ç¬¬2å±‚ $N_2=500, \\bar{Y}_{2T}=200, \\bar{Y}_{2C}=180$ã€‚è®¡ç®—åˆ†å±‚ ATEã€‚\n",
    "\n",
    "3. **ç¼–ç¨‹é¢˜**: å®ç°ä¸€ä¸ªå‡½æ•°ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜çš„åˆ†å±‚å˜é‡ï¼ˆä»å¤šä¸ªå€™é€‰ä¸­é€‰æ‹©èƒ½æœ€å¤§ç¨‹åº¦å‡å°‘æ–¹å·®çš„ï¼‰ã€‚\n",
    "\n",
    "## è¿›é˜¶é¢˜\n",
    "\n",
    "4. **ç†è®ºé¢˜**: è¯æ˜åœ¨å®Œå…¨éšæœºåŒ–å®éªŒä¸­ï¼Œåˆ†å±‚ä¼°è®¡é‡å’Œç®€å•å·®åˆ†ä¼°è®¡é‡éƒ½æ˜¯æ— åçš„ï¼Œä½†å‰è€…æ–¹å·®æ›´å°ã€‚\n",
    "\n",
    "5. **å®è·µé¢˜**: ä½ è´Ÿè´£ä¸€ä¸ªA/Bæµ‹è¯•ï¼Œå‘ç°æ ·æœ¬ä¸­VIPç”¨æˆ·å æ¯”æ˜¯30%ï¼Œä½†æ€»ä½“ä¸­åªæœ‰10%ã€‚å¦‚ä½•è°ƒæ•´åˆ†æï¼Ÿéœ€è¦æ³¨æ„ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "6. **è®¾è®¡é¢˜**: è®¾è®¡ä¸€ä¸ªå‡½æ•°ï¼Œè¾“å…¥å†å²æ•°æ®ï¼Œè‡ªåŠ¨æ¨èæœ€ä¼˜çš„ï¼š\n",
    "   - åˆ†å±‚å˜é‡\n",
    "   - åˆ†å±‚ç²’åº¦ï¼ˆå‡ ä¸ªå±‚ï¼‰\n",
    "   - å„å±‚æ ·æœ¬åˆ†é…\n",
    "\n",
    "## æ€è€ƒé¢˜\n",
    "\n",
    "7. **åˆ†å±‚ vs CUPED**: ä¸¤è€…éƒ½ç”¨åå˜é‡å‡å°‘æ–¹å·®ï¼Œå„æœ‰ä»€ä¹ˆä¼˜ç¼ºç‚¹ï¼Ÿèƒ½å¦ç»“åˆä½¿ç”¨ï¼Ÿ\n",
    "\n",
    "8. **Simpsonæ‚–è®º**: åˆ†å±‚åå‘ç°æ¯å±‚æ•ˆåº”éƒ½ä¸ºæ­£ï¼Œä½†æ€»ä½“æ•ˆåº”ä¸ºè´Ÿï¼Œå¯èƒ½å—ï¼Ÿæ€ä¹ˆè§£é‡Šï¼Ÿ\n",
    "\n",
    "9. **ä¸šåŠ¡æƒè¡¡**: åˆ†å±‚è¶Šç»†è¶Šå¥½å—ï¼Ÿè¿‡åº¦åˆ†å±‚æœ‰ä»€ä¹ˆé£é™©ï¼Ÿ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ€»ç»“ä¸è¦ç‚¹\n",
    "\n",
    "## æ ¸å¿ƒæ”¶è·\n",
    "\n",
    "### 1ï¸âƒ£ åˆ†å±‚çš„æœ¬è´¨\n",
    "- åˆ©ç”¨å·²çŸ¥çš„åå˜é‡ä¿¡æ¯å‡å°‘ä¼°è®¡æ–¹å·®\n",
    "- é€šè¿‡"ç»„å†…æ›´åŒè´¨"æé«˜ç²¾åº¦\n",
    "- å¯ä»¥èŠ‚çœ 30%-70% çš„æ ·æœ¬é‡\n",
    "\n",
    "### 2ï¸âƒ£ ä¸¤ç§åˆ†å±‚æ–¹å¼\n",
    "- **åˆ†å±‚éšæœºåŒ–**: è®¾è®¡é˜¶æ®µï¼Œå±‚å†…ç‹¬ç«‹éšæœºåŒ–\n",
    "- **äº‹ååˆ†å±‚**: åˆ†æé˜¶æ®µï¼Œç”¨æ€»ä½“æƒé‡è°ƒæ•´\n",
    "\n",
    "### 3ï¸âƒ£ Neyman ä¼°è®¡é‡\n",
    "$$\n",
    "\\hat{\\tau}_{\\text{strat}} = \\sum_{h=1}^{H} W_h (\\bar{Y}_{h,T} - \\bar{Y}_{h,C})\n",
    "$$\n",
    "\n",
    "### 4ï¸âƒ£ å®è·µè¦ç‚¹\n",
    "- é€‰æ‹©ä¸ç»“æœé«˜åº¦ç›¸å…³çš„åˆ†å±‚å˜é‡\n",
    "- å±‚æ•°ä¸å®œè¿‡å¤šï¼ˆæ¯å±‚è‡³å°‘å‡ ç™¾æ ·æœ¬ï¼‰\n",
    "- æ³¨æ„æ ·æœ¬ä¸å¹³è¡¡é—®é¢˜\n",
    "- å¯ä»¥ç»“åˆ CUPED ç­‰æ–¹æ³•è¿›ä¸€æ­¥æå‡\n",
    "\n",
    "---\n",
    "\n",
    "## ä¸‹ä¸€æ­¥\n",
    "\n",
    "- **Part 1.4**: Sequential Testingï¼ˆåºè´¯æ£€éªŒï¼‰\n",
    "- **Part 1.5**: Network Effectsï¼ˆç½‘ç»œæ•ˆåº”å¤„ç†ï¼‰\n",
    "- **Part 2**: ä»å®éªŒåˆ°è§‚å¯Ÿæ€§ç ”ç©¶\n",
    "\n",
    "---\n",
    "\n",
    "## å‚è€ƒèµ„æ–™\n",
    "\n",
    "1. **Imbens & Rubin (2015)**: Causal Inference for Statistics, Social, and Biomedical Sciences\n",
    "2. **Athey & Imbens (2017)**: The Econometrics of Randomized Experiments\n",
    "3. **Kohavi et al. (2020)**: Trustworthy Online Controlled Experiments - Chapter 6\n",
    "4. **Deng et al. (2013)**: Improving the Sensitivity of Online Controlled Experiments by Utilizing Pre-Experiment Data\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
