{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ•¸ï¸ ç¬¬ä¸€ç«  ç»ƒä¹  2: å› æœå›¾ä¸ DAG\n",
    "\n",
    "---\n",
    "\n",
    "## ä»ã€Œçœ‹å›¾è¯´è¯ã€åˆ°ã€Œçœ‹å›¾æ–­å› æœã€\n",
    "\n",
    "åœ¨ä¸Šä¸€ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†æ½œåœ¨ç»“æœæ¡†æ¶ã€‚ä½†æ˜¯ï¼Œå½“ä½ é‡åˆ°è¿™æ ·çš„é—®é¢˜æ—¶ï¼š\n",
    "\n",
    "> \"è¿™ä¸ªå˜é‡åº”è¯¥æ§åˆ¶å—ï¼Ÿæ§åˆ¶äº†ä¼šæ€æ ·ï¼Ÿä¸æ§åˆ¶åˆä¼šæ€æ ·ï¼Ÿ\"\n",
    "\n",
    "å•çº¯é æ•°å­¦å…¬å¼å°±ä¸å¤Ÿç›´è§‚äº†ã€‚è¿™æ—¶å€™ï¼Œ**å› æœå›¾ (Causal Graph)** å°±æ´¾ä¸Šç”¨åœºäº†ï¼\n",
    "\n",
    "### ä¸€ä¸ªæœ‰è¶£çš„ä¾‹å­ ğŸ¥\n",
    "\n",
    "ä½ æ˜¯ä¸€åæµè¡Œç—…å­¦å®¶ï¼Œåœ¨ç ”ç©¶ã€Œè¿åŠ¨ã€å¯¹ã€Œå¥åº·ã€çš„å½±å“ã€‚ä½ å‘ç°ï¼š\n",
    "\n",
    "- ç»å¸¸è¿åŠ¨çš„äººæ›´å¥åº· âœ“\n",
    "- ä½†ç»å¸¸è¿åŠ¨çš„äººæ”¶å…¥ä¹Ÿæ›´é«˜...\n",
    "- è€Œé«˜æ”¶å…¥çš„äººæœ¬æ¥å°±æ›´å¥åº·ï¼ˆæ›´å¥½çš„åŒ»ç–—ã€é¥®é£Ÿï¼‰...\n",
    "\n",
    "æ‰€ä»¥è¿åŠ¨åˆ°åº•æœ‰æ²¡æœ‰ç”¨ï¼Ÿæ”¶å…¥æ˜¯æ€ä¹ˆå›äº‹ï¼Ÿåº”è¯¥æ€ä¹ˆåˆ†æï¼Ÿ\n",
    "\n",
    "ç”¨å› æœå›¾ï¼Œè¿™ä¸ªé—®é¢˜ä¸€ç”»å°±æ¸…æ¥šäº†ï¼\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š æœ¬èŠ‚å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "1. ç†è§£å› æœå›¾çš„åŸºæœ¬æ¦‚å¿µ\n",
    "2. è¯†åˆ«ä¸‰ç§æ ¸å¿ƒç»“æ„ï¼šæ··æ·†ã€ä¸­ä»‹ã€ç¢°æ’\n",
    "3. ç†è§£åé—¨è·¯å¾„å’Œ d-åˆ†ç¦»\n",
    "4. æŒæ¡ã€Œåº”è¯¥æ§åˆ¶å“ªäº›å˜é‡ã€çš„å†³ç­–æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Set, Tuple\n",
    "\n",
    "# è®¾ç½®\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæ¯•ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸŒŸ Part 1: ä»€ä¹ˆæ˜¯å› æœå›¾ (DAG)ï¼Ÿ\n",
    "\n",
    "### DAG = Directed Acyclic Graphï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰\n",
    "\n",
    "- **æœ‰å‘ (Directed)**: ç®­å¤´æŒ‡å‘å› æœçš„æ–¹å‘ï¼ˆåŸå›  â†’ ç»“æœï¼‰\n",
    "- **æ— ç¯ (Acyclic)**: ä¸èƒ½æœ‰å¾ªç¯ï¼ˆA â†’ B â†’ C â†’ A æ˜¯ä¸å…è®¸çš„ï¼‰\n",
    "- **å›¾ (Graph)**: ç”¨èŠ‚ç‚¹å’Œè¾¹è¡¨ç¤ºå˜é‡ä¹‹é—´çš„å…³ç³»\n",
    "\n",
    "### æœ€ç®€å•çš„å› æœå›¾\n",
    "\n",
    "```\n",
    "T â†’ Y\n",
    "```\n",
    "\n",
    "è¿™è¡¨ç¤ºï¼šT **å¯¼è‡´** Yï¼ˆT æ˜¯åŸå› ï¼ŒY æ˜¯ç»“æœï¼‰\n",
    "\n",
    "### ç»å…¸çš„æ··æ·†ç»“æ„\n",
    "\n",
    "```\n",
    "    X\n",
    "   â†™ â†˜\n",
    "  T   Y\n",
    "   â†˜ â†—\n",
    "```\n",
    "\n",
    "ç­‰ä»·äºï¼š\n",
    "- X â†’ Tï¼ˆX å½±å“ Tï¼‰\n",
    "- X â†’ Yï¼ˆX å½±å“ Yï¼‰  \n",
    "- T â†’ Yï¼ˆT å½±å“ Yï¼‰\n",
    "\n",
    "è¿™é‡Œ X å°±æ˜¯**æ··æ·†å˜é‡ (Confounder)**ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¨ ç”¨ä»£ç ç”»å› æœå›¾\n",
    "\n",
    "è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªç®€å•çš„å‡½æ•°æ¥å¯è§†åŒ–å› æœå›¾ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_dag(edges, title=\"å› æœå›¾ (DAG)\", highlight_path=None):\n",
    "    \"\"\"\n",
    "    ç”»ä¸€ä¸ªç®€å•çš„å› æœå›¾\n",
    "    \n",
    "    Args:\n",
    "        edges: è¾¹çš„åˆ—è¡¨ï¼Œå¦‚ [(\"X\", \"T\"), (\"X\", \"Y\"), (\"T\", \"Y\")]\n",
    "        title: å›¾çš„æ ‡é¢˜\n",
    "        highlight_path: è¦é«˜äº®çš„è·¯å¾„\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import networkx as nx\n",
    "        \n",
    "        G = nx.DiGraph()\n",
    "        G.add_edges_from(edges)\n",
    "        \n",
    "        # è®¾ç½®èŠ‚ç‚¹ä½ç½®\n",
    "        pos = nx.spring_layout(G, seed=42)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        \n",
    "        # ç”»è¾¹\n",
    "        nx.draw_networkx_edges(G, pos, edge_color='gray', \n",
    "                               arrows=True, arrowsize=20,\n",
    "                               connectionstyle=\"arc3,rad=0.1\")\n",
    "        \n",
    "        # å¦‚æœæœ‰é«˜äº®è·¯å¾„\n",
    "        if highlight_path:\n",
    "            highlight_edges = [(highlight_path[i], highlight_path[i+1]) \n",
    "                              for i in range(len(highlight_path)-1)]\n",
    "            nx.draw_networkx_edges(G, pos, edgelist=highlight_edges,\n",
    "                                   edge_color='red', width=2,\n",
    "                                   arrows=True, arrowsize=25)\n",
    "        \n",
    "        # ç”»èŠ‚ç‚¹\n",
    "        nx.draw_networkx_nodes(G, pos, node_color='lightblue', \n",
    "                               node_size=2000, alpha=0.9)\n",
    "        nx.draw_networkx_labels(G, pos, font_size=14, font_weight='bold')\n",
    "        \n",
    "        plt.title(title, fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"éœ€è¦å®‰è£… networkx: pip install networkx\")\n",
    "        print(f\"\\nè¾¹: {edges}\")\n",
    "\n",
    "# ç”»ä¸€ä¸ªç®€å•çš„æ··æ·†ç»“æ„\n",
    "confounding_edges = [(\"X\", \"T\"), (\"X\", \"Y\"), (\"T\", \"Y\")]\n",
    "draw_dag(confounding_edges, \"ç»å…¸æ··æ·†ç»“æ„: X æ˜¯æ··æ·†å˜é‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ” Part 2: ä¸‰ç§æ ¸å¿ƒå› æœç»“æ„\n",
    "\n",
    "å› æœå›¾ä¸­æœ‰ä¸‰ç§æœ€åŸºæœ¬çš„ç»“æ„ï¼Œç†è§£å®ƒä»¬æ˜¯æŒæ¡å› æœæ¨æ–­çš„å…³é”®ï¼\n",
    "\n",
    "### ç»“æ„ 1: å‰å­ (Fork) - æ··æ·†\n",
    "\n",
    "```\n",
    "T â† X â†’ Y\n",
    "```\n",
    "\n",
    "**ç‰¹ç‚¹**: X åŒæ—¶å½±å“ T å’Œ Y\n",
    "\n",
    "**ä¾‹å­**: \n",
    "- X = å¹´é¾„\n",
    "- T = æ˜¯å¦å–å’–å•¡\n",
    "- Y = æ˜¯å¦æœ‰å¿ƒè„ç—…\n",
    "\n",
    "å¹´è½»äººå–å’–å•¡æ›´å¤šï¼Œä½†å¹´è½»äººå¿ƒè„ç—…ä¹Ÿæ›´å°‘ã€‚å¦‚æœä¸æ§åˆ¶å¹´é¾„ï¼Œä¼šé”™è¯¯åœ°è®¤ä¸ºå’–å•¡é¢„é˜²å¿ƒè„ç—…ï¼\n",
    "\n",
    "**è§„åˆ™**: éœ€è¦æ§åˆ¶ X æ¥é˜»æ–­æ··æ·†\n",
    "\n",
    "---\n",
    "\n",
    "### ç»“æ„ 2: é“¾æ¡ (Chain) - ä¸­ä»‹\n",
    "\n",
    "```\n",
    "T â†’ M â†’ Y\n",
    "```\n",
    "\n",
    "**ç‰¹ç‚¹**: T é€šè¿‡ M å½±å“ Y\n",
    "\n",
    "**ä¾‹å­**:\n",
    "- T = å—æ•™è‚²ç¨‹åº¦\n",
    "- M = æ”¶å…¥\n",
    "- Y = å¥åº·çŠ¶å†µ\n",
    "\n",
    "æ•™è‚²é€šè¿‡æé«˜æ”¶å…¥æ¥æ”¹å–„å¥åº·ã€‚M æ˜¯ä¸­ä»‹å˜é‡ã€‚\n",
    "\n",
    "**è§„åˆ™**: \n",
    "- å¦‚æœæƒ³ä¼°è®¡ T çš„**æ€»æ•ˆåº”**ï¼Œä¸è¦æ§åˆ¶ M\n",
    "- å¦‚æœæƒ³ä¼°è®¡ T çš„**ç›´æ¥æ•ˆåº”**ï¼Œéœ€è¦æ§åˆ¶ M\n",
    "\n",
    "---\n",
    "\n",
    "### ç»“æ„ 3: ç¢°æ’ (Collider) - ç¢°æ’å˜é‡\n",
    "\n",
    "```\n",
    "T â†’ C â† Y\n",
    "```\n",
    "\n",
    "**ç‰¹ç‚¹**: T å’Œ Y éƒ½å½±å“ C\n",
    "\n",
    "**ä¾‹å­** (ç»å…¸ï¼):\n",
    "- T = æ¼”æŠ€å¥½\n",
    "- Y = é¢œå€¼é«˜\n",
    "- C = æˆä¸ºæ˜æ˜Ÿ\n",
    "\n",
    "æˆä¸ºæ˜æ˜Ÿéœ€è¦æ¼”æŠ€**æˆ–**é¢œå€¼ï¼ˆè‡³å°‘ä¸€ä¸ªï¼‰ã€‚åœ¨æ˜æ˜Ÿç¾¤ä½“ä¸­ï¼Œæ¼”æŠ€å¥½å’Œé¢œå€¼é«˜ä¼šå‘ˆç°è´Ÿç›¸å…³â€”â€”å› ä¸ºåªé é¢œå€¼çš„äººæ¼”æŠ€å¯èƒ½ä¸å¥½ï¼Œåªé æ¼”æŠ€çš„äººå¯èƒ½ä¸æ˜¯é è„¸åƒé¥­ã€‚\n",
    "\n",
    "**è§„åˆ™**: åƒä¸‡ä¸è¦æ§åˆ¶ç¢°æ’å˜é‡ Cï¼å¦åˆ™ä¼šåˆ›é€ è™šå‡å…³è”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”»å‡ºä¸‰ç§ç»“æ„\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "structures = [\n",
    "    ([(\"X\", \"T\"), (\"X\", \"Y\")], \"Fork (å‰å­/æ··æ·†)\\nT â† X â†’ Y\\næ§åˆ¶ X âœ“\"),\n",
    "    ([(\"T\", \"M\"), (\"M\", \"Y\")], \"Chain (é“¾æ¡/ä¸­ä»‹)\\nT â†’ M â†’ Y\\né€šå¸¸ä¸æ§åˆ¶ M\"),\n",
    "    ([(\"T\", \"C\"), (\"Y\", \"C\")], \"Collider (ç¢°æ’)\\nT â†’ C â† Y\\nç»å¯¹ä¸æ§åˆ¶ C âœ—\")\n",
    "]\n",
    "\n",
    "for idx, (edges, title) in enumerate(structures):\n",
    "    ax = axes[idx]\n",
    "    try:\n",
    "        import networkx as nx\n",
    "        G = nx.DiGraph()\n",
    "        G.add_edges_from(edges)\n",
    "        pos = nx.spring_layout(G, seed=42)\n",
    "        \n",
    "        nx.draw_networkx_edges(G, pos, ax=ax, edge_color='gray', \n",
    "                               arrows=True, arrowsize=20)\n",
    "        nx.draw_networkx_nodes(G, pos, ax=ax, node_color='lightblue', \n",
    "                               node_size=1500, alpha=0.9)\n",
    "        nx.draw_networkx_labels(G, pos, ax=ax, font_size=12, font_weight='bold')\n",
    "        ax.set_title(title, fontsize=11)\n",
    "        ax.axis('off')\n",
    "    except:\n",
    "        ax.text(0.5, 0.5, f\"è¾¹: {edges}\\n{title}\", ha='center', va='center')\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ§ª ç»ƒä¹ : è¯†åˆ«å› æœç»“æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_structure(edges: List[Tuple[str, str]], node: str) -> str:\n",
    "    \"\"\"\n",
    "    æ ¹æ® DAG è¾¹ï¼Œè¯†åˆ«ç»™å®šèŠ‚ç‚¹çš„å› æœç»“æ„ç±»å‹\n",
    "    \n",
    "    ç»“æ„ç±»å‹:\n",
    "    - \"confounder\": æ··æ·†å˜é‡ (å‡ºåº¦ >= 2ï¼Œåƒå‰å­çš„ä¸­å¿ƒ)\n",
    "    - \"mediator\": ä¸­ä»‹å˜é‡ (å…¥åº¦ >= 1 ä¸” å‡ºåº¦ >= 1ï¼Œåœ¨é“¾æ¡ä¸­é—´)\n",
    "    - \"collider\": ç¢°æ’å˜é‡ (å…¥åº¦ >= 2ï¼Œåƒç¢°æ’çš„ä¸­å¿ƒ)\n",
    "    \n",
    "    Args:\n",
    "        edges: è¾¹åˆ—è¡¨ï¼Œå¦‚ [(\"X\", \"T\"), (\"X\", \"Y\"), (\"T\", \"Y\")]\n",
    "        node: è¦è¯†åˆ«çš„èŠ‚ç‚¹\n",
    "    \n",
    "    Returns:\n",
    "        ç»“æ„ç±»å‹å­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    # è®¡ç®—å…¥åº¦ï¼šæœ‰å¤šå°‘æ¡è¾¹æŒ‡å‘è¿™ä¸ªèŠ‚ç‚¹\n",
    "    in_degree = sum(1 for edge in edges if edge[1] == node)\n",
    "    \n",
    "    # è®¡ç®—å‡ºåº¦ï¼šè¿™ä¸ªèŠ‚ç‚¹æœ‰å¤šå°‘æ¡è¾¹æŒ‡å‡ºå»\n",
    "    out_degree = sum(1 for edge in edges if edge[0] == node)\n",
    "    \n",
    "    # TODO: æ ¹æ®å…¥åº¦å’Œå‡ºåº¦åˆ¤æ–­ç»“æ„ç±»å‹\n",
    "    # ç¢°æ’å˜é‡ (collider): å…¥åº¦ >= 2, å‡ºåº¦ = 0ï¼ˆå¤šä¸ªç®­å¤´æŒ‡å‘å®ƒï¼‰\n",
    "    # æ··æ·†å˜é‡ (confounder): å‡ºåº¦ >= 2ï¼ˆå®ƒæŒ‡å‘å¤šä¸ªèŠ‚ç‚¹ï¼‰\n",
    "    # ä¸­ä»‹å˜é‡ (mediator): å…¥åº¦ >= 1 ä¸” å‡ºåº¦ >= 1ï¼ˆåœ¨é“¾æ¡ä¸­é—´ï¼‰\n",
    "    \n",
    "    # ğŸ‘ˆ ä½ çš„ä»£ç \n",
    "    if in_degree >= 2 and out_degree == 0:\n",
    "        return None  # è¿™æ˜¯ä»€ä¹ˆç±»å‹ï¼Ÿ\n",
    "    elif out_degree >= 2:\n",
    "        return None  # è¿™æ˜¯ä»€ä¹ˆç±»å‹ï¼Ÿ\n",
    "    elif in_degree >= 1 and out_degree >= 1:\n",
    "        return None  # è¿™æ˜¯ä»€ä¹ˆç±»å‹ï¼Ÿ\n",
    "    else:\n",
    "        return \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•ä½ çš„ä»£ç \n",
    "test_edges = [(\"X\", \"T\"), (\"X\", \"Y\"), (\"T\", \"Y\")]\n",
    "\n",
    "print(\"DAG: X â†’ T, X â†’ Y, T â†’ Y\")\n",
    "print(\"\\nè¯†åˆ«æ¯ä¸ªèŠ‚ç‚¹çš„è§’è‰²:\")\n",
    "\n",
    "for node in [\"X\", \"T\", \"Y\"]:\n",
    "    structure = identify_structure(test_edges, node)\n",
    "    if structure:\n",
    "        print(f\"   èŠ‚ç‚¹ {node}: {structure}\")\n",
    "    else:\n",
    "        print(f\"   èŠ‚ç‚¹ {node}: [æœªå®Œæˆ]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ›¤ï¸ Part 3: è·¯å¾„ä¸åé—¨å‡†åˆ™\n",
    "\n",
    "### ä»€ä¹ˆæ˜¯ã€Œè·¯å¾„ã€ï¼Ÿ\n",
    "\n",
    "åœ¨å› æœå›¾ä¸­ï¼Œä» T åˆ° Y å¯èƒ½æœ‰å¤šæ¡è·¯å¾„ï¼š\n",
    "\n",
    "```\n",
    "    X\n",
    "   â†™ â†˜\n",
    "  T â†’ Y\n",
    "```\n",
    "\n",
    "ä» T åˆ° Y æœ‰ä¸¤æ¡è·¯å¾„ï¼š\n",
    "1. **ç›´æ¥è·¯å¾„ (å› æœè·¯å¾„)**: T â†’ Y âœ…\n",
    "2. **åé—¨è·¯å¾„**: T â† X â†’ Y âš ï¸\n",
    "\n",
    "### ä»€ä¹ˆæ˜¯ã€Œåé—¨è·¯å¾„ã€ï¼Ÿ\n",
    "\n",
    "åé—¨è·¯å¾„æ˜¯ä» T åˆ° Y çš„è·¯å¾„ä¸­ï¼Œç¬¬ä¸€ä¸ªç®­å¤´**æŒ‡å‘ T** çš„è·¯å¾„ã€‚\n",
    "\n",
    "- T â†’ Y ä¸æ˜¯åé—¨ï¼ˆç®­å¤´ä» T å‡ºå‘ï¼‰\n",
    "- T â† X â†’ Y æ˜¯åé—¨ï¼ˆç¬¬ä¸€ä¸ªç®­å¤´æŒ‡å‘ Tï¼‰\n",
    "\n",
    "**åé—¨è·¯å¾„ä¼šé€ æˆæ··æ·†åå·®ï¼æˆ‘ä»¬éœ€è¦æŠŠå®ƒé˜»æ–­ã€‚**\n",
    "\n",
    "### åé—¨å‡†åˆ™ (Backdoor Criterion)\n",
    "\n",
    "è¦æ— ååœ°ä¼°è®¡ T å¯¹ Y çš„å› æœæ•ˆåº”ï¼Œéœ€è¦æ‰¾åˆ°ä¸€ç»„å˜é‡ Z æ»¡è¶³ï¼š\n",
    "\n",
    "1. Z é˜»æ–­äº†æ‰€æœ‰ä» T åˆ° Y çš„åé—¨è·¯å¾„\n",
    "2. Z ä¸åŒ…å« T çš„ä»»ä½•åä»£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_paths(edges: List[Tuple[str, str]], \n",
    "                   start: str, \n",
    "                   end: str,\n",
    "                   ignore_direction: bool = True) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    æ‰¾å‡º DAG ä¸­ä» start åˆ° end çš„æ‰€æœ‰è·¯å¾„\n",
    "    \n",
    "    Args:\n",
    "        edges: è¾¹åˆ—è¡¨\n",
    "        start: èµ·å§‹èŠ‚ç‚¹\n",
    "        end: ç»ˆæ­¢èŠ‚ç‚¹\n",
    "        ignore_direction: æ˜¯å¦å¿½ç•¥è¾¹çš„æ–¹å‘ï¼ˆæ‰¾åé—¨è·¯å¾„æ—¶éœ€è¦å¿½ç•¥ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "        è·¯å¾„åˆ—è¡¨ï¼Œæ¯æ¡è·¯å¾„æ˜¯èŠ‚ç‚¹åºåˆ—\n",
    "    \"\"\"\n",
    "    # æ„å»ºé‚»æ¥è¡¨\n",
    "    adj = {}\n",
    "    for u, v in edges:\n",
    "        if u not in adj:\n",
    "            adj[u] = []\n",
    "        adj[u].append(v)\n",
    "        \n",
    "        if ignore_direction:  # å¦‚æœå¿½ç•¥æ–¹å‘ï¼Œä¹Ÿæ·»åŠ åå‘è¾¹\n",
    "            if v not in adj:\n",
    "                adj[v] = []\n",
    "            adj[v].append(u)\n",
    "    \n",
    "    paths = []\n",
    "    \n",
    "    # TODO: ä½¿ç”¨ DFS æ‰¾å‡ºæ‰€æœ‰è·¯å¾„\n",
    "    def dfs(current, path, visited):\n",
    "        \"\"\"\n",
    "        æ·±åº¦ä¼˜å…ˆæœç´¢æ‰¾è·¯å¾„\n",
    "        \n",
    "        current: å½“å‰èŠ‚ç‚¹\n",
    "        path: å½“å‰è·¯å¾„\n",
    "        visited: å·²è®¿é—®èŠ‚ç‚¹é›†åˆ\n",
    "        \"\"\"\n",
    "        # å¦‚æœåˆ°è¾¾ç»ˆç‚¹ï¼Œä¿å­˜è·¯å¾„\n",
    "        if current == end:\n",
    "            paths.append(path.copy())\n",
    "            return\n",
    "        \n",
    "        # éå†é‚»å±…\n",
    "        for neighbor in adj.get(current, []):\n",
    "            if neighbor not in visited:\n",
    "                # ğŸ‘ˆ ä½ çš„ä»£ç ï¼šå°†é‚»å±…åŠ å…¥å·²è®¿é—®ï¼Œé€’å½’è°ƒç”¨ï¼Œç„¶åç§»é™¤\n",
    "                # æç¤º: \n",
    "                # 1. visited.add(neighbor)\n",
    "                # 2. path.append(neighbor)\n",
    "                # 3. dfs(neighbor, path, visited)\n",
    "                # 4. path.pop()\n",
    "                # 5. visited.remove(neighbor)\n",
    "                pass\n",
    "    \n",
    "    dfs(start, [start], {start})\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_backdoor_paths(edges: List[Tuple[str, str]], \n",
    "                            treatment: str, \n",
    "                            outcome: str) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    è¯†åˆ«ä» treatment åˆ° outcome çš„åé—¨è·¯å¾„\n",
    "    \n",
    "    åé—¨è·¯å¾„: ä» T åˆ° Y çš„è·¯å¾„ï¼Œå…¶ä¸­ç¬¬ä¸€æ¡è¾¹æŒ‡å‘ T\n",
    "    \n",
    "    Returns:\n",
    "        åé—¨è·¯å¾„åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    all_paths = find_all_paths(edges, treatment, outcome, ignore_direction=True)\n",
    "    \n",
    "    backdoor_paths = []\n",
    "    for path in all_paths:\n",
    "        if len(path) < 2:\n",
    "            continue\n",
    "        \n",
    "        # TODO: æ£€æŸ¥æ˜¯å¦æ˜¯åé—¨è·¯å¾„\n",
    "        # åé—¨è·¯å¾„çš„ç¬¬ä¸€æ¡è¾¹æŒ‡å‘ treatment\n",
    "        # å³æ£€æŸ¥ (path[1], treatment) æ˜¯å¦åœ¨ edges ä¸­\n",
    "        \n",
    "        first_step = path[1]  # è·¯å¾„ä¸Šçš„ç¬¬äºŒä¸ªèŠ‚ç‚¹\n",
    "        \n",
    "        # æ£€æŸ¥è¾¹ first_step â†’ treatment æ˜¯å¦å­˜åœ¨\n",
    "        # ğŸ‘ˆ ä½ çš„ä»£ç \n",
    "        is_backdoor = None  # (first_step, treatment) in edges\n",
    "        \n",
    "        if is_backdoor:\n",
    "            backdoor_paths.append(path)\n",
    "    \n",
    "    return backdoor_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•åé—¨è·¯å¾„è¯†åˆ«\n",
    "test_edges = [(\"X\", \"T\"), (\"X\", \"Y\"), (\"T\", \"Y\")]\n",
    "\n",
    "print(\"DAG: X â†’ T, X â†’ Y, T â†’ Y\")\n",
    "print(\"\\nå¯»æ‰¾ä» T åˆ° Y çš„è·¯å¾„...\")\n",
    "\n",
    "all_paths = find_all_paths(test_edges, \"T\", \"Y\", ignore_direction=True)\n",
    "print(f\"\\næ‰€æœ‰è·¯å¾„: {all_paths}\")\n",
    "\n",
    "backdoor = identify_backdoor_paths(test_edges, \"T\", \"Y\")\n",
    "print(f\"åé—¨è·¯å¾„: {backdoor}\")\n",
    "\n",
    "if backdoor:\n",
    "    print(f\"\\nâœ… éœ€è¦æ§åˆ¶çš„å˜é‡: {set(sum(backdoor, [])) - {'T', 'Y'}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”’ Part 4: é˜»æ–­è·¯å¾„\n",
    "\n",
    "### é˜»æ–­è§„åˆ™\n",
    "\n",
    "| ç»“æ„ | è·¯å¾„ | æ§åˆ¶ä¸­é—´èŠ‚ç‚¹å |\n",
    "|-----|------|-------------|\n",
    "| Fork | A â† X â†’ B | **é˜»æ–­** |\n",
    "| Chain | A â†’ X â†’ B | **é˜»æ–­** |\n",
    "| Collider | A â†’ X â† B | **æ‰“å¼€**ï¼ˆåŸæœ¬æ˜¯é˜»æ–­çš„ï¼ï¼‰|\n",
    "\n",
    "âš ï¸ **å…³é”®ç‚¹**: ç¢°æ’å˜é‡é»˜è®¤æ˜¯é˜»æ–­çš„ï¼Œæ§åˆ¶å®ƒåè€Œä¼šæ‰“å¼€è·¯å¾„ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_adjustment_set(edges: List[Tuple[str, str]], \n",
    "                            treatment: str, \n",
    "                            outcome: str,\n",
    "                            adjustment_set: Set[str]) -> bool:\n",
    "    \"\"\"\n",
    "    æ£€æŸ¥ç»™å®šçš„è°ƒæ•´é›†æ˜¯å¦æœ‰æ•ˆï¼ˆæ»¡è¶³åé—¨å‡†åˆ™ï¼‰\n",
    "    \n",
    "    åé—¨å‡†åˆ™è¦æ±‚è°ƒæ•´é›†:\n",
    "    1. é˜»æ–­æ‰€æœ‰åé—¨è·¯å¾„\n",
    "    2. ä¸åŒ…å« treatment çš„åä»£\n",
    "    \n",
    "    Returns:\n",
    "        True å¦‚æœè°ƒæ•´é›†æœ‰æ•ˆ\n",
    "    \"\"\"\n",
    "    # æ­¥éª¤ 1: æ‰¾å‡º treatment çš„æ‰€æœ‰åä»£\n",
    "    def find_descendants(node):\n",
    "        \"\"\"æ‰¾å‡ºä¸€ä¸ªèŠ‚ç‚¹çš„æ‰€æœ‰åä»£\"\"\"\n",
    "        descendants = set()\n",
    "        to_visit = [n for (s, n) in edges if s == node]\n",
    "        while to_visit:\n",
    "            current = to_visit.pop()\n",
    "            if current not in descendants:\n",
    "                descendants.add(current)\n",
    "                to_visit.extend([n for (s, n) in edges if s == current])\n",
    "        return descendants\n",
    "    \n",
    "    descendants_of_T = find_descendants(treatment)\n",
    "    \n",
    "    # TODO: æ£€æŸ¥è°ƒæ•´é›†æ˜¯å¦åŒ…å« treatment çš„åä»£\n",
    "    # ğŸ‘ˆ ä½ çš„ä»£ç \n",
    "    contains_descendant = None  # bool(adjustment_set & descendants_of_T)\n",
    "    \n",
    "    if contains_descendant:\n",
    "        return False  # è¿åæ¡ä»¶ 2\n",
    "    \n",
    "    # æ­¥éª¤ 2: æ‰¾å‡ºæ‰€æœ‰åé—¨è·¯å¾„\n",
    "    backdoor_paths = identify_backdoor_paths(edges, treatment, outcome)\n",
    "    \n",
    "    # TODO: æ£€æŸ¥è°ƒæ•´é›†æ˜¯å¦é˜»æ–­æ‰€æœ‰åé—¨è·¯å¾„\n",
    "    # ä¸€æ¡è·¯å¾„è¢«é˜»æ–­å½“ä¸”ä»…å½“è°ƒæ•´é›†åŒ…å«è·¯å¾„ä¸Šçš„è‡³å°‘ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆé™¤äº† T å’Œ Yï¼‰\n",
    "    for path in backdoor_paths:\n",
    "        path_nodes = set(path) - {treatment, outcome}\n",
    "        # ğŸ‘ˆ ä½ çš„ä»£ç ï¼šæ£€æŸ¥ adjustment_set æ˜¯å¦ä¸ path_nodes æœ‰äº¤é›†\n",
    "        is_blocked = None\n",
    "        \n",
    "        if not is_blocked:\n",
    "            return False  # æœ‰åé—¨è·¯å¾„æ²¡è¢«é˜»æ–­\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•è°ƒæ•´é›†\n",
    "test_edges = [(\"X\", \"T\"), (\"X\", \"Y\"), (\"T\", \"Y\")]\n",
    "\n",
    "print(\"DAG: X â†’ T, X â†’ Y, T â†’ Y\")\n",
    "print(\"\\næ£€éªŒä¸åŒçš„è°ƒæ•´é›†:\")\n",
    "\n",
    "adjustment_sets = [set(), {\"X\"}, {\"Y\"}]\n",
    "for adj_set in adjustment_sets:\n",
    "    result = is_valid_adjustment_set(test_edges, \"T\", \"Y\", adj_set)\n",
    "    status = \"âœ… æœ‰æ•ˆ\" if result else \"âŒ æ— æ•ˆ\"\n",
    "    print(f\"   è°ƒæ•´é›† {adj_set if adj_set else '{}'}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ® Part 5: æ¨¡æ‹ŸéªŒè¯\n",
    "\n",
    "è®©æˆ‘ä»¬ç”¨æ¨¡æ‹Ÿæ•°æ®æ¥éªŒè¯å› æœå›¾çš„ç†è®ºï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_confounding_dag(n: int = 2000, seed: int = 42):\n",
    "    \"\"\"\n",
    "    æ¨¡æ‹Ÿç»å…¸æ··æ·† DAG çš„æ•°æ®\n",
    "    \n",
    "    DAG: X â†’ T, X â†’ Y, T â†’ Y\n",
    "    \n",
    "    æ•°æ®ç”Ÿæˆè¿‡ç¨‹:\n",
    "    - X ~ N(0, 1)\n",
    "    - T = 1 if X + noise > 0 else 0\n",
    "    - Y = 1 + 2*T + 1.5*X + noise\n",
    "    \n",
    "    çœŸå® ATE = 2\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆæ··æ·†å˜é‡ X\n",
    "    X = None  # ğŸ‘ˆ ä½ çš„ä»£ç : np.random.randn(n)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆå¤„ç† Tï¼ˆå— X å½±å“ï¼‰\n",
    "    # T = 1 å½“ X + noise > 0\n",
    "    T = None  # ğŸ‘ˆ ä½ çš„ä»£ç : (X + np.random.randn(n) > 0).astype(int)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆç»“æœ Yï¼ˆå— T å’Œ X å½±å“ï¼‰\n",
    "    # Y = 1 + 2*T + 1.5*X + noise\n",
    "    Y = None  # ğŸ‘ˆ ä½ çš„ä»£ç \n",
    "    \n",
    "    df = pd.DataFrame({'X': X, 'T': T, 'Y': Y})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_ate_with_adjustment(df: pd.DataFrame, \n",
    "                                  adjustment_vars: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨çº¿æ€§å›å½’è¿›è¡Œè°ƒæ•´ä¼°è®¡\n",
    "    \n",
    "    Y = b0 + b1*T + b2*X1 + b3*X2 + ...\n",
    "    b1 å°±æ˜¯è°ƒæ•´åçš„ ATE ä¼°è®¡\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    # æ„å»ºç‰¹å¾çŸ©é˜µ\n",
    "    features = ['T'] + adjustment_vars\n",
    "    X = df[features].values\n",
    "    y = df['Y'].values\n",
    "    \n",
    "    # æ‹Ÿåˆçº¿æ€§å›å½’\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # T çš„ç³»æ•°å°±æ˜¯è°ƒæ•´åçš„ ATE\n",
    "    return model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œæ¨¡æ‹Ÿ\n",
    "df = simulate_confounding_dag(n=5000)\n",
    "\n",
    "if df is not None and df['X'] is not None:\n",
    "    true_ate = 2.0\n",
    "    \n",
    "    # æœ´ç´ ä¼°è®¡ï¼ˆä¸æ§åˆ¶ä»»ä½•å˜é‡ï¼‰\n",
    "    naive_ate = df[df['T']==1]['Y'].mean() - df[df['T']==0]['Y'].mean()\n",
    "    \n",
    "    # è°ƒæ•´ä¼°è®¡ï¼ˆæ§åˆ¶ Xï¼‰\n",
    "    adjusted_ate = estimate_ate_with_adjustment(df, ['X'])\n",
    "    \n",
    "    print(\"ğŸ”¬ æ··æ·† DAG æ¨¡æ‹Ÿç»“æœ:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"çœŸå® ATE: {true_ate:.4f}\")\n",
    "    print(f\"\\næœ´ç´ ä¼°è®¡ï¼ˆä¸æ§åˆ¶ Xï¼‰: {naive_ate:.4f}\")\n",
    "    print(f\"   åå·®: {naive_ate - true_ate:+.4f} {'âš ï¸ æœ‰åï¼' if abs(naive_ate - true_ate) > 0.1 else ''}\")\n",
    "    print(f\"\\nè°ƒæ•´ä¼°è®¡ï¼ˆæ§åˆ¶ Xï¼‰: {adjusted_ate:.4f}\")\n",
    "    print(f\"   åå·®: {adjusted_ate - true_ate:+.4f} {'âœ… å¾ˆå‡†ï¼' if abs(adjusted_ate - true_ate) < 0.1 else ''}\")\n",
    "else:\n",
    "    print(\"âŒ è¯·å®Œæˆ simulate_confounding_dag å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âš ï¸ Part 6: ç¢°æ’åå·®çš„å±é™©\n",
    "\n",
    "è¿™æ˜¯å› æœæ¨æ–­ä¸­æœ€å®¹æ˜“è¸©çš„å‘ä¹‹ä¸€ï¼\n",
    "\n",
    "### å¥½è±åæ‚–è®º ğŸ¬\n",
    "\n",
    "å¦‚æœä½ åªçœ‹å¥½è±åæ˜æ˜Ÿï¼Œä½ ä¼šå‘ç°ï¼š\n",
    "- é¢œå€¼é«˜çš„æ¼”æŠ€å¾€å¾€ä¸€èˆ¬\n",
    "- æ¼”æŠ€å¥½çš„é•¿ç›¸å¾€å¾€ä¸€èˆ¬\n",
    "\n",
    "éš¾é“æ¼”æŠ€å’Œé¢œå€¼æ˜¯è´Ÿç›¸å…³çš„ï¼Ÿ**ä¸æ˜¯çš„ï¼**\n",
    "\n",
    "è¿™æ˜¯å› ä¸ºã€Œæˆä¸ºæ˜æ˜Ÿã€æ˜¯ä¸€ä¸ª**ç¢°æ’å˜é‡**ï¼š\n",
    "\n",
    "```\n",
    "æ¼”æŠ€ â†’ æˆä¸ºæ˜æ˜Ÿ â† é¢œå€¼\n",
    "```\n",
    "\n",
    "å½“æˆ‘ä»¬åªçœ‹æ˜æ˜Ÿï¼ˆæ¡ä»¶äº C=1ï¼‰æ—¶ï¼Œæ‰“å¼€äº†æ¼”æŠ€å’Œé¢œå€¼ä¹‹é—´çš„è™šå‡å…³è”ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_collider_bias(n: int = 2000, seed: int = 42):\n",
    "    \"\"\"\n",
    "    æ¨¡æ‹Ÿç¢°æ’åå·®\n",
    "    \n",
    "    DAG: T â†’ C â† Yï¼ˆT å’Œ Y æœ¬æ¥æ˜¯ç‹¬ç«‹çš„ï¼ï¼‰\n",
    "    \n",
    "    åœºæ™¯: å¥½è±åæ‚–è®º\n",
    "    - T = æ¼”æŠ€ï¼ˆ0åˆ°10åˆ†ï¼‰\n",
    "    - Y = é¢œå€¼ï¼ˆ0åˆ°10åˆ†ï¼‰\n",
    "    - C = æ˜¯å¦æˆä¸ºæ˜æ˜Ÿï¼ˆéœ€è¦æ¼”æŠ€+é¢œå€¼ > 12ï¼‰\n",
    "    \n",
    "    æ¼”æŠ€å’Œé¢œå€¼æ˜¯ç‹¬ç«‹çš„ï¼ä½†åœ¨æ˜æ˜Ÿç¾¤ä½“ä¸­ä¼šå‘ˆç°è´Ÿç›¸å…³ã€‚\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆæ¼”æŠ€ Tï¼ˆç‹¬ç«‹ï¼‰\n",
    "    T = None  # ğŸ‘ˆ ä½ çš„ä»£ç : np.random.uniform(0, 10, n)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆé¢œå€¼ Yï¼ˆç‹¬ç«‹ï¼‰\n",
    "    Y = None  # ğŸ‘ˆ ä½ çš„ä»£ç : np.random.uniform(0, 10, n)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆç¢°æ’å˜é‡ Cï¼ˆæ˜¯å¦æˆä¸ºæ˜æ˜Ÿï¼‰\n",
    "    # å½“ T + Y > 12 æ—¶æˆä¸ºæ˜æ˜Ÿ\n",
    "    C = None  # ğŸ‘ˆ ä½ çš„ä»£ç : (T + Y > 12).astype(int)\n",
    "    \n",
    "    df = pd.DataFrame({'æ¼”æŠ€': T, 'é¢œå€¼': Y, 'æ˜æ˜Ÿ': C})\n",
    "    \n",
    "    # è®¡ç®—ç›¸å…³æ€§\n",
    "    overall_corr = np.corrcoef(T, Y)[0, 1]\n",
    "    \n",
    "    # åªçœ‹æ˜æ˜Ÿçš„ç›¸å…³æ€§\n",
    "    stars = df[df['æ˜æ˜Ÿ'] == 1]\n",
    "    conditional_corr = np.corrcoef(stars['æ¼”æŠ€'], stars['é¢œå€¼'])[0, 1] if len(stars) > 10 else 0\n",
    "    \n",
    "    return df, overall_corr, conditional_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œç¢°æ’åå·®æ¨¡æ‹Ÿ\n",
    "df_collider, overall, conditional = simulate_collider_bias(n=5000)\n",
    "\n",
    "if overall is not None:\n",
    "    print(\"ğŸ¬ å¥½è±åæ‚–è®ºæ¨¡æ‹Ÿ:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"æ€»äººå£ä¸­æ¼”æŠ€å’Œé¢œå€¼çš„ç›¸å…³æ€§: {overall:.4f}\")\n",
    "    print(f\"   è§£è¯»: {'å‡ ä¹ä¸ç›¸å…³ âœ…' if abs(overall) < 0.1 else 'æœ‰ç›¸å…³æ€§'}\")\n",
    "    print(f\"\\nåªçœ‹æ˜æ˜Ÿæ—¶æ¼”æŠ€å’Œé¢œå€¼çš„ç›¸å…³æ€§: {conditional:.4f}\")\n",
    "    print(f\"   è§£è¯»: {'å¼ºè´Ÿç›¸å…³ âš ï¸' if conditional < -0.3 else 'æœ‰è´Ÿç›¸å…³'}\")\n",
    "    \n",
    "    print(f\"\\næ˜æ˜Ÿå æ€»äººå£: {df_collider['æ˜æ˜Ÿ'].mean()*100:.1f}%\")\n",
    "else:\n",
    "    print(\"âŒ è¯·å®Œæˆ simulate_collider_bias å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ç¢°æ’åå·®\n",
    "if overall is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # å›¾1: æ€»äººå£\n",
    "    ax1 = axes[0]\n",
    "    stars = df_collider[df_collider['æ˜æ˜Ÿ'] == 1]\n",
    "    non_stars = df_collider[df_collider['æ˜æ˜Ÿ'] == 0]\n",
    "    \n",
    "    ax1.scatter(non_stars['æ¼”æŠ€'], non_stars['é¢œå€¼'], \n",
    "                alpha=0.3, c='gray', label='æ™®é€šäºº', s=20)\n",
    "    ax1.scatter(stars['æ¼”æŠ€'], stars['é¢œå€¼'], \n",
    "                alpha=0.7, c='gold', label='æ˜æ˜Ÿ', s=50, edgecolors='black')\n",
    "    ax1.set_xlabel('æ¼”æŠ€')\n",
    "    ax1.set_ylabel('é¢œå€¼')\n",
    "    ax1.set_title(f'æ€»äººå£\\nç›¸å…³æ€§ = {overall:.3f}')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # å›¾2: åªçœ‹æ˜æ˜Ÿ\n",
    "    ax2 = axes[1]\n",
    "    ax2.scatter(stars['æ¼”æŠ€'], stars['é¢œå€¼'], \n",
    "                alpha=0.7, c='gold', s=50, edgecolors='black')\n",
    "    \n",
    "    # æ·»åŠ è¶‹åŠ¿çº¿\n",
    "    z = np.polyfit(stars['æ¼”æŠ€'], stars['é¢œå€¼'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_line = np.linspace(stars['æ¼”æŠ€'].min(), stars['æ¼”æŠ€'].max(), 100)\n",
    "    ax2.plot(x_line, p(x_line), 'r--', linewidth=2, label='è¶‹åŠ¿çº¿')\n",
    "    \n",
    "    ax2.set_xlabel('æ¼”æŠ€')\n",
    "    ax2.set_ylabel('é¢œå€¼')\n",
    "    ax2.set_title(f'åªçœ‹æ˜æ˜Ÿç¾¤ä½“\\nç›¸å…³æ€§ = {conditional:.3f} (è™šå‡è´Ÿç›¸å…³ï¼)')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nğŸ’¡ å¯ç¤º: æ§åˆ¶ç¢°æ’å˜é‡ä¼šåˆ›é€ è™šå‡å…³è”ï¼\")\n",
    "    print(\"   åœ¨å› æœæ¨æ–­ä¸­ï¼Œç»å¯¹ä¸èƒ½æ§åˆ¶ç¢°æ’å˜é‡ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Part 7: æ€è€ƒé¢˜\n",
    "\n",
    "### é—®é¢˜ 1: DAG åˆ†æ\n",
    "\n",
    "ç»™å®šä»¥ä¸‹ DAG:\n",
    "\n",
    "```\n",
    "X â†’ T â†’ Y â† U â†’ X\n",
    "```\n",
    "\n",
    "å›ç­”:\n",
    "- T å’Œ Y ä¹‹é—´æœ‰å“ªäº›è·¯å¾„ï¼Ÿ\n",
    "- å“ªäº›æ˜¯åé—¨è·¯å¾„ï¼Ÿ\n",
    "- æœ€å°è°ƒæ•´é›†æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„åˆ†æ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 2: ä¸ºä»€ä¹ˆæ§åˆ¶ç¢°æ’å˜é‡ä¼šå¼•å…¥åå·®ï¼Ÿ\n",
    "\n",
    "**æç¤º:** æƒ³æƒ³å¥½è±åæ‚–è®ºçš„ä¾‹å­...\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 3: ä¸­ä»‹å˜é‡åº”è¯¥æ§åˆ¶å—ï¼Ÿ\n",
    "\n",
    "åœ¨ä»¥ä¸‹ DAG ä¸­ï¼šT â†’ M â†’ Y\n",
    "\n",
    "- ä»€ä¹ˆæ—¶å€™åº”è¯¥æ§åˆ¶ Mï¼Ÿ\n",
    "- ä»€ä¹ˆæ—¶å€™ä¸åº”è¯¥æ§åˆ¶ Mï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 4: æœªè§‚æµ‹æ··æ·†\n",
    "\n",
    "å¦‚æœå­˜åœ¨æœªè§‚æµ‹çš„æ··æ·†å˜é‡ Uï¼ˆæˆ‘ä»¬æ²¡æœ‰æ•°æ®ï¼‰ï¼Œæœ‰ä»€ä¹ˆæ–¹æ³•å¯ä»¥è¯†åˆ«å› æœæ•ˆåº”ï¼Ÿ\n",
    "\n",
    "**æç¤º:** æƒ³æƒ³å·¥å…·å˜é‡ã€æ–­ç‚¹å›å½’ã€åŒé‡å·®åˆ†...\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ‰ æ€»ç»“\n",
    "\n",
    "### æ ¸å¿ƒçŸ¥è¯†ç‚¹\n",
    "\n",
    "| æ¦‚å¿µ | å®šä¹‰ | è§„åˆ™ |\n",
    "|-----|------|------|\n",
    "| æ··æ·†å˜é‡ | T â† X â†’ Y | å¿…é¡»æ§åˆ¶ |\n",
    "| ä¸­ä»‹å˜é‡ | T â†’ M â†’ Y | ä¼°è®¡æ€»æ•ˆåº”æ—¶ä¸æ§åˆ¶ |\n",
    "| ç¢°æ’å˜é‡ | T â†’ C â† Y | ç»å¯¹ä¸èƒ½æ§åˆ¶ |\n",
    "\n",
    "### åé—¨å‡†åˆ™\n",
    "\n",
    "è¦æ— åä¼°è®¡ T å¯¹ Y çš„æ•ˆåº”ï¼š\n",
    "1. æ‰¾å‡ºæ‰€æœ‰åé—¨è·¯å¾„\n",
    "2. é€‰æ‹©ä¸€ç»„å˜é‡é˜»æ–­æ‰€æœ‰åé—¨è·¯å¾„\n",
    "3. ç¡®ä¿è¿™ç»„å˜é‡ä¸åŒ…å« T çš„åä»£\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬çŸ¥é“äº†ã€Œåº”è¯¥æ§åˆ¶ä»€ä¹ˆã€ï¼Œä¸‹ä¸€ä¸ªç»ƒä¹ æˆ‘ä»¬å°†æ·±å…¥å­¦ä¹ **æ··æ·†åå·®**â€”â€”å®ƒæœ‰å¤šå¤§ï¼Ÿæ€ä¹ˆé‡åŒ–ï¼Ÿæ€ä¹ˆé¿å…ï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "**ã€Œç”»å›¾å…ˆè¡Œï¼Œåˆ†æåè¡Œã€æ˜¯å› æœæ¨æ–­çš„ç¬¬ä¸€åŸåˆ™ã€‚**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
