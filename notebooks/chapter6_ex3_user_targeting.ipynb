{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ Chapter 6 ç»ƒä¹  3: ç”¨æˆ·å®šå‘å¹²é¢„ - å› æœæ¨æ–­çš„ç»ˆæåº”ç”¨\n",
    "\n",
    "## æŠŠæ‰€æœ‰æŠ€æœ¯ä¸²èµ·æ¥!\n",
    "\n",
    "æ­å–œä½ æ¥åˆ°æœ€åä¸€ä¸ªç»ƒä¹ ï¼è¿™é‡Œæˆ‘ä»¬å°†ç»¼åˆè¿ç”¨å‰é¢å­¦åˆ°çš„æ‰€æœ‰æŠ€æœ¯ï¼š\n",
    "\n",
    "- **CATE ä¼°è®¡**: T-Learner, X-Learner\n",
    "- **ç”¨æˆ·åˆ†ç¾¤**: è¯†åˆ«é«˜ä»·å€¼ç”¨æˆ·\n",
    "- **ç­–ç•¥ä¼˜åŒ–**: æˆæœ¬-æ”¶ç›Šæƒè¡¡\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "1. æŒæ¡ T-Learner å’Œ X-Learner æ–¹æ³•\n",
    "2. å­¦ä¹ æœ€ä¼˜å¹²é¢„ç­–ç•¥ (Policy Learning)\n",
    "3. ç†è§£æˆæœ¬-æ”¶ç›Šæƒè¡¡\n",
    "4. è¿›è¡Œæ•æ„Ÿæ€§åˆ†æ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒŸ åœºæ™¯: ç½‘çº¦è½¦å¸æœºæ¿€åŠ±\n",
    "\n",
    "ä½ æ˜¯ä¸€å®¶ç½‘çº¦è½¦å¹³å°çš„è¿è¥ç»ç†ï¼Œéœ€è¦å†³å®šï¼š\n",
    "\n",
    "> **ç»™å“ªäº›å¸æœºå‘å¥–åŠ±ï¼Ÿæ¯ä¸ªå¥–åŠ±èŠ±è´¹ Â¥100ï¼Œå¸Œæœ›å¸æœºå¤šåœ¨çº¿ï¼Œæ¯å¤šåœ¨çº¿ 1 å°æ—¶å¹³å°èƒ½èµš Â¥30**\n",
    "\n",
    "### å…³é”®æ´å¯Ÿ\n",
    "\n",
    "ä¸åŒå¸æœºå¯¹æ¿€åŠ±çš„ååº”ä¸åŒï¼š\n",
    "\n",
    "| å¸æœºç±»å‹ | æ¿€åŠ±æ•ˆæœ | åŸå›  |\n",
    "|----------|----------|------|\n",
    "| å…¼èŒå¸æœº | +2 å°æ—¶ | å¯¹æ¿€åŠ±æ•æ„Ÿ |\n",
    "| å…¨èŒå¸æœº | +0.5 å°æ—¶ | å·²ç»å¾ˆæ´»è·ƒï¼Œè¾¹é™…æ•ˆåº”å° |\n",
    "| æ–°æ‰‹å¸æœº | +2.5 å°æ—¶ | éœ€è¦æ¿€åŠ±æ¥å»ºç«‹ä¹ æƒ¯ |\n",
    "| è€å¸æœº | +1 å°æ—¶ | å·²ç»æœ‰ç¨³å®šä¹ æƒ¯ |\n",
    "\n",
    "**å…³é”®**: è¦æ‰¾åˆ°é‚£äº›ã€Œæ¿€åŠ±æ•ˆæœå¥½ã€çš„å¸æœºï¼Œè€Œä¸æ˜¯ã€Œæœ¬æ¥å°±æ´»è·ƒã€çš„å¸æœºï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ æ ¸å¿ƒå…¬å¼\n",
    "\n",
    "### æœ€ä¼˜å†³ç­–è§„åˆ™\n",
    "\n",
    "$$\\text{å¹²é¢„} \\Leftrightarrow \\text{CATE}(x) \\times \\text{Value} > \\text{Cost}$$\n",
    "\n",
    "å³ï¼šåªæœ‰å½“é¢„æœŸæ”¶ç›Šè¶…è¿‡æˆæœ¬æ—¶æ‰å¹²é¢„ã€‚\n",
    "\n",
    "### X-Learner å…¬å¼\n",
    "\n",
    "**Stage 1**: è®­ç»ƒä¸¤ä¸ªç»“æœæ¨¡å‹\n",
    "$$\\hat{\\mu}_0(x) = \\mathbb{E}[Y|X=x, T=0]$$\n",
    "$$\\hat{\\mu}_1(x) = \\mathbb{E}[Y|X=x, T=1]$$\n",
    "\n",
    "**Stage 2**: è®¡ç®—ä¼ªå¤„ç†æ•ˆåº”\n",
    "$$D_i^1 = Y_i - \\hat{\\mu}_0(X_i) \\quad \\text{(å¤„ç†ç»„)}$$\n",
    "$$D_i^0 = \\hat{\\mu}_1(X_i) - Y_i \\quad \\text{(æ§åˆ¶ç»„)}$$\n",
    "\n",
    "**Stage 3**: åŠ æƒç»„åˆ\n",
    "$$\\hat{\\tau}(x) = g(x) \\cdot \\hat{\\tau}_0(x) + (1-g(x)) \\cdot \\hat{\\tau}_1(x)$$\n",
    "\n",
    "å…¶ä¸­ $g(x)$ æ˜¯å€¾å‘å¾—åˆ†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯å¢ƒè®¾ç½®\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Dict\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "np.random.seed(42)\n",
    "\n",
    "# ç»˜å›¾è®¾ç½®\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"ç¯å¢ƒé…ç½®å®Œæˆ! ğŸ¯\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  3.1: ç”Ÿæˆå¸æœºæ¿€åŠ±æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_driver_data(\n",
    "    n_samples: int = 2000,\n",
    "    seed: int = 42\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆç½‘çº¦è½¦å¸æœºæ¿€åŠ±æ•°æ®\n",
    "    \n",
    "    åœºæ™¯: å¹³å°ç»™å¸æœºå‘æ”¾å¥–åŠ±ï¼Œæ¿€åŠ±å…¶å¢åŠ åœ¨çº¿æ—¶é•¿\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆå¸æœºç‰¹å¾\n",
    "    # rating: è¯„åˆ† 4.0-5.0\n",
    "    rating = None  # ä½ çš„ä»£ç : np.random.beta(8, 1, n_samples) * 1.0 + 4.0\n",
    "    \n",
    "    # order_history: å†å²å®Œå•æ•°\n",
    "    order_history = None  # ä½ çš„ä»£ç : np.random.poisson(200, n_samples)\n",
    "    \n",
    "    # is_fulltime: æ˜¯å¦å…¨èŒ (30% æ¦‚ç‡)\n",
    "    is_fulltime = None  # ä½ çš„ä»£ç : np.random.binomial(1, 0.3, n_samples)\n",
    "    \n",
    "    # TODO: éšæœºåˆ†é…å¤„ç†\n",
    "    T = None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    # ç”Ÿæˆåœ¨çº¿æ—¶é•¿\n",
    "    online_hours = []\n",
    "    for i in range(n_samples):\n",
    "        if rating is not None and order_history is not None and is_fulltime is not None and T is not None:\n",
    "            # åŸºçº¿æ—¶é•¿\n",
    "            if is_fulltime[i] == 1:\n",
    "                base = 6 + np.random.randn() * 1.5\n",
    "            else:\n",
    "                base = 3 + np.random.randn() * 1.0\n",
    "            \n",
    "            # æ¿€åŠ±æ•ˆåº” (å¼‚è´¨æ€§!)\n",
    "            if T[i] == 1:\n",
    "                # å…¼èŒæ•ˆåº”æ›´å¤§\n",
    "                fulltime_effect = 0.5 if is_fulltime[i] == 1 else 2.0\n",
    "                # ä½å•é‡æ•ˆåº”æ›´å¤§\n",
    "                order_effect = 2.5 if order_history[i] < 150 else 1.0\n",
    "                # ç»¼åˆæ•ˆåº”\n",
    "                effect = (fulltime_effect + order_effect) / 2\n",
    "            else:\n",
    "                effect = 0\n",
    "            \n",
    "            online_hours.append(max(0, base + effect))\n",
    "        else:\n",
    "            online_hours.append(0)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'rating': rating,\n",
    "        'order_history': order_history,\n",
    "        'is_fulltime': is_fulltime,\n",
    "        'T': T,\n",
    "        'online_hours': online_hours\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆæ•°æ®\n",
    "df = generate_driver_data(n_samples=2000)\n",
    "\n",
    "if df is not None and df['rating'].iloc[0] is not None:\n",
    "    print(\"å¸æœºæ•°æ®ç”ŸæˆæˆåŠŸ! ğŸš—\")\n",
    "    print(f\"\\næ ·æœ¬é‡: {len(df)}\")\n",
    "    print(f\"å…¨èŒå¸æœºå æ¯”: {df['is_fulltime'].mean():.2%}\")\n",
    "    print(f\"å¹³å‡åœ¨çº¿æ—¶é•¿: {df['online_hours'].mean():.1f} å°æ—¶\")\n",
    "    print(f\"æ¿€åŠ±ç»„å æ¯”: {df['T'].mean():.2%}\")\n",
    "    \n",
    "    # æŒ‰ç»„æŸ¥çœ‹\n",
    "    print(f\"\\n=== å„ç»„å¹³å‡åœ¨çº¿æ—¶é•¿ ===\")\n",
    "    for is_ft in [0, 1]:\n",
    "        for t in [0, 1]:\n",
    "            mask = (df['is_fulltime']==is_ft) & (df['T']==t)\n",
    "            ft_str = 'å…¨èŒ' if is_ft == 1 else 'å…¼èŒ'\n",
    "            t_str = 'æ¿€åŠ±' if t == 1 else 'æ— æ¿€åŠ±'\n",
    "            print(f\"  {ft_str} + {t_str}: {df.loc[mask, 'online_hours'].mean():.2f} å°æ—¶\")\n",
    "else:\n",
    "    print(\"[TODO] è¯·å®Œæˆ generate_driver_data å‡½æ•°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  3.2: T-Learner CATE ä¼°è®¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLearner:\n",
    "    \"\"\"\n",
    "    T-Learner: åˆ†åˆ«è®­ç»ƒå¤„ç†ç»„å’Œæ§åˆ¶ç»„çš„æ¨¡å‹\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model_control = GradientBoostingRegressor(\n",
    "            n_estimators=50, max_depth=4, random_state=42\n",
    "        )\n",
    "        self.model_treatment = GradientBoostingRegressor(\n",
    "            n_estimators=50, max_depth=4, random_state=43\n",
    "        )\n",
    "    \n",
    "    def fit(self, X: np.ndarray, T: np.ndarray, Y: np.ndarray):\n",
    "        \"\"\"è®­ç»ƒ T-Learner\"\"\"\n",
    "        # TODO: åˆ†ç¦»æ§åˆ¶ç»„å’Œå¤„ç†ç»„\n",
    "        mask_control = None  # ä½ çš„ä»£ç : T == 0\n",
    "        mask_treatment = None  # ä½ çš„ä»£ç : T == 1\n",
    "        \n",
    "        # TODO: è®­ç»ƒä¸¤ä¸ªæ¨¡å‹\n",
    "        # self.model_control.fit(X[mask_control], Y[mask_control])\n",
    "        # self.model_treatment.fit(X[mask_treatment], Y[mask_treatment])\n",
    "        \n",
    "        # ä½ çš„ä»£ç \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_cate(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"é¢„æµ‹ CATE\"\"\"\n",
    "        # TODO: åˆ†åˆ«é¢„æµ‹\n",
    "        mu1 = None  # ä½ çš„ä»£ç \n",
    "        mu0 = None  # ä½ çš„ä»£ç \n",
    "        \n",
    "        # TODO: CATE = mu1 - mu0\n",
    "        cate = None  # ä½ çš„ä»£ç \n",
    "        \n",
    "        return cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒ T-Learner\n",
    "if df is not None and df['rating'].iloc[0] is not None:\n",
    "    X = df[['rating', 'order_history', 'is_fulltime']].values\n",
    "    T = df['T'].values\n",
    "    Y = df['online_hours'].values\n",
    "    \n",
    "    try:\n",
    "        t_learner = TLearner()\n",
    "        t_learner.fit(X, T, Y)\n",
    "        cate_t = t_learner.predict_cate(X)\n",
    "        \n",
    "        if cate_t is not None:\n",
    "            print(\"T-Learner è®­ç»ƒæˆåŠŸ! ğŸ‰\")\n",
    "            print(f\"\\nCATE ç»Ÿè®¡:\")\n",
    "            print(f\"  èŒƒå›´: [{cate_t.min():.2f}, {cate_t.max():.2f}] å°æ—¶\")\n",
    "            print(f\"  å‡å€¼: {cate_t.mean():.2f} å°æ—¶\")\n",
    "            print(f\"  æ ‡å‡†å·®: {cate_t.std():.2f} å°æ—¶\")\n",
    "            \n",
    "            # æŒ‰å¸æœºç±»å‹æŸ¥çœ‹\n",
    "            print(f\"\\nå„ç±»å‹å¸æœºçš„é¢„æµ‹ CATE:\")\n",
    "            print(f\"  å…¨èŒ: {cate_t[df['is_fulltime']==1].mean():.2f} å°æ—¶\")\n",
    "            print(f\"  å…¼èŒ: {cate_t[df['is_fulltime']==0].mean():.2f} å°æ—¶\")\n",
    "        else:\n",
    "            print(\"[TODO] è¯·å®Œæˆ TLearner.predict_cate æ–¹æ³•\")\n",
    "    except Exception as e:\n",
    "        print(f\"[TODO] TLearner å®ç°æœ‰è¯¯: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  3.3: X-Learner CATE ä¼°è®¡\n",
    "\n",
    "X-Learner æ˜¯æ›´é«˜çº§çš„ Meta-Learnerï¼Œé€šå¸¸æ¯” T-Learner æ›´å‡†ç¡®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLearner:\n",
    "    \"\"\"\n",
    "    X-Learner: é¢å¤–å­¦ä¹ ä¼ªå¤„ç†æ•ˆåº”\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model_control = GradientBoostingRegressor(n_estimators=50, max_depth=4, random_state=42)\n",
    "        self.model_treatment = GradientBoostingRegressor(n_estimators=50, max_depth=4, random_state=43)\n",
    "        self.tau_control = GradientBoostingRegressor(n_estimators=30, max_depth=3, random_state=44)\n",
    "        self.tau_treatment = GradientBoostingRegressor(n_estimators=30, max_depth=3, random_state=45)\n",
    "        self.propensity_model = LogisticRegression(random_state=46)\n",
    "    \n",
    "    def fit(self, X: np.ndarray, T: np.ndarray, Y: np.ndarray):\n",
    "        \"\"\"è®­ç»ƒ X-Learner (ä¸‰é˜¶æ®µ)\"\"\"\n",
    "        mask_control = (T == 0)\n",
    "        mask_treatment = (T == 1)\n",
    "        \n",
    "        # TODO: Stage 1 - è®­ç»ƒ mu_0 å’Œ mu_1\n",
    "        # ä½ çš„ä»£ç \n",
    "        \n",
    "        # TODO: Stage 2 - è®¡ç®—ä¼ªå¤„ç†æ•ˆåº”\n",
    "        # D_treatment = Y_treatment - mu_0(X_treatment)  # å¤„ç†ç»„: å®é™… - åäº‹å®\n",
    "        # D_control = mu_1(X_control) - Y_control        # æ§åˆ¶ç»„: åäº‹å® - å®é™…\n",
    "        # ä½ çš„ä»£ç \n",
    "        \n",
    "        # TODO: Stage 3 - ä¼°è®¡å€¾å‘å¾—åˆ†\n",
    "        # ä½ çš„ä»£ç \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_cate(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"é¢„æµ‹ CATE (ä½¿ç”¨å€¾å‘å¾—åˆ†åŠ æƒ)\"\"\"\n",
    "        # TODO: é¢„æµ‹ä¸¤ä¸ª tau\n",
    "        tau0 = None  # ä½ çš„ä»£ç \n",
    "        tau1 = None  # ä½ çš„ä»£ç \n",
    "        \n",
    "        # TODO: ä¼°è®¡å€¾å‘å¾—åˆ†\n",
    "        propensity = None  # ä½ çš„ä»£ç \n",
    "        \n",
    "        # TODO: åŠ æƒç»„åˆ\n",
    "        # cate = propensity * tau0 + (1 - propensity) * tau1\n",
    "        cate = None  # ä½ çš„ä»£ç \n",
    "        \n",
    "        return cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒ X-Learner\n",
    "if df is not None and df['rating'].iloc[0] is not None:\n",
    "    try:\n",
    "        x_learner = XLearner()\n",
    "        x_learner.fit(X, T, Y)\n",
    "        cate_x = x_learner.predict_cate(X)\n",
    "        \n",
    "        if cate_x is not None:\n",
    "            print(\"X-Learner è®­ç»ƒæˆåŠŸ! ğŸ‰\")\n",
    "            print(f\"\\nCATE ç»Ÿè®¡:\")\n",
    "            print(f\"  èŒƒå›´: [{cate_x.min():.2f}, {cate_x.max():.2f}] å°æ—¶\")\n",
    "            print(f\"  å‡å€¼: {cate_x.mean():.2f} å°æ—¶\")\n",
    "            \n",
    "            if cate_t is not None:\n",
    "                corr = np.corrcoef(cate_t, cate_x)[0, 1]\n",
    "                print(f\"\\nä¸ T-Learner çš„ç›¸å…³æ€§: {corr:.3f}\")\n",
    "        else:\n",
    "            print(\"[TODO] è¯·å®Œæˆ XLearner.predict_cate æ–¹æ³•\")\n",
    "    except Exception as e:\n",
    "        print(f\"[TODO] XLearner å®ç°æœ‰è¯¯: {e}\")\n",
    "        # ä½¿ç”¨ T-Learner çš„ç»“æœç»§ç»­\n",
    "        if 'cate_t' in dir() and cate_t is not None:\n",
    "            cate_x = cate_t\n",
    "            print(\"ä½¿ç”¨ T-Learner çš„ç»“æœç»§ç»­...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  3.4: æœ€ä¼˜ç­–ç•¥å­¦ä¹ \n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬æ¥å­¦ä¹ æœ€ä¼˜çš„æ¿€åŠ±ç­–ç•¥ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_optimal_policy(\n",
    "    cate: np.ndarray,\n",
    "    cost_per_treatment: float = 100,\n",
    "    value_per_hour: float = 30\n",
    ") -> Tuple[np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    å­¦ä¹ æœ€ä¼˜å¹²é¢„ç­–ç•¥\n",
    "    \n",
    "    å†³ç­–è§„åˆ™: å½“ CATE * value > cost æ—¶è¿›è¡Œå¹²é¢„\n",
    "    \n",
    "    Args:\n",
    "        cate: ä¼°è®¡çš„ CATE (åœ¨çº¿æ—¶é•¿å¢é‡)\n",
    "        cost_per_treatment: æ¯æ¬¡æ¿€åŠ±çš„æˆæœ¬ (å…ƒ)\n",
    "        value_per_hour: æ¯å°æ—¶çš„ä»·å€¼ (å…ƒ)\n",
    "    \"\"\"\n",
    "    # TODO: è®¡ç®—é˜ˆå€¼\n",
    "    # å¤šå°‘å°æ—¶å¢é‡æ‰åˆ’ç®—? cost / value\n",
    "    threshold = None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    # TODO: æœ€ä¼˜ç­–ç•¥\n",
    "    optimal_policy = None  # ä½ çš„ä»£ç : (cate > threshold).astype(int)\n",
    "    \n",
    "    if optimal_policy is None:\n",
    "        return None, {}\n",
    "    \n",
    "    # TODO: è®¡ç®—æŒ‡æ ‡\n",
    "    n_treated = optimal_policy.sum()\n",
    "    expected_hours = cate[optimal_policy == 1].sum() if n_treated > 0 else 0\n",
    "    total_cost = None  # ä½ çš„ä»£ç : n_treated * cost_per_treatment\n",
    "    total_value = None  # ä½ çš„ä»£ç : expected_hours * value_per_hour\n",
    "    net_benefit = None  # ä½ çš„ä»£ç : total_value - total_cost\n",
    "    roi = None  # ä½ çš„ä»£ç : net_benefit / total_cost if total_cost > 0 else 0\n",
    "    \n",
    "    metrics = {\n",
    "        'n_treated': n_treated,\n",
    "        'treatment_rate': n_treated / len(cate),\n",
    "        'expected_hours': expected_hours,\n",
    "        'total_cost': total_cost,\n",
    "        'total_value': total_value,\n",
    "        'net_benefit': net_benefit,\n",
    "        'roi': roi,\n",
    "        'threshold': threshold\n",
    "    }\n",
    "    \n",
    "    return optimal_policy, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ä¹ æœ€ä¼˜ç­–ç•¥\n",
    "if 'cate_x' in dir() and cate_x is not None:\n",
    "    cate_to_use = cate_x if cate_x is not None else cate_t\n",
    "    \n",
    "    optimal_policy, metrics = learn_optimal_policy(\n",
    "        cate_to_use, \n",
    "        cost_per_treatment=100, \n",
    "        value_per_hour=30\n",
    "    )\n",
    "    \n",
    "    if optimal_policy is not None and metrics.get('total_cost') is not None:\n",
    "        print(\"æœ€ä¼˜ç­–ç•¥å­¦ä¹ æˆåŠŸ! ğŸ¯\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"\\næ¿€åŠ±æˆæœ¬: Â¥100/äºº\")\n",
    "        print(f\"æ¯å°æ—¶ä»·å€¼: Â¥30\")\n",
    "        print(f\"é˜ˆå€¼: {metrics['threshold']:.2f} å°æ—¶ (CATE éœ€è¦è¶…è¿‡è¿™ä¸ªå€¼æ‰åˆ’ç®—)\")\n",
    "        print(f\"\\n=== æœ€ä¼˜ç­–ç•¥ç»“æœ ===\")\n",
    "        print(f\"å¹²é¢„äººæ•°: {metrics['n_treated']}\")\n",
    "        print(f\"å¹²é¢„æ¯”ä¾‹: {metrics['treatment_rate']:.2%}\")\n",
    "        print(f\"é¢„æœŸæ—¶é•¿å¢é‡: {metrics['expected_hours']:.0f} å°æ—¶\")\n",
    "        print(f\"æ€»æˆæœ¬: Â¥{metrics['total_cost']:,.0f}\")\n",
    "        print(f\"æ€»ä»·å€¼: Â¥{metrics['total_value']:,.0f}\")\n",
    "        print(f\"å‡€æ”¶ç›Š: Â¥{metrics['net_benefit']:,.0f}\")\n",
    "        print(f\"ROI: {metrics['roi']:.2f}\")\n",
    "    else:\n",
    "        print(\"[TODO] è¯·å®Œæˆ learn_optimal_policy å‡½æ•°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  3.5: ç­–ç•¥å¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_targeting_strategies(\n",
    "    df: pd.DataFrame,\n",
    "    cate: np.ndarray,\n",
    "    cost: float = 100,\n",
    "    value: float = 30\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    å¯¹æ¯”ä¸åŒå¹²é¢„ç­–ç•¥\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # ç­–ç•¥ 1 - No Treatment\n",
    "    results.append({\n",
    "        'strategy': 'No Treatment',\n",
    "        'n_treated': 0,\n",
    "        'cost': 0,\n",
    "        'value': 0,\n",
    "        'net_benefit': 0,\n",
    "        'roi': 0\n",
    "    })\n",
    "    \n",
    "    # TODO: ç­–ç•¥ 2 - Treat All\n",
    "    n_all = len(df)\n",
    "    expected_hours_all = cate.sum()\n",
    "    cost_all = n_all * cost\n",
    "    value_all = expected_hours_all * value\n",
    "    results.append({\n",
    "        'strategy': 'Treat All',\n",
    "        'n_treated': n_all,\n",
    "        'cost': cost_all,\n",
    "        'value': value_all,\n",
    "        'net_benefit': value_all - cost_all,\n",
    "        'roi': (value_all - cost_all) / cost_all if cost_all > 0 else 0\n",
    "    })\n",
    "    \n",
    "    # TODO: ç­–ç•¥ 3 - Treat Part-time Only (ä¼ ç»Ÿè§„åˆ™)\n",
    "    parttime_mask = df['is_fulltime'] == 0\n",
    "    n_parttime = parttime_mask.sum()\n",
    "    expected_hours_parttime = cate[parttime_mask].sum()\n",
    "    cost_parttime = n_parttime * cost\n",
    "    value_parttime = expected_hours_parttime * value\n",
    "    results.append({\n",
    "        'strategy': 'Treat Part-time',\n",
    "        'n_treated': n_parttime,\n",
    "        'cost': cost_parttime,\n",
    "        'value': value_parttime,\n",
    "        'net_benefit': value_parttime - cost_parttime,\n",
    "        'roi': (value_parttime - cost_parttime) / cost_parttime if cost_parttime > 0 else 0\n",
    "    })\n",
    "    \n",
    "    # ç­–ç•¥ 4 - Optimal Policy\n",
    "    optimal_policy, optimal_metrics = learn_optimal_policy(cate, cost, value)\n",
    "    if optimal_policy is not None and optimal_metrics.get('total_cost') is not None:\n",
    "        results.append({\n",
    "            'strategy': 'Optimal Policy',\n",
    "            'n_treated': optimal_metrics['n_treated'],\n",
    "            'cost': optimal_metrics['total_cost'],\n",
    "            'value': optimal_metrics['total_value'],\n",
    "            'net_benefit': optimal_metrics['net_benefit'],\n",
    "            'roi': optimal_metrics['roi']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç­–ç•¥å¯¹æ¯”\n",
    "if 'cate_to_use' in dir() and cate_to_use is not None:\n",
    "    comparison = compare_targeting_strategies(df, cate_to_use, cost=100, value=30)\n",
    "    \n",
    "    if comparison is not None and len(comparison) > 0:\n",
    "        print(\"ç­–ç•¥å¯¹æ¯”:\")\n",
    "        print(\"=\"*70)\n",
    "        display(comparison.round(0))\n",
    "        \n",
    "        # æ‰¾æœ€ä½³ç­–ç•¥\n",
    "        best_idx = comparison['net_benefit'].idxmax()\n",
    "        best_strategy = comparison.loc[best_idx, 'strategy']\n",
    "        best_benefit = comparison.loc[best_idx, 'net_benefit']\n",
    "        \n",
    "        print(f\"\\næœ€ä½³ç­–ç•¥: {best_strategy}\")\n",
    "        print(f\"å‡€æ”¶ç›Š: Â¥{best_benefit:,.0f}\")\n",
    "        \n",
    "        # å¯è§†åŒ–\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        colors = ['#95a5a6', '#e74c3c', '#3498db', '#2ecc71']\n",
    "        \n",
    "        # å‡€æ”¶ç›Šå¯¹æ¯”\n",
    "        bars = axes[0].bar(comparison['strategy'], comparison['net_benefit'], color=colors)\n",
    "        axes[0].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "        axes[0].set_ylabel('å‡€æ”¶ç›Š (Â¥)')\n",
    "        axes[0].set_title('ä¸åŒç­–ç•¥çš„å‡€æ”¶ç›Šå¯¹æ¯”')\n",
    "        axes[0].tick_params(axis='x', rotation=15)\n",
    "        \n",
    "        # ROI å¯¹æ¯”\n",
    "        bars = axes[1].bar(comparison['strategy'], comparison['roi'], color=colors)\n",
    "        axes[1].axhline(y=0, color='red', linestyle='--')\n",
    "        axes[1].set_ylabel('ROI')\n",
    "        axes[1].set_title('ä¸åŒç­–ç•¥çš„ ROI å¯¹æ¯”')\n",
    "        axes[1].tick_params(axis='x', rotation=15)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  3.6: ç”¨æˆ·åˆ†å±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_by_cate(\n",
    "    df: pd.DataFrame,\n",
    "    cate: np.ndarray\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    æ ¹æ® CATE å°†ç”¨æˆ·åˆ†å±‚\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['cate'] = cate\n",
    "    \n",
    "    # TODO: è®¡ç®—åˆ†ä½æ•°\n",
    "    p75 = np.percentile(cate, 75)\n",
    "    p25 = np.percentile(cate, 25)\n",
    "    \n",
    "    # åˆ†å±‚\n",
    "    segments = []\n",
    "    for c in cate:\n",
    "        if c >= p75:\n",
    "            segments.append('High Impact')\n",
    "        elif c >= p25:\n",
    "            segments.append('Medium Impact')\n",
    "        elif c > 0:\n",
    "            segments.append('Low Impact')\n",
    "        else:\n",
    "            segments.append('Negative Impact')\n",
    "    \n",
    "    df['segment'] = segments\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”¨æˆ·åˆ†å±‚\n",
    "if 'cate_to_use' in dir() and cate_to_use is not None:\n",
    "    df_segmented = segment_by_cate(df, cate_to_use)\n",
    "    \n",
    "    print(\"ç”¨æˆ·åˆ†å±‚ç»“æœ:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nåˆ†å±‚åˆ†å¸ƒ:\")\n",
    "    print(df_segmented['segment'].value_counts())\n",
    "    \n",
    "    print(f\"\\nå„å±‚ç»Ÿè®¡:\")\n",
    "    for segment in ['High Impact', 'Medium Impact', 'Low Impact', 'Negative Impact']:\n",
    "        mask = df_segmented['segment'] == segment\n",
    "        if mask.sum() > 0:\n",
    "            avg_cate = df_segmented.loc[mask, 'cate'].mean()\n",
    "            avg_fulltime = df_segmented.loc[mask, 'is_fulltime'].mean()\n",
    "            avg_orders = df_segmented.loc[mask, 'order_history'].mean()\n",
    "            print(f\"\\n  {segment}:\")\n",
    "            print(f\"    å¹³å‡ CATE: {avg_cate:.2f} å°æ—¶\")\n",
    "            print(f\"    å…¨èŒæ¯”ä¾‹: {avg_fulltime:.1%}\")\n",
    "            print(f\"    å¹³å‡å†å²è®¢å•: {avg_orders:.0f}\")\n",
    "    \n",
    "    # å¯è§†åŒ–\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    segment_order = ['High Impact', 'Medium Impact', 'Low Impact', 'Negative Impact']\n",
    "    colors = ['#2ecc71', '#3498db', '#f39c12', '#e74c3c']\n",
    "    \n",
    "    segment_cates = [df_segmented.loc[df_segmented['segment']==s, 'cate'].mean() \n",
    "                    for s in segment_order]\n",
    "    \n",
    "    bars = ax.bar(segment_order, segment_cates, color=colors)\n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax.set_ylabel('å¹³å‡ CATE (å°æ—¶)')\n",
    "    ax.set_title('å„ç”¨æˆ·åˆ†å±‚çš„å¹³å‡æ¿€åŠ±æ•ˆæœ')\n",
    "    ax.tick_params(axis='x', rotation=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤” æ€è€ƒé¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 1: T-Learner å’Œ X-Learner çš„ä¸»è¦åŒºåˆ«æ˜¯ä»€ä¹ˆï¼ŸX-Learner åœ¨ä»€ä¹ˆæƒ…å†µä¸‹æ›´ä¼˜ï¼Ÿ\n",
    "\n",
    "answer_1 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 2: æœ€ä¼˜ç­–ç•¥ \"CATE Ã— value > cost\" çš„ç»æµå­¦ç›´è§‰æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "answer_2 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 3: ä¸ºä»€ä¹ˆè¦ä½¿ç”¨å€¾å‘å¾—åˆ†æ¥åŠ æƒ X-Learner çš„é¢„æµ‹ï¼Ÿ\n",
    "\n",
    "answer_3 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 4: åœ¨çœŸå®ä¸šåŠ¡ä¸­ï¼Œå¦‚ä½•å¤„ç† CATE ä¼°è®¡çš„ä¸ç¡®å®šæ€§ï¼Ÿ\n",
    "\n",
    "answer_4 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 5: å¦‚æœæ¿€åŠ±æ•ˆåº”ä¼šéšæ—¶é—´è¡°å‡ï¼ˆæ¿€åŠ±ç–²åŠ³ï¼‰ï¼Œåº”è¯¥å¦‚ä½•è°ƒæ•´ç­–ç•¥ï¼Ÿ\n",
    "\n",
    "answer_5 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ€»ç»“\n",
    "\n",
    "### Meta-Learner å¯¹æ¯”\n",
    "\n",
    "| æ–¹æ³• | å¤æ‚åº¦ | ä¼˜ç‚¹ | ç¼ºç‚¹ |\n",
    "|------|--------|------|------|\n",
    "| S-Learner | ä½ | ç®€å• | å¯èƒ½æ— æ³•æ•è·å¼‚è´¨æ€§ |\n",
    "| T-Learner | ä¸­ | ç›´è§‚ | å¤„ç†ç»„å’Œæ§åˆ¶ç»„ä¸å…±äº«ä¿¡æ¯ |\n",
    "| X-Learner | é«˜ | æ›´å‡†ç¡®ï¼Œé€‚åˆä¸å¹³è¡¡æ•°æ® | æ›´å¤æ‚ |\n",
    "\n",
    "### æœ€ä¼˜ç­–ç•¥å…¬å¼\n",
    "\n",
    "$$\\pi^*(x) = \\mathbb{1}[\\hat{\\tau}(x) \\cdot \\text{value} > \\text{cost}]$$\n",
    "\n",
    "### ä¸šåŠ¡åº”ç”¨æ¡†æ¶\n",
    "\n",
    "1. **æ•°æ®å‡†å¤‡**: æ”¶é›†å†å²å®éªŒæ•°æ®\n",
    "2. **CATE ä¼°è®¡**: ä½¿ç”¨ T/X-Learner\n",
    "3. **ç”¨æˆ·åˆ†å±‚**: è¯†åˆ«é«˜ä»·å€¼ç”¨æˆ·\n",
    "4. **ç­–ç•¥ä¼˜åŒ–**: æˆæœ¬-æ”¶ç›Šæƒè¡¡\n",
    "5. **æŒç»­è¿­ä»£**: A/B æµ‹è¯•éªŒè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ æ­å–œå®Œæˆç”¨æˆ·å®šå‘å¹²é¢„ç»ƒä¹ !\")\n",
    "print(\"\\nä½ å·²ç»å­¦ä¼šäº†:\")\n",
    "print(\"  âœ“ T-Learner å’Œ X-Learner CATE ä¼°è®¡\")\n",
    "print(\"  âœ“ æœ€ä¼˜å¹²é¢„ç­–ç•¥å­¦ä¹ \")\n",
    "print(\"  âœ“ æˆæœ¬-æ”¶ç›Šæƒè¡¡\")\n",
    "print(\"  âœ“ ç”¨æˆ·åˆ†å±‚åˆ†æ\")\n",
    "print(\"\\nğŸ‰ æ­å–œå®Œæˆæ‰€æœ‰ç« èŠ‚!\")\n",
    "print(\"\\nä½ ç°åœ¨å·²ç»æŒæ¡äº†:\")\n",
    "print(\"  âœ“ å› æœæ¨æ–­åŸºç¡€æ¦‚å¿µ\")\n",
    "print(\"  âœ“ å¤„ç†æ•ˆåº”ä¼°è®¡æ–¹æ³•\")\n",
    "print(\"  âœ“ Uplift å»ºæ¨¡\")\n",
    "print(\"  âœ“ æ·±åº¦å› æœæ¨¡å‹\")\n",
    "print(\"  âœ“ å¼‚è´¨æ•ˆåº”åˆ†æ\")\n",
    "print(\"  âœ“ å®é™…åº”ç”¨åœºæ™¯\")\n",
    "print(\"\\nç»§ç»­æ¢ç´¢ï¼Œç»§ç»­å­¦ä¹ ! ğŸš€\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
