{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ğŸ” Chapter 5 ç»ƒä¹  3: æ•æ„Ÿæ€§åˆ†æ - å› æœç»“è®ºçš„ã€Œå‹åŠ›æµ‹è¯•ã€\n\n## æ— æ··æ·†å‡è®¾èƒ½éªŒè¯å—ï¼Ÿ\n\nåœ¨å› æœæ¨æ–­ä¸­ï¼Œæœ‰ä¸€ä¸ªä»¤äººä¸å®‰çš„äº‹å®ï¼š\n\n> **æ— æ··æ·†å‡è®¾ (Unconfoundedness) æ— æ³•ä»æ•°æ®ä¸­éªŒè¯**\n\næˆ‘ä»¬æ°¸è¿œä¸çŸ¥é“æ˜¯å¦é—æ¼äº†æŸä¸ªé‡è¦çš„æ··æ·†å› å­ï¼è¿™å°±åƒä½ æ°¸è¿œæ— æ³•è¯æ˜ã€Œæˆ¿é—´é‡Œæ²¡æœ‰éšå½¢çš„å¤§è±¡ã€ã€‚\n\né‚£æ€ä¹ˆåŠå‘¢ï¼Ÿ**æ•æ„Ÿæ€§åˆ†æ (Sensitivity Analysis)** æ¥å¸®å¿™ï¼\n\n---\n\n## ğŸ¯ å­¦ä¹ ç›®æ ‡\n\n1. ç†è§£æœªè§‚æµ‹æ··æ·†çš„å½±å“\n2. å®ç° Rosenbaum æ•æ„Ÿæ€§è¾¹ç•Œ\n3. **æ·±å…¥æŒæ¡ E-value æ–¹æ³•** â­\n   - E-value çš„æ¦‚å¿µå’Œå…¬å¼æ¨å¯¼\n   - è®¡ç®—ç‚¹ä¼°è®¡å’Œç½®ä¿¡åŒºé—´çš„ E-value\n   - è§£è¯»å’ŒæŠ¥å‘Š E-value\n   - åœ¨å®é™…ç ”ç©¶ä¸­åº”ç”¨ E-value\n4. è¿›è¡Œ Placebo ç¨³å¥æ€§æ£€éªŒ\n5. å¯¹æ¯”ä¸åŒæ•æ„Ÿæ€§åˆ†ææ–¹æ³•çš„ä¼˜ç¼ºç‚¹"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒŸ æ•æ„Ÿæ€§åˆ†æçš„ç›´è§‰\n",
    "\n",
    "### ç±»æ¯”ï¼šè¯ç‰©è¯•éªŒçš„ã€Œé­”é¬¼ä»£è¨€äººã€\n",
    "\n",
    "æƒ³è±¡ä½ æ˜¯ FDA çš„å®¡æŸ¥å‘˜ï¼Œåˆ¶è¯å…¬å¸å£°ç§°ä»–ä»¬çš„æ–°è¯æœ‰æ•ˆï¼š\n",
    "\n",
    "- **ä»–ä»¬è¯´**: ã€Œåƒè¯åï¼Œæ‚£è€…æ¢å¤ç‡é«˜äº† 20%ï¼ã€\n",
    "- **ä½ é—®**: ã€Œä¼šä¸ä¼šæ˜¯å› ä¸ºé€‰æ‹©åƒè¯çš„äººæœ¬æ¥å°±æ›´å¥åº·ï¼Ÿã€\n",
    "- **ä»–ä»¬è¯´**: ã€Œæˆ‘ä»¬å·²ç»æ§åˆ¶äº†æ‰€æœ‰è§‚æµ‹åˆ°çš„å› ç´ ï¼ã€\n",
    "- **ä½ é—®**: ã€Œä½†å¦‚æœæœ‰ä½ ä»¬æ²¡æµ‹é‡çš„å› ç´ å‘¢ï¼Ÿæ¯”å¦‚æ‚£è€…çš„ä¹è§‚ç¨‹åº¦ï¼Ÿã€\n",
    "\n",
    "æ•æ„Ÿæ€§åˆ†æå°±æ˜¯ç³»ç»Ÿåœ°é—®è¿™ä¸ªé—®é¢˜ï¼š\n",
    "\n",
    "> **ã€Œéœ€è¦å¤šå¼ºçš„æœªè§‚æµ‹æ··æ·†ï¼Œæ‰èƒ½æ¨ç¿»æˆ‘ä»¬çš„ç»“è®ºï¼Ÿã€**\n",
    "\n",
    "### ä¸¤ç§æ–¹æ³•\n",
    "\n",
    "1. **Rosenbaum æ•æ„Ÿæ€§è¾¹ç•Œ**: å‡è®¾å­˜åœ¨æœªè§‚æµ‹æ··æ·†ï¼Œçœ‹ç»“è®ºä½•æ—¶å˜å¾—ä¸æ˜¾è‘—\n",
    "2. **E-value**: è®¡ç®—èƒ½è§£é‡Šè§‚æµ‹å…³è”çš„æœ€å°æ··æ·†å¼ºåº¦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ“ æ ¸å¿ƒå…¬å¼\n\n### Rosenbaum æ•æ„Ÿæ€§å‚æ•° Î“\n\nå¯¹äºä¸¤ä¸ªåå˜é‡ç›¸åŒçš„ä¸ªä½“ i å’Œ jï¼š\n\n$$\\frac{1}{\\Gamma} \\leq \\frac{P(T_i=1|X)}{P(T_j=1|X)} \\leq \\Gamma$$\n\n- **Î“ = 1**: æ— æœªè§‚æµ‹æ··æ·†ï¼ˆå®Œç¾çš„éšæœºåŒ–ï¼‰\n- **Î“ = 2**: å€¾å‘å¾—åˆ†æœ€å¤šç›¸å·® 2 å€\n- **Î“ = 3**: å€¾å‘å¾—åˆ†æœ€å¤šç›¸å·® 3 å€\n\n### E-value å…¬å¼ (VanderWeele & Ding, 2017)\n\n**åŸºæœ¬å…¬å¼**:\n\n$$E = RR + \\sqrt{RR \\times (RR - 1)}$$\n\nå…¶ä¸­ RR æ˜¯é£é™©æ¯” (Risk Ratio)ã€‚\n\n**æ¨å¯¼ç›´è§‰**:\nå‡è®¾å­˜åœ¨æœªè§‚æµ‹æ··æ·†å› å­ Uï¼Œå®ƒä¸å¤„ç† T å’Œç»“æœ Y çš„å…³è”å¼ºåº¦éƒ½æ˜¯ RR_Uã€‚\nE-value å°±æ˜¯ä½¿è§‚æµ‹åˆ°çš„ RR å®Œå…¨è¢« U è§£é‡Šæ‰€éœ€çš„æœ€å° RR_U å€¼ã€‚\n\n**é‡è¦æ€§è´¨**:\n1. E-value â‰¥ 1 (æœ€å°å€¼ä¸º 1ï¼Œè¡¨ç¤ºä»»ä½•æ··æ·†éƒ½èƒ½æ¨ç¿»ç»“è®º)\n2. E-value å…³äº RR å•è°ƒé€’å¢ï¼ˆæ•ˆåº”è¶Šå¤§ï¼Œè¶Šç¨³å¥ï¼‰\n3. å½“ RR = 1 (æ— æ•ˆåº”)æ—¶ï¼ŒE-value = 1\n\n**å¯¹äºç½®ä¿¡åŒºé—´**:\n- ç‚¹ä¼°è®¡çš„ E-value: åŸºäº RR çš„ç‚¹ä¼°è®¡\n- CI ä¸‹ç•Œçš„ E-value: åŸºäºç½®ä¿¡åŒºé—´ä¸‹ç•Œï¼ˆæ›´ä¿å®ˆçš„ä¼°è®¡ï¼‰\n\n**å®é™…è§£è¯»**:\nE-value è¡¨ç¤ºï¼š**ä½¿è§‚æµ‹å…³è”å®Œå…¨è¢«æ··æ·†è§£é‡Šæ‰€éœ€çš„æœ€å°é£é™©æ¯”**\n\nä¾‹å¦‚ï¼ŒE-value = 3.0 æ„å‘³ç€ï¼š\n- éœ€è¦ä¸€ä¸ªæœªè§‚æµ‹å› å­ U\n- U ä½¿ã€Œæ¥å—å¤„ç†çš„æ¦‚ç‡ã€æé«˜ 3 å€\n- U åŒæ—¶ä½¿ã€Œç»“æœå‘ç”Ÿæ¦‚ç‡ã€æé«˜ 3 å€\n- æ‰èƒ½å®Œå…¨è§£é‡Šæ‰è§‚æµ‹åˆ°çš„æ•ˆåº”"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯å¢ƒè®¾ç½®\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Dict\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "np.random.seed(42)\n",
    "\n",
    "# ç»˜å›¾è®¾ç½®\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"ç¯å¢ƒé…ç½®å®Œæˆ! ğŸ”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  3.1: æ¨¡æ‹Ÿæœªè§‚æµ‹æ··æ·†\n",
    "\n",
    "é¦–å…ˆï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæœ‰**æœªè§‚æµ‹æ··æ·†**çš„æ•°æ®é›†ï¼Œçœ‹çœ‹å®ƒå¦‚ä½•å½±å“å› æœä¼°è®¡ï¼\n",
    "\n",
    "### åœºæ™¯\n",
    "\n",
    "ç ”ç©¶ã€Œå‚åŠ åŸ¹è®­ã€å¯¹ã€Œè–ªèµ„ã€çš„å½±å“ï¼š\n",
    "- **X**: è§‚æµ‹åˆ°çš„èƒ½åŠ›æŒ‡æ ‡\n",
    "- **U**: æœªè§‚æµ‹çš„ã€ŒåŠ¨æœºã€å› ç´ ï¼ˆæˆ‘ä»¬å‡è£…çœ‹ä¸åˆ°ï¼‰\n",
    "- **T**: æ˜¯å¦å‚åŠ åŸ¹è®­ï¼ˆå— X å’Œ U å½±å“ï¼‰\n",
    "- **Y**: è–ªèµ„ï¼ˆå— Tã€Xã€U å½±å“ï¼‰\n",
    "\n",
    "é—®é¢˜ï¼šé«˜åŠ¨æœºçš„äººæ—¢æ›´å¯èƒ½å‚åŠ åŸ¹è®­ï¼Œä¹Ÿæ›´å¯èƒ½æœ‰é«˜è–ªèµ„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_unobserved_confounding(\n",
    "    n: int = 1000,\n",
    "    confounder_strength: float = 0.5,\n",
    "    seed: int = 42\n",
    ") -> Tuple[pd.DataFrame, np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    æ¨¡æ‹ŸåŒ…å«æœªè§‚æµ‹æ··æ·†çš„æ•°æ®\n",
    "    \n",
    "    æ•°æ®ç”Ÿæˆè¿‡ç¨‹:\n",
    "    - X ~ N(0, 1)  # è§‚æµ‹åå˜é‡ï¼ˆèƒ½åŠ›ï¼‰\n",
    "    - U ~ N(0, 1)  # æœªè§‚æµ‹æ··æ·†å› å­ï¼ˆåŠ¨æœºï¼‰\n",
    "    - P(T=1|X,U) = sigmoid(0.5*X + strength*U)\n",
    "    - Y = 10 + 2*T + 1.5*X + strength*2*U + noise\n",
    "    \n",
    "    çœŸå® ATE = 2.0\n",
    "    \n",
    "    Returns:\n",
    "        (df, U, params)\n",
    "        df: åŒ…å« X, T, Y çš„ DataFrame (ä¸åŒ…å« U!)\n",
    "        U: æœªè§‚æµ‹æ··æ·†å› å­\n",
    "        params: çœŸå®å‚æ•°\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆè§‚æµ‹åå˜é‡ X (èƒ½åŠ›)\n",
    "    X = None  # ä½ çš„ä»£ç : np.random.randn(n)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆæœªè§‚æµ‹æ··æ·†å› å­ U (åŠ¨æœº)\n",
    "    U = None  # ä½ çš„ä»£ç : np.random.randn(n)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆå¤„ç† T (å‚åŠ åŸ¹è®­)\n",
    "    # é«˜èƒ½åŠ›å’Œé«˜åŠ¨æœºçš„äººæ›´å¯èƒ½å‚åŠ åŸ¹è®­\n",
    "    # propensity_logit = 0.5*X + confounder_strength*U\n",
    "    # propensity = sigmoid(propensity_logit) = 1 / (1 + exp(-logit))\n",
    "    propensity_logit = None  # ä½ çš„ä»£ç \n",
    "    propensity = None  # ä½ çš„ä»£ç \n",
    "    T = None  # ä½ çš„ä»£ç : np.random.binomial(1, propensity)\n",
    "    \n",
    "    # TODO: ç”Ÿæˆç»“æœ Y (è–ªèµ„)\n",
    "    # Y = 10 + 2*T + 1.5*X + confounder_strength*2*U + noise\n",
    "    # è§£è¯»: åŸ¹è®­çœŸæ­£å¢åŠ è–ªèµ„ 2ï¼Œèƒ½åŠ›å½±å“ 1.5ï¼ŒåŠ¨æœºå½±å“ confounder_strength*2\n",
    "    noise = np.random.randn(n) * 0.5\n",
    "    Y = None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    # åˆ›å»º DataFrame (å‡è£…æˆ‘ä»¬çœ‹ä¸åˆ° U!)\n",
    "    df = pd.DataFrame({\n",
    "        'X': X,\n",
    "        'T': T,\n",
    "        'Y': Y\n",
    "    })\n",
    "    \n",
    "    params = {\n",
    "        'true_ate': 2.0,\n",
    "        'confounder_strength': confounder_strength\n",
    "    }\n",
    "    \n",
    "    return df, U, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—ä¸åŒçš„ ATE ä¼°è®¡\n",
    "def compute_naive_ate(df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    æœ´ç´  ATE ä¼°è®¡: E[Y|T=1] - E[Y|T=0]\n",
    "    (å¿½ç•¥æ‰€æœ‰æ··æ·†)\n",
    "    \"\"\"\n",
    "    # TODO: è®¡ç®—æœ´ç´ ä¼°è®¡\n",
    "    # ä½ çš„ä»£ç \n",
    "    pass\n",
    "\n",
    "\n",
    "def compute_adjusted_ate(df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    è°ƒæ•´ X åçš„ ATE ä¼°è®¡\n",
    "    ä½¿ç”¨çº¿æ€§å›å½’: Y ~ T + X\n",
    "    \"\"\"\n",
    "    # TODO: ä½¿ç”¨å›å½’ä¼°è®¡ ATE\n",
    "    # 1. æ„å»ºç‰¹å¾çŸ©é˜µ [[T1, X1], [T2, X2], ...]\n",
    "    # 2. æ‹Ÿåˆçº¿æ€§å›å½’\n",
    "    # 3. è¿”å› T çš„ç³»æ•°\n",
    "    \n",
    "    # ä½ çš„ä»£ç \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•ä¸åŒæ··æ·†å¼ºåº¦\n",
    "print(\"=== æœªè§‚æµ‹æ··æ·†çš„å½±å“ ===\")\n",
    "print(f\"çœŸå® ATE = 2.0\\n\")\n",
    "\n",
    "strengths = [0.0, 0.3, 0.6, 1.0]\n",
    "results = []\n",
    "\n",
    "for strength in strengths:\n",
    "    df, U, params = simulate_unobserved_confounding(\n",
    "        n=2000,\n",
    "        confounder_strength=strength\n",
    "    )\n",
    "    \n",
    "    if df is not None and df['X'].iloc[0] is not None:\n",
    "        naive_ate = compute_naive_ate(df)\n",
    "        adjusted_ate = compute_adjusted_ate(df)\n",
    "        \n",
    "        if naive_ate is not None and adjusted_ate is not None:\n",
    "            results.append({\n",
    "                'Strength': strength,\n",
    "                'Naive ATE': naive_ate,\n",
    "                'Naive Bias': naive_ate - 2.0,\n",
    "                'Adjusted ATE': adjusted_ate,\n",
    "                'Adjusted Bias': adjusted_ate - 2.0\n",
    "            })\n",
    "\n",
    "if len(results) > 0:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    display(results_df.round(4))\n",
    "    \n",
    "    print(\"\\nè§£è¯»:\")\n",
    "    print(\"- æ··æ·†å¼ºåº¦ = 0: æ— æ··æ·†ï¼Œä¸¤ç§ä¼°è®¡éƒ½æ¥è¿‘çœŸå®å€¼\")\n",
    "    print(\"- æ··æ·†å¼ºåº¦å¢åŠ : æœ´ç´ ä¼°è®¡åå·®å¢å¤§ï¼ˆé«˜ä¼°æ•ˆåº”ï¼‰\")\n",
    "    print(\"- è°ƒæ•´ X å: ä»æœ‰åå·®ï¼Œå› ä¸º U æœªè¢«æ§åˆ¶ï¼\")\n",
    "else:\n",
    "    print(\"[TODO] è¯·å®Œæˆæ•°æ®ç”Ÿæˆå’Œä¼°è®¡å‡½æ•°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–æ··æ·†çš„å½±å“\n",
    "if len(results) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # ä¼°è®¡å€¼ vs æ··æ·†å¼ºåº¦\n",
    "    axes[0].plot(results_df['Strength'], results_df['Naive ATE'], \n",
    "                'bo-', label='æœ´ç´ ä¼°è®¡', linewidth=2, markersize=8)\n",
    "    axes[0].plot(results_df['Strength'], results_df['Adjusted ATE'], \n",
    "                'gs-', label='è°ƒæ•´ X å', linewidth=2, markersize=8)\n",
    "    axes[0].axhline(y=2.0, color='red', linestyle='--', label='çœŸå® ATE')\n",
    "    axes[0].set_xlabel('æœªè§‚æµ‹æ··æ·†å¼ºåº¦')\n",
    "    axes[0].set_ylabel('ATE ä¼°è®¡')\n",
    "    axes[0].set_title('ä¼°è®¡å€¼éšæ··æ·†å¼ºåº¦å˜åŒ–')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # åå·® vs æ··æ·†å¼ºåº¦\n",
    "    axes[1].bar(np.arange(len(strengths)) - 0.2, results_df['Naive Bias'], \n",
    "               0.35, label='æœ´ç´ ä¼°è®¡åå·®', color='#3498db')\n",
    "    axes[1].bar(np.arange(len(strengths)) + 0.2, results_df['Adjusted Bias'], \n",
    "               0.35, label='è°ƒæ•´ååå·®', color='#2ecc71')\n",
    "    axes[1].axhline(y=0, color='red', linestyle='--')\n",
    "    axes[1].set_xticks(np.arange(len(strengths)))\n",
    "    axes[1].set_xticklabels([f'{s:.1f}' for s in strengths])\n",
    "    axes[1].set_xlabel('æœªè§‚æµ‹æ··æ·†å¼ºåº¦')\n",
    "    axes[1].set_ylabel('åå·® (ä¼°è®¡ - çœŸå®)')\n",
    "    axes[1].set_title('åå·®éšæ··æ·†å¼ºåº¦å˜åŒ–')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  3.2: Rosenbaum æ•æ„Ÿæ€§è¾¹ç•Œ\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬å®ç° Rosenbaum æ•æ„Ÿæ€§åˆ†æï¼\n",
    "\n",
    "æ ¸å¿ƒé—®é¢˜ï¼š**å¦‚æœå­˜åœ¨æœªè§‚æµ‹æ··æ·†ï¼Œæˆ‘ä»¬çš„ç»“è®ºä¼šæœ‰å¤šè„†å¼±ï¼Ÿ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rosenbaum_bounds(\n",
    "    Y: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    gamma: float\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    è®¡ç®— Rosenbaum æ•æ„Ÿæ€§è¾¹ç•Œ\n",
    "    \n",
    "    Î“ å‚æ•°çš„å«ä¹‰:\n",
    "    - Î“ = 1: å‡è®¾æ— æœªè§‚æµ‹æ··æ·†\n",
    "    - Î“ > 1: å…è®¸å€¾å‘å¾—åˆ†æœ€å¤šç›¸å·® Î“ å€\n",
    "    \n",
    "    Args:\n",
    "        Y: ç»“æœå˜é‡\n",
    "        T: å¤„ç†å˜é‡\n",
    "        gamma: æ•æ„Ÿæ€§å‚æ•°\n",
    "    \n",
    "    Returns:\n",
    "        (lower_bound, upper_bound)\n",
    "    \"\"\"\n",
    "    # è§‚æµ‹çš„ ATE\n",
    "    ate_obs = Y[T == 1].mean() - Y[T == 0].mean()\n",
    "    \n",
    "    if gamma == 1.0:\n",
    "        # æ— æ··æ·†å‡è®¾ä¸‹ï¼Œè¾¹ç•Œå°±æ˜¯ç‚¹ä¼°è®¡\n",
    "        return ate_obs, ate_obs\n",
    "    \n",
    "    # TODO: è®¡ç®—æ•æ„Ÿæ€§è¾¹ç•Œ\n",
    "    # ç®€åŒ–ç‰ˆæœ¬: è¾¹ç•Œå®½åº¦ä¸ gamma å’Œæ ‡å‡†è¯¯ç›¸å…³\n",
    "    \n",
    "    # 1. è®¡ç®— ATE çš„æ ‡å‡†è¯¯å·®\n",
    "    n1 = (T == 1).sum()\n",
    "    n0 = (T == 0).sum()\n",
    "    var1 = Y[T == 1].var()\n",
    "    var0 = Y[T == 0].var()\n",
    "    \n",
    "    se = None  # ä½ çš„ä»£ç : np.sqrt(var1/n1 + var0/n0)\n",
    "    \n",
    "    # 2. è¾¹ç•Œå®½åº¦éš gamma å¢åŠ \n",
    "    # ç®€åŒ–å…¬å¼: bound_width = se * log(gamma) * 2\n",
    "    bound_width = None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    # 3. è®¡ç®—ä¸Šä¸‹ç•Œ\n",
    "    lower_bound = None  # ä½ çš„ä»£ç : ate_obs - bound_width\n",
    "    upper_bound = None  # ä½ çš„ä»£ç : ate_obs + bound_width\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_curve(\n",
    "    Y: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    gamma_range: np.ndarray,\n",
    "    true_ate: float = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    è®¡ç®—æ•æ„Ÿæ€§æ›²çº¿\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for gamma in gamma_range:\n",
    "        lower, upper = compute_rosenbaum_bounds(Y, T, gamma)\n",
    "        \n",
    "        row = {\n",
    "            'gamma': gamma,\n",
    "            'lower': lower,\n",
    "            'upper': upper\n",
    "        }\n",
    "        \n",
    "        if true_ate is not None:\n",
    "            row['true_ate'] = true_ate\n",
    "        \n",
    "        results.append(row)\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆæœ‰æ··æ·†çš„æ•°æ®\n",
    "df, U, params = simulate_unobserved_confounding(\n",
    "    n=2000,\n",
    "    confounder_strength=0.6\n",
    ")\n",
    "\n",
    "if df is not None and df['Y'].iloc[0] is not None:\n",
    "    # è®¡ç®—æ•æ„Ÿæ€§æ›²çº¿\n",
    "    gamma_range = np.linspace(1.0, 5.0, 30)\n",
    "    \n",
    "    try:\n",
    "        sens_df = sensitivity_curve(\n",
    "            df['Y'].values,\n",
    "            df['T'].values,\n",
    "            gamma_range,\n",
    "            true_ate=params['true_ate']\n",
    "        )\n",
    "        \n",
    "        if sens_df is not None and sens_df['lower'].iloc[0] is not None:\n",
    "            print(\"æ•æ„Ÿæ€§åˆ†æç»“æœ:\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"\\nè§‚æµ‹ ATE: {df['Y'][df['T']==1].mean() - df['Y'][df['T']==0].mean():.4f}\")\n",
    "            print(f\"çœŸå® ATE: {params['true_ate']:.4f}\")\n",
    "            \n",
    "            print(\"\\néƒ¨åˆ†ç»“æœ:\")\n",
    "            display(sens_df.iloc[::5].round(4))  # æ¯5è¡Œæ˜¾ç¤ºä¸€æ¬¡\n",
    "            \n",
    "            # æ‰¾åˆ°åŒ…å« 0 çš„æœ€å° gamma\n",
    "            includes_zero = (sens_df['lower'] <= 0) & (sens_df['upper'] >= 0)\n",
    "            if includes_zero.any():\n",
    "                gamma_threshold = sens_df.loc[includes_zero, 'gamma'].min()\n",
    "                print(f\"\\næ•æ„Ÿæ€§é˜ˆå€¼: Î“ = {gamma_threshold:.2f}\")\n",
    "                print(f\"è§£è¯»: å¦‚æœæœªè§‚æµ‹æ··æ·†ä½¿å€¾å‘å¾—åˆ†ç›¸å·® {gamma_threshold:.1f} å€ï¼Œ\")\n",
    "                print(f\"      æ•ˆåº”å¯èƒ½å˜ä¸ºé›¶ï¼ˆä¸æ˜¾è‘—ï¼‰\")\n",
    "            else:\n",
    "                print(f\"\\nåœ¨ Î“ â‰¤ {gamma_range.max():.1f} èŒƒå›´å†…ï¼Œæ•ˆåº”å§‹ç»ˆæ˜¾è‘—\")\n",
    "                print(\"ç»“è®ºç›¸å¯¹ç¨³å¥ï¼\")\n",
    "        else:\n",
    "            print(\"[TODO] è¯·å®Œæˆ compute_rosenbaum_bounds å‡½æ•°\")\n",
    "    except Exception as e:\n",
    "        print(f\"[é”™è¯¯] {e}\")\n",
    "else:\n",
    "    print(\"[TODO] è¯·å®Œæˆæ•°æ®ç”Ÿæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–æ•æ„Ÿæ€§åˆ†æ\n",
    "if 'sens_df' in dir() and sens_df is not None and sens_df['lower'].iloc[0] is not None:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # ç»˜åˆ¶è¾¹ç•Œ\n",
    "    ax.fill_between(\n",
    "        sens_df['gamma'], \n",
    "        sens_df['lower'], \n",
    "        sens_df['upper'],\n",
    "        alpha=0.3, color='#3498db', label='æ•æ„Ÿæ€§åŒºé—´'\n",
    "    )\n",
    "    ax.plot(sens_df['gamma'], sens_df['lower'], 'b-', linewidth=2, label='ä¸‹ç•Œ')\n",
    "    ax.plot(sens_df['gamma'], sens_df['upper'], 'b-', linewidth=2, label='ä¸Šç•Œ')\n",
    "    \n",
    "    # çœŸå® ATE\n",
    "    ax.axhline(y=params['true_ate'], color='green', linestyle='--', \n",
    "              linewidth=2, label=f'çœŸå® ATE = {params[\"true_ate\"]}')\n",
    "    \n",
    "    # é›¶çº¿\n",
    "    ax.axhline(y=0, color='red', linestyle='-', linewidth=1, label='é›¶æ•ˆåº”')\n",
    "    \n",
    "    # æ‰¾åˆ°äº¤å‰ç‚¹\n",
    "    includes_zero = (sens_df['lower'] <= 0) & (sens_df['upper'] >= 0)\n",
    "    if includes_zero.any():\n",
    "        gamma_threshold = sens_df.loc[includes_zero, 'gamma'].min()\n",
    "        ax.axvline(x=gamma_threshold, color='orange', linestyle=':', \n",
    "                  linewidth=2, label=f'æ•æ„Ÿæ€§é˜ˆå€¼ Î“={gamma_threshold:.2f}')\n",
    "    \n",
    "    ax.set_xlabel('Î“ (æ•æ„Ÿæ€§å‚æ•°)', fontsize=12)\n",
    "    ax.set_ylabel('ATE ä¼°è®¡', fontsize=12)\n",
    "    ax.set_title('Rosenbaum æ•æ„Ÿæ€§åˆ†æ\\n\"ç»“è®ºå¯¹æœªè§‚æµ‹æ··æ·†æœ‰å¤šè„†å¼±?\"', fontsize=14)\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nè§£è¯»æŒ‡å—:\")\n",
    "    print(\"- Î“ = 1: å‡è®¾æ— æœªè§‚æµ‹æ··æ·†\")\n",
    "    print(\"- éšç€ Î“ å¢åŠ ï¼Œå…è®¸æ›´å¼ºçš„æœªè§‚æµ‹æ··æ·†\")\n",
    "    print(\"- å½“åŒºé—´åŒ…å« 0 æ—¶ï¼Œç»“è®ºå˜å¾—ä¸ç¡®å®š\")\n",
    "    print(\"- æ•æ„Ÿæ€§é˜ˆå€¼è¶Šé«˜ï¼Œç»“è®ºè¶Šç¨³å¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ç»ƒä¹  3.3: E-value - æ›´ç›´è§‚çš„æ•æ„Ÿæ€§åº¦é‡\n\nE-value æ˜¯ç”± VanderWeele & Ding (2017) æå‡ºçš„ä¸€ç§æµè¡Œçš„æ•æ„Ÿæ€§åº¦é‡æ–¹æ³•ã€‚\n\n### ä¸ºä»€ä¹ˆéœ€è¦ E-valueï¼Ÿ\n\n**Rosenbaum æ–¹æ³•çš„å±€é™**:\n- éœ€è¦åŒ¹é…è®¾è®¡\n- Î“ å‚æ•°çš„å®é™…æ„ä¹‰ä¸å¤Ÿç›´è§‚\n- éš¾ä»¥è§£é‡Šç»™éæŠ€æœ¯äººå‘˜\n\n**E-value çš„ä¼˜åŠ¿**:\n- é€‚ç”¨äºä»»ä½•ç ”ç©¶è®¾è®¡\n- ç›´æ¥é‡åŒ–ã€Œéœ€è¦å¤šå¼ºçš„æ··æ·†ã€\n- å®¹æ˜“å‘åˆ©ç›Šç›¸å…³è€…è§£é‡Š\n\n### æ ¸å¿ƒé—®é¢˜\n\n> **ã€Œéœ€è¦å¤šå¼ºçš„æœªè§‚æµ‹æ··æ·†å› å­ï¼Œæ‰èƒ½å®Œå…¨è§£é‡Šæ‰è§‚æµ‹åˆ°çš„å…³è”ï¼Ÿã€**\n\n### E-value çš„ç›´è§‰\n\nå‡è®¾ä½ å‘ç°ã€ŒåŸ¹è®­ä½¿è–ªèµ„æé«˜ 50%ã€(RR = 1.5):\n\n- **E-value = 2.0**: éœ€è¦ä¸€ä¸ªä¸å¤„ç†å’Œç»“æœéƒ½æœ‰ 2 å€å…³è”çš„æ··æ·†å› å­\n- **å®é™…æ„ä¹‰**: å¦‚æœå­˜åœ¨ä¸€ä¸ªæœªè§‚æµ‹å› å­ï¼Œå®ƒä½¿ã€Œå‚åŠ åŸ¹è®­çš„æ¦‚ç‡ã€æé«˜ 2 å€ï¼ŒåŒæ—¶ä¹Ÿä½¿ã€Œè–ªèµ„ã€æé«˜ 2 å€ï¼Œé‚£ä¹ˆè§‚æµ‹åˆ°çš„æ•ˆåº”å¯èƒ½å®Œå…¨æ˜¯å‡çš„\n\n**åˆ¤æ–­æ ‡å‡†**:\n- E-value è¶Šå¤§ï¼Œç»“è®ºè¶Šç¨³å¥\n- E-value å¾ˆå° (< 1.5)ï¼Œè¯´æ˜ç»“è®ºå®¹æ˜“è¢«æ¨ç¿»\n- E-value å¾ˆå¤§ (> 3)ï¼Œè¯´æ˜éœ€è¦å¾ˆå¼ºçš„æ··æ·†æ‰èƒ½æ¨ç¿»ç»“è®º"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def ate_to_risk_ratio(ate: float, baseline_mean: float) -> float:\n    \"\"\"\n    å°† ATE è½¬æ¢ä¸ºé£é™©æ¯” (Risk Ratio)\n    \n    å½“ç»“æœå˜é‡æ˜¯è¿ç»­çš„æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦è½¬æ¢ä¸ºé£é™©æ¯”ï¼š\n    RR = (baseline + ATE) / baseline\n    \n    ç¤ºä¾‹ï¼š\n    - åŸºçº¿è–ªèµ„: 10 ä¸‡\n    - ATE: 2 ä¸‡\n    - RR = (10 + 2) / 10 = 1.2  (è–ªèµ„æé«˜äº† 20%)\n    \n    Args:\n        ate: å¹³å‡å¤„ç†æ•ˆåº”\n        baseline_mean: æ§åˆ¶ç»„çš„å¹³å‡ç»“æœ\n    \n    Returns:\n        é£é™©æ¯”\n    \"\"\"\n    # TODO: è®¡ç®—é£é™©æ¯”\n    # ä½ çš„ä»£ç \n    pass\n\n\ndef compute_e_value(observed_rr: float, ci_lower: float = None) -> Dict[str, float]:\n    \"\"\"\n    è®¡ç®— E-value\n    \n    E-value: ä½¿è§‚æµ‹å…³è”å®Œå…¨è¢«æ··æ·†è§£é‡Šæ‰€éœ€çš„æœ€å°é£é™©æ¯”\n    \n    å…¬å¼æ¨å¯¼ï¼š\n    å‡è®¾å­˜åœ¨æœªè§‚æµ‹æ··æ·†å› å­ Uï¼Œå®ƒä¸å¤„ç† T å’Œç»“æœ Y çš„é£é™©æ¯”éƒ½æ˜¯ RR_Uã€‚\n    å¦‚æœè¦å®Œå…¨è§£é‡Šè§‚æµ‹åˆ°çš„ RR_obsï¼Œåˆ™ï¼š\n    \n    E = RR_obs + sqrt(RR_obs * (RR_obs - 1))  [å½“ RR >= 1]\n    \n    ç›´è§‰ç†è§£ï¼š\n    - E-value æ˜¯å…³äº RR çš„é€’å¢å‡½æ•°\n    - RR_obs è¶Šå¤§ï¼ŒE-value è¶Šå¤§ï¼Œç»“è®ºè¶Šç¨³å¥\n    - E-value = 1 æ„å‘³ç€ä»»ä½•æ··æ·†éƒ½èƒ½æ¨ç¿»ç»“è®ºï¼ˆç»“è®ºéå¸¸è„†å¼±ï¼‰\n    \n    Args:\n        observed_rr: è§‚æµ‹åˆ°çš„é£é™©æ¯”\n        ci_lower: ç½®ä¿¡åŒºé—´ä¸‹ç•Œ (å¯é€‰)\n    \n    Returns:\n        {'e_value': ..., 'e_value_ci': ...}\n    \"\"\"\n    # ç¡®ä¿ RR >= 1 (å¦‚æœ < 1ï¼Œå–å€’æ•°)\n    if observed_rr < 1:\n        observed_rr = 1 / observed_rr\n    \n    # TODO: è®¡ç®— E-value\n    # E = RR + sqrt(RR * (RR - 1))\n    e_value = None  # ä½ çš„ä»£ç \n    \n    result = {'e_value': e_value}\n    \n    # TODO: å¦‚æœæœ‰ç½®ä¿¡åŒºé—´ä¸‹ç•Œï¼Œä¹Ÿè®¡ç®—å…¶ E-value\n    # è¿™ç»™å‡ºäº†æ›´ä¿å®ˆçš„ä¼°è®¡\n    if ci_lower is not None:\n        if ci_lower < 1:\n            ci_lower = 1 / ci_lower\n        e_value_ci = None  # ä½ çš„ä»£ç : ci_lower + np.sqrt(ci_lower * (ci_lower - 1))\n        result['e_value_ci'] = e_value_ci\n    \n    return result\n\n\ndef compute_ate_ci(Y: np.ndarray, T: np.ndarray, alpha: float = 0.05) -> Tuple[float, float, float]:\n    \"\"\"\n    è®¡ç®— ATE çš„ç½®ä¿¡åŒºé—´\n    \n    ä½¿ç”¨ t æ£€éªŒè®¡ç®—\n    \n    Returns:\n        (ate, ci_lower, ci_upper)\n    \"\"\"\n    Y1 = Y[T == 1]\n    Y0 = Y[T == 0]\n    \n    ate = Y1.mean() - Y0.mean()\n    \n    # TODO: è®¡ç®—æ ‡å‡†è¯¯\n    n1, n0 = len(Y1), len(Y0)\n    var1, var0 = Y1.var(ddof=1), Y0.var(ddof=1)\n    \n    se = None  # ä½ çš„ä»£ç : np.sqrt(var1/n1 + var0/n0)\n    \n    # TODO: è®¡ç®—ç½®ä¿¡åŒºé—´\n    # ä½¿ç”¨ t åˆ†å¸ƒçš„ä¸´ç•Œå€¼\n    from scipy import stats\n    df = n1 + n0 - 2\n    t_crit = None  # ä½ çš„ä»£ç : stats.t.ppf(1 - alpha/2, df)\n    \n    ci_lower = None  # ä½ çš„ä»£ç : ate - t_crit * se\n    ci_upper = None  # ä½ çš„ä»£ç : ate + t_crit * se\n    \n    return ate, ci_lower, ci_upper"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æµ‹è¯• E-value è®¡ç®—\nprint(\"=== E-value åˆ†æç¤ºä¾‹ ===\\n\")\n\nif df is not None and df['Y'].iloc[0] is not None:\n    try:\n        # è®¡ç®— ATE å’Œç½®ä¿¡åŒºé—´\n        ate, ci_lower, ci_upper = compute_ate_ci(df['Y'].values, df['T'].values)\n        \n        if ate is not None and ci_lower is not None:\n            baseline_mean = df.loc[df['T'] == 0, 'Y'].mean()\n            \n            # è½¬æ¢ä¸ºé£é™©æ¯”\n            rr = ate_to_risk_ratio(ate, baseline_mean)\n            rr_ci_lower = ate_to_risk_ratio(ci_lower, baseline_mean)\n            rr_ci_upper = ate_to_risk_ratio(ci_upper, baseline_mean)\n            \n            if rr is not None:\n                print(f\"æ­¥éª¤ 1: è®¡ç®—æ•ˆåº”ä¼°è®¡\")\n                print(f\"  è§‚æµ‹ ATE: {ate:.4f}\")\n                print(f\"  95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n                print(f\"  åŸºçº¿å‡å€¼: {baseline_mean:.4f}\")\n                \n                print(f\"\\næ­¥éª¤ 2: è½¬æ¢ä¸ºé£é™©æ¯”\")\n                print(f\"  é£é™©æ¯” (RR): {rr:.4f}\")\n                print(f\"  95% CI: [{rr_ci_lower:.4f}, {rr_ci_upper:.4f}]\")\n                \n                # è®¡ç®— E-value\n                e_values = compute_e_value(rr, rr_ci_lower)\n                \n                if e_values['e_value'] is not None:\n                    print(f\"\\næ­¥éª¤ 3: è®¡ç®— E-value\")\n                    print(f\"  ç‚¹ä¼°è®¡çš„ E-value: {e_values['e_value']:.4f}\")\n                    \n                    if 'e_value_ci' in e_values and e_values['e_value_ci'] is not None:\n                        print(f\"  ç½®ä¿¡åŒºé—´ä¸‹ç•Œçš„ E-value: {e_values['e_value_ci']:.4f}\")\n                    \n                    print(f\"\\næ­¥éª¤ 4: è§£è¯» E-value\")\n                    print(\"=\"*60)\n                    print(f\"\\nç‚¹ä¼°è®¡è§£è¯»:\")\n                    print(f\"  éœ€è¦ä¸€ä¸ªæœªè§‚æµ‹æ··æ·†å› å­ Uï¼Œå®ƒåŒæ—¶æ»¡è¶³:\")\n                    print(f\"    â€¢ ä½¿å‚åŠ åŸ¹è®­çš„æ¦‚ç‡æé«˜ {e_values['e_value']:.2f} å€\")\n                    print(f\"    â€¢ ä½¿è–ªèµ„æé«˜ {e_values['e_value']:.2f} å€\")\n                    print(f\"  æ‰èƒ½å®Œå…¨è§£é‡Šæ‰è§‚æµ‹åˆ°çš„ {rr:.2f} å€æ•ˆåº”\")\n                    \n                    if 'e_value_ci' in e_values and e_values['e_value_ci'] is not None:\n                        print(f\"\\nç½®ä¿¡åŒºé—´è§£è¯» (æ›´ä¿å®ˆ):\")\n                        print(f\"  å³ä½¿è€ƒè™‘ç»Ÿè®¡ä¸ç¡®å®šæ€§ï¼Œä¹Ÿéœ€è¦ {e_values['e_value_ci']:.2f} å€çš„\")\n                        print(f\"  æ··æ·†å…³è”æ‰èƒ½ä½¿æ•ˆåº”å˜ä¸ºé›¶\")\n                    \n                    # ç¨³å¥æ€§è¯„ä»·\n                    print(f\"\\nç¨³å¥æ€§è¯„ä»·:\")\n                    if e_values['e_value'] < 1.5:\n                        print(\"  âš ï¸ E-value < 1.5: ç»“è®ºéå¸¸è„†å¼±\")\n                        print(\"     å³ä½¿è¾ƒå¼±çš„æ··æ·†ä¹Ÿå¯èƒ½æ¨ç¿»ç»“è®º\")\n                    elif e_values['e_value'] < 2.5:\n                        print(\"  âš ï¸ E-value åœ¨ 1.5-2.5: ç»“è®ºä¸­ç­‰ç¨³å¥\")\n                        print(\"     éœ€è¦è€ƒè™‘å¯èƒ½çš„æ··æ·†å› å­\")\n                    elif e_values['e_value'] < 4.0:\n                        print(\"  âœ… E-value åœ¨ 2.5-4.0: ç»“è®ºè¾ƒä¸ºç¨³å¥\")\n                        print(\"     éœ€è¦è¾ƒå¼ºçš„æ··æ·†æ‰èƒ½æ¨ç¿»ç»“è®º\")\n                    else:\n                        print(\"  âœ…âœ… E-value > 4.0: ç»“è®ºéå¸¸ç¨³å¥\")\n                        print(\"     éœ€è¦éå¸¸å¼ºçš„æ··æ·†æ‰èƒ½æ¨ç¿»ç»“è®º\")\n                    \n                    print(f\"\\nå®é™…åˆ¤æ–­:\")\n                    print(f\"  é—®è‡ªå·±: æ˜¯å¦å­˜åœ¨ä¸€ä¸ªæœªè§‚æµ‹å› å­ï¼Œèƒ½åŒæ—¶ä¸\")\n                    print(f\"  å¤„ç†å’Œç»“æœéƒ½æœ‰ {e_values['e_value']:.1f} å€çš„å…³è”?\")\n                    print(f\"  å¦‚æœå¾ˆéš¾æƒ³è±¡è¿™æ ·çš„å› å­ï¼Œé‚£ä¹ˆç»“è®ºæ˜¯ç¨³å¥çš„ï¼\")\n                else:\n                    print(\"[TODO] è¯·å®Œæˆ compute_e_value å‡½æ•°\")\n            else:\n                print(\"[TODO] è¯·å®Œæˆ ate_to_risk_ratio å‡½æ•°\")\n        else:\n            print(\"[TODO] è¯·å®Œæˆ compute_ate_ci å‡½æ•°\")\n    except Exception as e:\n        print(f\"[é”™è¯¯] {e}\")\nelse:\n    print(\"[TODO] è¯·å…ˆå®Œæˆæ•°æ®ç”Ÿæˆ\")"
  },
  {
   "cell_type": "markdown",
   "source": "### å¦‚ä½•åœ¨è®ºæ–‡ä¸­æŠ¥å‘Š E-value\n\nE-value å·²ç»æˆä¸ºé¡¶çº§æœŸåˆŠï¼ˆå¦‚ JAMA, The Lancet, Epidemiologyï¼‰æ¨èçš„æ•æ„Ÿæ€§åˆ†ææ–¹æ³•ã€‚\n\n#### æŠ¥å‘Šæ¨¡æ¿\n\n**æƒ…å†µ 1: E-value è¾ƒé«˜ï¼ˆç¨³å¥ï¼‰**\n\n> \"We observed a risk ratio of 1.80 (95% CI: 1.45-2.20) for the association between [treatment] and [outcome]. The E-value for the point estimate was 3.0, and the E-value for the lower confidence limit was 2.3. This suggests that an unmeasured confounder would need to be associated with both [treatment] and [outcome] by a risk ratio of at least 3.0-fold each, above and beyond the measured confounders, to fully explain away the observed association. Such strong confounding seems unlikely given the measured covariates already controlled for.\"\n\nä¸­æ–‡ç‰ˆ:\n> \"æˆ‘ä»¬è§‚å¯Ÿåˆ° [å¤„ç†] ä¸ [ç»“æœ] çš„é£é™©æ¯”ä¸º 1.80 (95% CI: 1.45-2.20)ã€‚ç‚¹ä¼°è®¡çš„ E-value ä¸º 3.0ï¼Œç½®ä¿¡åŒºé—´ä¸‹ç•Œçš„ E-value ä¸º 2.3ã€‚è¿™æ„å‘³ç€ï¼Œåœ¨å·²ç»æ§åˆ¶çš„æ··æ·†å› å­ä¹‹å¤–ï¼Œè¿˜éœ€è¦ä¸€ä¸ªæœªè§‚æµ‹æ··æ·†å› å­ä¸å¤„ç†å’Œç»“æœéƒ½æœ‰è‡³å°‘ 3.0 å€çš„å…³è”ï¼Œæ‰èƒ½å®Œå…¨è§£é‡Šæ‰è§‚æµ‹åˆ°çš„å…³è”ã€‚è€ƒè™‘åˆ°æˆ‘ä»¬å·²ç»æ§åˆ¶äº†ä¸»è¦æ··æ·†å› å­ï¼Œå¦‚æ­¤å¼ºçš„æ··æ·†ä¸å¤ªå¯èƒ½å­˜åœ¨ã€‚\"\n\n**æƒ…å†µ 2: E-value è¾ƒä½ï¼ˆéœ€è¦è°¨æ…ï¼‰**\n\n> \"The E-value for our point estimate was 1.8, suggesting that moderate unmeasured confounding could potentially explain the observed association. We acknowledge this as a limitation and recommend cautious interpretation of our findings.\"\n\nä¸­æ–‡ç‰ˆ:\n> \"æˆ‘ä»¬ç‚¹ä¼°è®¡çš„ E-value ä¸º 1.8ï¼Œè¯´æ˜ä¸­ç­‰å¼ºåº¦çš„æœªè§‚æµ‹æ··æ·†å°±å¯èƒ½è§£é‡Šè§‚æµ‹åˆ°çš„å…³è”ã€‚æˆ‘ä»¬æ‰¿è®¤è¿™æ˜¯ç ”ç©¶çš„å±€é™æ€§ï¼Œå»ºè®®è°¨æ…è§£è¯»ç»“æœã€‚\"\n\n#### ä»€ä¹ˆæ—¶å€™æŠ¥å‘Š E-valueï¼Ÿ\n\nâœ… **åº”è¯¥æŠ¥å‘Šçš„æƒ…å†µ**:\n1. è§‚å¯Ÿæ€§ç ”ç©¶ï¼ˆééšæœºå®éªŒï¼‰\n2. æ— æ³•æ§åˆ¶æ‰€æœ‰é‡è¦æ··æ·†å› å­\n3. ç»“è®ºæœ‰é‡è¦æ”¿ç­–æˆ–ä¸´åºŠæ„ä¹‰\n4. å®¡ç¨¿äººæˆ–æœŸåˆŠè¦æ±‚\n\nâŒ **ä¸éœ€è¦æŠ¥å‘Šçš„æƒ…å†µ**:\n1. éšæœºå¯¹ç…§å®éªŒ (RCT)\n2. å·¥å…·å˜é‡ (IV) ç ”ç©¶ï¼ˆå·²ç»å¤„ç†äº†æ··æ·†ï¼‰\n3. ç»“æœå·²ç»ä¸æ˜¾è‘—ï¼ˆE-value æ²¡æœ‰æ„ä¹‰ï¼‰\n\n#### E-value çš„å±€é™æ€§\n\nâš ï¸ **é‡è¦è­¦å‘Š**:\n\n1. **E-value ä¸èƒ½è¯æ˜æ— æ··æ·†**: E-value é«˜åªè¯´æ˜éœ€è¦å¼ºæ··æ·†æ‰èƒ½æ¨ç¿»ç»“è®ºï¼Œä¸ä»£è¡¨ä¸å­˜åœ¨æ··æ·†\n2. **å¯¹æ•ˆåº”å¤§å°æ•æ„Ÿ**: æ•ˆåº”è¶Šå¤§ï¼ŒE-value è¶Šå¤§ï¼Œä½†æ•ˆåº”å¤§å¯èƒ½æœ¬èº«å°±æ˜¯å› ä¸ºæ··æ·†\n3. **å‡è®¾ç®€åŒ–**: E-value å‡è®¾æ··æ·†å› å­ä¸å¤„ç†ã€ç»“æœçš„å…³è”å¼ºåº¦ç›¸åŒï¼Œå®é™…å¯èƒ½ä¸åŒ\n4. **ä¸èƒ½æ›¿ä»£é¢†åŸŸçŸ¥è¯†**: éœ€è¦ç»“åˆä¸“ä¸šçŸ¥è¯†åˆ¤æ–­ã€Œè¿™æ ·çš„æ··æ·†å› å­æ˜¯å¦åˆç†å­˜åœ¨ã€\n\n#### å®é™…æ¡ˆä¾‹\n\n**æ¡ˆä¾‹ 1: å¸çƒŸä¸è‚ºç™Œ**\n- è§‚æµ‹ RR â‰ˆ 10\n- E-value â‰ˆ 19\n- è§£è¯»: éœ€è¦ä¸€ä¸ªä¸å¸çƒŸå’Œè‚ºç™Œéƒ½æœ‰ 19 å€å…³è”çš„æ··æ·†å› å­ã€‚å¾ˆéš¾æƒ³è±¡è¿™æ ·çš„å› å­ï¼\n\n**æ¡ˆä¾‹ 2: åŸ¹è®­ä¸è–ªèµ„**\n- è§‚æµ‹ RR = 1.2\n- E-value â‰ˆ 1.6\n- è§£è¯»: ã€ŒåŠ¨æœºã€è¿™ä¸ªæœªè§‚æµ‹å› å­å¾ˆå¯èƒ½åŒæ—¶å½±å“åŸ¹è®­å’Œè–ªèµ„ï¼Œä¸”å…³è”å¼ºåº¦å¯èƒ½è¶…è¿‡ 1.6 å€ã€‚ç»“è®ºè„†å¼±ï¼",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# å¯¹æ¯”ä¸åŒæ··æ·†å¼ºåº¦ä¸‹çš„ E-value\nprint(\"=== ä¸åŒæ··æ·†å¼ºåº¦ä¸‹çš„ E-value å¯¹æ¯” ===\\n\")\n\ncomparison_results = []\n\nfor strength in [0.0, 0.3, 0.6, 1.0]:\n    df_temp, U_temp, params_temp = simulate_unobserved_confounding(\n        n=2000,\n        confounder_strength=strength,\n        seed=42 + int(strength * 10)\n    )\n    \n    if df_temp is not None and df_temp['Y'].iloc[0] is not None:\n        try:\n            # æœ´ç´ ä¼°è®¡\n            naive_ate = df_temp['Y'][df_temp['T']==1].mean() - df_temp['Y'][df_temp['T']==0].mean()\n            baseline = df_temp.loc[df_temp['T'] == 0, 'Y'].mean()\n            \n            # è®¡ç®—ç½®ä¿¡åŒºé—´\n            ate, ci_lower, ci_upper = compute_ate_ci(\n                df_temp['Y'].values, \n                df_temp['T'].values\n            )\n            \n            if ate is not None and ci_lower is not None:\n                # è½¬æ¢ä¸ºé£é™©æ¯”\n                rr = ate_to_risk_ratio(ate, baseline)\n                rr_ci_lower = ate_to_risk_ratio(ci_lower, baseline)\n                \n                if rr is not None:\n                    # è®¡ç®— E-value\n                    e_vals = compute_e_value(rr, rr_ci_lower)\n                    \n                    if e_vals['e_value'] is not None:\n                        comparison_results.append({\n                            'æ··æ·†å¼ºåº¦': strength,\n                            'ATE (çœŸå®=2.0)': ate,\n                            'åå·®': ate - 2.0,\n                            'é£é™©æ¯”': rr,\n                            'E-value (ç‚¹ä¼°è®¡)': e_vals['e_value'],\n                            'E-value (CIä¸‹ç•Œ)': e_vals.get('e_value_ci', np.nan)\n                        })\n        except:\n            pass\n\nif len(comparison_results) > 0:\n    comp_df = pd.DataFrame(comparison_results)\n    display(comp_df.round(4))\n    \n    print(\"\\nå…³é”®æ´å¯Ÿ:\")\n    print(\"1. æ··æ·†å¼ºåº¦ = 0: æ— åä¼°è®¡ï¼ŒE-value è¾ƒé«˜ (ç¨³å¥)\")\n    print(\"2. æ··æ·†å¼ºåº¦å¢åŠ : ä¼°è®¡åå·®å¢å¤§ï¼Œä½† E-value ä¹Ÿå¯èƒ½å¢å¤§\")\n    print(\"3. E-value é«˜ä¸ä»£è¡¨ä¼°è®¡æ— åï¼åªè¡¨ç¤ºã€Œå¦‚æœè¦æ¨ç¿»ç»“è®ºï¼Œéœ€è¦å¤šå¼ºçš„æ··æ·†ã€\")\n    print(\"4. è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ E-value æ˜¯ã€Œæ•æ„Ÿæ€§åˆ†æã€è€Œéã€ŒéªŒè¯æ— åæ€§ã€\")\nelse:\n    print(\"[TODO] è¯·å®Œæˆä¸Šé¢çš„å‡½æ•°\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# å¯è§†åŒ– E-value ä¸é£é™©æ¯”çš„å…³ç³»\ndef plot_evalue_curve():\n    \"\"\"\n    ç»˜åˆ¶ E-value ä¸é£é™©æ¯”çš„å…³ç³»æ›²çº¿\n    å¸®åŠ©ç†è§£ä¸åŒæ•ˆåº”å¤§å°å¯¹åº”çš„ E-value\n    \"\"\"\n    rr_range = np.linspace(1.0, 5.0, 100)\n    e_values = rr_range + np.sqrt(rr_range * (rr_range - 1))\n    \n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # å·¦å›¾: E-value vs RR\n    axes[0].plot(rr_range, e_values, 'b-', linewidth=2)\n    axes[0].axhline(y=1.5, color='red', linestyle='--', alpha=0.5, label='E=1.5 (è„†å¼±)')\n    axes[0].axhline(y=2.5, color='orange', linestyle='--', alpha=0.5, label='E=2.5 (ä¸­ç­‰)')\n    axes[0].axhline(y=4.0, color='green', linestyle='--', alpha=0.5, label='E=4.0 (ç¨³å¥)')\n    axes[0].fill_between(rr_range, 0, 1.5, alpha=0.1, color='red')\n    axes[0].fill_between(rr_range, 1.5, 2.5, alpha=0.1, color='orange')\n    axes[0].fill_between(rr_range, 2.5, 4.0, alpha=0.1, color='yellow')\n    axes[0].fill_between(rr_range, 4.0, e_values.max(), alpha=0.1, color='green')\n    \n    # æ ‡æ³¨å®é™…æ¡ˆä¾‹\n    if 'rr' in dir() and rr is not None and e_values is not None:\n        try:\n            current_evalue = compute_e_value(rr)\n            if current_evalue['e_value'] is not None:\n                axes[0].scatter([rr], [current_evalue['e_value']], \n                              s=200, color='darkblue', zorder=5, \n                              label=f'å½“å‰ç ”ç©¶ (RR={rr:.2f}, E={current_evalue[\"e_value\"]:.2f})')\n        except:\n            pass\n    \n    axes[0].set_xlabel('è§‚æµ‹åˆ°çš„é£é™©æ¯” (RR)', fontsize=12)\n    axes[0].set_ylabel('E-value', fontsize=12)\n    axes[0].set_title('E-value ä¸é£é™©æ¯”çš„å…³ç³»\\n\"æ•ˆåº”è¶Šå¤§ï¼Œç»“è®ºè¶Šç¨³å¥\"', fontsize=13)\n    axes[0].legend(loc='upper left')\n    axes[0].grid(True, alpha=0.3)\n    \n    # å³å›¾: éœ€è¦çš„æ··æ·†å¼ºåº¦ç¤ºæ„å›¾\n    example_rrs = [1.5, 2.0, 3.0, 4.0]\n    example_evalues = [rr + np.sqrt(rr * (rr - 1)) for rr in example_rrs]\n    \n    colors = ['#e74c3c', '#e67e22', '#f39c12', '#27ae60']\n    bars = axes[1].barh(range(len(example_rrs)), example_evalues, color=colors, alpha=0.7)\n    \n    axes[1].set_yticks(range(len(example_rrs)))\n    axes[1].set_yticklabels([f'RR = {rr:.1f}' for rr in example_rrs])\n    axes[1].set_xlabel('éœ€è¦çš„æ··æ·†å¼ºåº¦ (E-value)', fontsize=12)\n    axes[1].set_title('ä¸åŒæ•ˆåº”å¤§å°å¯¹åº”çš„ç¨³å¥æ€§è¦æ±‚', fontsize=13)\n    axes[1].grid(True, alpha=0.3, axis='x')\n    \n    # æ·»åŠ æ•°å€¼æ ‡æ³¨\n    for i, (rr, ev) in enumerate(zip(example_rrs, example_evalues)):\n        axes[1].text(ev + 0.1, i, f'E = {ev:.2f}', \n                    va='center', fontsize=11, fontweight='bold')\n    \n    plt.tight_layout()\n    plt.show()\n\n# ç»˜åˆ¶æ›²çº¿\ntry:\n    plot_evalue_curve()\n    \n    print(\"\\nå›¾è¡¨è§£è¯»:\")\n    print(\"å·¦å›¾: E-value éšé£é™©æ¯”å•è°ƒé€’å¢\")\n    print(\"  - æ•ˆåº”è¶Šå¤§ (RR è¶Šå¤§)ï¼Œéœ€è¦è¶Šå¼ºçš„æ··æ·†æ‰èƒ½æ¨ç¿»\")\n    print(\"  - é¢œè‰²åˆ†åŒºæ˜¾ç¤ºä¸åŒçš„ç¨³å¥æ€§ç­‰çº§\")\n    print(\"\\nå³å›¾: å…·ä½“æ¡ˆä¾‹å¯¹æ¯”\")\n    print(\"  - RR=1.5 â†’ E=2.0: éœ€è¦ 2 å€çš„æ··æ·†\")\n    print(\"  - RR=3.0 â†’ E=4.7: éœ€è¦ 4.7 å€çš„æ··æ·† (å¾ˆç¨³å¥!)\")\nexcept Exception as e:\n    print(f\"[æç¤º] å›¾è¡¨éœ€è¦å®Œæˆä¸Šé¢çš„å‡½æ•°æ‰èƒ½æ˜¾ç¤º: {e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  3.4: Placebo ç¨³å¥æ€§æ£€éªŒ\n",
    "\n",
    "Placebo æµ‹è¯•æ˜¯ä¸€ç§ç®€å•ä½†å¼ºå¤§çš„ç¨³å¥æ€§æ£€éªŒï¼š\n",
    "\n",
    "**æ€è·¯**: å¦‚æœæˆ‘ä»¬çš„å› æœä¼°è®¡æ–¹æ³•æ˜¯æ­£ç¡®çš„ï¼Œé‚£ä¹ˆå¯¹äºã€Œä¸åº”å—å¤„ç†å½±å“çš„å˜é‡ã€ï¼Œæˆ‘ä»¬ä¸åº”è¯¥æ£€æµ‹åˆ°æ˜¾è‘—æ•ˆåº”ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼š\n",
    "- ç ”ç©¶ã€ŒåŸ¹è®­ã€å¯¹ã€Œè–ªèµ„ã€çš„å½±å“\n",
    "- Placebo å˜é‡ï¼šå‚åŠ åŸ¹è®­å‰çš„èº«é«˜ï¼ˆæ˜¾ç„¶åŸ¹è®­ä¸åº”è¯¥æ”¹å˜èº«é«˜ï¼‰\n",
    "- å¦‚æœæˆ‘ä»¬åœ¨èº«é«˜ä¸Šä¹Ÿå‘ç°äº†ã€Œæ•ˆåº”ã€ï¼Œè¯´æ˜å¯èƒ½æœ‰é—®é¢˜ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def placebo_test(\n",
    "    df: pd.DataFrame,\n",
    "    outcome_col: str = 'Y',\n",
    "    placebo_outcome_col: str = 'Y_placebo'\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Placebo æµ‹è¯•\n",
    "    \n",
    "    ä½¿ç”¨ä¸åº”å—å¤„ç†å½±å“çš„\"å‡\"ç»“æœå˜é‡è¿›è¡Œæµ‹è¯•\n",
    "    \n",
    "    Args:\n",
    "        df: åŒ…å« T, Y, Y_placebo çš„ DataFrame\n",
    "        outcome_col: çœŸå®ç»“æœåˆ—å\n",
    "        placebo_outcome_col: å‡ç»“æœåˆ—å\n",
    "    \n",
    "    Returns:\n",
    "        {'true_effect': ..., 'placebo_effect': ..., 'p_value_placebo': ...}\n",
    "    \"\"\"\n",
    "    T = df['T'].values\n",
    "    \n",
    "    # TODO: è®¡ç®—çœŸå®ç»“æœçš„æ•ˆåº”\n",
    "    Y = df[outcome_col].values\n",
    "    true_effect = None  # ä½ çš„ä»£ç : Y[T==1].mean() - Y[T==0].mean()\n",
    "    \n",
    "    # TODO: è®¡ç®—å‡ç»“æœçš„æ•ˆåº”\n",
    "    Y_placebo = df[placebo_outcome_col].values\n",
    "    placebo_effect = None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    # TODO: t æ£€éªŒæµ‹è¯•å‡ç»“æœæ•ˆåº”æ˜¯å¦æ˜¾è‘—\n",
    "    # ä½¿ç”¨ scipy.stats.ttest_ind\n",
    "    t_stat, p_value = None, None  # ä½ çš„ä»£ç \n",
    "    \n",
    "    return {\n",
    "        'true_effect': true_effect,\n",
    "        'placebo_effect': placebo_effect,\n",
    "        'p_value_placebo': p_value\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯• Placebo æ£€éªŒ\n",
    "if df is not None and df['Y'].iloc[0] is not None:\n",
    "    # ç”Ÿæˆå‡ç»“æœå˜é‡ï¼ˆä¸åº”å— T å½±å“ï¼Œåªä¸ X ç›¸å…³ï¼‰\n",
    "    np.random.seed(123)\n",
    "    df['Y_placebo'] = df['X'] * 2 + np.random.randn(len(df)) * 0.5\n",
    "    \n",
    "    try:\n",
    "        placebo_results = placebo_test(df, 'Y', 'Y_placebo')\n",
    "        \n",
    "        if placebo_results['true_effect'] is not None:\n",
    "            print(\"Placebo æµ‹è¯•ç»“æœ:\")\n",
    "            print(\"=\"*50)\n",
    "            print(f\"\\nçœŸå®ç»“æœ (Y) çš„æ•ˆåº”: {placebo_results['true_effect']:.4f}\")\n",
    "            print(f\"å‡ç»“æœ (Y_placebo) çš„æ•ˆåº”: {placebo_results['placebo_effect']:.4f}\")\n",
    "            \n",
    "            if placebo_results['p_value_placebo'] is not None:\n",
    "                print(f\"å‡ç»“æœ p-value: {placebo_results['p_value_placebo']:.4f}\")\n",
    "                \n",
    "                print(\"\\nè§£è¯»:\")\n",
    "                if placebo_results['p_value_placebo'] < 0.05:\n",
    "                    print(\"  âš ï¸ è­¦å‘Š: å‡ç»“æœä¹Ÿæ˜¾ç¤ºæ˜¾è‘—æ•ˆåº”!\")\n",
    "                    print(\"  è¿™å¯èƒ½æ„å‘³ç€:\")\n",
    "                    print(\"  - å­˜åœ¨æœªæ§åˆ¶çš„æ··æ·†\")\n",
    "                    print(\"  - é€‰æ‹©åå·®é—®é¢˜\")\n",
    "                    print(\"  - æ¨¡å‹è®¾å®šé”™è¯¯\")\n",
    "                else:\n",
    "                    print(\"  âœ… å‡ç»“æœæ— æ˜¾è‘—æ•ˆåº”ï¼Œé€šè¿‡ Placebo æµ‹è¯•!\")\n",
    "                    print(\"  è¿™å¢å¼ºäº†æˆ‘ä»¬å¯¹å› æœä¼°è®¡çš„ä¿¡å¿ƒ\")\n",
    "        else:\n",
    "            print(\"[TODO] è¯·å®Œæˆ placebo_test å‡½æ•°\")\n",
    "    except Exception as e:\n",
    "        print(f\"[é”™è¯¯] {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹æ¯”æœ‰æ··æ·†å’Œæ— æ··æ·†æƒ…å†µä¸‹çš„ Placebo æµ‹è¯•\n",
    "print(\"å¯¹æ¯”ä¸åŒæ··æ·†å¼ºåº¦ä¸‹çš„ Placebo æµ‹è¯•:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "placebo_comparison = []\n",
    "\n",
    "for strength in [0.0, 0.3, 0.6, 1.0]:\n",
    "    df_temp, U_temp, params_temp = simulate_unobserved_confounding(\n",
    "        n=2000,\n",
    "        confounder_strength=strength\n",
    "    )\n",
    "    \n",
    "    if df_temp is not None and df_temp['Y'].iloc[0] is not None:\n",
    "        # ç”Ÿæˆä¾èµ–äº U çš„å‡ç»“æœï¼ˆå¦‚æœ U æ˜¯æ··æ·†ï¼Œè¿™ä¸ªä¹Ÿä¼šè¢«\"å½±å“\"ï¼‰\n",
    "        df_temp['Y_placebo'] = U_temp * 2 + np.random.randn(len(df_temp)) * 0.5\n",
    "        \n",
    "        results = placebo_test(df_temp, 'Y', 'Y_placebo')\n",
    "        \n",
    "        if results['placebo_effect'] is not None:\n",
    "            placebo_comparison.append({\n",
    "                'Strength': strength,\n",
    "                'True Effect': results['true_effect'],\n",
    "                'Placebo Effect': results['placebo_effect'],\n",
    "                'P-value': results['p_value_placebo']\n",
    "            })\n",
    "\n",
    "if len(placebo_comparison) > 0:\n",
    "    comp_df = pd.DataFrame(placebo_comparison)\n",
    "    display(comp_df.round(4))\n",
    "    \n",
    "    print(\"\\nè§£è¯»:\")\n",
    "    print(\"- å½“æ··æ·†å¼ºåº¦ä¸º 0 æ—¶ï¼ŒPlacebo æ•ˆåº”æ¥è¿‘ 0\")\n",
    "    print(\"- éšç€æ··æ·†å¼ºåº¦å¢åŠ ï¼ŒPlacebo æ•ˆåº”å˜å¾—æ˜¾è‘—\")\n",
    "    print(\"- è¿™è¯´æ˜ Placebo æµ‹è¯•å¯ä»¥å¸®åŠ©æ£€æµ‹æ··æ·†!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# æ€è€ƒé¢˜ 3: E-value å’Œ Rosenbaum bounds æœ‰ä½•å¼‚åŒï¼Ÿ\n\nanswer_3 = \"\"\"\nä½ çš„ç­”æ¡ˆ:\n\nç›¸åŒç‚¹:\n- \n\nä¸åŒç‚¹:\n- \n\nå„è‡ªé€‚ç”¨åœºæ™¯:\n- \n\n\"\"\"\nprint(answer_3)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 1: ä¸ºä»€ä¹ˆæ— æ··æ·†å‡è®¾æ— æ³•ä»æ•°æ®ä¸­éªŒè¯ï¼Ÿ\n",
    "\n",
    "answer_1 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 2: Rosenbaum Î“ = 2 æ„å‘³ç€ä»€ä¹ˆï¼Ÿåœ¨å®è·µä¸­è¿™ç®—å¼ºæ··æ·†è¿˜æ˜¯å¼±æ··æ·†ï¼Ÿ\n",
    "\n",
    "answer_2 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_2)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# æ€è€ƒé¢˜ 9: E-value å¾ˆé«˜æ˜¯å¦æ„å‘³ç€å› æœå…³ç³»ä¸€å®šæˆç«‹ï¼Ÿ\n\nanswer_9 = \"\"\"\nä½ çš„ç­”æ¡ˆ:\n\n\n\n\"\"\"\nprint(answer_9)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# æ€è€ƒé¢˜ 8: ä¸ºä»€ä¹ˆ E-value è¦åŒæ—¶è®¡ç®—ç‚¹ä¼°è®¡å’Œç½®ä¿¡åŒºé—´ä¸‹ç•Œçš„å€¼ï¼Ÿ\n\nanswer_8 = \"\"\"\nä½ çš„ç­”æ¡ˆ:\n\n\n\n\"\"\"\nprint(answer_8)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# æ€è€ƒé¢˜ 7: E-value = 2.5 åœ¨å®è·µä¸­ç®—é«˜è¿˜æ˜¯ä½ï¼Ÿèƒ½ä¸¾ä¸€ä¸ªç°å®ä¸­çš„æ··æ·†å› å­ä¾‹å­å—ï¼Ÿ\n\nanswer_7 = \"\"\"\nä½ çš„ç­”æ¡ˆ:\n\n\n\n\"\"\"\nprint(answer_7)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 3: E-value å’Œ Rosenbaum bounds æœ‰ä½•å¼‚åŒï¼Ÿ\n",
    "\n",
    "answer_3 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## ğŸ“Š æ€»ç»“\n\n### æ•æ„Ÿæ€§åˆ†ææ–¹æ³•å¯¹æ¯”\n\n| æ–¹æ³• | å›ç­”çš„é—®é¢˜ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |\n|------|------------|------|------|---------|\n| **Rosenbaum Bounds** | å¤šå¼ºçš„æ··æ·†ä¼šæ¨ç¿»ç»“è®ºï¼Ÿ| æœ‰ä¸¥æ ¼ç†è®ºåŸºç¡€ | éœ€è¦åŒ¹é…è®¾è®¡ï¼›Î“ ä¸å¤Ÿç›´è§‚ | å€¾å‘å¾—åˆ†åŒ¹é…å |\n| **E-value** | è§£é‡Šæ•ˆåº”éœ€è¦å¤šå¼ºçš„æ··æ·†ï¼Ÿ| ç®€å•è®¡ç®—ï¼›æ˜“äºè§£é‡Šï¼›å¹¿æ³›é€‚ç”¨ | å‡è®¾ç®€åŒ–ï¼›ä¸èƒ½è¯æ˜å› æœ | ä»»ä½•è§‚å¯Ÿæ€§ç ”ç©¶ |\n| **Placebo Test** | æ–¹æ³•æ˜¯å¦å¯é ï¼Ÿ| ç›´æ¥æ£€éªŒå‡è®¾ï¼›æ˜“äºç†è§£ | éœ€è¦å¥½çš„ placebo å˜é‡ | æœ‰åˆé€‚ placebo æ—¶ |\n\n### E-value è§£è¯»æŒ‡å—\n\n| E-value èŒƒå›´ | ç¨³å¥æ€§è¯„ä»· | å®é™…å«ä¹‰ | å»ºè®® |\n|-------------|-----------|---------|------|\n| < 1.5 | âŒ éå¸¸è„†å¼± | å¼±æ··æ·†å³å¯æ¨ç¿» | è°¨æ…è§£é‡Šï¼Œæ‰¿è®¤å±€é™ |\n| 1.5 - 2.0 | âš ï¸ è¾ƒä¸ºè„†å¼± | ä¸­ç­‰æ··æ·†å¯èƒ½æ¨ç¿» | å¯»æ‰¾æ›´å¤šè¯æ® |\n| 2.0 - 2.5 | ğŸŸ¡ ä¸­ç­‰ç¨³å¥ | éœ€è¦è¾ƒå¼ºæ··æ·† | ç»“åˆé¢†åŸŸçŸ¥è¯†åˆ¤æ–­ |\n| 2.5 - 4.0 | âœ… è¾ƒä¸ºç¨³å¥ | éœ€è¦å¼ºæ··æ·† | å¯ä»¥æœ‰ä¸€å®šä¿¡å¿ƒ |\n| > 4.0 | âœ…âœ… éå¸¸ç¨³å¥ | éœ€è¦æå¼ºæ··æ·† | ç»“è®ºå¯ä¿¡åº¦é«˜ |\n\n**å…³é”®æé†’**: E-value é«˜ä¸ä»£è¡¨æ— æ··æ·†ï¼Œåªè¡¨ç¤ºéœ€è¦å¤šå¼ºçš„æ··æ·†æ‰èƒ½æ¨ç¿»ç»“è®ºï¼\n\n### E-value å…¬å¼é€ŸæŸ¥\n\nå¯¹äºä¸åŒçš„æ•ˆåº”åº¦é‡ï¼ŒE-value çš„è®¡ç®—å…¬å¼ï¼š\n\n**1. é£é™©æ¯” (Risk Ratio, RR)**\n```\nE = RR + sqrt(RR * (RR - 1))   [å½“ RR â‰¥ 1]\nE = 1/RR + sqrt(1/RR * (1/RR - 1))   [å½“ RR < 1]\n```\n\n**2. æ¯”å€¼æ¯” (Odds Ratio, OR)** - å¯¹äºç½•è§ç»“æœ\n```\nE â‰ˆ OR + sqrt(OR * (OR - 1))   [å½“ OR â‰¥ 1]\n```\n\n**3. æ ‡å‡†åŒ–å‡å€¼å·® (Cohen's d)**\n```\nRR_approx = exp(0.91 * d)\nç„¶åè®¡ç®— E-value\n```\n\n### ä½•æ—¶ä½¿ç”¨æ•æ„Ÿæ€§åˆ†æï¼Ÿ\n\nâœ… **æ€»æ˜¯åº”è¯¥åš**:\n- è§‚å¯Ÿæ€§ç ”ç©¶\n- æ— æ³•éšæœºåŒ–çš„åœºæ™¯\n- ç»“è®ºæœ‰é‡è¦æ”¿ç­–/ä¸´åºŠæ„ä¹‰\n- å¯èƒ½å­˜åœ¨æœªè§‚æµ‹æ··æ·†\n\nâš ï¸ **è°¨æ…ä½¿ç”¨**:\n- éšæœºå¯¹ç…§å®éªŒï¼ˆå·²ç»å¤„ç†äº†æ··æ·†ï¼‰\n- å·¥å…·å˜é‡ç ”ç©¶ï¼ˆæœ‰å…¶ä»–æ–¹æ³•å¤„ç†æ··æ·†ï¼‰\n\n### æ•æ„Ÿæ€§åˆ†æçš„æ­£ç¡®å¿ƒæ€\n\n**ä¸æ˜¯ä¸ºäº†**:\n- âŒ è¯æ˜å› æœå…³ç³»æˆç«‹\n- âŒ éªŒè¯æ— æ··æ·†å‡è®¾\n- âŒ æ›¿ä»£éšæœºå®éªŒ\n\n**è€Œæ˜¯ä¸ºäº†**:\n- âœ… è¯„ä¼°ç»“è®ºçš„ç¨³å¥æ€§\n- âœ… é‡åŒ–ä¸ç¡®å®šæ€§\n- âœ… æŒ‡å¯¼åç»­ç ”ç©¶æ–¹å‘\n- âœ… è¯šå®åœ°è®¨è®ºå±€é™æ€§\n\n### æœ€ä½³å®è·µ\n\n1. **æŠ¥å‘Šå¤šä¸ªæŒ‡æ ‡**: åŒæ—¶æŠ¥å‘Šç‚¹ä¼°è®¡å’Œç½®ä¿¡åŒºé—´çš„ E-value\n2. **ç»“åˆé¢†åŸŸçŸ¥è¯†**: æ€è€ƒã€Œè¿™æ ·çš„æ··æ·†å› å­æ˜¯å¦åˆç†å­˜åœ¨ã€\n3. **ä½¿ç”¨å¤šç§æ–¹æ³•**: Rosenbaum + E-value + Placebo äº¤å‰éªŒè¯\n4. **è¯šå®è®¨è®º**: åœ¨è®ºæ–‡çš„ Limitation éƒ¨åˆ†å¦è¯šè®¨è®º\n5. **è€ƒè™‘æ–¹å‘**: æœªè§‚æµ‹æ··æ·†å¯èƒ½é«˜ä¼°ä¹Ÿå¯èƒ½ä½ä¼°æ•ˆåº”"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 5: å¦‚æœæ•æ„Ÿæ€§åˆ†ææ˜¾ç¤ºç»“è®ºå¯¹æœªè§‚æµ‹æ··æ·†å¾ˆæ•æ„Ÿï¼Œåº”è¯¥æ€ä¹ˆåŠï¼Ÿ\n",
    "\n",
    "answer_5 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€è€ƒé¢˜ 6: Placebo æµ‹è¯•çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿå®ƒèƒ½æ£€æµ‹å“ªç§ç±»å‹çš„åå·®ï¼Ÿ\n",
    "\n",
    "answer_6 = \"\"\"\n",
    "ä½ çš„ç­”æ¡ˆ:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(answer_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ€»ç»“\n",
    "\n",
    "### æ•æ„Ÿæ€§åˆ†ææ–¹æ³•å¯¹æ¯”\n",
    "\n",
    "| æ–¹æ³• | å›ç­”çš„é—®é¢˜ | ä¼˜ç‚¹ | ç¼ºç‚¹ |\n",
    "|------|------------|------|------|\n",
    "| Rosenbaum Bounds | å¤šå¼ºçš„æ··æ·†ä¼šæ¨ç¿»ç»“è®ºï¼Ÿ | ç›´è§‚ã€æœ‰ç†è®ºæ”¯æ’‘ | éœ€è¦åŒ¹é… |\n",
    "| E-value | è§£é‡Šæ•ˆåº”éœ€è¦å¤šå¼ºçš„æ··æ·†ï¼Ÿ | ç®€å•è®¡ç®—ã€å¹¿æ³›é€‚ç”¨ | å‡è®¾è¾ƒå¼º |\n",
    "| Placebo Test | æ–¹æ³•æ˜¯å¦å¯é ï¼Ÿ | ç›´æ¥æ£€éªŒå‡è®¾ | éœ€è¦å¥½çš„ placebo å˜é‡ |\n",
    "\n",
    "### ä½•æ—¶ä½¿ç”¨æ•æ„Ÿæ€§åˆ†æï¼Ÿ\n",
    "\n",
    "âœ… **æ€»æ˜¯åº”è¯¥åš**:\n",
    "- è§‚å¯Ÿæ€§ç ”ç©¶\n",
    "- æ— æ³•éšæœºåŒ–çš„æƒ…å†µ\n",
    "- ç»“è®ºæœ‰é‡è¦æ”¿ç­–å«ä¹‰\n",
    "\n",
    "### å¦‚ä½•è§£è¯»ç»“æœï¼Ÿ\n",
    "\n",
    "| E-value / Î“ é˜ˆå€¼ | è§£è¯» |\n",
    "|------------------|------|\n",
    "| < 1.5 | ç»“è®ºéå¸¸è„†å¼± |\n",
    "| 1.5 - 2.5 | ä¸­ç­‰ç¨³å¥ |\n",
    "| 2.5 - 4.0 | è¾ƒä¸ºç¨³å¥ |\n",
    "| > 4.0 | éå¸¸ç¨³å¥ |\n",
    "\n",
    "### æœ€ä½³å®è·µ\n",
    "\n",
    "1. **æ€»æ˜¯æŠ¥å‘Šæ•æ„Ÿæ€§åˆ†æ**\n",
    "2. **ç»“åˆé¢†åŸŸçŸ¥è¯†**åˆ¤æ–­å‡è®¾çš„æ··æ·†æ˜¯å¦åˆç†\n",
    "3. **ä½¿ç”¨å¤šç§æ–¹æ³•**äº¤å‰éªŒè¯\n",
    "4. **è¯šå®åœ°è®¨è®ºå±€é™æ€§**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ” æ­å–œå®Œæˆæ•æ„Ÿæ€§åˆ†æç»ƒä¹ !\")\n",
    "print(\"\\nä½ å·²ç»å­¦ä¼šäº†:\")\n",
    "print(\"  âœ“ ç†è§£æœªè§‚æµ‹æ··æ·†çš„å½±å“\")\n",
    "print(\"  âœ“ Rosenbaum æ•æ„Ÿæ€§è¾¹ç•Œ\")\n",
    "print(\"  âœ“ E-value è®¡ç®—å’Œè§£è¯»\")\n",
    "print(\"  âœ“ Placebo ç¨³å¥æ€§æ£€éªŒ\")\n",
    "print(\"\\næ­å–œå®Œæˆ Chapter 5 æ‰€æœ‰ç»ƒä¹ !\")\n",
    "print(\"ä¸‹ä¸€æ­¥: Chapter 6 åº”ç”¨åœºæ™¯ - ä¼˜æƒ åˆ¸ä¼˜åŒ–!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}