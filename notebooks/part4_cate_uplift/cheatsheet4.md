# Part 4: CATE & Uplift å»ºæ¨¡ - é¢è¯•é€ŸæŸ¥æ‰‹å†Œ

> æœ€åæ›´æ–°ï¼š2026-01-04
> é€‚ç”¨åœºæ™¯ï¼šæŠ€æœ¯é¢è¯•ã€å¿«é€Ÿå¤ä¹ ã€å®æˆ˜å‚è€ƒ

---

## ğŸ“Œ æ ¸å¿ƒæ¦‚å¿µé€ŸæŸ¥

### 1. CATE vs ATE vs ITE

| æ¦‚å¿µ | å…¬å¼ | å«ä¹‰ | å¯è§‚æµ‹æ€§ |
|------|------|------|---------|
| **ATE** | $\mathbb{E}[Y(1) - Y(0)]$ | å¹³å‡å¤„ç†æ•ˆåº” | å¯ä¼°è®¡ |
| **CATE** | $\mathbb{E}[Y(1) - Y(0) \| X=x]$ | æ¡ä»¶å¹³å‡å¤„ç†æ•ˆåº” | å¯ä¼°è®¡ |
| **ITE** | $Y_i(1) - Y_i(0)$ | ä¸ªä½“å¤„ç†æ•ˆåº” | **ä¸å¯è§‚æµ‹** |

**å…³é”®å…³ç³»**ï¼š
$$\text{ATE} = \mathbb{E}_X[\text{CATE}(X)]$$

**è®°å¿†å£è¯€**ï¼š
- ATEï¼šå¤§é”…é¥­ï¼Œæ‰€æœ‰äººå¹³å‡
- CATEï¼šå°ç¶é¥­ï¼ŒæŒ‰ç‰¹å¾åˆ†ç»„
- ITEï¼šç§äººè®¢åˆ¶ï¼Œæ¯ä¸ªäººç‹¬ç«‹

---

## ğŸ”¥ 2 åˆ†é’Ÿæ‰‹å†™å®ç°ç³»åˆ—

### é¢˜ç›® 1ï¼šæ‰‹å†™ T-Learner

**é¢˜ç›®**ï¼šç”¨ Python å®ç° T-Learnerï¼Œä¼°è®¡ CATEã€‚

**æ ¸å¿ƒæ€è·¯**ï¼š
1. åˆ†åˆ«åœ¨å¤„ç†ç»„å’Œæ§åˆ¶ç»„è®­ç»ƒæ¨¡å‹
2. CATE = Î¼â‚(x) - Î¼â‚€(x)

**å‚è€ƒä»£ç **ï¼ˆé¢è¯•å¯ç›´æ¥æ‰‹å†™ï¼‰ï¼š

```python
from sklearn.ensemble import RandomForestRegressor
import numpy as np

class TLearner:
    def __init__(self):
        self.model_0 = RandomForestRegressor(n_estimators=100)
        self.model_1 = RandomForestRegressor(n_estimators=100)

    def fit(self, X, T, Y):
        """
        X: ç‰¹å¾çŸ©é˜µ (n, p)
        T: å¤„ç†çŠ¶æ€ (n,) - 0/1
        Y: ç»“æœå˜é‡ (n,)
        """
        # åˆ†ç¦»å¤„ç†ç»„å’Œæ§åˆ¶ç»„
        mask_0 = (T == 0)
        mask_1 = (T == 1)

        # åˆ†åˆ«è®­ç»ƒ
        self.model_0.fit(X[mask_0], Y[mask_0])
        self.model_1.fit(X[mask_1], Y[mask_1])

        return self

    def predict_cate(self, X):
        """é¢„æµ‹ CATE"""
        Y1_pred = self.model_1.predict(X)
        Y0_pred = self.model_0.predict(X)
        return Y1_pred - Y0_pred
```

**é¢è¯•è¿½é—®**ï¼š
- Q: T-Learner çš„ä¼˜ç¼ºç‚¹ï¼Ÿ
- A: ä¼˜ç‚¹-çµæ´»æ— åï¼›ç¼ºç‚¹-é«˜æ–¹å·®ï¼Œéœ€è¦å¤§æ ·æœ¬

---

### é¢˜ç›® 2ï¼šæ‰‹å†™ S-Learner

**é¢˜ç›®**ï¼šå®ç° S-Learnerï¼Œå°†å¤„ç† T ä½œä¸ºç‰¹å¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼š
1. æŠŠ T å½“ä½œæ™®é€šç‰¹å¾
2. è®­ç»ƒå•ä¸€æ¨¡å‹ Y = f(X, T)
3. CATE = f(X, 1) - f(X, 0)

**å‚è€ƒä»£ç **ï¼š

```python
class SLearner:
    def __init__(self):
        self.model = RandomForestRegressor(n_estimators=100)

    def fit(self, X, T, Y):
        """è®­ç»ƒ S-Learner"""
        # å°† T æ·»åŠ ä¸ºæœ€åä¸€åˆ—ç‰¹å¾
        X_with_T = np.column_stack([X, T])
        self.model.fit(X_with_T, Y)
        return self

    def predict_cate(self, X):
        """é¢„æµ‹ CATE"""
        n = X.shape[0]

        # æ„é€  T=1 çš„ç‰¹å¾
        X_with_T1 = np.column_stack([X, np.ones(n)])
        Y1_pred = self.model.predict(X_with_T1)

        # æ„é€  T=0 çš„ç‰¹å¾
        X_with_T0 = np.column_stack([X, np.zeros(n)])
        Y0_pred = self.model.predict(X_with_T0)

        return Y1_pred - Y0_pred
```

**é¢è¯•è¿½é—®**ï¼š
- Q: S-Learner ä»€ä¹ˆæ—¶å€™è¡¨ç°å·®ï¼Ÿ
- A: å½“ T çš„æ•ˆåº”è¢«æ­£åˆ™åŒ–å‹ç¼©æ—¶ï¼ˆå°æ•°æ®+å¼ºæ­£åˆ™åŒ–ï¼‰

---

### é¢˜ç›® 3ï¼šæ‰‹å†™ Uplift è®¡ç®—

**é¢˜ç›®**ï¼šç»™å®šä¸€ç»„æ•°æ®ï¼Œè®¡ç®— Upliftã€‚

**æ ¸å¿ƒæ€è·¯**ï¼š
$$\text{Uplift} = P(Y=1|T=1) - P(Y=1|T=0)$$

**å‚è€ƒä»£ç **ï¼š

```python
def calculate_uplift(y, t):
    """
    è®¡ç®— Uplift (å¤„ç†ç»„è½¬åŒ–ç‡ - æ§åˆ¶ç»„è½¬åŒ–ç‡)

    å‚æ•°:
        y: ç»“æœ (0/1)
        t: å¤„ç†çŠ¶æ€ (0/1)

    è¿”å›:
        uplift: å¤„ç†æ•ˆåº”
    """
    # åˆ†ç¦»å¤„ç†ç»„å’Œæ§åˆ¶ç»„
    mask_t = (t == 1)
    mask_c = (t == 0)

    # è¾¹ç•Œæ£€æŸ¥
    if mask_t.sum() == 0 or mask_c.sum() == 0:
        return 0.0

    # è®¡ç®—è½¬åŒ–ç‡
    rate_t = y[mask_t].mean()
    rate_c = y[mask_c].mean()

    return rate_t - rate_c

# ä½¿ç”¨ç¤ºä¾‹
y = np.array([1, 1, 0, 1, 0, 0, 1, 0])
t = np.array([1, 1, 1, 1, 0, 0, 0, 0])
uplift = calculate_uplift(y, t)
print(f"Uplift: {uplift:.4f}")  # 0.2500
```

---

### é¢˜ç›® 4ï¼šæ‰‹å†™ PEHE è®¡ç®—

**é¢˜ç›®**ï¼šè®¡ç®— PEHE (Precision in Estimation of Heterogeneous Effects)ã€‚

**æ ¸å¿ƒå…¬å¼**ï¼š
$$\text{PEHE} = \sqrt{\mathbb{E}[(\tau(X) - \hat{\tau}(X))^2]}$$

**å‚è€ƒä»£ç **ï¼š

```python
def calculate_pehe(tau_true, tau_pred):
    """
    è®¡ç®— PEHE

    å‚æ•°:
        tau_true: çœŸå® CATE (n,)
        tau_pred: é¢„æµ‹ CATE (n,)

    è¿”å›:
        pehe: PEHE å€¼ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
    """
    return np.sqrt(np.mean((tau_true - tau_pred) ** 2))

# ä½¿ç”¨ç¤ºä¾‹
tau_true = np.array([2.5, 3.0, 1.5, 4.0])
tau_pred = np.array([2.3, 3.2, 1.4, 3.8])
pehe = calculate_pehe(tau_true, tau_pred)
print(f"PEHE: {pehe:.4f}")  # 0.1581
```

---

### é¢˜ç›® 5ï¼šæ‰‹å†™ Qini æ›²çº¿è®¡ç®—

**é¢˜ç›®**ï¼šå®ç° Qini æ›²çº¿è®¡ç®—ã€‚

**æ ¸å¿ƒå…¬å¼**ï¼š
$$\text{Qini}(k) = Y_t(k) - Y_c(k) \times \frac{n_t(k)}{n_c(k)}$$

**å‚è€ƒä»£ç **ï¼š

```python
def calculate_qini_curve(y_true, treatment, uplift_score):
    """
    è®¡ç®— Qini æ›²çº¿

    å‚æ•°:
        y_true: çœŸå®ç»“æœ (n,)
        treatment: å¤„ç†çŠ¶æ€ (n,)
        uplift_score: é¢„æµ‹ uplift å¾—åˆ† (n,)

    è¿”å›:
        (fraction, qini): æ¨ªåæ ‡å’Œçºµåæ ‡
    """
    # æŒ‰ uplift å¾—åˆ†é™åºæ’åˆ—
    order = np.argsort(uplift_score)[::-1]
    y_sorted = y_true[order]
    t_sorted = treatment[order]

    n = len(y_true)

    # ç´¯ç§¯ç»Ÿè®¡é‡
    cum_y_t = np.cumsum(y_sorted * t_sorted)  # å¤„ç†ç»„ç´¯ç§¯è½¬åŒ–
    cum_y_c = np.cumsum(y_sorted * (1 - t_sorted))  # æ§åˆ¶ç»„ç´¯ç§¯è½¬åŒ–
    cum_n_t = np.cumsum(t_sorted)  # å¤„ç†ç»„ç´¯ç§¯æ ·æœ¬
    cum_n_c = np.cumsum(1 - t_sorted)  # æ§åˆ¶ç»„ç´¯ç§¯æ ·æœ¬

    # è®¡ç®— Qini å€¼
    qini = np.zeros(n)
    mask = (cum_n_c > 0)
    qini[mask] = cum_y_t[mask] - cum_y_c[mask] * (cum_n_t[mask] / cum_n_c[mask])

    # å¹²é¢„æ¯”ä¾‹
    fraction = np.arange(1, n+1) / n

    # æ·»åŠ åŸç‚¹
    fraction = np.insert(fraction, 0, 0)
    qini = np.insert(qini, 0, 0)

    return fraction, qini

# ä½¿ç”¨ç¤ºä¾‹
n = 100
y = np.random.binomial(1, 0.3, n)
t = np.random.binomial(1, 0.5, n)
scores = np.random.randn(n)

fraction, qini = calculate_qini_curve(y, t, scores)
print(f"Qini æ›²çº¿ç‚¹æ•°: {len(fraction)}")
```

---

### é¢˜ç›® 6ï¼šæ‰‹å†™è¯šå®åˆ†è£‚ (Honest Splitting)

**é¢˜ç›®**ï¼šå®ç°å› æœæ£®æ—çš„è¯šå®åˆ†è£‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼š
- å°†æ•°æ®åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼šåˆ†è£‚æ ·æœ¬ + ä¼°è®¡æ ·æœ¬
- åˆ†è£‚æ ·æœ¬ï¼šæ„å»ºæ ‘ç»“æ„
- ä¼°è®¡æ ·æœ¬ï¼šä¼°è®¡å¶èŠ‚ç‚¹ CATE

**å‚è€ƒä»£ç **ï¼š

```python
def honest_split(X, T, Y, split_ratio=0.5, seed=42):
    """
    è¯šå®åˆ†è£‚ï¼šå°†æ•°æ®åˆ†ä¸ºä¸¤ä¸ªä¸é‡å çš„å­é›†

    å‚æ•°:
        X: ç‰¹å¾ (n, p)
        T: å¤„ç† (n,)
        Y: ç»“æœ (n,)
        split_ratio: åˆ†è£‚æ ·æœ¬æ¯”ä¾‹
        seed: éšæœºç§å­

    è¿”å›:
        ((X_split, T_split, Y_split), (X_est, T_est, Y_est))
    """
    np.random.seed(seed)
    n = len(X)

    # éšæœºæ‰“ä¹±ç´¢å¼•
    indices = np.arange(n)
    np.random.shuffle(indices)

    # è®¡ç®—åˆ†è£‚ç‚¹
    split_point = int(n * split_ratio)

    # åˆ’åˆ†ç´¢å¼•
    split_idx = indices[:split_point]
    est_idx = indices[split_point:]

    # åˆ†è£‚æ•°æ®
    X_split, T_split, Y_split = X[split_idx], T[split_idx], Y[split_idx]
    X_est, T_est, Y_est = X[est_idx], T[est_idx], Y[est_idx]

    return (X_split, T_split, Y_split), (X_est, T_est, Y_est)

# ä½¿ç”¨ç¤ºä¾‹
X = np.random.randn(100, 3)
T = np.random.binomial(1, 0.5, 100)
Y = np.random.randn(100)

(X_s, T_s, Y_s), (X_e, T_e, Y_e) = honest_split(X, T, Y)
print(f"åˆ†è£‚æ ·æœ¬: {len(X_s)}, ä¼°è®¡æ ·æœ¬: {len(X_e)}")
```

---

## ğŸ“Š é«˜é¢‘æ¦‚å¿µé¢˜

### Q1: CATE æ˜¯ä»€ä¹ˆï¼Ÿä¸ ATE çš„åŒºåˆ«ï¼Ÿ

**ç­”æ¡ˆ**ï¼š

**CATE (Conditional Average Treatment Effect)**ï¼šæ¡ä»¶å¹³å‡å¤„ç†æ•ˆåº”
$$\text{CATE}(x) = \mathbb{E}[Y(1) - Y(0) | X = x]$$

**ä¸ ATE çš„åŒºåˆ«**ï¼š

| ç»´åº¦ | ATE | CATE |
|------|-----|------|
| å®šä¹‰ | æ‰€æœ‰äººçš„å¹³å‡æ•ˆåº” | ç‰¹å®šç‰¹å¾äººç¾¤çš„å¹³å‡æ•ˆåº” |
| ç²’åº¦ | ç²—ï¼ˆå•ä¸ªæ•°å€¼ï¼‰ | ç»†ï¼ˆæ¯ä¸ª x ä¸€ä¸ªå€¼ï¼‰ |
| ç”¨é€” | è¯„ä¼°æ•´ä½“æ•ˆæœ | ä¸ªæ€§åŒ–å†³ç­– |
| å…³ç³» | $\text{ATE} = \mathbb{E}[\text{CATE}]$ | CATE çš„æœŸæœ› |

**å®é™…ä¾‹å­**ï¼š
- ATEï¼šé™å‹è¯å¹³å‡é™ä½ 10 mmHg
- CATEï¼šå¹´è½»äººé™ 5 mmHgï¼Œè€å¹´äººé™ 15 mmHg

---

### Q2: Meta-Learners å„ç±»æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | æ¨¡å‹æ•° | æ ¸å¿ƒæ€æƒ³ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|--------|---------|------|------|---------|
| **S-Learner** | 1 | T ä½œä¸ºç‰¹å¾ | ç®€å•ï¼Œæ ·æœ¬åˆ©ç”¨å……åˆ† | æ­£åˆ™åŒ–åå·® | å°æ•°æ®ï¼Œå°æ•ˆåº” |
| **T-Learner** | 2 | åˆ†ç»„å»ºæ¨¡ | çµæ´»ï¼Œæ— å | é«˜æ–¹å·® | å¤§æ•°æ®ï¼Œå¤§æ•ˆåº” |
| **X-Learner** | 4 | äº¤å‰ä¼°è®¡+å€¾å‘åŠ æƒ | å¤„ç†ä¸å¹³è¡¡ | å¤æ‚ | æ ·æœ¬ä¸å¹³è¡¡ |
| **R-Learner** | 3 | åŒé‡å»å | ç†è®ºä¼˜é›… | å®ç°å¤æ‚ | éœ€è¦æ¨æ–­ |
| **DR-Learner** | 4 | åŒé‡ç¨³å¥ | ç¨³å¥æ€§å¼º | æœ€å¤æ‚ | æ¨¡å‹ä¸ç¡®å®š |

**é€‰æ‹©å†³ç­–æ ‘**ï¼š
```
æ•°æ®é‡å° (n<500) â†’ S-Learner
æ ·æœ¬ä¸å¹³è¡¡ (90:10) â†’ X-Learner
éœ€è¦ç½®ä¿¡åŒºé—´ â†’ R/DR-Learner
å¿«é€ŸåŸå‹ â†’ T-Learner
```

---

### Q3: Uplift å»ºæ¨¡çš„æ ¸å¿ƒæ€æƒ³

**æ ¸å¿ƒç›®æ ‡**ï¼šè¯†åˆ«å¯¹å¤„ç†å“åº”æœ€å¤§çš„äººç¾¤

**ä¸ä¼ ç»Ÿå»ºæ¨¡çš„åŒºåˆ«**ï¼š

| ç»´åº¦ | ä¼ ç»Ÿåˆ†ç±» | Uplift å»ºæ¨¡ |
|------|---------|------------|
| ç›®æ ‡ | é¢„æµ‹ Y | é¢„æµ‹ Ï„ = Y(1) - Y(0) |
| æ ‡ç­¾ | Y å¯è§‚æµ‹ | Ï„ **ä¸å¯è§‚æµ‹** |
| è¯„ä¼° | AUC, Accuracy | Qini, AUUC |
| åº”ç”¨ | æ‰¾é«˜è½¬åŒ–äººç¾¤ | æ‰¾é«˜å¢é‡äººç¾¤ |

**Uplift çš„å››ç±»äººç¾¤**ï¼š

```
                   è½¬åŒ– (Y=1)    ä¸è½¬åŒ– (Y=0)
å¤„ç† (T=1)           A              B
æ§åˆ¶ (T=0)           C              D
```

| äººç¾¤ | è½¬åŒ–æ¨¡å¼ | Uplift | å†³ç­– |
|------|---------|--------|------|
| Persuadables | Câ†’A | æ­£ | **æŠ•æ”¾ï¼** |
| Sure Things | Aâ†’A | 0 | ä¸æŠ•ï¼ˆæµªè´¹ï¼‰ |
| Lost Causes | Dâ†’D | 0 | ä¸æŠ•ï¼ˆæ— æ•ˆï¼‰ |
| Sleeping Dogs | Câ†’D | **è´Ÿ** | **åƒä¸‡åˆ«æŠ•ï¼** |

---

### Q4: å› æœæ£®æ—çš„æ ¸å¿ƒåˆ›æ–°

**1. è¯šå®åˆ†è£‚ (Honest Splitting)**

```
æ•°æ®åˆ†æˆä¸¤åŠ:
  - åˆ†è£‚æ ·æœ¬ (50%): æ„å»ºæ ‘ç»“æ„
  - ä¼°è®¡æ ·æœ¬ (50%): ä¼°è®¡å¶èŠ‚ç‚¹ CATE
```

**ä¸ºä»€ä¹ˆé‡è¦**ï¼š
- é¿å…è¿‡æ‹Ÿåˆ
- ä¿è¯æ¸è¿‘æ­£æ€æ€§
- ç½®ä¿¡åŒºé—´æœ‰æ•ˆ

**2. ä¸“ç”¨åˆ†è£‚å‡†åˆ™**

**ç›®æ ‡**ï¼šæœ€å¤§åŒ–å­èŠ‚ç‚¹é—´çš„ CATE å¼‚è´¨æ€§

$$\text{Split Gain} = \frac{n_L \cdot n_R}{(n_L + n_R)^2} \times (\hat{\tau}_L - \hat{\tau}_R)^2$$

**ä¸éšæœºæ£®æ—çš„åŒºåˆ«**ï¼š

| ç‰¹æ€§ | éšæœºæ£®æ— | å› æœæ£®æ— |
|------|---------|---------|
| ç›®æ ‡ | é¢„æµ‹ Y | ä¼°è®¡ CATE |
| åˆ†è£‚å‡†åˆ™ | å‡å°‘ MSE | æœ€å¤§åŒ– CATE å·®å¼‚ |
| Honest Split | å¦ | **æ˜¯** |
| ç½®ä¿¡åŒºé—´ | æ— ä¿è¯ | æœ‰ç†è®ºä¿è¯ |

---

### Q5: Qini æ›²çº¿ä¸ AUUC

**Qini æ›²çº¿**ï¼šUplift ç‰ˆçš„ ROC æ›²çº¿

**å…¬å¼**ï¼š
$$\text{Qini}(k) = Y_t(k) - Y_c(k) \times \frac{n_t(k)}{n_c(k)}$$

**ç›´è§‰è§£é‡Š**ï¼š
- æŒ‰é¢„æµ‹ Uplift ä»é«˜åˆ°ä½æ’åº
- ç´¯ç§¯è®¡ç®—å‰ k ä¸ªäººçš„å¢é‡æ”¶ç›Š
- è°ƒæ•´å› å­å¤„ç†æ ·æœ¬ä¸å¹³è¡¡

**AUUC (Area Under Uplift Curve)**ï¼š
- Qini æ›²çº¿ä¸‹é¢ç§¯
- è¶Šå¤§è¶Šå¥½
- ç±»ä¼¼ ROC çš„ AUC

**è¯„ä¼°æ ‡å‡†**ï¼š

| AUUC | æ¨¡å‹è´¨é‡ |
|------|---------|
| < 0 | åå‘é€‰æ‹©ï¼ˆå¾ˆå·®ï¼‰ |
| = 0 | éšæœºé€‰æ‹©ï¼ˆæ— ç”¨ï¼‰ |
| > 0 | æœ‰æ•ˆï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰ |

---

## ğŸ¬ åœºæ™¯åº”ç”¨é¢˜

### åœºæ™¯ 1ï¼šç”µå•†ä¼˜æƒ åˆ¸æŠ•æ”¾

**é—®é¢˜**ï¼šæœ‰ 100 ä¸‡ç”¨æˆ·ï¼Œé¢„ç®—åªå¤Ÿç»™ 10 ä¸‡äººå‘åˆ¸ï¼Œæ€ä¹ˆé€‰ï¼Ÿ

**é”™è¯¯åšæ³•**ï¼š
```python
# âŒ ä¼ ç»Ÿåˆ†ç±»æ€è·¯ï¼šæ‰¾è½¬åŒ–ç‡é«˜çš„äºº
model.predict_proba(X)[:, 1]  # P(è´­ä¹°|ç‰¹å¾)
# é—®é¢˜ï¼šè½¬åŒ–ç‡é«˜çš„äººå¯èƒ½æœ¬æ¥å°±ä¼šä¹°ï¼
```

**æ­£ç¡®åšæ³•**ï¼š
```python
# âœ… Uplift æ€è·¯ï¼šæ‰¾å¢é‡æ•ˆåº”å¤§çš„äºº
uplift_model.predict_cate(X)  # Ï„(X) = E[Y|T=1,X] - E[Y|T=0,X]

# é€‰æ‹© Top 10%
top_10_percent = np.argsort(uplift)[::-1][:100000]
```

**å®Œæ•´æµç¨‹**ï¼š

```python
# 1. è®­ç»ƒ Uplift æ¨¡å‹
from econml.grf import CausalForest

model = CausalForest(n_estimators=100, honest=True)
model.fit(Y, T, X=X)

# 2. é¢„æµ‹ CATE
uplift_pred = model.predict(X_new).flatten()

# 3. æ’åºå¹¶é€‰æ‹©
top_users = np.argsort(uplift_pred)[::-1][:100000]

# 4. è¯„ä¼°æ•ˆæœ
expected_uplift = uplift_pred[top_users].mean()
print(f"é¢„æœŸå¹³å‡ Uplift: {expected_uplift:.4f}")
```

---

### åœºæ™¯ 2ï¼šåŒ»ç–—ä¸ªæ€§åŒ–æ²»ç–—

**é—®é¢˜**ï¼šä¸¤ç§æ²»ç–—æ–¹æ¡ˆ A å’Œ Bï¼Œå¦‚ä½•ä¸ºæ‚£è€…é€‰æ‹©ï¼Ÿ

**Uplift è§†è§’**ï¼š
```python
# è®­ç»ƒä¸¤ä¸ª Uplift æ¨¡å‹
uplift_A = model_A.predict_cate(patient_features)
uplift_B = model_B.predict_cate(patient_features)

# é€‰æ‹© Uplift æ›´é«˜çš„æ–¹æ¡ˆ
optimal_treatment = np.where(uplift_A > uplift_B, 'A', 'B')

# åªå¯¹ Uplift > é˜ˆå€¼çš„æ‚£è€…æ²»ç–—
threshold = cost / benefit_per_unit
treat = (np.maximum(uplift_A, uplift_B) > threshold)
```

---

### åœºæ™¯ 3ï¼šA/B æµ‹è¯•å¼‚è´¨æ€§åˆ†æ

**é—®é¢˜**ï¼šA/B æµ‹è¯•æ˜¾ç¤ºæ–°åŠŸèƒ½ ATE = +2%ï¼Œä½†å“ªäº›ç”¨æˆ·å—ç›Šï¼Ÿ

**åˆ†ææµç¨‹**ï¼š

```python
# 1. è®­ç»ƒ CATE æ¨¡å‹
tlearner = TLearner()
tlearner.fit(X, T, Y)
cate_pred = tlearner.predict_cate(X)

# 2. å­ç¾¤ä½“åˆ†æ
from sklearn.tree import DecisionTreeRegressor

# ç”¨å†³ç­–æ ‘æ‰¾å…³é”®ç‰¹å¾
tree = DecisionTreeRegressor(max_depth=3)
tree.fit(X, cate_pred)

# 3. å¯è§†åŒ–åˆ†ç¾¤
import pandas as pd

df = pd.DataFrame(X, columns=feature_names)
df['CATE'] = cate_pred

# æŒ‰ CATE åˆ†ç»„
df['Group'] = pd.qcut(cate_pred, q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])

# åˆ†æå„ç»„ç‰¹å¾
for group in ['Q1', 'Q2', 'Q3', 'Q4']:
    print(f"\n{group} (CATE={df[df.Group==group].CATE.mean():.4f}):")
    print(df[df.Group==group][feature_names].describe())
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
Q4 (CATE=+5%):
  - å¹´é¾„: 25-35
  - æ´»è·ƒåº¦: é«˜
  - å†å²æ¶ˆè´¹: ä¸­ç­‰

Q1 (CATE=-1%):
  - å¹´é¾„: 50+
  - æ´»è·ƒåº¦: ä½
  - å†å²æ¶ˆè´¹: ä½
```

---

### åœºæ™¯ 4ï¼šè¥é”€æ´»åŠ¨ ROI ä¼˜åŒ–

**é—®é¢˜**ï¼šå‘åˆ¸æˆæœ¬ $1ï¼Œå¹³å‡è½¬åŒ–ä»·å€¼ $10ï¼Œå‘ç»™è°ï¼Ÿ

**ROI è®¡ç®—**ï¼š

```python
def calculate_roi(uplift_pred, cost=1.0, revenue_per_conversion=10.0):
    """
    è®¡ç®—ä¸åŒå¹²é¢„æ¯”ä¾‹ä¸‹çš„ ROI
    """
    n = len(uplift_pred)
    order = np.argsort(uplift_pred)[::-1]

    rois = []
    fractions = np.linspace(0.05, 1.0, 20)

    for frac in fractions:
        n_target = int(frac * n)

        # é¢„æœŸå¢é‡è½¬åŒ–
        expected_uplift = uplift_pred[order[:n_target]].mean()
        incremental_conversions = expected_uplift * n_target

        # ROI = (æ”¶ç›Š - æˆæœ¬) / æˆæœ¬
        revenue = incremental_conversions * revenue_per_conversion
        total_cost = n_target * cost
        roi = (revenue - total_cost) / total_cost if total_cost > 0 else 0

        rois.append(roi)

    # æ‰¾æœ€ä¼˜ç‚¹
    optimal_idx = np.argmax(rois)
    return fractions[optimal_idx], rois[optimal_idx]

# ä½¿ç”¨
opt_frac, opt_roi = calculate_roi(uplift_pred)
print(f"æœ€ä¼˜å¹²é¢„æ¯”ä¾‹: {opt_frac*100:.1f}%")
print(f"æœ€å¤§ ROI: {opt_roi:.2f}")
```

---

## ğŸ¯ é¢è¯•å¿…è€ƒçŸ¥è¯†ç‚¹

### çŸ¥è¯†ç‚¹ 1ï¼šPEHE çš„å«ä¹‰

**PEHE (Precision in Estimation of Heterogeneous Effects)**

$$\text{PEHE} = \sqrt{\mathbb{E}[(\tau(X) - \hat{\tau}(X))^2]}$$

**ä¸ºä»€ä¹ˆé‡è¦**ï¼š
- ç›´æ¥è¡¡é‡ CATE ä¼°è®¡ç²¾åº¦
- å³ä½¿ ATE ä¼°è®¡å‡†ç¡®ï¼ŒCATE å¯èƒ½å®Œå…¨é”™è¯¯

**ä¾‹å­**ï¼š
```
çœŸå® CATE: [0, 10, 20]
é¢„æµ‹ CATE: [10, 10, 10]

ATE: éƒ½æ˜¯ 10 âœ“ï¼ˆå‡†ç¡®ï¼‰
PEHE: âˆš((100+0+100)/3) â‰ˆ 8.16 âœ—ï¼ˆå¾ˆå¤§ï¼‰
```

---

### çŸ¥è¯†ç‚¹ 2ï¼šUplift Tree çš„åˆ†è£‚å‡†åˆ™

**ç›®æ ‡**ï¼šæœ€å¤§åŒ–å­èŠ‚ç‚¹é—´çš„ Uplift å·®å¼‚

**å¸¸ç”¨å‡†åˆ™**ï¼š

1. **KL æ•£åº¦**ï¼š
$$D_{KL} = p_t \log\frac{p_t}{p_c} + (1-p_t) \log\frac{1-p_t}{1-p_c}$$

2. **æ¬§æ°è·ç¦»**ï¼š
$$ED = (p_t - p_c)^2 = \text{Uplift}^2$$

3. **å¡æ–¹ç»Ÿè®¡é‡**ï¼š
$$\chi^2 = \sum \frac{(O - E)^2}{E}$$

**é€‰æ‹©å»ºè®®**ï¼š
- KL æ•£åº¦ï¼šè½¬åŒ–ç‡å·®å¼‚å¤§
- æ¬§æ°è·ç¦»ï¼šå¿«é€ŸåŸå‹
- å¡æ–¹ï¼šæ ·æœ¬ä¸å¹³è¡¡

---

### çŸ¥è¯†ç‚¹ 3ï¼šHonest Splitting çš„å¿…è¦æ€§

**é—®é¢˜**ï¼šä¼ ç»Ÿå†³ç­–æ ‘ç”¨åŒä¸€æ‰¹æ•°æ®æ—¢æ„å»ºæ ‘åˆä¼°è®¡å€¼

**åæœ**ï¼š
- è¿‡æ‹Ÿåˆ
- ç½®ä¿¡åŒºé—´å¤±æ•ˆ
- æ— æ³•ç»Ÿè®¡æ¨æ–­

**Honest Splitting è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# æ•°æ®åˆ†æˆä¸¤åŠ
split_data, estimate_data = train_test_split(data, test_size=0.5)

# split_data: å†³å®šæ ‘çš„ç»“æ„
tree.build_structure(split_data)

# estimate_data: ä¼°è®¡å¶èŠ‚ç‚¹å€¼
for leaf in tree.leaves:
    leaf.estimate_cate(estimate_data)
```

**ç»Ÿè®¡æ€§è´¨**ï¼š
- æ¸è¿‘æ­£æ€æ€§
- æœ‰æ•ˆçš„ç½®ä¿¡åŒºé—´
- æ— åä¼°è®¡

---

### çŸ¥è¯†ç‚¹ 4ï¼šQini æ›²çº¿çš„è°ƒæ•´å› å­

**ä¸ºä»€ä¹ˆéœ€è¦è°ƒæ•´**ï¼š

$$\text{Qini}(k) = Y_t(k) - Y_c(k) \times \underbrace{\frac{n_t(k)}{n_c(k)}}_{\text{è°ƒæ•´å› å­}}$$

**åŸå› **ï¼š
1. å¤„ç†ç»„å’Œæ§åˆ¶ç»„äººæ•°å¯èƒ½ä¸åŒ
2. éœ€è¦"æ”¾å¤§"æ§åˆ¶ç»„åˆ°å¤„ç†ç»„çš„è§„æ¨¡
3. ç¡®ä¿å…¬å¹³æ¯”è¾ƒ

**ä¾‹å­**ï¼š
```
å‰ 100 äºº:
  - å¤„ç†ç»„: 60 äººï¼Œè½¬åŒ– 30 äºº
  - æ§åˆ¶ç»„: 40 äººï¼Œè½¬åŒ– 10 äºº

ä¸è°ƒæ•´: 30 - 10 = 20 âœ—ï¼ˆä¸å¯¹ï¼‰
è°ƒæ•´: 30 - 10 Ã— (60/40) = 30 - 15 = 15 âœ“ï¼ˆæ­£ç¡®ï¼‰
```

---

### çŸ¥è¯†ç‚¹ 5ï¼šæœ€ä¼˜å¹²é¢„ç­–ç•¥

**å†³ç­–è§„åˆ™**ï¼š
$$\pi^*(x) = \mathbb{1}[\hat{\tau}(x) > c]$$

å…¶ä¸­ $c$ æ˜¯å¤„ç†æˆæœ¬ã€‚

**å®ç°**ï¼š

```python
def optimal_policy(cate_pred, cost=1.0):
    """
    æœ€ä¼˜å¹²é¢„ç­–ç•¥

    åªå¯¹ CATE > cost çš„äººå¹²é¢„
    """
    return (cate_pred > cost).astype(int)

# ä½¿ç”¨
treatment_decision = optimal_policy(uplift_pred, cost=1.0)

# è®¡ç®—é¢„æœŸä»·å€¼
expected_value = (uplift_pred * treatment_decision - cost * treatment_decision).sum()
```

**ä¸šåŠ¡å«ä¹‰**ï¼š
- é«˜ Uplift äººç¾¤ï¼šå¹²é¢„
- ä½ Uplift äººç¾¤ï¼šä¸å¹²é¢„ï¼ˆçœæˆæœ¬ï¼‰
- **è´Ÿ Uplift äººç¾¤**ï¼šåƒä¸‡åˆ«å¹²é¢„ï¼

---

## ğŸ“ å¿«é€Ÿå¤ä¹ æ£€æŸ¥è¡¨

### Meta-Learners

- [ ] èƒ½æ‰‹å†™ T-Learner å’Œ S-Learner
- [ ] çŸ¥é“ X-Learner è§£å†³ä»€ä¹ˆé—®é¢˜ï¼ˆæ ·æœ¬ä¸å¹³è¡¡ï¼‰
- [ ] ç†è§£ R-Learner çš„åŒé‡å»åæ€æƒ³
- [ ] çŸ¥é“ DR-Learner çš„åŒé‡ç¨³å¥æ€§
- [ ] èƒ½å¯¹æ¯”å„æ–¹æ³•çš„ä¼˜ç¼ºç‚¹

### Causal Forest

- [ ] ç†è§£ Honest Splitting çš„å¿…è¦æ€§
- [ ] çŸ¥é“å› æœæ£®æ—çš„åˆ†è£‚å‡†åˆ™ï¼ˆæœ€å¤§åŒ– CATE å·®å¼‚ï¼‰
- [ ] èƒ½è§£é‡Šç‰¹å¾é‡è¦æ€§çš„å«ä¹‰ï¼ˆå¯¹å¼‚è´¨æ€§çš„è´¡çŒ®ï¼‰
- [ ] çŸ¥é“å¦‚ä½•è·å–ç½®ä¿¡åŒºé—´
- [ ] èƒ½å¯¹æ¯”å› æœæ£®æ—å’Œ T-Learner

### Uplift Modeling

- [ ] èƒ½æ‰‹å†™ Uplift è®¡ç®—
- [ ] ç†è§£ Uplift Tree çš„åˆ†è£‚å‡†åˆ™ï¼ˆKLã€EDã€Ï‡Â²ï¼‰
- [ ] çŸ¥é“å››ç±»äººç¾¤ï¼ˆPersuadables, Sure Things, Lost Causes, Sleeping Dogsï¼‰
- [ ] èƒ½å®ç°å¶èŠ‚ç‚¹ CATE ä¼°è®¡
- [ ] ç†è§£ Uplift ä¸ä¼ ç»Ÿåˆ†ç±»çš„åŒºåˆ«

### Evaluation

- [ ] èƒ½æ‰‹å†™ Qini æ›²çº¿è®¡ç®—
- [ ] ç†è§£ AUUC çš„å«ä¹‰
- [ ] çŸ¥é“ Uplift by Decile çš„ç”¨æ³•
- [ ] èƒ½è®¡ç®—æœ€ä¼˜å¹²é¢„æ¯”ä¾‹
- [ ] ç†è§£ä¸ºä»€ä¹ˆéœ€è¦è°ƒæ•´å› å­ n_t/n_c

---

## ğŸ” å¸¸è§é™·é˜±ä¸æ³¨æ„äº‹é¡¹

### é™·é˜± 1ï¼šæ··æ·†é«˜è½¬åŒ–ç‡å’Œé«˜ Uplift

```python
# âŒ é”™è¯¯
high_conversion = model.predict_proba(X)[:, 1] > 0.8
target_users = X[high_conversion]  # è½¬åŒ–ç‡é«˜çš„äºº

# âœ… æ­£ç¡®
high_uplift = uplift_model.predict_cate(X) > threshold
target_users = X[high_uplift]  # å¢é‡æ•ˆåº”å¤§çš„äºº
```

**ä¸ºä»€ä¹ˆ**ï¼šè½¬åŒ–ç‡é«˜çš„äººå¯èƒ½æœ¬æ¥å°±ä¼šè½¬åŒ–ï¼

---

### é™·é˜± 2ï¼šå¿½ç•¥è´Ÿ Uplift äººç¾¤

```python
# âŒ å±é™©
treatment = (uplift_pred > 0).astype(int)  # åªè¦å¤§äº 0 å°±å¹²é¢„

# âœ… å®‰å…¨
treatment = (uplift_pred > cost).astype(int)  # è€ƒè™‘æˆæœ¬
# æˆ–è€…
treatment = (uplift_pred > np.percentile(uplift_pred, 80)).astype(int)
```

**åæœ**ï¼šå¯¹è´Ÿ Uplift äººç¾¤å¹²é¢„ä¼šé€‚å¾—å…¶åï¼

---

### é™·é˜± 3ï¼šåœ¨è®­ç»ƒé›†ä¸Šè¯„ä¼° CATE

```python
# âŒ é”™è¯¯
model.fit(X_train, T_train, Y_train)
cate_pred = model.predict_cate(X_train)  # åœ¨è®­ç»ƒé›†ä¸Šé¢„æµ‹
pehe = calculate_pehe(true_cate_train, cate_pred)  # è¿‡æ‹Ÿåˆï¼

# âœ… æ­£ç¡®
model.fit(X_train, T_train, Y_train)
cate_pred = model.predict_cate(X_test)  # åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹
pehe = calculate_pehe(true_cate_test, cate_pred)
```

---

### é™·é˜± 4ï¼šQini æ›²çº¿ä¸æ·»åŠ åŸç‚¹

```python
# âŒ ä¸å®Œæ•´
qini = calculate_qini(...)  # ä»ç¬¬ä¸€ä¸ªæ ·æœ¬å¼€å§‹

# âœ… å®Œæ•´
qini = np.insert(qini, 0, 0)  # æ·»åŠ åŸç‚¹ (0, 0)
fraction = np.insert(fraction, 0, 0)
```

**åŸå› **ï¼šQini æ›²çº¿åº”è¯¥ä» (0, 0) å¼€å§‹ï¼

---

### é™·é˜± 5ï¼šæ²¡æœ‰æ£€æŸ¥å­ç¾¤ä½“æ ·æœ¬é‡

```python
# âŒ å±é™©
for group in groups:
    uplift = calculate_uplift(Y[group], T[group])  # å¯èƒ½æ ·æœ¬å¤ªå°‘

# âœ… å®‰å…¨
min_samples = 100
for group in groups:
    if len(group) >= min_samples:
        uplift = calculate_uplift(Y[group], T[group])
    else:
        print(f"è­¦å‘Šï¼š{group} æ ·æœ¬é‡ä¸è¶³")
```

---

## ğŸ“š æ¨èèµ„æº

### è®ºæ–‡
- **Causal Forest**: Athey & Imbens (2016) - "Recursive Partitioning for Heterogeneous Causal Effects"
- **Meta-Learners**: KÃ¼nzel et al. (2019) - "Metalearners for estimating heterogeneous treatment effects"
- **Qini Curve**: Radcliffe & Surry (2011) - "Real-World Uplift Modelling with Significance-Based Uplift Trees"

### å·¥å…·åº“
- **EconML**: https://github.com/microsoft/EconML
- **CausalML**: https://github.com/uber/causalml
- **DoWhy**: https://github.com/py-why/dowhy

### å®æˆ˜æ¡ˆä¾‹
- Uber: ç”¨ Uplift ä¼˜åŒ–ä¿ƒé”€æŠ•æ”¾
- Booking.com: ä¸ªæ€§åŒ–æ¨è
- Netflix: A/B æµ‹è¯•å¼‚è´¨æ€§åˆ†æ

---

**æœ€åå»ºè®®**ï¼š
1. **å¤šç»ƒä¹ æ‰‹å†™å®ç°**ï¼šé¢è¯•å¸¸è€ƒ T-Learnerã€Qini æ›²çº¿
2. **ç†è§£è€Œéè®°å¿†**ï¼šçŸ¥é“ä¸ºä»€ä¹ˆï¼Œè€ŒéåªçŸ¥é“æ€ä¹ˆåš
3. **ç»“åˆå®é™…åœºæ™¯**ï¼šç”¨ä¸šåŠ¡ä¾‹å­è§£é‡ŠæŠ€æœ¯æ¦‚å¿µ
4. **å…³æ³¨ç»†èŠ‚**ï¼šè¾¹ç•Œæ¡ä»¶ã€æ•°å€¼ç¨³å®šæ€§

**ç¥ä½ é¢è¯•é¡ºåˆ©ï¼** ğŸ‰
