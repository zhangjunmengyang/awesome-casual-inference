{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 识别策略框架 - 从数据到方法的决策指南\n",
    "\n",
    "## 学习目标\n",
    "\n",
    "完成本 Notebook 后，你将能够：\n",
    "\n",
    "1. **区分识别与估计**：理解为什么「识别」比「估计」更重要\n",
    "2. **掌握识别假设层级**：从最强的随机化到最弱的条件独立\n",
    "3. **构建决策框架**：根据数据特征和业务场景选择正确的因果推断方法\n",
    "4. **实战案例分析**：通过 4 个真实业务场景练习识别策略选择\n",
    "\n",
    "---\n",
    "\n",
    "## 开场故事：数据科学家的困惑\n",
    "\n",
    "小王是一家电商公司的数据科学家。某天，产品经理找他分析：\n",
    "\n",
    "> **产品经理**：\"我们给部分用户发了 50 元优惠券，需要评估这个券能带来多少 GMV 增长。\"\n",
    "> \n",
    "> **小王**：\"这个简单，我跑个回归模型，控制一下年龄、性别、历史消费...\"\n",
    "> \n",
    "> **产品经理**：\"等等，我们这次是随机发放的，不需要控制变量吧？\"\n",
    "> \n",
    "> **小王**：\"呃...那如果不是随机发放呢？\"\n",
    "> \n",
    "> **产品经理**：\"上次我们只给活跃用户发了券，那次怎么分析？\"\n",
    "\n",
    "小王陷入沉思：**同样是评估优惠券效果，为什么随机发放和定向发放的分析方法完全不同？**\n",
    "\n",
    "这个问题的答案，就是本 Notebook 的核心：**识别策略 (Identification Strategy)**。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotly 主题配置\n",
    "COLORS = {\n",
    "    'primary': '#2D9CDB',\n",
    "    'success': '#27AE60',\n",
    "    'danger': '#EB5757',\n",
    "    'warning': '#F2994A',\n",
    "    'info': '#9B51E0',\n",
    "    'gray': '#4F4F4F'\n",
    "}\n",
    "\n",
    "print(\"环境准备完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: 识别 vs 估计 - 因果推断的灵魂拷问\n",
    "\n",
    "## 1.1 核心概念\n",
    "\n",
    "### 什么是「识别」(Identification)？\n",
    "\n",
    "**识别**回答的问题是：\n",
    "> \"在理想情况下（数据量无限大、模型完美拟合），我能否从观测数据中唯一确定因果效应？\"\n",
    "\n",
    "**通俗理解**：识别就像是问\"这道题有没有唯一解\"。如果识别不成立，就算你有再多数据、再牛的模型，也算不出正确答案。\n",
    "\n",
    "### 什么是「估计」(Estimation)？\n",
    "\n",
    "**估计**回答的问题是：\n",
    "> \"在有限数据下，我如何用统计方法逼近真实的因果效应？\"\n",
    "\n",
    "**通俗理解**：估计就像是\"如何解这道题\"。只有在识别成立的前提下，估计才有意义。\n",
    "\n",
    "---\n",
    "\n",
    "## 1.2 生动比喻：考古学家的困境\n",
    "\n",
    "想象你是一位考古学家，发现了一块古代石碑，上面刻着模糊的文字。\n",
    "\n",
    "- **识别问题**：这些符号是否包含足够的信息，能让我还原出原文？（信息是否足够）\n",
    "- **估计问题**：如果信息足够，我该用什么技术手段（红外线、化学试剂）来还原文字？（技术方法选择）\n",
    "\n",
    "如果石碑上只剩下 3 个字，无论你用多先进的技术，都无法还原出完整的 1000 字文章。这就是**识别失败**。\n",
    "\n",
    "---\n",
    "\n",
    "## 1.3 数学表达\n",
    "\n",
    "我们想估计的因果效应是：\n",
    "\n",
    "$$\n",
    "\\tau = \\mathbb{E}[Y_i(1) - Y_i(0)]\n",
    "$$\n",
    "\n",
    "但我们实际观测到的是：\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[Y | T=1] - \\mathbb{E}[Y | T=0]\n",
    "$$\n",
    "\n",
    "**识别问题**：在什么条件下，观测差异 = 因果效应？\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[Y | T=1] - \\mathbb{E}[Y | T=0] = \\mathbb{E}[Y_i(1) - Y_i(0)] \\quad \\text{???}\n",
    "$$\n",
    "\n",
    "**答案**：需要满足某种**识别假设**（下一部分详细介绍）。\n",
    "\n",
    "---\n",
    "\n",
    "## 1.4 为什么识别比估计更重要？\n",
    "\n",
    "### 案例：谷歌的失败教训\n",
    "\n",
    "2009 年，谷歌的数据科学家发现：**使用谷歌搜索的人，收入比不用的人高 30%**。\n",
    "\n",
    "他们用了最先进的机器学习模型，控制了年龄、教育、地区等上百个变量，结论依然稳健。\n",
    "\n",
    "**产品团队的推论**：\"推广谷歌搜索可以提高用户收入！\"\n",
    "\n",
    "**问题在哪**？\n",
    "\n",
    "- **识别失败**：无论如何控制变量，都无法排除\"高收入的人本来就更愿意用谷歌\"这种**反向因果**。\n",
    "- **估计精确无用**：就算模型 R² = 0.99，也只是精确地估计了一个错误的数字。\n",
    "\n",
    "### 黄金法则\n",
    "\n",
    "```\n",
    "识别 > 估计\n",
    "```\n",
    "\n",
    "- 识别错误 + 估计精确 = 精确的错误\n",
    "- 识别正确 + 估计粗糙 = 粗糙的正确（可以通过更多数据改进）\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化：识别 vs 估计\n",
    "\n",
    "def visualize_identification_vs_estimation():\n",
    "    \"\"\"\n",
    "    用靶心图展示识别与估计的关系\n",
    "    \"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=3,\n",
    "        subplot_titles=(\n",
    "            '识别正确 + 估计精确<br>(理想情况)',\n",
    "            '识别正确 + 估计粗糙<br>(可通过更多数据改进)',\n",
    "            '识别错误 + 估计精确<br>(精确的错误)'\n",
    "        ),\n",
    "        specs=[[{'type': 'scatter'}, {'type': 'scatter'}, {'type': 'scatter'}]]\n",
    "    )\n",
    "    \n",
    "    # 真值位置\n",
    "    true_value = (0, 0)\n",
    "    \n",
    "    # 场景 1: 识别正确 + 估计精确\n",
    "    estimates_1 = np.random.normal(0, 0.1, (50, 2))\n",
    "    \n",
    "    # 场景 2: 识别正确 + 估计粗糙\n",
    "    estimates_2 = np.random.normal(0, 0.5, (50, 2))\n",
    "    \n",
    "    # 场景 3: 识别错误 + 估计精确\n",
    "    estimates_3 = np.random.normal(2, 0.1, (50, 2))  # 偏离真值\n",
    "    \n",
    "    for i, (estimates, color) in enumerate([\n",
    "        (estimates_1, COLORS['success']),\n",
    "        (estimates_2, COLORS['warning']),\n",
    "        (estimates_3, COLORS['danger'])\n",
    "    ], 1):\n",
    "        # 绘制靶心\n",
    "        for radius in [0.5, 1.0, 1.5, 2.0]:\n",
    "            theta = np.linspace(0, 2*np.pi, 100)\n",
    "            x_circle = radius * np.cos(theta)\n",
    "            y_circle = radius * np.sin(theta)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x_circle, y=y_circle,\n",
    "                    mode='lines',\n",
    "                    line=dict(color='lightgray', width=1),\n",
    "                    showlegend=False,\n",
    "                    hoverinfo='skip'\n",
    "                ),\n",
    "                row=1, col=i\n",
    "            )\n",
    "        \n",
    "        # 绘制真值\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[true_value[0]], y=[true_value[1]],\n",
    "                mode='markers',\n",
    "                marker=dict(size=15, color='gold', symbol='star', line=dict(color='black', width=2)),\n",
    "                name='真实因果效应',\n",
    "                showlegend=(i==1),\n",
    "                hovertemplate='真值<extra></extra>'\n",
    "            ),\n",
    "            row=1, col=i\n",
    "        )\n",
    "        \n",
    "        # 绘制估计值\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=estimates[:, 0], y=estimates[:, 1],\n",
    "                mode='markers',\n",
    "                marker=dict(size=8, color=color, opacity=0.6),\n",
    "                name='估计值',\n",
    "                showlegend=(i==1),\n",
    "                hovertemplate='估计值<extra></extra>'\n",
    "            ),\n",
    "            row=1, col=i\n",
    "        )\n",
    "        \n",
    "        # 设置坐标轴范围\n",
    "        fig.update_xaxes(range=[-3, 3], row=1, col=i, showticklabels=False)\n",
    "        fig.update_yaxes(range=[-3, 3], row=1, col=i, showticklabels=False)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text='识别 vs 估计：靶心图示意',\n",
    "        height=400,\n",
    "        showlegend=True,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = visualize_identification_vs_estimation()\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n关键洞察：\")\n",
    "print(\"- 左图：完美情况，估计值紧密围绕真值\")\n",
    "print(\"- 中图：识别正确但估计有噪音，可通过增加样本量改进\")\n",
    "print(\"- 右图：识别错误导致系统性偏差，再多数据也无法修正！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: 识别假设的层级 - 从最强到最弱\n",
    "\n",
    "不同的数据场景，需要不同强度的识别假设。这些假设按\"强度\"排序：\n",
    "\n",
    "```\n",
    "随机化 > 条件独立 > 自然实验 > 工具变量\n",
    "(最强)                               (最弱)\n",
    "```\n",
    "\n",
    "**核心原则**：假设越强，识别越可靠，但在真实世界越难满足。\n",
    "\n",
    "---\n",
    "\n",
    "## Level 1: 随机化 (Randomization) - 黄金标准\n",
    "\n",
    "### 核心假设\n",
    "\n",
    "$$\n",
    "T_i \\perp\\!\\!\\!\\perp (Y_i(0), Y_i(1))\n",
    "$$\n",
    "\n",
    "**含义**：处理分配 $T$ 与潜在结果 $(Y(0), Y(1))$ 完全独立。\n",
    "\n",
    "### 通俗理解\n",
    "\n",
    "就像抛硬币决定谁吃药、谁吃糖，用户的所有特征（年龄、性别、健康状况）都不会影响分组。\n",
    "\n",
    "### 识别公式\n",
    "\n",
    "$$\n",
    "\\tau = \\mathbb{E}[Y | T=1] - \\mathbb{E}[Y | T=0]\n",
    "$$\n",
    "\n",
    "### 真实案例\n",
    "\n",
    "- **A/B Testing**：谷歌每年运行 10,000+ 个随机实验\n",
    "- **医学试验**：FDA 要求新药必须通过双盲随机对照试验 (RCT)\n",
    "\n",
    "### 优点 & 缺点\n",
    "\n",
    "| 优点 | 缺点 |\n",
    "|------|------|\n",
    "| 识别最可靠 | 成本高、周期长 |\n",
    "| 无需控制变量 | 可能有伦理问题 |\n",
    "| 估计方法简单（均值差） | 外部有效性问题（实验环境 ≠ 真实场景） |\n",
    "\n",
    "---\n",
    "\n",
    "## Level 2: 条件独立 (Conditional Independence) - 观测数据的救星\n",
    "\n",
    "### 核心假设（CIA / Unconfoundedness）\n",
    "\n",
    "$$\n",
    "T_i \\perp\\!\\!\\!\\perp (Y_i(0), Y_i(1)) \\mid X_i\n",
    "$$\n",
    "\n",
    "**含义**：给定协变量 $X$（如年龄、性别），处理分配与潜在结果独立。\n",
    "\n",
    "### 通俗理解\n",
    "\n",
    "虽然整体分组不随机，但在\"同龄、同性别、同收入\"的人群内部，分组是随机的。\n",
    "\n",
    "### 额外要求：Overlap / Common Support\n",
    "\n",
    "$$\n",
    "0 < P(T=1 | X) < 1 \\quad \\forall X\n",
    "$$\n",
    "\n",
    "**含义**：每种特征组合下，都要有接受处理和不接受处理的个体。\n",
    "\n",
    "### 真实案例\n",
    "\n",
    "- **定向营销效果评估**：给\"高价值用户\"发券，通过 PSM/IPW 控制用户特征\n",
    "- **政策评估**：某省实施教育改革，用其他省份作为对照组\n",
    "\n",
    "### 常用方法\n",
    "\n",
    "- **Propensity Score Matching (PSM)**\n",
    "- **Inverse Probability Weighting (IPW)**\n",
    "- **Doubly Robust Estimation (DR)**\n",
    "\n",
    "### 优点 & 缺点\n",
    "\n",
    "| 优点 | 缺点 |\n",
    "|------|------|\n",
    "| 适用于观测数据 | 无法验证（需要\"测量了所有混淆因素\"） |\n",
    "| 可以事后分析 | 对未观测混淆因素敏感 |\n",
    "|  | 需要 Overlap 假设 |\n",
    "\n",
    "---\n",
    "\n",
    "## Level 3: 自然实验 (Natural Experiments) - 利用外部冲击\n",
    "\n",
    "### 核心思想\n",
    "\n",
    "利用自然发生的\"类随机\"事件（政策变化、地震、天气）作为处理分配机制。\n",
    "\n",
    "### 常见方法\n",
    "\n",
    "#### 3.1 双重差分 (Difference-in-Differences, DID)\n",
    "\n",
    "$$\n",
    "\\tau = \\left[ \\mathbb{E}[Y_{\\text{treat}, \\text{post}}] - \\mathbb{E}[Y_{\\text{treat}, \\text{pre}}] \\right] - \\left[ \\mathbb{E}[Y_{\\text{control}, \\text{post}}] - \\mathbb{E}[Y_{\\text{control}, \\text{pre}}] \\right]\n",
    "$$\n",
    "\n",
    "**关键假设**：平行趋势 (Parallel Trends)\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[Y_{\\text{treat}}(0)_{\\text{post}} - Y_{\\text{treat}}(0)_{\\text{pre}}] = \\mathbb{E}[Y_{\\text{control}, \\text{post}} - Y_{\\text{control}, \\text{pre}}]\n",
    "$$\n",
    "\n",
    "**案例**：某省份 2020 年提高最低工资，评估对就业的影响（用邻省作对照）。\n",
    "\n",
    "#### 3.2 断点回归 (Regression Discontinuity Design, RDD)\n",
    "\n",
    "$$\n",
    "\\tau = \\lim_{x \\downarrow c} \\mathbb{E}[Y | X=x] - \\lim_{x \\uparrow c} \\mathbb{E}[Y | X=x]\n",
    "$$\n",
    "\n",
    "**关键假设**：断点附近的个体除了处理状态，其他都相似。\n",
    "\n",
    "**案例**：高考分数 ≥ 600 的学生能上重点大学，比较 599 分和 601 分学生的未来收入。\n",
    "\n",
    "### 优点 & 缺点\n",
    "\n",
    "| 优点 | 缺点 |\n",
    "|------|------|\n",
    "| 假设相对可验证（如平行趋势检验） | 需要特殊的数据结构 |\n",
    "| 不需要完美的随机化 | 外部有效性有限（只对断点附近/特定政策有效） |\n",
    "| 政策评估中广泛应用 | 需要满足特定假设（平行趋势、连续性） |\n",
    "\n",
    "---\n",
    "\n",
    "## Level 4: 工具变量 (Instrumental Variables, IV) - 最后的武器\n",
    "\n",
    "### 核心思想\n",
    "\n",
    "找一个变量 $Z$（工具变量），它满足：\n",
    "\n",
    "1. **相关性** (Relevance)：$Z$ 影响处理 $T$\n",
    "   $$Cov(Z, T) \\neq 0$$\n",
    "\n",
    "2. **外生性** (Exogeneity)：$Z$ 只通过 $T$ 影响 $Y$\n",
    "   $$Z \\perp\\!\\!\\!\\perp Y(0), Y(1)$$\n",
    "\n",
    "3. **单调性** (Monotonicity)：$Z$ 对所有人的影响方向一致\n",
    "\n",
    "### 识别公式 (Wald Estimator)\n",
    "\n",
    "$$\n",
    "\\tau_{\\text{LATE}} = \\frac{\\mathbb{E}[Y | Z=1] - \\mathbb{E}[Y | Z=0]}{\\mathbb{E}[T | Z=1] - \\mathbb{E}[T | Z=0]}\n",
    "$$\n",
    "\n",
    "**注意**：IV 估计的是 **Local Average Treatment Effect (LATE)**，即\"听从工具变量指引的人群\"的平均效应。\n",
    "\n",
    "### 真实案例\n",
    "\n",
    "- **教育回报率**：父母教育水平作为 IV，估计受教育年限对收入的因果效应\n",
    "- **价格弹性**：天气作为 IV（影响供给 → 价格），估计价格对需求的因果效应\n",
    "\n",
    "### 优点 & 缺点\n",
    "\n",
    "| 优点 | 缺点 |\n",
    "|------|------|\n",
    "| 可以处理未观测混淆 | 好的 IV 极难找 |\n",
    "| 不需要测量所有混淆因素 | 外生性假设无法检验 |\n",
    "|  | 只能估计 LATE，不是 ATE |\n",
    "|  | 弱工具变量问题（相关性不足） |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化：识别假设层级\n",
    "\n",
    "def visualize_identification_hierarchy():\n",
    "    \"\"\"\n",
    "    用金字塔图展示识别假设的强度与适用性\n",
    "    \"\"\"\n",
    "    methods = ['工具变量 (IV)', '自然实验 (DID/RDD)', '条件独立 (PSM/IPW)', '随机化 (RCT)']\n",
    "    assumption_strength = [30, 50, 75, 100]  # 假设强度\n",
    "    real_world_availability = [80, 60, 40, 20]  # 真实世界中的可用性\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # 绘制假设强度（金字塔）\n",
    "    fig.add_trace(go.Funnel(\n",
    "        name='假设强度',\n",
    "        y=methods,\n",
    "        x=assumption_strength,\n",
    "        textinfo=\"value+percent initial\",\n",
    "        marker=dict(\n",
    "            color=[COLORS['danger'], COLORS['warning'], COLORS['info'], COLORS['success']]\n",
    "        ),\n",
    "        texttemplate='<b>%{y}</b><br>强度: %{x}',\n",
    "        hovertemplate='%{y}<br>假设强度: %{x}/100<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='识别假设层级：强度 vs 可用性',\n",
    "        height=500,\n",
    "        template='plotly_white',\n",
    "        showlegend=False,\n",
    "        annotations=[\n",
    "            dict(\n",
    "                x=0.5, y=1.15,\n",
    "                xref='paper', yref='paper',\n",
    "                text='<b>越往上：假设越强，识别越可靠</b><br>越往下：假设越弱,真实世界越常见',\n",
    "                showarrow=False,\n",
    "                font=dict(size=12, color=COLORS['gray']),\n",
    "                align='center'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = visualize_identification_hierarchy()\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n核心洞察：\")\n",
    "print(\"- 随机化 (RCT): 最强假设，但真实世界中很难实施\")\n",
    "print(\"- 条件独立: 最常用，但需要'测量了所有混淆因素'这个强假设\")\n",
    "print(\"- 自然实验: 需要特殊的数据结构（政策、时间断点）\")\n",
    "print(\"- 工具变量: 最弱假设，但好的 IV 极难找到\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: 决策树实战 - 5 种场景的识别策略\n",
    "\n",
    "## 决策流程图\n",
    "\n",
    "```\n",
    "开始：我想评估 X 对 Y 的因果效应\n",
    "        |\n",
    "        v\n",
    "    有随机实验数据？\n",
    "    ├─ 是 → A/B Testing (简单均值差)\n",
    "    └─ 否 ↓\n",
    "        |\n",
    "        v\n",
    "    有时间维度 + 处理在某时点发生？\n",
    "    ├─ 是 → DID (双重差分)\n",
    "    └─ 否 ↓\n",
    "        |\n",
    "        v\n",
    "    有明确的分配规则（阈值）？\n",
    "    ├─ 是 → RDD (断点回归)\n",
    "    └─ 否 ↓\n",
    "        |\n",
    "        v\n",
    "    能找到好的工具变量？\n",
    "    ├─ 是 → IV (工具变量)\n",
    "    └─ 否 ↓\n",
    "        |\n",
    "        v\n",
    "    能测量所有重要混淆因素？\n",
    "    ├─ 是 → PSM/IPW/DR (条件独立方法)\n",
    "    └─ 否 → 无法可靠识别，需要收集更多数据或重新设计研究\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 场景 1: 有随机实验 → A/B Testing\n",
    "\n",
    "### 业务场景\n",
    "\n",
    "> **问题**：新版本推荐算法能否提升用户点击率？\n",
    "> \n",
    "> **数据**：随机将 50% 用户分配到新算法，50% 保持旧算法。\n",
    "\n",
    "### 识别策略\n",
    "\n",
    "- **假设**：随机化 → $T \\perp\\!\\!\\!\\perp (Y(0), Y(1))$\n",
    "- **估计量**：简单均值差\n",
    "  $$\\hat{\\tau} = \\bar{Y}_{\\text{treatment}} - \\bar{Y}_{\\text{control}}$$\n",
    "\n",
    "### 注意事项\n",
    "\n",
    "1. **验证随机化**：检查协变量在两组间是否平衡\n",
    "2. **多重检验**：如果同时测试多个指标，需要 Bonferroni 校正\n",
    "3. **网络效应**：社交产品可能违反 SUTVA（一个用户的处理影响其他用户）\n",
    "\n",
    "---\n",
    "\n",
    "## 场景 2: 有时间断点 → DID\n",
    "\n",
    "### 业务场景\n",
    "\n",
    "> **问题**：某城市 2023 年 6 月禁止外卖使用塑料包装，评估对订单量的影响。\n",
    "> \n",
    "> **数据**：有该城市和邻近城市（未禁塑料）的月度订单数据。\n",
    "\n",
    "### 识别策略\n",
    "\n",
    "- **假设**：平行趋势（没有政策的话,两城市订单量趋势相同）\n",
    "- **估计量**：\n",
    "  $$\\hat{\\tau} = (Y_{\\text{treated,post}} - Y_{\\text{treated,pre}}) - (Y_{\\text{control,post}} - Y_{\\text{control,pre}})$$\n",
    "\n",
    "### 验证平行趋势\n",
    "\n",
    "```python\n",
    "# 检验政策前的趋势是否平行\n",
    "pre_period_data = data[data['time'] < policy_time]\n",
    "model = smf.ols('outcome ~ time * treated', data=pre_period_data).fit()\n",
    "print(model.params['time:treated'])  # 应该接近 0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 场景 3: 有政策门槛 → RDD\n",
    "\n",
    "### 业务场景\n",
    "\n",
    "> **问题**：会员等级提升（消费满 5000 元升级为金卡）能否提升用户留存？\n",
    "> \n",
    "> **数据**：有用户历史消费额和后续留存情况。\n",
    "\n",
    "### 识别策略\n",
    "\n",
    "- **假设**：消费 4999 元和 5001 元的用户，除了会员等级，其他特征相似\n",
    "- **估计量**：断点处的跳跃\n",
    "  $$\\hat{\\tau} = \\lim_{x \\downarrow 5000} \\mathbb{E}[Y|X=x] - \\lim_{x \\uparrow 5000} \\mathbb{E}[Y|X=x]$$\n",
    "\n",
    "### 关键检验\n",
    "\n",
    "1. **连续性检验**：协变量在断点处应该连续\n",
    "2. **密度检验**：断点附近的个体数量不应该有异常跳跃（排除操纵）\n",
    "\n",
    "---\n",
    "\n",
    "## 场景 4: 有工具变量 → IV\n",
    "\n",
    "### 业务场景\n",
    "\n",
    "> **问题**：降价 10% 能否提升销量？（价格与需求同时由\"质量\"决定，简单回归有偏）\n",
    "> \n",
    "> **工具变量**：原材料价格上涨 → 影响定价，但不直接影响消费者需求。\n",
    "\n",
    "### 识别策略\n",
    "\n",
    "- **假设**：\n",
    "  1. 原材料价格影响产品定价（相关性）\n",
    "  2. 原材料价格不直接影响需求（外生性）\n",
    "- **估计量**：Two-Stage Least Squares (2SLS)\n",
    "\n",
    "### 代码示例\n",
    "\n",
    "```python\n",
    "from linearmodels.iv import IV2SLS\n",
    "\n",
    "# 第一阶段：用 IV 预测处理变量\n",
    "# 第二阶段：用预测值估计因果效应\n",
    "model = IV2SLS.from_formula('sales ~ 1 + [price ~ raw_material_cost]', data=df)\n",
    "result = model.fit()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 场景 5: 只有观测数据 → PSM/IPW/DR\n",
    "\n",
    "### 业务场景\n",
    "\n",
    "> **问题**：给活跃用户发放优惠券，评估对 GMV 的提升效果。\n",
    "> \n",
    "> **数据**：有用户特征（年龄、历史消费、活跃度）和是否收到券。\n",
    "\n",
    "### 识别策略\n",
    "\n",
    "- **假设**：给定观测到的特征 $X$，收券是\"随机\"的\n",
    "  $$T \\perp\\!\\!\\!\\perp (Y(0), Y(1)) \\mid X$$\n",
    "- **估计方法**：\n",
    "  - **PSM**：找到特征相似的未收券用户作为对照\n",
    "  - **IPW**：用倾向得分加权，使样本\"看起来像随机样本\"\n",
    "  - **DR**：结合 IPW 和回归，更稳健\n",
    "\n",
    "### 关键检验\n",
    "\n",
    "1. **平衡性检验**：匹配/加权后，两组的协变量分布应该相似\n",
    "2. **Overlap 检验**：确保每种特征组合下都有处理组和对照组\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1: 决策树交互工具\n",
    "# \n",
    "# 任务：实现一个函数，根据数据特征推荐识别策略\n",
    "# \n",
    "# 提示：\n",
    "# 1. 输入：has_randomization, has_time_dimension, has_cutoff, has_iv, can_measure_confounders\n",
    "# 2. 输出：推荐的方法名称和简短说明\n",
    "# 3. 使用 if-elif-else 逻辑链\n",
    "\n",
    "def recommend_identification_strategy(\n",
    "    has_randomization: bool,\n",
    "    has_time_dimension: bool,\n",
    "    has_cutoff: bool,\n",
    "    has_iv: bool,\n",
    "    can_measure_confounders: bool\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    根据数据特征推荐因果推断方法\n",
    "    \n",
    "    返回：\n",
    "        dict: {'method': str, 'description': str, 'assumptions': list}\n",
    "    \"\"\"\n",
    "    # ===== YOUR CODE HERE =====\n",
    "    pass\n",
    "    # ===== END OF YOUR CODE =====\n",
    "\n",
    "# 测试用例\n",
    "test_cases = [\n",
    "    {\n",
    "        'name': '场景 1: A/B 测试',\n",
    "        'params': {'has_randomization': True, 'has_time_dimension': False, \n",
    "                   'has_cutoff': False, 'has_iv': False, 'can_measure_confounders': False}\n",
    "    },\n",
    "    {\n",
    "        'name': '场景 2: 政策评估',\n",
    "        'params': {'has_randomization': False, 'has_time_dimension': True, \n",
    "                   'has_cutoff': False, 'has_iv': False, 'can_measure_confounders': False}\n",
    "    },\n",
    "    {\n",
    "        'name': '场景 5: 观测数据',\n",
    "        'params': {'has_randomization': False, 'has_time_dimension': False, \n",
    "                   'has_cutoff': False, 'has_iv': False, 'can_measure_confounders': True}\n",
    "    },\n",
    "]\n",
    "\n",
    "# for case in test_cases:\n",
    "#     result = recommend_identification_strategy(**case['params'])\n",
    "#     print(f\"\\n{case['name']}\")\n",
    "#     print(f\"推荐方法: {result['method']}\")\n",
    "#     print(f\"说明: {result['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考答案 (运行此单元格查看)\n",
    "\n",
    "def recommend_identification_strategy(\n",
    "    has_randomization: bool,\n",
    "    has_time_dimension: bool,\n",
    "    has_cutoff: bool,\n",
    "    has_iv: bool,\n",
    "    can_measure_confounders: bool\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    根据数据特征推荐因果推断方法\n",
    "    \"\"\"\n",
    "    if has_randomization:\n",
    "        return {\n",
    "            'method': 'A/B Testing (RCT)',\n",
    "            'description': '使用随机对照试验，直接比较处理组和对照组的均值差异',\n",
    "            'assumptions': ['随机化', 'SUTVA'],\n",
    "            'estimator': '简单均值差',\n",
    "            'strength': '最强'\n",
    "        }\n",
    "    \n",
    "    elif has_time_dimension:\n",
    "        return {\n",
    "            'method': 'Difference-in-Differences (DID)',\n",
    "            'description': '利用时间维度和对照组，双重差分估计因果效应',\n",
    "            'assumptions': ['平行趋势', 'SUTVA'],\n",
    "            'estimator': '双重差分',\n",
    "            'strength': '中等'\n",
    "        }\n",
    "    \n",
    "    elif has_cutoff:\n",
    "        return {\n",
    "            'method': 'Regression Discontinuity Design (RDD)',\n",
    "            'description': '利用分配规则的阈值，比较阈值两侧的个体',\n",
    "            'assumptions': ['连续性', '无操纵'],\n",
    "            'estimator': '断点处的跳跃',\n",
    "            'strength': '中等'\n",
    "        }\n",
    "    \n",
    "    elif has_iv:\n",
    "        return {\n",
    "            'method': 'Instrumental Variables (IV)',\n",
    "            'description': '使用工具变量处理内生性问题',\n",
    "            'assumptions': ['相关性', '外生性', '单调性'],\n",
    "            'estimator': '2SLS',\n",
    "            'strength': '中等（取决于工具变量强度）'\n",
    "        }\n",
    "    \n",
    "    elif can_measure_confounders:\n",
    "        return {\n",
    "            'method': 'Conditional Independence (PSM/IPW/DR)',\n",
    "            'description': '通过控制观测到的混淆因素实现识别',\n",
    "            'assumptions': ['条件独立', 'Overlap'],\n",
    "            'estimator': 'PSM / IPW / Doubly Robust',\n",
    "            'strength': '较弱（需要"无遗漏变量"假设）'\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        return {\n",
    "            'method': '无法可靠识别',\n",
    "            'description': '当前数据和场景无法满足任何识别假设，建议：\\n' + \n",
    "                           '1. 设计随机实验\\n' + \n",
    "                           '2. 寻找自然实验或工具变量\\n' + \n",
    "                           '3. 收集更多混淆因素数据',\n",
    "            'assumptions': [],\n",
    "            'estimator': 'N/A',\n",
    "            'strength': 'N/A'\n",
    "        }\n",
    "\n",
    "# 测试\n",
    "for case in test_cases:\n",
    "    result = recommend_identification_strategy(**case['params'])\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{case['name']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"推荐方法: {result['method']}\")\n",
    "    print(f\"说明: {result['description']}\")\n",
    "    print(f\"关键假设: {', '.join(result['assumptions'])}\")\n",
    "    print(f\"估计量: {result['estimator']}\")\n",
    "    print(f\"识别强度: {result['strength']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: 案例分析 - 4 个真实业务场景\n",
    "\n",
    "通过 4 个完整的案例，练习识别策略的选择和实施。\n",
    "\n",
    "---\n",
    "\n",
    "## 案例 1: 优惠券效果评估 (有实验)\n",
    "\n",
    "### 背景\n",
    "\n",
    "某电商平台想评估\"满 200 减 50\"优惠券对 GMV 的提升效果。\n",
    "\n",
    "**实验设计**：\n",
    "- 随机抽取 10,000 名用户，50% 发券，50% 不发\n",
    "- 观测 7 天内的消费金额\n",
    "\n",
    "### 数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coupon_rct_data(n=10000, seed=42):\n",
    "    \"\"\"\n",
    "    生成优惠券随机实验数据\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 用户特征\n",
    "    age = np.random.normal(35, 10, n)\n",
    "    income = np.random.lognormal(10, 0.5, n)\n",
    "    \n",
    "    # 随机分配（真正的随机化）\n",
    "    treatment = np.random.binomial(1, 0.5, n)\n",
    "    \n",
    "    # 潜在结果\n",
    "    # Y(0): 不发券的消费\n",
    "    baseline = 100 + 2 * age + 0.001 * income + np.random.normal(0, 50, n)\n",
    "    \n",
    "    # 处理效应（异质性：年轻人对优惠券更敏感）\n",
    "    treatment_effect = 80 + (40 - age) * 0.5  # 年龄越小，效果越大\n",
    "    \n",
    "    # 观测结果\n",
    "    gmv = baseline + treatment * treatment_effect\n",
    "    gmv = np.maximum(gmv, 0)  # 消费不能为负\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'user_id': range(n),\n",
    "        'age': age,\n",
    "        'income': income,\n",
    "        'treatment': treatment,\n",
    "        'gmv': gmv,\n",
    "        'true_effect': treatment_effect  # 真实效应（实际中观测不到）\n",
    "    })\n",
    "\n",
    "df_coupon = generate_coupon_rct_data()\n",
    "print(\"数据概览:\")\n",
    "print(df_coupon.head())\n",
    "print(f\"\\n处理组人数: {df_coupon['treatment'].sum()}\")\n",
    "print(f\"对照组人数: {(1 - df_coupon['treatment']).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: 验证随机化（协变量平衡检验）\n",
    "\n",
    "def check_balance(df, covariates, treatment_col='treatment'):\n",
    "    \"\"\"\n",
    "    检验协变量在处理组和对照组是否平衡\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for cov in covariates:\n",
    "        treat_mean = df[df[treatment_col] == 1][cov].mean()\n",
    "        control_mean = df[df[treatment_col] == 0][cov].mean()\n",
    "        diff = treat_mean - control_mean\n",
    "        \n",
    "        # t-test\n",
    "        t_stat, p_val = stats.ttest_ind(\n",
    "            df[df[treatment_col] == 1][cov],\n",
    "            df[df[treatment_col] == 0][cov]\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'covariate': cov,\n",
    "            'treat_mean': treat_mean,\n",
    "            'control_mean': control_mean,\n",
    "            'diff': diff,\n",
    "            'p_value': p_val,\n",
    "            'balanced': p_val > 0.05\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "balance_check = check_balance(df_coupon, ['age', 'income'])\n",
    "print(\"协变量平衡检验:\")\n",
    "print(balance_check)\n",
    "print(\"\\n结论: 所有协变量 p > 0.05，随机化成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: 估计平均处理效应 (ATE)\n",
    "\n",
    "ate_estimate = df_coupon[df_coupon['treatment'] == 1]['gmv'].mean() - \\\n",
    "               df_coupon[df_coupon['treatment'] == 0]['gmv'].mean()\n",
    "\n",
    "# 标准误（使用异方差稳健估计）\n",
    "n1 = df_coupon['treatment'].sum()\n",
    "n0 = len(df_coupon) - n1\n",
    "var1 = df_coupon[df_coupon['treatment'] == 1]['gmv'].var()\n",
    "var0 = df_coupon[df_coupon['treatment'] == 0]['gmv'].var()\n",
    "se = np.sqrt(var1/n1 + var0/n0)\n",
    "\n",
    "# 95% 置信区间\n",
    "ci_lower = ate_estimate - 1.96 * se\n",
    "ci_upper = ate_estimate + 1.96 * se\n",
    "\n",
    "# 真实 ATE（用于验证）\n",
    "true_ate = df_coupon['true_effect'].mean()\n",
    "\n",
    "print(f\"估计的 ATE: {ate_estimate:.2f} 元\")\n",
    "print(f\"95% 置信区间: [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
    "print(f\"真实 ATE: {true_ate:.2f} 元\")\n",
    "print(f\"\\n结论: 优惠券平均提升 GMV {ate_estimate:.0f} 元，效果显著！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化：处理效应的分布\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# 对照组\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=df_coupon[df_coupon['treatment'] == 0]['gmv'],\n",
    "    name='对照组（无券）',\n",
    "    marker_color=COLORS['gray'],\n",
    "    opacity=0.7,\n",
    "    nbinsx=50\n",
    "))\n",
    "\n",
    "# 处理组\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=df_coupon[df_coupon['treatment'] == 1]['gmv'],\n",
    "    name='处理组（有券）',\n",
    "    marker_color=COLORS['primary'],\n",
    "    opacity=0.7,\n",
    "    nbinsx=50\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='案例 1: 优惠券实验结果分布',\n",
    "    xaxis_title='GMV (元)',\n",
    "    yaxis_title='用户数',\n",
    "    barmode='overlay',\n",
    "    template='plotly_white',\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 案例 2: 政策效果评估 (DID)\n",
    "\n",
    "### 背景\n",
    "\n",
    "某外卖平台在北京地区（2023 年 6 月）推出\"30 分钟必达\"服务，想评估对订单量的影响。\n",
    "\n",
    "**数据**：\n",
    "- 北京（处理城市）和上海（对照城市）的月度订单数\n",
    "- 时间跨度：2023.1 - 2023.12\n",
    "\n",
    "### 数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_did_data(seed=42):\n",
    "    \"\"\"\n",
    "    生成 DID 政策评估数据\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    months = pd.date_range('2023-01', '2023-12', freq='MS')\n",
    "    time = np.arange(len(months))\n",
    "    \n",
    "    # 政策实施时间：2023-06 (第 6 个月，索引为 5)\n",
    "    policy_time = 5\n",
    "    \n",
    "    data = []\n",
    "    for city, base_level in [('北京', 5000), ('上海', 4800)]:\n",
    "        is_treated = (city == '北京')\n",
    "        \n",
    "        # 共同趋势（两城市都在增长）\n",
    "        trend = 100 * time\n",
    "        \n",
    "        # 北京基础水平稍高\n",
    "        baseline = base_level + trend\n",
    "        \n",
    "        # 政策效应（只对北京，且只在 6 月之后）\n",
    "        policy_effect = np.where(\n",
    "            (time >= policy_time) & is_treated,\n",
    "            800,  # 政策使订单量提升 800 单/月\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # 观测值\n",
    "        orders = baseline + policy_effect + np.random.normal(0, 200, len(time))\n",
    "        \n",
    "        for i, month in enumerate(months):\n",
    "            data.append({\n",
    "                'city': city,\n",
    "                'month': month,\n",
    "                'time': time[i],\n",
    "                'post': time[i] >= policy_time,\n",
    "                'treated': is_treated,\n",
    "                'orders': orders[i]\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df_did = generate_did_data()\n",
    "print(\"数据概览:\")\n",
    "print(df_did.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化：平行趋势检验\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for city in ['北京', '上海']:\n",
    "    city_data = df_did[df_did['city'] == city]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=city_data['month'],\n",
    "        y=city_data['orders'],\n",
    "        mode='lines+markers',\n",
    "        name=city,\n",
    "        line=dict(width=3),\n",
    "        marker=dict(size=8)\n",
    "    ))\n",
    "\n",
    "# 标记政策实施时点\n",
    "fig.add_vline(\n",
    "    x=pd.Timestamp('2023-06'),\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"政策实施 (6月)\",\n",
    "    annotation_position=\"top\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='案例 2: DID 平行趋势可视化',\n",
    "    xaxis_title='月份',\n",
    "    yaxis_title='订单量',\n",
    "    template='plotly_white',\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"观察: 政策前两城市趋势平行，政策后北京订单量跳升！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2: 实现 DID 估计量\n",
    "#\n",
    "# 任务：计算双重差分估计量\n",
    "# \n",
    "# 提示：\n",
    "# 1. 计算 4 个均值：(北京,政策后), (北京,政策前), (上海,政策后), (上海,政策前)\n",
    "# 2. DID = [北京政策后 - 北京政策前] - [上海政策后 - 上海政策前]\n",
    "\n",
    "def estimate_did(df, outcome='orders', treated_col='treated', post_col='post'):\n",
    "    \"\"\"\n",
    "    计算 DID 估计量\n",
    "    \n",
    "    返回：\n",
    "        float: DID 估计值\n",
    "    \"\"\"\n",
    "    # ===== YOUR CODE HERE =====\n",
    "    pass\n",
    "    # ===== END OF YOUR CODE =====\n",
    "\n",
    "# did_estimate = estimate_did(df_did)\n",
    "# print(f\"DID 估计: 政策使订单量提升 {did_estimate:.2f} 单/月\")\n",
    "# print(f\"真实效应: 800 单/月\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考答案\n",
    "\n",
    "def estimate_did(df, outcome='orders', treated_col='treated', post_col='post'):\n",
    "    \"\"\"\n",
    "    计算 DID 估计量\n",
    "    \"\"\"\n",
    "    # 4 个均值\n",
    "    treated_post = df[(df[treated_col]) & (df[post_col])][outcome].mean()\n",
    "    treated_pre = df[(df[treated_col]) & (~df[post_col])][outcome].mean()\n",
    "    control_post = df[(~df[treated_col]) & (df[post_col])][outcome].mean()\n",
    "    control_pre = df[(~df[treated_col]) & (~df[post_col])][outcome].mean()\n",
    "    \n",
    "    # DID 估计量\n",
    "    did = (treated_post - treated_pre) - (control_post - control_pre)\n",
    "    \n",
    "    print(f\"北京政策后均值: {treated_post:.2f}\")\n",
    "    print(f\"北京政策前均值: {treated_pre:.2f}\")\n",
    "    print(f\"北京差异: {treated_post - treated_pre:.2f}\")\n",
    "    print(f\"\\n上海政策后均值: {control_post:.2f}\")\n",
    "    print(f\"上海政策前均值: {control_pre:.2f}\")\n",
    "    print(f\"上海差异: {control_post - control_pre:.2f}\")\n",
    "    print(f\"\\nDID 估计: {did:.2f}\")\n",
    "    \n",
    "    return did\n",
    "\n",
    "did_estimate = estimate_did(df_did)\n",
    "print(f\"\\n结论: 政策使订单量提升约 {did_estimate:.0f} 单/月 (真实值 800)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 案例 3: 价格弹性估计 (IV)\n",
    "\n",
    "### 背景\n",
    "\n",
    "某咖啡店想知道：**价格下降 10%，销量会提升多少？**\n",
    "\n",
    "**问题**：价格与销量同时受\"质量\"影响（高质量→高价格→高销量），简单回归有偏。\n",
    "\n",
    "**工具变量**：咖啡豆原材料成本（影响价格，但不直接影响消费者需求）。\n",
    "\n",
    "### 数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_iv_data(n=500, seed=42):\n",
    "    \"\"\"\n",
    "    生成工具变量数据\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 工具变量：原材料成本（外生冲击）\n",
    "    raw_material_cost = np.random.uniform(10, 30, n)\n",
    "    \n",
    "    # 未观测混淆因素：产品质量\n",
    "    quality = np.random.normal(50, 10, n)\n",
    "    \n",
    "    # 内生变量：价格（同时受成本和质量影响）\n",
    "    price = 20 + 0.5 * raw_material_cost + 0.3 * quality + np.random.normal(0, 2, n)\n",
    "    \n",
    "    # 结果变量：销量（受价格和质量影响）\n",
    "    # 真实价格弹性: -2（价格每涨 1 元，销量下降 2 单）\n",
    "    sales = 200 - 2 * price + 1.5 * quality + np.random.normal(0, 10, n)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'raw_material_cost': raw_material_cost,\n",
    "        'price': price,\n",
    "        'sales': sales,\n",
    "        'quality': quality  # 实际中观测不到\n",
    "    })\n",
    "\n",
    "df_iv = generate_iv_data()\n",
    "print(\"数据概览:\")\n",
    "print(df_iv.head())\n",
    "print(f\"\\n价格与销量相关系数: {df_iv[['price', 'sales']].corr().iloc[0, 1]:.3f}\")\n",
    "print(\"注意: 简单相关系数为正! (因为质量同时提升价格和销量)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比较：OLS vs IV\n",
    "\n",
    "# 1. 朴素 OLS（有偏）\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(df_iv[['price']], df_iv['sales'])\n",
    "ols_coef = ols_model.coef_[0]\n",
    "\n",
    "# 2. 两阶段最小二乘 (2SLS)\n",
    "# 第一阶段：用 IV 预测价格\n",
    "first_stage = LinearRegression()\n",
    "first_stage.fit(df_iv[['raw_material_cost']], df_iv['price'])\n",
    "price_hat = first_stage.predict(df_iv[['raw_material_cost']])\n",
    "\n",
    "# 第二阶段：用预测价格估计因果效应\n",
    "second_stage = LinearRegression()\n",
    "second_stage.fit(price_hat.reshape(-1, 1), df_iv['sales'])\n",
    "iv_coef = second_stage.coef_[0]\n",
    "\n",
    "print(\"估计结果对比:\")\n",
    "print(f\"朴素 OLS 估计: {ols_coef:.3f} (严重向上偏误!)\")\n",
    "print(f\"IV (2SLS) 估计: {iv_coef:.3f}\")\n",
    "print(f\"真实系数: -2.000\")\n",
    "print(\"\\n结论: IV 成功修正了质量导致的内生性偏误！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化：IV 的识别逻辑\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('第一阶段: IV → 价格', '第二阶段: 预测价格 → 销量')\n",
    ")\n",
    "\n",
    "# 第一阶段\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_iv['raw_material_cost'],\n",
    "        y=df_iv['price'],\n",
    "        mode='markers',\n",
    "        marker=dict(color=COLORS['primary'], opacity=0.5),\n",
    "        name='实际数据',\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 拟合线\n",
    "x_range = np.linspace(df_iv['raw_material_cost'].min(), df_iv['raw_material_cost'].max(), 100)\n",
    "y_pred = first_stage.predict(x_range.reshape(-1, 1))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_range,\n",
    "        y=y_pred,\n",
    "        mode='lines',\n",
    "        line=dict(color=COLORS['danger'], width=3),\n",
    "        name='拟合线',\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 第二阶段\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=price_hat,\n",
    "        y=df_iv['sales'],\n",
    "        mode='markers',\n",
    "        marker=dict(color=COLORS['success'], opacity=0.5),\n",
    "        name='实际数据',\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 拟合线\n",
    "x_range2 = np.linspace(price_hat.min(), price_hat.max(), 100)\n",
    "y_pred2 = second_stage.predict(x_range2.reshape(-1, 1))\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=x_range2,\n",
    "        y=y_pred2,\n",
    "        mode='lines',\n",
    "        line=dict(color=COLORS['danger'], width=3),\n",
    "        name='拟合线',\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='原材料成本', row=1, col=1)\n",
    "fig.update_xaxes(title_text='预测价格 (由 IV 驱动)', row=1, col=2)\n",
    "fig.update_yaxes(title_text='价格', row=1, col=1)\n",
    "fig.update_yaxes(title_text='销量', row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='案例 3: 工具变量两阶段估计',\n",
    "    height=400,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 案例 4: 用户行为分析 (观测数据 + PSM)\n",
    "\n",
    "### 背景\n",
    "\n",
    "某视频平台想评估：**开通会员能否提升用户留存率？**\n",
    "\n",
    "**问题**：会员用户本身就更活跃、更忠诚，简单比较有选择偏差。\n",
    "\n",
    "**策略**：用倾向得分匹配 (PSM) 找到\"可比\"的非会员用户。\n",
    "\n",
    "### 数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_membership_data(n=2000, seed=42):\n",
    "    \"\"\"\n",
    "    生成会员效果观测数据（有选择偏差）\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 用户特征\n",
    "    age = np.random.normal(30, 8, n)\n",
    "    watch_history = np.random.exponential(50, n)  # 历史观看时长\n",
    "    income = np.random.lognormal(10, 0.6, n)\n",
    "    \n",
    "    # 倾向得分（活跃、高收入用户更可能开会员）\n",
    "    propensity_score = 1 / (1 + np.exp(-(\n",
    "        -3 + 0.05 * age + 0.02 * watch_history + 0.0001 * income\n",
    "    )))\n",
    "    \n",
    "    # 处理分配（基于倾向得分，非随机）\n",
    "    treatment = np.random.binomial(1, propensity_score)\n",
    "    \n",
    "    # 潜在结果（会员效应 + 用户本身特征）\n",
    "    retention = 0.3 + 0.002 * watch_history + 0.00001 * income + \\\n",
    "                0.15 * treatment + \\\n",
    "                np.random.normal(0, 0.1, n)\n",
    "    retention = np.clip(retention, 0, 1)  # 限制在 [0, 1]\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'user_id': range(n),\n",
    "        'age': age,\n",
    "        'watch_history': watch_history,\n",
    "        'income': income,\n",
    "        'treatment': treatment,\n",
    "        'retention': retention,\n",
    "        'propensity_score': propensity_score\n",
    "    })\n",
    "\n",
    "df_membership = generate_membership_data()\n",
    "print(\"数据概览:\")\n",
    "print(df_membership.head())\n",
    "print(f\"\\n会员用户数: {df_membership['treatment'].sum()}\")\n",
    "print(f\"非会员用户数: {(1 - df_membership['treatment']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: 朴素比较（有偏）\n",
    "\n",
    "naive_diff = df_membership[df_membership['treatment'] == 1]['retention'].mean() - \\\n",
    "             df_membership[df_membership['treatment'] == 0]['retention'].mean()\n",
    "\n",
    "print(f\"朴素估计（直接比较）: {naive_diff:.3f}\")\n",
    "print(f\"真实会员效应: 0.150\")\n",
    "print(\"\\n朴素估计过高，因为会员用户本身就更活跃！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: 估计倾向得分\n",
    "\n",
    "ps_model = LogisticRegression(max_iter=1000)\n",
    "ps_model.fit(\n",
    "    df_membership[['age', 'watch_history', 'income']],\n",
    "    df_membership['treatment']\n",
    ")\n",
    "df_membership['ps_estimated'] = ps_model.predict_proba(\n",
    "    df_membership[['age', 'watch_history', 'income']]\n",
    ")[:, 1]\n",
    "\n",
    "print(\"倾向得分估计完成\")\n",
    "print(f\"估计的倾向得分范围: [{df_membership['ps_estimated'].min():.3f}, {df_membership['ps_estimated'].max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: 倾向得分匹配\n",
    "\n",
    "def propensity_score_matching(df, treatment_col='treatment', ps_col='ps_estimated', caliper=0.01):\n",
    "    \"\"\"\n",
    "    简单的 1:1 最近邻匹配\n",
    "    \"\"\"\n",
    "    treated = df[df[treatment_col] == 1].copy()\n",
    "    control = df[df[treatment_col] == 0].copy()\n",
    "    \n",
    "    matched_pairs = []\n",
    "    used_controls = set()\n",
    "    \n",
    "    for _, treated_unit in treated.iterrows():\n",
    "        # 找到倾向得分最接近的对照单元\n",
    "        distances = np.abs(control[ps_col] - treated_unit[ps_col])\n",
    "        \n",
    "        # 排除已经匹配过的\n",
    "        available = control[~control.index.isin(used_controls)]\n",
    "        if len(available) == 0:\n",
    "            continue\n",
    "        \n",
    "        distances_available = np.abs(available[ps_col] - treated_unit[ps_col])\n",
    "        min_dist = distances_available.min()\n",
    "        \n",
    "        # 卡尺限制\n",
    "        if min_dist <= caliper:\n",
    "            matched_control_idx = distances_available.idxmin()\n",
    "            matched_pairs.append({\n",
    "                'treated_id': treated_unit.name,\n",
    "                'control_id': matched_control_idx,\n",
    "                'distance': min_dist\n",
    "            })\n",
    "            used_controls.add(matched_control_idx)\n",
    "    \n",
    "    return pd.DataFrame(matched_pairs)\n",
    "\n",
    "matched_pairs = propensity_score_matching(df_membership)\n",
    "print(f\"成功匹配 {len(matched_pairs)} 对用户\")\n",
    "print(f\"平均倾向得分差异: {matched_pairs['distance'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: 匹配后的 ATT 估计\n",
    "\n",
    "treated_outcomes = df_membership.loc[matched_pairs['treated_id'], 'retention']\n",
    "control_outcomes = df_membership.loc[matched_pairs['control_id'], 'retention']\n",
    "\n",
    "att_psm = (treated_outcomes.values - control_outcomes.values).mean()\n",
    "\n",
    "print(f\"\\n估计结果对比:\")\n",
    "print(f\"朴素估计: {naive_diff:.3f} (有偏)\")\n",
    "print(f\"PSM 估计: {att_psm:.3f}\")\n",
    "print(f\"真实效应: 0.150\")\n",
    "print(\"\\n结论: PSM 成功消除了选择偏差！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化：匹配前后的协变量平衡\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('匹配前: 观看时长分布', '匹配后: 观看时长分布')\n",
    ")\n",
    "\n",
    "# 匹配前\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=df_membership[df_membership['treatment'] == 0]['watch_history'],\n",
    "        name='非会员',\n",
    "        marker_color=COLORS['gray'],\n",
    "        opacity=0.7,\n",
    "        nbinsx=30,\n",
    "        showlegend=True\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=df_membership[df_membership['treatment'] == 1]['watch_history'],\n",
    "        name='会员',\n",
    "        marker_color=COLORS['primary'],\n",
    "        opacity=0.7,\n",
    "        nbinsx=30,\n",
    "        showlegend=True\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 匹配后\n",
    "matched_control = df_membership.loc[matched_pairs['control_id']]\n",
    "matched_treated = df_membership.loc[matched_pairs['treated_id']]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=matched_control['watch_history'],\n",
    "        name='匹配后非会员',\n",
    "        marker_color=COLORS['gray'],\n",
    "        opacity=0.7,\n",
    "        nbinsx=30,\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=matched_treated['watch_history'],\n",
    "        name='匹配后会员',\n",
    "        marker_color=COLORS['primary'],\n",
    "        opacity=0.7,\n",
    "        nbinsx=30,\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='观看时长', row=1, col=1)\n",
    "fig.update_xaxes(title_text='观看时长', row=1, col=2)\n",
    "fig.update_yaxes(title_text='用户数', row=1, col=1)\n",
    "fig.update_yaxes(title_text='用户数', row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='案例 4: PSM 匹配前后的协变量平衡',\n",
    "    barmode='overlay',\n",
    "    template='plotly_white',\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n观察: 匹配后两组的观看时长分布高度重合！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 思考题\n",
    "\n",
    "1. **识别 vs 估计**\n",
    "   - 为什么说\"识别比估计更重要\"？能否举一个\"估计精确但识别错误\"的现实例子？\n",
    "\n",
    "2. **假设层级**\n",
    "   - 随机化假设最强但最可靠，为什么真实世界中我们还需要其他更弱的假设？\n",
    "\n",
    "3. **工具变量的悖论**\n",
    "   - IV 可以处理未观测混淆，但\"好的工具变量极难找\"。如何判断一个变量是否是好的 IV？\n",
    "\n",
    "4. **PSM 的局限**\n",
    "   - 案例 4 中，PSM 假设\"给定观测到的特征，处理分配是随机的\"。如果还有重要的未观测混淆因素（如用户的\"内在兴趣\"),PSM 会失效吗？\n",
    "\n",
    "5. **实战决策**\n",
    "   - 假设你要评估\"推荐算法改版\"对用户留存的影响。数据：\n",
    "     - 新算法只对 iOS 用户上线（Android 未上线）\n",
    "     - 有上线前后 3 个月的数据\n",
    "     - 有用户特征（年龄、历史活跃度）\n",
    "   \n",
    "   你会选择哪种识别策略？为什么？\n",
    "\n",
    "---\n",
    "\n",
    "# 总结\n",
    "\n",
    "## 核心要点\n",
    "\n",
    "1. **识别 > 估计**\n",
    "   - 识别回答\"能否算出因果效应\"\n",
    "   - 估计回答\"如何算出因果效应\"\n",
    "   - 识别错误，估计再精确也无意义\n",
    "\n",
    "2. **识别假设层级**\n",
    "   ```\n",
    "   随机化 > 条件独立 > 自然实验 > 工具变量\n",
    "   (最强)                               (最弱)\n",
    "   ```\n",
    "\n",
    "3. **决策流程**\n",
    "   ```\n",
    "   有随机实验？ → RCT\n",
    "   有时间断点？ → DID\n",
    "   有分配阈值？ → RDD\n",
    "   有工具变量？ → IV\n",
    "   能测量混淆？ → PSM/IPW/DR\n",
    "   都没有？     → 无法可靠识别\n",
    "   ```\n",
    "\n",
    "4. **实战案例**\n",
    "   - **案例 1 (RCT)**：优惠券效果评估，简单均值差\n",
    "   - **案例 2 (DID)**：政策效果评估，双重差分\n",
    "   - **案例 3 (IV)**：价格弹性估计，工具变量\n",
    "   - **案例 4 (PSM)**：会员效果评估，倾向得分匹配\n",
    "\n",
    "## 下一步学习\n",
    "\n",
    "- **Part 1 (Foundation Lab)**：深入学习潜在结果框架、因果图\n",
    "- **Part 2 (Treatment Effect Lab)**：掌握 PSM、IPW、DR 的实现细节\n",
    "- **Part 3 (Advanced Methods)**：学习 DID、RDD、IV 的高级技巧\n",
    "\n",
    "---\n",
    "\n",
    "**恭喜你完成了识别策略框架的学习！你现在已经掌握了因果推断最核心的决策能力：根据数据特征选择正确的识别策略。**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
