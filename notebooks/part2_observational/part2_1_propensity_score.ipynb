{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ ç¬¬äºŒç«  ç»ƒä¹  1: å€¾å‘å¾—åˆ†åŒ¹é… (Propensity Score Matching)\n",
    "\n",
    "---\n",
    "\n",
    "## ä»ã€Œæ‰¾ç›¸ä¼¼çš„äººã€å¼€å§‹\n",
    "\n",
    "åœ¨ç¬¬ä¸€ç« ï¼Œæˆ‘ä»¬çŸ¥é“äº†éšæœºå®éªŒä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸ºå¤„ç†ç»„å’Œæ§åˆ¶ç»„çš„ç‰¹å¾åˆ†å¸ƒç›¸åŒã€‚ä½†åœ¨è§‚æµ‹æ•°æ®ä¸­ï¼Œè¿™ä¸ªæ¡ä»¶é€šå¸¸ä¸æ»¡è¶³ã€‚\n",
    "\n",
    "é‚£æ€ä¹ˆåŠå‘¢ï¼Ÿ\n",
    "\n",
    "ä¸€ä¸ªç›´è§‰çš„æƒ³æ³•ï¼š**æ—¢ç„¶ä¸¤ç»„äººä¸ä¸€æ ·ï¼Œé‚£å°±æ‰¾ä¸€æ ·çš„å‘—ï¼**\n",
    "\n",
    "### ç›¸äº²çš„è‰ºæœ¯ ğŸ’‘\n",
    "\n",
    "æƒ³è±¡ä½ æ˜¯ä¸€ä¸ªç›¸äº²å¹³å°çš„ç®—æ³•å·¥ç¨‹å¸ˆã€‚ä½ è¦å¸®åŠ©è¯„ä¼°ã€Œé€ç«ç‘°èŠ±ã€å¯¹ã€Œç›¸äº²æˆåŠŸç‡ã€çš„å½±å“ã€‚\n",
    "\n",
    "é—®é¢˜æ˜¯ï¼šé€èŠ±çš„äººå’Œä¸é€èŠ±çš„äººæœ¬æ¥å°±ä¸ä¸€æ ·â€”â€”\n",
    "- é€èŠ±çš„äººå¯èƒ½æ›´æµªæ¼«\n",
    "- é€èŠ±çš„äººå¯èƒ½æ”¶å…¥æ›´é«˜ï¼ˆä¹°å¾—èµ·èŠ±ï¼‰\n",
    "- é€èŠ±çš„äººå¯èƒ½æ›´é‡è§†è¿™æ®µå…³ç³»\n",
    "\n",
    "æ‰€ä»¥ç®€å•æ¯”è¾ƒé€èŠ±è€…å’Œä¸é€èŠ±è€…çš„æˆåŠŸç‡æ˜¯æœ‰åçš„ã€‚\n",
    "\n",
    "**è§£å†³æ–¹æ¡ˆ**: ä¸ºæ¯ä¸ªé€èŠ±çš„äººï¼Œæ‰¾ä¸€ä¸ªã€Œå‡ ä¹ä¸€æ¨¡ä¸€æ ·ä½†æ²¡é€èŠ±ã€çš„äººåšå¯¹æ¯”ï¼\n",
    "\n",
    "è¿™å°±æ˜¯**åŒ¹é… (Matching)** çš„æ ¸å¿ƒæ€æƒ³ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š æœ¬èŠ‚å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "1. ç†è§£å€¾å‘å¾—åˆ†çš„æ¦‚å¿µå’Œæ•°å­¦åŸç†\n",
    "2. å®ç°å€¾å‘å¾—åˆ†åŒ¹é… (PSM) ç®—æ³•\n",
    "3. è¯„ä¼°åŒ¹é…è´¨é‡ï¼ˆSMDã€æ–¹å·®æ¯”ï¼‰\n",
    "4. ç†è§£ PSM çš„å‡è®¾å’Œå±€é™æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "# è®¾ç½®\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæ¯•ï¼è®©æˆ‘ä»¬å¼€å§‹å­¦ä¹  PSMï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## ğŸŒŸ Part 1: ä»€ä¹ˆæ˜¯å€¾å‘å¾—åˆ†ï¼Ÿ\n\n### æ ¸å¿ƒå®šä¹‰\n\n**å€¾å‘å¾—åˆ† (Propensity Score)** æ˜¯ç»™å®šåå˜é‡ Xï¼Œä¸ªä½“æ¥å—å¤„ç†çš„æ¦‚ç‡ï¼š\n\n$$e(X) = P(T=1 | X)$$\n\n### ç›´è§‰ç†è§£\n\nå€¾å‘å¾—åˆ†å‘Šè¯‰æˆ‘ä»¬ï¼šã€Œè¿™ä¸ªäººæœ‰å¤šå¤§å¯èƒ½æ¥å—å¤„ç†ã€\n\n| åœºæ™¯ | å¤„ç† T | å€¾å‘å¾—åˆ†çš„å«ä¹‰ |\n|-----|--------|---------------|\n| è¥é”€ | å‘ä¼˜æƒ åˆ¸ | ç”¨æˆ·å¤šå¤§æ¦‚ç‡ä¼šæ”¶åˆ°åˆ¸ |\n| åŒ»å­¦ | æœç”¨æ–°è¯ | æ‚£è€…å¤šå¤§æ¦‚ç‡ä¼šè¢«å¤„æ–¹æ–°è¯ |\n| æ•™è‚² | å‚åŠ åŸ¹è®­ | å‘˜å·¥å¤šå¤§æ¦‚ç‡ä¼šå‚åŠ åŸ¹è®­ |\n\n### ä¸ºä»€ä¹ˆå€¾å‘å¾—åˆ†å¦‚æ­¤ç¥å¥‡ï¼Ÿ\n\n**Rosenbaum & Rubin (1983)** è¯æ˜äº†ä¸€ä¸ªæƒŠäººçš„å®šç†ï¼š\n\n> å¦‚æœç»™å®š Xï¼Œæ½œåœ¨ç»“æœä¸ T ç‹¬ç«‹ï¼Œé‚£ä¹ˆç»™å®š e(X)ï¼Œæ½œåœ¨ç»“æœä¹Ÿä¸ T ç‹¬ç«‹ï¼\n\n$$Y(0), Y(1) \\perp T | X \\Rightarrow Y(0), Y(1) \\perp T | e(X)$$\n\n**ç¿»è¯‘æˆäººè¯**ï¼šæˆ‘ä»¬ä¸éœ€è¦åœ¨æ¯ä¸ªåå˜é‡ä¸Šéƒ½åŒ¹é…ï¼Œåªéœ€è¦åœ¨å€¾å‘å¾—åˆ†è¿™ä¸€ä¸ªæ•°ä¸ŠåŒ¹é…å°±å¤Ÿäº†ï¼\n\nè¿™å¤§å¤§é™ä½äº†åŒ¹é…çš„éš¾åº¦ï¼Œå› ä¸ºæˆ‘ä»¬æŠŠé«˜ç»´çš„ X å‹ç¼©æˆäº†ä¸€ç»´çš„ e(X)ã€‚\n\n---\n\n## ğŸ“ æ ¸å¿ƒæ•°å­¦æ¨å¯¼\n\n### å€¾å‘å¾—åˆ†å®šç† (Rosenbaum & Rubin, 1983)\n\n**å®šç†**: å¦‚æœ $(Y(0), Y(1)) \\perp T | X$ï¼ˆæ— æ··æ·†å‡è®¾ï¼‰ï¼Œé‚£ä¹ˆï¼š\n\n$$(Y(0), Y(1)) \\perp T | e(X)$$\n\nå…¶ä¸­ $e(X) = P(T=1|X)$\n\n**è¯æ˜æ€è·¯**:\n\n1. **å……åˆ†æ€§**: æˆ‘ä»¬éœ€è¦è¯æ˜å¯¹ä»»æ„ $y_0, y_1, t$ï¼š\n   $$P(Y(0)=y_0, Y(1)=y_1 | T=t, e(X)) = P(Y(0)=y_0, Y(1)=y_1 | e(X))$$\n\n2. **å…³é”®æ­¥éª¤**: å¯¹ X ç§¯åˆ†\n   $$P(Y(0), Y(1) | T=t, e(X)=e) = \\int P(Y(0), Y(1) | T=t, X) \\cdot P(X | T=t, e(X)=e) dX$$\n\n3. **åº”ç”¨æ— æ··æ·†å‡è®¾**: ç”± $(Y(0), Y(1)) \\perp T | X$\n   $$= \\int P(Y(0), Y(1) | X) \\cdot P(X | T=t, e(X)=e) dX$$\n\n4. **å€¾å‘å¾—åˆ†çš„å·§å¦™ä¹‹å¤„**: \n   $$P(X | T=t, e(X)=e) = \\frac{P(T=t|X) \\cdot P(X|e(X)=e)}{P(T=t|e(X)=e)}$$\n   \n   ç”±äº $e(X)$ æ˜¯ X çš„å‡½æ•°ï¼Œç»™å®š $e(X)=e$ åï¼Œä¸Šå¼ä¸ T çš„å–å€¼æ— å…³ï¼\n\n5. **ç»“è®º**: å› æ­¤æ¡ä»¶åˆ†å¸ƒä¸ T æ— å…³ï¼Œè¯æ¯•ã€‚\n\n**ç»´åº¦ç¼©å‡çš„æ„ä¹‰**:\n\n- åŸé—®é¢˜ï¼šåœ¨ p ç»´ç©ºé—´ X ä¸ŠåšåŒ¹é…ï¼ˆç»´åº¦ç¾éš¾ï¼‰\n- å€¾å‘å¾—åˆ†ï¼šåªéœ€åœ¨ 1 ç»´çš„ e(X) ä¸ŠåŒ¹é…\n- ä¾‹å¦‚ï¼šå¦‚æœæœ‰ 20 ä¸ªåå˜é‡ï¼ŒåŒ¹é…å‡ ä¹ä¸å¯èƒ½ï¼›ä½†å‹ç¼©æˆ 1 ä¸ªå€¾å‘å¾—åˆ†ï¼ŒåŒ¹é…å°±å¯è¡Œäº†ï¼"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¬ åŠ¨æ‰‹ä¼°è®¡å€¾å‘å¾—åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def generate_confounded_data(n: int = 2000, seed: int = 42) -> pd.DataFrame:\n    \"\"\"\n    ç”Ÿæˆæœ‰æ··æ·†çš„è§‚æµ‹æ•°æ®\n    \n    DAG: X -> T, X -> Y, T -> Y\n    \n    åœºæ™¯: ç ”ç©¶ã€Œå¥èº«ã€å¯¹ã€Œå¥åº·æŒ‡æ•°ã€çš„å½±å“\n    - X1: å¹´é¾„ï¼ˆå¹´è½»äººæ›´çˆ±å¥èº«ï¼Œå¥åº·ä¹Ÿæ›´å¥½ï¼‰\n    - X2: æ”¶å…¥ï¼ˆé«˜æ”¶å…¥æ›´å¯èƒ½æœ‰æ—¶é—´å¥èº«ï¼‰\n    - X3: é—ä¼ å› ç´ ï¼ˆä¸å¥èº«æ— å…³ï¼‰\n    \n    çœŸå® ATE = 2\n    \"\"\"\n    np.random.seed(seed)\n    \n    # ç”Ÿæˆä¸‰ä¸ªåå˜é‡\n    X1 = np.random.randn(n)  # å¹´é¾„ï¼ˆæ ‡å‡†åŒ–ï¼‰\n    X2 = np.random.randn(n)  # æ”¶å…¥\n    X3 = np.random.randn(n)  # é—ä¼ å› ç´ \n    \n    # ç”Ÿæˆå¤„ç† Tï¼ˆæ˜¯å¦å¥èº«ï¼‰\n    # å¹´è½»äººï¼ˆX1ä½ï¼‰å’Œé«˜æ”¶å…¥è€…ï¼ˆX2é«˜ï¼‰æ›´å¯èƒ½å¥èº«\n    # logit(e) = -0.5*X1 + 0.8*X2\n    propensity_logit = -0.5 * X1 + 0.8 * X2\n    propensity = 1 / (1 + np.exp(-propensity_logit))\n    T = np.random.binomial(1, propensity)\n    \n    # ç”Ÿæˆç»“æœ Yï¼ˆå¥åº·æŒ‡æ•°ï¼‰\n    # Y = 50 + 2*T - 1.5*X1 + 0.8*X2 + 0.5*X3 + noise\n    # çœŸå® ATE = 2\n    Y = 50 + 2*T - 1.5*X1 + 0.8*X2 + 0.5*X3 + np.random.randn(n)\n    \n    return pd.DataFrame({\n        'X1': X1, 'X2': X2, 'X3': X3, 'T': T, 'Y': Y\n    })\n\n# ===== ğŸ“ å‚è€ƒç­”æ¡ˆ =====\n# å®Œæ•´å®ç°è§ä¸Šæ–¹ä»£ç "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def estimate_propensity_score(X: np.ndarray, T: np.ndarray) -> np.ndarray:\n    \"\"\"\n    ä¼°è®¡å€¾å‘å¾—åˆ† e(X) = P(T=1|X)\n    \n    ä½¿ç”¨é€»è¾‘å›å½’æ¥ä¼°è®¡\n    \n    Args:\n        X: ç‰¹å¾çŸ©é˜µ (n, p)\n        T: å¤„ç†çŠ¶æ€ (n,)\n    \n    Returns:\n        å€¾å‘å¾—åˆ†æ•°ç»„ (n,)\n    \"\"\"\n    # TODO: ä½¿ç”¨ LogisticRegression æ‹Ÿåˆ T ~ X\n    # æç¤º: \n    # 1. åˆ›å»º LogisticRegression(max_iter=1000)\n    # 2. è°ƒç”¨ fit(X, T)\n    # 3. ä½¿ç”¨ predict_proba(X)[:, 1] è·å– P(T=1|X)\n    \n    # ğŸ‘ˆ ä½ çš„ä»£ç \n    pass\n\n# ===== ğŸ“ å‚è€ƒç­”æ¡ˆï¼ˆæŠ˜å ï¼‰=====\n\"\"\"\ndef estimate_propensity_score(X: np.ndarray, T: np.ndarray) -> np.ndarray:\n    model = LogisticRegression(max_iter=1000)\n    model.fit(X, T)\n    propensity = model.predict_proba(X)[:, 1]\n    return propensity\n\"\"\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•æ•°æ®ç”Ÿæˆå’Œå€¾å‘å¾—åˆ†ä¼°è®¡\n",
    "df = generate_confounded_data(n=2000, seed=42)\n",
    "\n",
    "if df['X1'] is not None:\n",
    "    print(\"ğŸ“Š æ•°æ®æ¦‚è§ˆ:\")\n",
    "    print(f\"   æ ·æœ¬é‡: {len(df)}\")\n",
    "    print(f\"   å¤„ç†ç»„: {df['T'].sum()} ({df['T'].mean()*100:.1f}%)\")\n",
    "    print(f\"   æ§åˆ¶ç»„: {(1-df['T']).sum()} ({(1-df['T']).mean()*100:.1f}%)\")\n",
    "    \n",
    "    # æœ´ç´ ä¼°è®¡\n",
    "    naive_ate = df[df['T']==1]['Y'].mean() - df[df['T']==0]['Y'].mean()\n",
    "    print(f\"\\n   æœ´ç´  ATE ä¼°è®¡: {naive_ate:.4f}\")\n",
    "    print(f\"   çœŸå® ATE: 2.0\")\n",
    "    print(f\"   åå·®: {naive_ate - 2.0:+.4f}\")\n",
    "    \n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"âŒ è¯·å®Œæˆ generate_confounded_data å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¼°è®¡å€¾å‘å¾—åˆ†\n",
    "if df['X1'] is not None:\n",
    "    X = df[['X1', 'X2', 'X3']].values\n",
    "    T = df['T'].values\n",
    "    Y = df['Y'].values\n",
    "    \n",
    "    propensity = estimate_propensity_score(X, T)\n",
    "    \n",
    "    if propensity is not None:\n",
    "        df['propensity'] = propensity\n",
    "        \n",
    "        print(\"ğŸ“ˆ å€¾å‘å¾—åˆ†ç»Ÿè®¡:\")\n",
    "        print(f\"   èŒƒå›´: [{propensity.min():.4f}, {propensity.max():.4f}]\")\n",
    "        print(f\"   å¤„ç†ç»„å¹³å‡: {propensity[T==1].mean():.4f}\")\n",
    "        print(f\"   æ§åˆ¶ç»„å¹³å‡: {propensity[T==0].mean():.4f}\")\n",
    "        \n",
    "        # å¯è§†åŒ–\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # å›¾1: å€¾å‘å¾—åˆ†åˆ†å¸ƒ\n",
    "        ax1 = axes[0]\n",
    "        ax1.hist(propensity[T==1], bins=30, alpha=0.5, label='å¤„ç†ç»„', color='coral', density=True)\n",
    "        ax1.hist(propensity[T==0], bins=30, alpha=0.5, label='æ§åˆ¶ç»„', color='steelblue', density=True)\n",
    "        ax1.set_xlabel('å€¾å‘å¾—åˆ† e(X)', fontsize=12)\n",
    "        ax1.set_ylabel('å¯†åº¦', fontsize=12)\n",
    "        ax1.set_title('å€¾å‘å¾—åˆ†åˆ†å¸ƒ', fontsize=14)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # å›¾2: å…±åŒæ”¯æ’‘\n",
    "        ax2 = axes[1]\n",
    "        ax2.scatter(propensity[T==0], np.random.uniform(-0.1, 0.1, (T==0).sum()), \n",
    "                   alpha=0.3, label='æ§åˆ¶ç»„', c='steelblue', s=20)\n",
    "        ax2.scatter(propensity[T==1], np.random.uniform(0.9, 1.1, (T==1).sum()), \n",
    "                   alpha=0.3, label='å¤„ç†ç»„', c='coral', s=20)\n",
    "        \n",
    "        # é‡å åŒºåŸŸ\n",
    "        overlap_min = max(propensity[T==0].min(), propensity[T==1].min())\n",
    "        overlap_max = min(propensity[T==0].max(), propensity[T==1].max())\n",
    "        ax2.axvspan(overlap_min, overlap_max, alpha=0.2, color='green', label='å…±åŒæ”¯æ’‘åŒºåŸŸ')\n",
    "        \n",
    "        ax2.set_xlabel('å€¾å‘å¾—åˆ† e(X)', fontsize=12)\n",
    "        ax2.set_yticks([0, 1])\n",
    "        ax2.set_yticklabels(['æ§åˆ¶ç»„', 'å¤„ç†ç»„'])\n",
    "        ax2.set_title('å…±åŒæ”¯æ’‘ (Common Support)', fontsize=14)\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"âŒ è¯·å®Œæˆ estimate_propensity_score å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”— Part 2: å®ç°å€¾å‘å¾—åˆ†åŒ¹é…\n",
    "\n",
    "### åŒ¹é…ç®—æ³•\n",
    "\n",
    "æœ€å¸¸ç”¨çš„åŒ¹é…æ–¹æ³•æ˜¯**æœ€è¿‘é‚»åŒ¹é… (Nearest Neighbor Matching)**ï¼š\n",
    "\n",
    "1. å¯¹äºæ¯ä¸ªå¤„ç†ç»„ä¸ªä½“ï¼Œæ‰¾åˆ°å€¾å‘å¾—åˆ†æœ€æ¥è¿‘çš„æ§åˆ¶ç»„ä¸ªä½“\n",
    "2. è¿™äº›é…å¯¹å°±æ˜¯ã€Œå¯æ¯”è¾ƒã€çš„\n",
    "3. ç”¨é…å¯¹åçš„æ•°æ®ä¼°è®¡ ATE\n",
    "\n",
    "### å¡å°ºåŒ¹é… (Caliper Matching)\n",
    "\n",
    "æœ‰æ—¶å€™æœ€è¿‘çš„é‚»å±…ä¹Ÿå¯èƒ½å¾ˆè¿œï¼Œè¿™æ—¶å€™å¯ä»¥è®¾ç½®ä¸€ä¸ªã€Œå¡å°ºã€é™åˆ¶æœ€å¤§è·ç¦»ï¼š\n",
    "\n",
    "$$|e(X_i) - e(X_j)| < \\text{caliper}$$\n",
    "\n",
    "è¶…è¿‡å¡å°ºçš„åŒ¹é…å°†è¢«ä¸¢å¼ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propensity_score_matching(\n",
    "    propensity: np.ndarray,\n",
    "    treatment: np.ndarray,\n",
    "    n_neighbors: int = 1,\n",
    "    caliper: Optional[float] = None\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    æ‰§è¡Œå€¾å‘å¾—åˆ†åŒ¹é…\n",
    "    \n",
    "    ä¸ºæ¯ä¸ªå¤„ç†ç»„ä¸ªä½“æ‰¾åˆ°å€¾å‘å¾—åˆ†æœ€æ¥è¿‘çš„æ§åˆ¶ç»„ä¸ªä½“\n",
    "    \n",
    "    Args:\n",
    "        propensity: å€¾å‘å¾—åˆ†\n",
    "        treatment: å¤„ç†çŠ¶æ€\n",
    "        n_neighbors: åŒ¹é…çš„é‚»å±…æ•°é‡\n",
    "        caliper: å¡å°ºå®½åº¦ï¼ˆæœ€å¤§å…è®¸çš„å€¾å‘å¾—åˆ†å·®å¼‚ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "        (matched_treated_indices, matched_control_indices)\n",
    "    \"\"\"\n",
    "    # è·å–å¤„ç†ç»„å’Œæ§åˆ¶ç»„çš„ç´¢å¼•\n",
    "    treated_idx = np.where(treatment == 1)[0]\n",
    "    control_idx = np.where(treatment == 0)[0]\n",
    "    \n",
    "    # TODO: ä½¿ç”¨ NearestNeighbors è¿›è¡ŒåŒ¹é…\n",
    "    # 1. ç”¨æ§åˆ¶ç»„çš„å€¾å‘å¾—åˆ†è®­ç»ƒ KNN\n",
    "    # 2. ä¸ºæ¯ä¸ªå¤„ç†ç»„ä¸ªä½“æ‰¾æœ€è¿‘çš„æ§åˆ¶ç»„ä¸ªä½“\n",
    "    \n",
    "    # ğŸ‘ˆ ä½ çš„ä»£ç \n",
    "    # knn = NearestNeighbors(n_neighbors=n_neighbors, metric='euclidean')\n",
    "    # knn.fit(propensity[control_idx].reshape(-1, 1))\n",
    "    # distances, indices = knn.kneighbors(propensity[treated_idx].reshape(-1, 1))\n",
    "    \n",
    "    knn = None\n",
    "    distances = None\n",
    "    indices = None\n",
    "    \n",
    "    if knn is None:\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    # åº”ç”¨å¡å°ºçº¦æŸ\n",
    "    matched_treated = []\n",
    "    matched_control = []\n",
    "    \n",
    "    for i, (dist, idx) in enumerate(zip(distances, indices)):\n",
    "        # TODO: å¦‚æœä½¿ç”¨å¡å°ºï¼Œæ£€æŸ¥è·ç¦»æ˜¯å¦åœ¨èŒƒå›´å†…\n",
    "        if caliper is None or dist[0] <= caliper:\n",
    "            matched_treated.append(treated_idx[i])\n",
    "            matched_control.append(control_idx[idx[0]])\n",
    "    \n",
    "    return np.array(matched_treated), np.array(matched_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_ate_psm(\n",
    "    Y: np.ndarray,\n",
    "    matched_treated_idx: np.ndarray,\n",
    "    matched_control_idx: np.ndarray\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ PSM ä¼°è®¡ ATE\n",
    "    \n",
    "    ATE = mean(Y_treated) - mean(Y_control)\n",
    "    \n",
    "    Returns:\n",
    "        (ATEä¼°è®¡, æ ‡å‡†è¯¯)\n",
    "    \"\"\"\n",
    "    if len(matched_treated_idx) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    # TODO: è®¡ç®—åŒ¹é…åçš„ ATE\n",
    "    y_treated = Y[matched_treated_idx]\n",
    "    y_control = Y[matched_control_idx]\n",
    "    \n",
    "    ate = None  # ğŸ‘ˆ ä½ çš„ä»£ç : y_treated.mean() - y_control.mean()\n",
    "    \n",
    "    # æ ‡å‡†è¯¯ï¼ˆç®€åŒ–ç‰ˆï¼‰\n",
    "    diff = y_treated - y_control\n",
    "    se = None  # ğŸ‘ˆ ä½ çš„ä»£ç : diff.std() / np.sqrt(len(diff))\n",
    "    \n",
    "    return ate, se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯• PSM\n",
    "if propensity is not None:\n",
    "    matched_t, matched_c = propensity_score_matching(propensity, T, caliper=None)\n",
    "    \n",
    "    if len(matched_t) > 0:\n",
    "        print(\"ğŸ”— PSM åŒ¹é…ç»“æœ:\")\n",
    "        print(f\"   åŒ¹é…å¯¹æ•°: {len(matched_t)}\")\n",
    "        print(f\"   åŒ¹é…ç‡: {len(matched_t) / T.sum() * 100:.1f}%\")\n",
    "        \n",
    "        # ä¼°è®¡ ATE\n",
    "        psm_ate, psm_se = estimate_ate_psm(Y, matched_t, matched_c)\n",
    "        \n",
    "        if psm_ate is not None:\n",
    "            print(f\"\\nğŸ“Š ATE ä¼°è®¡:\")\n",
    "            print(f\"   PSM ATE: {psm_ate:.4f} Â± {psm_se:.4f}\")\n",
    "            print(f\"   95% CI: [{psm_ate - 1.96*psm_se:.4f}, {psm_ate + 1.96*psm_se:.4f}]\")\n",
    "            print(f\"   åå·®: {psm_ate - 2.0:+.4f}\")\n",
    "            print(f\"\\n   å¯¹æ¯”æœ´ç´ ä¼°è®¡: {naive_ate:.4f} (åå·®: {naive_ate - 2.0:+.4f})\")\n",
    "            \n",
    "            if abs(psm_ate - 2.0) < abs(naive_ate - 2.0):\n",
    "                print(f\"\\n   âœ… PSM å‡å°‘äº† {abs(naive_ate - 2.0) - abs(psm_ate - 2.0):.2f} çš„åå·®ï¼\")\n",
    "        else:\n",
    "            print(\"âŒ è¯·å®Œæˆ estimate_ate_psm å‡½æ•°ï¼\")\n",
    "    else:\n",
    "        print(\"âŒ è¯·å®Œæˆ propensity_score_matching å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Part 3: è¯„ä¼°åŒ¹é…è´¨é‡\n",
    "\n",
    "åŒ¹é…ä¹‹åï¼Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥ï¼š**å¤„ç†ç»„å’Œæ§åˆ¶ç»„ç°åœ¨çœŸçš„ã€Œå¯æ¯”è¾ƒã€äº†å—ï¼Ÿ**\n",
    "\n",
    "### æ ‡å‡†åŒ–å‡å€¼å·® (Standardized Mean Difference, SMD)\n",
    "\n",
    "$$\\text{SMD} = \\frac{\\bar{X}_{\\text{treated}} - \\bar{X}_{\\text{control}}}{\\sqrt{(s^2_{\\text{treated}} + s^2_{\\text{control}})/2}}$$\n",
    "\n",
    "**ç»éªŒæ³•åˆ™**: |SMD| < 0.1 è¡¨ç¤ºè‰¯å¥½çš„å¹³è¡¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_smd(X_treated: np.ndarray, X_control: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    è®¡ç®—æ ‡å‡†åŒ–å‡å€¼å·® (SMD)\n",
    "    \n",
    "    SMD = (mean_treated - mean_control) / pooled_std\n",
    "    \"\"\"\n",
    "    # TODO: è®¡ç®—å‡å€¼å·®\n",
    "    mean_treated = X_treated.mean(axis=0)\n",
    "    mean_control = X_control.mean(axis=0)\n",
    "    mean_diff = None  # ğŸ‘ˆ ä½ çš„ä»£ç \n",
    "    \n",
    "    # TODO: è®¡ç®—åˆå¹¶æ ‡å‡†å·®\n",
    "    var_treated = X_treated.var(axis=0)\n",
    "    var_control = X_control.var(axis=0)\n",
    "    pooled_std = None  # ğŸ‘ˆ ä½ çš„ä»£ç : np.sqrt((var_treated + var_control) / 2)\n",
    "    \n",
    "    # TODO: è®¡ç®— SMD\n",
    "    smd = None  # ğŸ‘ˆ ä½ çš„ä»£ç : mean_diff / pooled_std\n",
    "    \n",
    "    return smd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_balance(\n",
    "    X: np.ndarray,\n",
    "    treatment: np.ndarray,\n",
    "    matched_treated_idx: Optional[np.ndarray] = None,\n",
    "    matched_control_idx: Optional[np.ndarray] = None,\n",
    "    feature_names: List[str] = None\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    è¯„ä¼°åŒ¹é…å‰åçš„åå˜é‡å¹³è¡¡\n",
    "    \"\"\"\n",
    "    if feature_names is None:\n",
    "        feature_names = [f'X{i+1}' for i in range(X.shape[1])]\n",
    "    \n",
    "    # åŒ¹é…å‰çš„ SMD\n",
    "    smd_before = compute_smd(X[treatment == 1], X[treatment == 0])\n",
    "    \n",
    "    # åŒ¹é…åçš„ SMD\n",
    "    if matched_treated_idx is not None and matched_control_idx is not None:\n",
    "        smd_after = compute_smd(X[matched_treated_idx], X[matched_control_idx])\n",
    "    else:\n",
    "        smd_after = None\n",
    "    \n",
    "    return smd_before, smd_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯„ä¼°åŒ¹é…è´¨é‡\n",
    "if len(matched_t) > 0:\n",
    "    smd_before, smd_after = evaluate_balance(X, T, matched_t, matched_c)\n",
    "    \n",
    "    if smd_before is not None and smd_after is not None:\n",
    "        feature_names = ['X1 (å¹´é¾„)', 'X2 (æ”¶å…¥)', 'X3 (é—ä¼ )']\n",
    "        \n",
    "        print(\"ğŸ“ åå˜é‡å¹³è¡¡æ£€æŸ¥:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"{'å˜é‡':<15} {'åŒ¹é…å‰ SMD':>12} {'åŒ¹é…å SMD':>12} {'æ”¹å–„':>8}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for i, name in enumerate(feature_names):\n",
    "            before = smd_before[i]\n",
    "            after = smd_after[i]\n",
    "            improvement = abs(before) - abs(after)\n",
    "            status = 'âœ…' if abs(after) < 0.1 else 'âš ï¸'\n",
    "            print(f\"{name:<15} {before:>12.4f} {after:>12.4f} {improvement:>+8.4f} {status}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "        print(f\"{'å¹³å‡ |SMD|':<15} {np.abs(smd_before).mean():>12.4f} {np.abs(smd_after).mean():>12.4f}\")\n",
    "        \n",
    "        # å¯è§†åŒ–\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        y_pos = np.arange(len(feature_names))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = ax.barh(y_pos - width/2, np.abs(smd_before), width, \n",
    "                       label='åŒ¹é…å‰', color='coral', alpha=0.7)\n",
    "        bars2 = ax.barh(y_pos + width/2, np.abs(smd_after), width, \n",
    "                       label='åŒ¹é…å', color='steelblue', alpha=0.7)\n",
    "        \n",
    "        ax.axvline(0.1, color='green', linestyle='--', linewidth=2, label='|SMD| = 0.1 é˜ˆå€¼')\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(feature_names)\n",
    "        ax.set_xlabel('|SMD|', fontsize=12)\n",
    "        ax.set_title('åŒ¹é…å‰åçš„åå˜é‡å¹³è¡¡', fontsize=14)\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.invert_yaxis()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"âŒ è¯·å®Œæˆ compute_smd å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ” Part 4: å…±åŒæ”¯æ’‘æ£€æŸ¥\n",
    "\n",
    "### ä»€ä¹ˆæ˜¯å…±åŒæ”¯æ’‘ (Common Support)ï¼Ÿ\n",
    "\n",
    "å…±åŒæ”¯æ’‘å‡è®¾è¦æ±‚ï¼šå¯¹äºä»»ä½•åå˜é‡å€¼ Xï¼Œéƒ½æœ‰ä¸€å®šæ¦‚ç‡æ¥å—æˆ–ä¸æ¥å—å¤„ç†ï¼š\n",
    "\n",
    "$$0 < P(T=1|X) < 1$$\n",
    "\n",
    "**ç›´è§‰ç†è§£**ï¼šå¦‚æœæŸäº›äºº 100% ä¼šæ¥å—å¤„ç†ï¼ˆæˆ– 100% ä¸ä¼šï¼‰ï¼Œé‚£æˆ‘ä»¬å°±æ‰¾ä¸åˆ°å¯¹ç…§ç»„æ¥æ¯”è¾ƒäº†ã€‚\n",
    "\n",
    "**ä¾‹å­**ï¼šå¦‚æœåªæœ‰å¹´æ”¶å…¥è¶…è¿‡ 100 ä¸‡çš„äººæ‰èƒ½ä¹°å¾—èµ·æŸç§å¥¢ä¾ˆä¿å¥å“ï¼Œé‚£æˆ‘ä»¬æ— æ³•ç”¨è¿™ä¸ªæ•°æ®æ¥æ¨æ–­ä¿å¥å“å¯¹æ™®é€šäººçš„æ•ˆæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_common_support(\n",
    "    propensity: np.ndarray,\n",
    "    treatment: np.ndarray\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    æ£€æŸ¥å…±åŒæ”¯æ’‘å‡è®¾\n",
    "    \"\"\"\n",
    "    prop_treated = propensity[treatment == 1]\n",
    "    prop_control = propensity[treatment == 0]\n",
    "    \n",
    "    # TODO: è®¡ç®—é‡å åŒºé—´\n",
    "    overlap_min = None  # ğŸ‘ˆ ä½ çš„ä»£ç : max(prop_treated.min(), prop_control.min())\n",
    "    overlap_max = None  # ğŸ‘ˆ ä½ çš„ä»£ç : min(prop_treated.max(), prop_control.max())\n",
    "    \n",
    "    # TODO: è®¡ç®—åœ¨é‡å åŒºé—´å¤–çš„æ ·æœ¬æ¯”ä¾‹\n",
    "    n_outside = 0\n",
    "    if overlap_min is not None and overlap_max is not None:\n",
    "        n_outside = ((propensity < overlap_min) | (propensity > overlap_max)).sum()\n",
    "    outside_pct = n_outside / len(propensity) if overlap_min is not None else 0\n",
    "    \n",
    "    return {\n",
    "        'treated_min': prop_treated.min(),\n",
    "        'treated_max': prop_treated.max(),\n",
    "        'control_min': prop_control.min(),\n",
    "        'control_max': prop_control.max(),\n",
    "        'overlap_min': overlap_min,\n",
    "        'overlap_max': overlap_max,\n",
    "        'outside_overlap_pct': outside_pct * 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥å…±åŒæ”¯æ’‘\n",
    "if propensity is not None:\n",
    "    support = check_common_support(propensity, T)\n",
    "    \n",
    "    if support['overlap_min'] is not None:\n",
    "        print(\"ğŸ” å…±åŒæ”¯æ’‘æ£€æŸ¥:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"å¤„ç†ç»„å€¾å‘å¾—åˆ†èŒƒå›´: [{support['treated_min']:.4f}, {support['treated_max']:.4f}]\")\n",
    "        print(f\"æ§åˆ¶ç»„å€¾å‘å¾—åˆ†èŒƒå›´: [{support['control_min']:.4f}, {support['control_max']:.4f}]\")\n",
    "        print(f\"é‡å åŒºé—´: [{support['overlap_min']:.4f}, {support['overlap_max']:.4f}]\")\n",
    "        print(f\"åŒºé—´å¤–æ ·æœ¬æ¯”ä¾‹: {support['outside_overlap_pct']:.2f}%\")\n",
    "        \n",
    "        if support['outside_overlap_pct'] < 5:\n",
    "            print(\"\\nâœ… å…±åŒæ”¯æ’‘è‰¯å¥½ï¼\")\n",
    "        else:\n",
    "            print(\"\\nâš ï¸ æœ‰è¾ƒå¤šæ ·æœ¬åœ¨å…±åŒæ”¯æ’‘åŒºé—´å¤–ï¼Œå¯èƒ½éœ€è¦ä¿®å‰ªæ ·æœ¬ã€‚\")\n",
    "    else:\n",
    "        print(\"âŒ è¯·å®Œæˆ check_common_support å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸšï¸ Part 5: å¡å°ºå®½åº¦çš„é€‰æ‹©\n",
    "\n",
    "å¡å°ºå®½åº¦æ˜¯ä¸€ä¸ªæƒè¡¡ï¼š\n",
    "\n",
    "| å¡å°ºå®½åº¦ | åŒ¹é…ç‡ | åŒ¹é…è´¨é‡ |\n",
    "|---------|--------|----------|\n",
    "| å¾ˆå° | ä½ï¼ˆå¾ˆå¤šåŒ¹é…ä¸ä¸Šï¼‰| é«˜ï¼ˆåŒ¹é…å¾ˆç²¾ç¡®ï¼‰|\n",
    "| å¾ˆå¤§/æ— é™ | é«˜ï¼ˆéƒ½èƒ½åŒ¹é…ä¸Šï¼‰| ä½ï¼ˆåŒ¹é…å¯èƒ½å¾ˆå·®ï¼‰|\n",
    "\n",
    "å¸¸ç”¨çš„å¡å°ºå®½åº¦æ˜¯å€¾å‘å¾—åˆ†æ ‡å‡†å·®çš„ 0.2 å€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_caliper_widths(\n",
    "    propensity: np.ndarray,\n",
    "    treatment: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    caliper_widths: List[float] = [0.01, 0.05, 0.1, 0.2, None]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    æ¯”è¾ƒä¸åŒå¡å°ºå®½åº¦çš„æ•ˆæœ\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for caliper in caliper_widths:\n",
    "        matched_t, matched_c = propensity_score_matching(propensity, treatment, caliper=caliper)\n",
    "        \n",
    "        if len(matched_t) == 0:\n",
    "            continue\n",
    "        \n",
    "        # è®¡ç®—åŒ¹é…ç‡\n",
    "        match_rate = len(matched_t) / treatment.sum()\n",
    "        \n",
    "        # è®¡ç®— ATE\n",
    "        ate, se = estimate_ate_psm(Y, matched_t, matched_c)\n",
    "        \n",
    "        results.append({\n",
    "            'caliper': caliper if caliper else 'æ— é™',\n",
    "            'matched_pairs': len(matched_t),\n",
    "            'match_rate': f\"{match_rate:.1%}\",\n",
    "            'ate': ate,\n",
    "            'se': se,\n",
    "            'bias': ate - 2.0 if ate else None\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¯”è¾ƒä¸åŒå¡å°º\n",
    "if propensity is not None:\n",
    "    caliper_results = compare_caliper_widths(propensity, T, Y)\n",
    "    \n",
    "    if not caliper_results.empty:\n",
    "        print(\"ğŸšï¸ ä¸åŒå¡å°ºå®½åº¦çš„æ¯”è¾ƒ:\")\n",
    "        print(\"=\" * 70)\n",
    "        display(caliper_results)\n",
    "        \n",
    "        print(\"\\nğŸ’¡ è§‚å¯Ÿ:\")\n",
    "        print(\"   - å¡å°ºè¶Šå°ï¼ŒåŒ¹é…è¶Šç²¾ç¡®ï¼Œä½†åŒ¹é…å¯¹æ•°è¶Šå°‘\")\n",
    "        print(\"   - å¡å°ºè¿‡å°å¯èƒ½å¯¼è‡´ä¼°è®¡ä¸ç¨³å®šï¼ˆæ ‡å‡†è¯¯å¢å¤§ï¼‰\")\n",
    "        print(\"   - æ¨èä½¿ç”¨ 0.2 Ã— std(propensity) ä½œä¸ºå¡å°º\")\n",
    "        print(f\"   - æœ¬æ•°æ®æ¨èå¡å°º: {0.2 * propensity.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Part 6: æ€è€ƒé¢˜\n",
    "\n",
    "### é—®é¢˜ 1: å€¾å‘å¾—åˆ†çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆåœ¨å€¾å‘å¾—åˆ†ä¸ŠåŒ¹é…å¯ä»¥å¹³è¡¡åå˜é‡ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 2: PSM ä¼°è®¡çš„æ˜¯ ATE è¿˜æ˜¯ ATTï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**æç¤º:** æƒ³æƒ³æˆ‘ä»¬æ˜¯ä¸ºè°æ‰¾åŒ¹é…å¯¹è±¡çš„...\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 3: ä»€ä¹ˆæ˜¯å…±åŒæ”¯æ’‘å‡è®¾ï¼Ÿä¸ºä»€ä¹ˆå®ƒå¾ˆé‡è¦ï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 4: å¦‚æœåŒ¹é…åæŸäº›åå˜é‡çš„ SMD ä»ç„¶å¾ˆå¤§ï¼Œåº”è¯¥æ€ä¹ˆåŠï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### é—®é¢˜ 5: PSM ç›¸æ¯”çº¿æ€§å›å½’è°ƒæ•´æœ‰ä»€ä¹ˆä¼˜ç¼ºç‚¹ï¼Ÿ\n\n**ä½ çš„ç­”æ¡ˆ:**\n\n*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n\n---\n\n## ğŸ¤ é«˜é¢‘é¢è¯•é¢˜æ¨¡æ‹Ÿ\n\n### é¢è¯•é¢˜ 1: ä»€ä¹ˆæ˜¯å€¾å‘å¾—åˆ†ï¼Ÿä¸ºä»€ä¹ˆå¯ä»¥ç”¨å®ƒæ§åˆ¶æ··æ·†ï¼Ÿ\n\n**å‚è€ƒå›ç­”**:\n\nå€¾å‘å¾—åˆ†æ˜¯ç»™å®šåå˜é‡ Xï¼Œä¸ªä½“æ¥å—å¤„ç†çš„æ¦‚ç‡ $e(X) = P(T=1|X)$ã€‚\n\nå®ƒå¯ä»¥æ§åˆ¶æ··æ·†çš„åŸå› æ˜¯ **Rosenbaum & Rubin (1983)** çš„å€¾å‘å¾—åˆ†å®šç†ï¼šå¦‚æœæ»¡è¶³æ— æ··æ·†å‡è®¾ $(Y(0), Y(1)) \\perp T | X$ï¼Œé‚£ä¹ˆ $(Y(0), Y(1)) \\perp T | e(X)$ã€‚\n\n**ç›´è§‚è§£é‡Š**: å€¾å‘å¾—åˆ†æ˜¯ X çš„ä¸€ä¸ª\"å¹³è¡¡åˆ†æ•°\"ï¼Œå®ƒæŠŠé«˜ç»´çš„åå˜é‡å‹ç¼©æˆä¸€ç»´ã€‚ä¸¤ä¸ªå€¾å‘å¾—åˆ†ç›¸åŒçš„ä¸ªä½“ï¼Œå³ä½¿ä»–ä»¬åœ¨å…·ä½“ç‰¹å¾ä¸Šä¸åŒï¼Œä½†åœ¨\"æ¥å—å¤„ç†çš„å€¾å‘\"ä¸Šæ˜¯ä¸€æ ·çš„ã€‚åœ¨å€¾å‘å¾—åˆ†ä¸ŠåŒ¹é…ï¼Œå°±ç›¸å½“äºåœ¨æ‰€æœ‰åå˜é‡ä¸Šè¾¾åˆ°äº†å¹³è¡¡ã€‚\n\n**å…³é”®ç‚¹**:\n- ç»´åº¦ç¼©å‡ï¼šæŠŠ p ç»´çš„ X å‹ç¼©æˆ 1 ç»´çš„ e(X)\n- å¹³è¡¡æ€§ï¼še(X) ç›¸åŒçš„ä¸ªä½“ï¼Œå¤„ç†ç»„å’Œæ§åˆ¶ç»„çš„åå˜é‡åˆ†å¸ƒç›¸åŒ\n- è¿™å°±åƒ\"æ‰¾åˆ°åŒæ ·å€¾å‘çš„äººåšå¯¹æ¯”\"\n\n---\n\n### é¢è¯•é¢˜ 2: PSM çš„å±€é™æ€§æ˜¯ä»€ä¹ˆï¼Ÿ\n\n**å‚è€ƒå›ç­”**:\n\nPSM ä¸»è¦æœ‰ä»¥ä¸‹å±€é™æ€§ï¼š\n\n1. **åªèƒ½æ§åˆ¶è§‚æµ‹åˆ°çš„æ··æ·†å˜é‡**: å¦‚æœå­˜åœ¨æœªè§‚æµ‹çš„æ··æ·†ï¼ŒPSM æ— èƒ½ä¸ºåŠ›ï¼ˆè¿™æ˜¯æ‰€æœ‰è§‚æµ‹ç ”ç©¶çš„é€šç—…ï¼‰\n\n2. **ä¾èµ–å€¾å‘å¾—åˆ†æ¨¡å‹çš„æ­£ç¡®æ€§**: å¦‚æœé€»è¾‘å›å½’æ¨¡å‹è¯¯è®¾å®šï¼ˆæ¯”å¦‚çœŸå®å…³ç³»æ˜¯éçº¿æ€§çš„ï¼‰ï¼Œå€¾å‘å¾—åˆ†ä¼°è®¡æœ‰å\n\n3. **ä¸¢å¼ƒæœªåŒ¹é…æ ·æœ¬**: \n   - åŒ¹é…ç‡å¯èƒ½å¾ˆä½ï¼ŒæŸå¤±æ ·æœ¬é‡\n   - ä¼°è®¡çš„æ˜¯ ATTï¼ˆå¤„ç†ç»„çš„æ•ˆåº”ï¼‰ï¼Œä¸æ˜¯ ATE\n\n4. **å…±åŒæ”¯æ’‘å‡è®¾**: å¦‚æœæŸäº›å¤„ç†ç»„ä¸ªä½“çš„å€¾å‘å¾—åˆ†åœ¨æ§åˆ¶ç»„ä¸­æ‰¾ä¸åˆ°å¯¹åº”çš„å€¼ï¼Œæ— æ³•åŒ¹é…\n\n5. **æ ‡å‡†è¯¯è®¡ç®—å¤æ‚**: éœ€è¦è€ƒè™‘å€¾å‘å¾—åˆ†ä¼°è®¡çš„ä¸ç¡®å®šæ€§ï¼ˆbootstrapï¼‰\n\n**æ”¹è¿›æ–¹æ³•**: IPWï¼ˆåˆ©ç”¨æ‰€æœ‰æ ·æœ¬ï¼‰ã€AIPWï¼ˆåŒé‡ç¨³å¥ï¼‰\n\n---\n\n### é¢è¯•é¢˜ 3: å¦‚ä½•è¯Šæ–­ PSM çš„åŒ¹é…è´¨é‡ï¼Ÿ\n\n**å‚è€ƒå›ç­”**:\n\nä¸»è¦æœ‰ä¸‰ä¸ªæ–¹é¢ï¼š\n\n**1. æ ‡å‡†åŒ–å‡å€¼å·® (SMD)**\n- å…¬å¼: $SMD = \\frac{\\bar{X}_{treated} - \\bar{X}_{control}}{\\sqrt{(s^2_{treated} + s^2_{control})/2}}$\n- é˜ˆå€¼: |SMD| < 0.1 è¡¨ç¤ºè‰¯å¥½å¹³è¡¡\n- éœ€è¦æ¯”è¾ƒåŒ¹é…å‰åçš„ SMD\n\n**2. å…±åŒæ”¯æ’‘æ£€æŸ¥**\n- å¯è§†åŒ–ï¼šå€¾å‘å¾—åˆ†çš„åˆ†å¸ƒå›¾\n- æ£€æŸ¥ï¼šå¤„ç†ç»„å’Œæ§åˆ¶ç»„çš„å€¾å‘å¾—åˆ†é‡å åŒºåŸŸ\n- è®¡ç®—ï¼šåœ¨é‡å åŒºåŸŸå¤–çš„æ ·æœ¬æ¯”ä¾‹\n\n**3. æ–¹å·®æ¯”**\n- æ£€æŸ¥åŒ¹é…åå¤„ç†ç»„å’Œæ§åˆ¶ç»„å„åå˜é‡çš„æ–¹å·®æ¯”\n- ç†æƒ³å€¼åº”æ¥è¿‘ 1\n\n**å®æ“å»ºè®®**:\n- åˆ¶ä½œ Love Plotï¼ˆSMD å¯¹æ¯”å›¾ï¼‰\n- ç»˜åˆ¶å€¾å‘å¾—åˆ†åˆ†å¸ƒå›¾\n- æŠ¥å‘ŠåŒ¹é…ç‡å’Œæ ·æœ¬é‡\n\n---\n\n### é¢è¯•é¢˜ 4: PSM ä¼°è®¡çš„æ˜¯ ATE è¿˜æ˜¯ ATTï¼Ÿèƒ½ä¼°è®¡ ATE å—ï¼Ÿ\n\n**å‚è€ƒå›ç­”**:\n\n**PSM é»˜è®¤ä¼°è®¡ ATTï¼ˆAverage Treatment Effect on the Treatedï¼‰**ã€‚\n\n**åŸå› **:\n- æˆ‘ä»¬æ˜¯ä¸ºå¤„ç†ç»„çš„æ¯ä¸ªä¸ªä½“æ‰¾æ§åˆ¶ç»„çš„åŒ¹é…\n- æœªè¢«åŒ¹é…çš„æ§åˆ¶ç»„æ ·æœ¬è¢«ä¸¢å¼ƒ\n- æœ€ç»ˆæ ·æœ¬ä»£è¡¨çš„æ˜¯\"æ¥å—å¤„ç†çš„é‚£ç¾¤äºº\"\n\n**ä¼°è®¡ ATE çš„æ–¹æ³•**:\n\n1. **åŒå‘åŒ¹é…**: \n   - ä¸ºå¤„ç†ç»„æ‰¾æ§åˆ¶ç»„åŒ¹é… â†’ ä¼°è®¡ ATT\n   - ä¸ºæ§åˆ¶ç»„æ‰¾å¤„ç†ç»„åŒ¹é… â†’ ä¼°è®¡ ATC\n   - åŠ æƒå¹³å‡: $ATE = P(T=1) \\cdot ATT + P(T=0) \\cdot ATC$\n\n2. **ä½¿ç”¨ IPW**: \n   - IPW å¤©ç„¶ä¼°è®¡ ATE\n   - æˆ–è€…ç”¨ AIPW ç»“åˆä¸¤ç§æ–¹æ³•çš„ä¼˜åŠ¿\n\n**é¢è¯•åŠ åˆ†ç‚¹**: \n- æåˆ° ATE â‰  ATT çš„åœºæ™¯ï¼ˆå¼‚è´¨æ€§æ•ˆåº”ï¼‰\n- çŸ¥é“ä»€ä¹ˆæ—¶å€™ç”¨å“ªä¸ªä¼°è®¡é‡\n\n---"
  },
  {
   "cell_type": "code",
   "source": "class MyPSMEstimator:\n    \"\"\"\n    ä»é›¶å®ç°çš„å€¾å‘å¾—åˆ†åŒ¹é…ä¼°è®¡å™¨\n    \n    åŠŸèƒ½:\n    - ä¼°è®¡å€¾å‘å¾—åˆ†\n    - æ‰§è¡Œæœ€è¿‘é‚»åŒ¹é…ï¼ˆå¸¦å¡å°ºï¼‰\n    - è®¡ç®— ATT å’Œæ ‡å‡†è¯¯\n    - è¯„ä¼°å¹³è¡¡æ€§ (SMD)\n    \"\"\"\n    \n    def __init__(self, caliper: Optional[float] = None, n_neighbors: int = 1):\n        self.caliper = caliper\n        self.n_neighbors = n_neighbors\n        self.propensity_ = None\n        self.matched_pairs_ = None\n        \n    def fit(self, X: np.ndarray, T: np.ndarray, Y: np.ndarray):\n        \"\"\"è®­ç»ƒå€¾å‘å¾—åˆ†æ¨¡å‹å¹¶æ‰§è¡ŒåŒ¹é…\"\"\"\n        # Step 1: ä¼°è®¡å€¾å‘å¾—åˆ†\n        self.propensity_model_ = LogisticRegression(max_iter=1000)\n        self.propensity_model_.fit(X, T)\n        self.propensity_ = self.propensity_model_.predict_proba(X)[:, 1]\n        \n        # Step 2: æ‰§è¡ŒåŒ¹é…\n        self._match(X, T, Y)\n        \n        return self\n    \n    def _match(self, X, T, Y):\n        \"\"\"æ‰§è¡Œ 1:1 æœ€è¿‘é‚»åŒ¹é…\"\"\"\n        treated_idx = np.where(T == 1)[0]\n        control_idx = np.where(T == 0)[0]\n        \n        # ä½¿ç”¨ KNN æ‰¾æœ€è¿‘é‚»\n        knn = NearestNeighbors(n_neighbors=self.n_neighbors, metric='euclidean')\n        knn.fit(self.propensity_[control_idx].reshape(-1, 1))\n        distances, indices = knn.kneighbors(self.propensity_[treated_idx].reshape(-1, 1))\n        \n        # åº”ç”¨å¡å°ºçº¦æŸ\n        matched_treated = []\n        matched_control = []\n        \n        for i, (dist, idx) in enumerate(zip(distances, indices)):\n            if self.caliper is None or dist[0] <= self.caliper:\n                matched_treated.append(treated_idx[i])\n                matched_control.append(control_idx[idx[0]])\n        \n        self.matched_pairs_ = (np.array(matched_treated), np.array(matched_control))\n        self.X_ = X\n        self.T_ = T\n        self.Y_ = Y\n    \n    def estimate_att(self) -> Tuple[float, float]:\n        \"\"\"ä¼°è®¡ ATT å’Œæ ‡å‡†è¯¯\"\"\"\n        if self.matched_pairs_ is None:\n            raise ValueError(\"Must fit before estimating ATT\")\n        \n        treated_idx, control_idx = self.matched_pairs_\n        \n        if len(treated_idx) == 0:\n            return None, None\n        \n        # ATT = E[Y(1) - Y(0) | T=1]\n        y_treated = self.Y_[treated_idx]\n        y_control = self.Y_[control_idx]\n        \n        att = (y_treated - y_control).mean()\n        se = (y_treated - y_control).std() / np.sqrt(len(treated_idx))\n        \n        return att, se\n    \n    def evaluate_balance(self, feature_names: List[str] = None) -> pd.DataFrame:\n        \"\"\"è¯„ä¼°åŒ¹é…å‰åçš„åå˜é‡å¹³è¡¡\"\"\"\n        if self.matched_pairs_ is None:\n            raise ValueError(\"Must fit before evaluating balance\")\n        \n        treated_idx, control_idx = self.matched_pairs_\n        \n        # åŒ¹é…å‰çš„ SMD\n        smd_before = self._compute_smd(\n            self.X_[self.T_ == 1],\n            self.X_[self.T_ == 0]\n        )\n        \n        # åŒ¹é…åçš„ SMD\n        smd_after = self._compute_smd(\n            self.X_[treated_idx],\n            self.X_[control_idx]\n        )\n        \n        if feature_names is None:\n            feature_names = [f'X{i+1}' for i in range(self.X_.shape[1])]\n        \n        return pd.DataFrame({\n            'Feature': feature_names,\n            'SMD_before': smd_before,\n            'SMD_after': smd_after,\n            'Improvement': np.abs(smd_before) - np.abs(smd_after),\n            'Balanced': np.abs(smd_after) < 0.1\n        })\n    \n    @staticmethod\n    def _compute_smd(X_treated, X_control):\n        \"\"\"è®¡ç®—æ ‡å‡†åŒ–å‡å€¼å·®\"\"\"\n        mean_t = X_treated.mean(axis=0)\n        mean_c = X_control.mean(axis=0)\n        var_t = X_treated.var(axis=0)\n        var_c = X_control.var(axis=0)\n        pooled_std = np.sqrt((var_t + var_c) / 2)\n        return (mean_t - mean_c) / pooled_std\n    \n    def summary(self):\n        \"\"\"æ‰“å°åŒ¹é…ç»“æœæ‘˜è¦\"\"\"\n        if self.matched_pairs_ is None:\n            print(\"âŒ å°šæœªæ‹Ÿåˆ\")\n            return\n        \n        att, se = self.estimate_att()\n        n_treated = (self.T_ == 1).sum()\n        n_matched = len(self.matched_pairs_[0])\n        match_rate = n_matched / n_treated\n        \n        print(\"=\" * 60)\n        print(\"PSM ä¼°è®¡ç»“æœ\")\n        print(\"=\" * 60)\n        print(f\"æ€»å¤„ç†ç»„æ ·æœ¬: {n_treated}\")\n        print(f\"æˆåŠŸåŒ¹é…å¯¹æ•°: {n_matched}\")\n        print(f\"åŒ¹é…ç‡: {match_rate:.1%}\")\n        print(f\"\\nATT ä¼°è®¡: {att:.4f} Â± {se:.4f}\")\n        print(f\"95% CI: [{att - 1.96*se:.4f}, {att + 1.96*se:.4f}]\")\n        print(\"=\" * 60)\n\n\n# æµ‹è¯•æˆ‘ä»¬çš„å®ç°\nprint(\"ğŸ§ª æµ‹è¯•è‡ªå·±å®ç°çš„ PSM ä¼°è®¡å™¨\")\nprint()\n\n# ç”Ÿæˆæ•°æ®\nnp.random.seed(42)\nn = 1000\nX_test = np.random.randn(n, 3)\npropensity_logit = 1.5 * (X_test[:, 0] + 0.5 * X_test[:, 1])\npropensity_true = 1 / (1 + np.exp(-propensity_logit))\nT_test = np.random.binomial(1, propensity_true)\nY_test = 2.0 * T_test + 1.5 * X_test[:, 0] + X_test[:, 1] + np.random.randn(n) * 0.5\n\n# ä½¿ç”¨æˆ‘ä»¬çš„ä¼°è®¡å™¨\nmy_psm = MyPSMEstimator(caliper=0.1)\nmy_psm.fit(X_test, T_test, Y_test)\nmy_psm.summary()\n\n# æŸ¥çœ‹å¹³è¡¡æ€§\nprint(\"\\nğŸ“Š åå˜é‡å¹³è¡¡æ£€æŸ¥:\")\nbalance_df = my_psm.evaluate_balance(['X1', 'X2', 'X3'])\ndisplay(balance_df)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## ğŸ’» ä»é›¶å®ç° PSM\n\nè®©æˆ‘ä»¬å®ç°ä¸€ä¸ªå®Œæ•´çš„ PSM ä¼°è®¡å™¨ç±»ï¼Œä¸ä¾èµ–ä»»ä½•å› æœæ¨æ–­åº“ï¼",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ‰ æ€»ç»“\n",
    "\n",
    "### æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "| æ¦‚å¿µ | å®šä¹‰ | ä½œç”¨ |\n",
    "|-----|------|------|\n",
    "| å€¾å‘å¾—åˆ† | $e(X) = P(T=1|X)$ | æŠŠé«˜ç»´ X å‹ç¼©æˆä¸€ç»´ |\n",
    "| PSM | åœ¨ e(X) ä¸Šå¯»æ‰¾æœ€è¿‘é‚» | åˆ›å»ºå¯æ¯”è¾ƒçš„é…å¯¹ |\n",
    "| SMD | æ ‡å‡†åŒ–å‡å€¼å·® | è¯„ä¼°åå˜é‡å¹³è¡¡ |\n",
    "| å…±åŒæ”¯æ’‘ | $0 < e(X) < 1$ | ç¡®ä¿å¯æ¯”è¾ƒæ€§ |\n",
    "\n",
    "### PSM çš„æ­¥éª¤\n",
    "\n",
    "1. **ä¼°è®¡å€¾å‘å¾—åˆ†**: ç”¨é€»è¾‘å›å½’æ‹Ÿåˆ $T \\sim X$\n",
    "2. **æ£€æŸ¥å…±åŒæ”¯æ’‘**: ç¡®ä¿ä¸¤ç»„çš„å€¾å‘å¾—åˆ†æœ‰é‡å \n",
    "3. **æ‰§è¡ŒåŒ¹é…**: ä¸ºæ¯ä¸ªå¤„ç†ä¸ªä½“æ‰¾æœ€ç›¸ä¼¼çš„æ§åˆ¶ä¸ªä½“\n",
    "4. **è¯„ä¼°å¹³è¡¡**: æ£€æŸ¥åŒ¹é…åçš„ SMD\n",
    "5. **ä¼°è®¡æ•ˆåº”**: ç”¨åŒ¹é…æ ·æœ¬è®¡ç®— ATE\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "PSM æœ‰ä¸€ä¸ªé—®é¢˜ï¼šå®ƒä¸¢å¼ƒäº†å¾ˆå¤šæ ·æœ¬ï¼ˆæœªè¢«åŒ¹é…çš„æ§åˆ¶ç»„ï¼‰ã€‚ä¸‹ä¸€ä¸ªç»ƒä¹ æˆ‘ä»¬å°†å­¦ä¹ **é€†æ¦‚ç‡åŠ æƒ (IPW)**â€”â€”ä¸€ç§åˆ©ç”¨æ‰€æœ‰æ ·æœ¬çš„æ–¹æ³•ï¼\n",
    "\n",
    "---\n",
    "\n",
    "**ã€Œæ‰¾åˆ°å¯¹çš„äººæ¯”è¾ƒï¼Œæ‰èƒ½å¾—å‡ºå¯¹çš„ç»“è®ºã€‚ã€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}