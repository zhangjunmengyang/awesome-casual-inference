#!/usr/bin/env python3
"""
åˆ›å»º Part 7.4: ä¸­ä»‹åˆ†æ Notebook
"""
import json

notebook = {
    "cells": [],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

def add_markdown(text):
    notebook["cells"].append({
        "cell_type": "markdown",
        "metadata": {},
        "source": text.split('\n')
    })

def add_code(code):
    notebook["cells"].append({
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": code.split('\n')
    })

# ========== Header ==========
add_markdown("""# Part 7.4: ä¸­ä»‹åˆ†æ (Mediation Analysis)

## å­¦ä¹ ç›®æ ‡

1. ç†è§£ä¸­ä»‹æ•ˆåº”çš„å®šä¹‰å’Œæ„ä¹‰
2. æŒæ¡ç›´æ¥æ•ˆåº”å’Œé—´æ¥æ•ˆåº”çš„åˆ†è§£
3. å­¦ä¹ å› æœä¸­ä»‹åˆ†ææ¡†æ¶
4. å®ç°ä»é›¶ä¸­ä»‹åˆ†æç®—æ³•
5. åº”ç”¨äºçœŸå®ä¸šåŠ¡åœºæ™¯

---

## ä¸šåŠ¡åœºæ™¯ï¼šä¼˜æƒ åˆ¸å¦‚ä½•æå‡è½¬åŒ–ï¼Ÿ

æƒ³è±¡ä½ æ˜¯æŸç”µå•†å¹³å°çš„æ•°æ®ç§‘å­¦å®¶ã€‚A/Bæµ‹è¯•æ˜¾ç¤ºï¼Œå‘é€ä¼˜æƒ åˆ¸å¯ä»¥æå‡15%çš„è´­ä¹°è½¬åŒ–ç‡ã€‚

**è€æ¿çš„è¿½é—®**ï¼š
- ä¼˜æƒ åˆ¸æ˜¯æ€ä¹ˆèµ·æ•ˆçš„ï¼Ÿ
- æ˜¯å› ä¸ºå¢åŠ äº†ç”¨æˆ·è®¿é—®æ¬¡æ•°ï¼Ÿ
- è¿˜æ˜¯æé«˜äº†å•æ¬¡è®¿é—®çš„è´­ä¹°æ„æ„¿ï¼Ÿ
- å¦‚æœä¸å‘åˆ¸ï¼Œèƒ½å¦é€šè¿‡å…¶ä»–æ–¹å¼ï¼ˆå¦‚æ¨é€ï¼‰è¾¾åˆ°åŒæ ·æ•ˆæœï¼Ÿ

**æ ¸å¿ƒé—®é¢˜**ï¼šä¸ä»…è¦çŸ¥é“ \"æœ‰æ²¡æœ‰æ•ˆ\"ï¼Œè¿˜è¦çŸ¥é“ \"æ€ä¹ˆèµ·æ•ˆ\"ï¼

è¿™å°±æ˜¯ **ä¸­ä»‹åˆ†æ (Mediation Analysis)** è¦è§£å†³çš„é—®é¢˜ã€‚

---""")

# ========== Setup ==========
add_code("""# ç¯å¢ƒå‡†å¤‡
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

np.random.seed(42)

# é¢œè‰²é…ç½®
COLORS = {
    'primary': '#2D9CDB',
    'success': '#27AE60',
    'danger': '#EB5757',
    'warning': '#F2994A',
    'info': '#9B51E0'
}

print("âœ… ç¯å¢ƒå‡†å¤‡å®Œæˆï¼")""")

# ========== Concepts ==========
add_markdown("""## Part 1: æ ¸å¿ƒæ¦‚å¿µ

### å› æœå›¾

ä¸­ä»‹åˆ†æçš„å…¸å‹å› æœç»“æ„ï¼š

```
      T (å¤„ç†: ä¼˜æƒ åˆ¸)
     / \\
    /   \\
   v     v
  M      Y
(ä¸­ä»‹)  (ç»“æœ)
   \\    /
    \\  /
     v
     Y
```

- **T**: å¤„ç†å˜é‡ (Treatment) - æ˜¯å¦å‘åˆ¸
- **M**: ä¸­ä»‹å˜é‡ (Mediator) - è®¿é—®æ¬¡æ•°
- **Y**: ç»“æœå˜é‡ (Outcome) - æ˜¯å¦è´­ä¹°
- **ç›´æ¥è·¯å¾„**: T â†’ Y (ä¸ç»è¿‡M)
- **é—´æ¥è·¯å¾„**: T â†’ M â†’ Y (ç»è¿‡M)

### æ•ˆåº”åˆ†è§£

**æ€»æ•ˆåº” (Total Effect, TE)**ï¼š
$$TE = E[Y(T=1) - Y(T=0)]$$

**ç›´æ¥æ•ˆåº” (Direct Effect, DE)**ï¼š
å¤„ç†å¯¹ç»“æœçš„ç›´æ¥å½±å“ï¼Œä¸ç»è¿‡ä¸­ä»‹
$$NDE = E[Y(T=1, M(T=0)) - Y(T=0, M(T=0))]$$

**é—´æ¥æ•ˆåº” (Indirect Effect, IE)**ï¼š
å¤„ç†é€šè¿‡ä¸­ä»‹å¯¹ç»“æœçš„å½±å“
$$NIE = E[Y(T=0, M(T=1)) - Y(T=0, M(T=0))]$$

**åˆ†è§£å…³ç³»**ï¼š
$$TE = NDE + NIE$$

### è¯†åˆ«å‡è®¾

1. **é¡ºåºå¿½ç•¥æ€§**ï¼š
   - $Y(t,m) \\perp T | X$
   - $M(t) \\perp T | X$
   - $Y(t,m) \\perp M | T, X$

2. **æ— æ··æ·†**ï¼šæ²¡æœ‰æœªè§‚æµ‹çš„æ··æ·†å› å­

---""")

# ========== Data Generation ==========
add_markdown("""## Part 2: æ•°æ®ç”Ÿæˆ""")

add_code("""def generate_mediation_data(n=2000, seed=42):
    \"\"\"
    ç”Ÿæˆä¸­ä»‹åˆ†ææ•°æ®

    åœºæ™¯ï¼šä¼˜æƒ åˆ¸(T) â†’ è®¿é—®æ¬¡æ•°(M) â†’ è´­ä¹°(Y)
    \"\"\"
    np.random.seed(seed)

    # åå˜é‡
    X1 = np.random.normal(0, 1, n)  # ç”¨æˆ·æ´»è·ƒåº¦
    X2 = np.random.normal(0, 1, n)  # ä»·æ ¼æ•æ„Ÿåº¦
    X = np.column_stack([X1, X2])

    # å¤„ç†åˆ†é…ï¼ˆæœ‰æ··æ·†ï¼‰
    propensity = 1 / (1 + np.exp(-(0.5 + 0.3*X1 + 0.2*X2)))
    T = np.random.binomial(1, propensity)

    # ä¸­ä»‹å˜é‡ï¼šè®¿é—®æ¬¡æ•°
    # M = f(T, X) + noise
    M = (
        2 +                    # åŸºçº¿
        0.5 * T +             # å‘åˆ¸å¢åŠ è®¿é—®
        0.3 * X1 +            # æ´»è·ƒåº¦å½±å“
        np.random.normal(0, 0.5, n)
    )
    M = np.maximum(0, M)

    # ç»“æœå˜é‡ï¼šè´­ä¹°æ¦‚ç‡
    # Y = f(T, M, X)
    logit_y = (
        -2 +                   # åŸºçº¿
        0.3 * T +             # åˆ¸çš„ç›´æ¥æ•ˆåº”
        0.5 * M +             # è®¿é—®æ¬¡æ•°æ•ˆåº”
        0.2 * X2 +            # ä»·æ ¼æ•æ„Ÿåº¦
        np.random.normal(0, 0.3, n)
    )
    prob_y = 1 / (1 + np.exp(-logit_y))
    Y = np.random.binomial(1, prob_y)

    # çœŸå®æ•ˆåº”ï¼ˆåŸºäºDGPï¼‰
    # é—´æ¥æ•ˆåº”: T â†’ M â†’ Y = 0.5 * 0.5 = 0.25 (logit scale)
    # ç›´æ¥æ•ˆåº”: T â†’ Y = 0.3
    # æ€»æ•ˆåº”: 0.3 + 0.25 = 0.55

    return {
        'X': X,
        'T': T,
        'M': M,
        'Y': Y,
        'true_effects': {
            'direct': 0.3,
            'indirect': 0.25,
            'total': 0.55
        }
    }

# ç”Ÿæˆæ•°æ®
data = generate_mediation_data()
X, T, M, Y = data['X'], data['T'], data['M'], data['Y']

print(f"æ•°æ®ç»´åº¦: n={len(T)}")
print(f"å¤„ç†ç»„æ¯”ä¾‹: {T.mean():.2%}")
print(f"å¹³å‡è®¿é—®æ¬¡æ•°: {M.mean():.2f}")
print(f"è´­ä¹°ç‡: {Y.mean():.2%}")
print(f"\\nçœŸå®æ•ˆåº”:")
for k, v in data['true_effects'].items():
    print(f"  {k}: {v:.3f}")""")

# ========== Visualization ==========
add_markdown("""## Part 3: æ¢ç´¢æ€§åˆ†æ""")

add_code("""# å¯è§†åŒ–å› æœè·¯å¾„
fig = make_subplots(
    rows=1, cols=3,
    subplot_titles=('Tå¯¹Mçš„å½±å“', 'Må¯¹Yçš„å½±å“', 'Tå¯¹Yçš„æ€»æ•ˆåº”')
)

# T â†’ M
m_t1 = M[T==1]
m_t0 = M[T==0]

fig.add_trace(go.Box(y=m_t1, name='å‘åˆ¸', marker_color=COLORS['success']), row=1, col=1)
fig.add_trace(go.Box(y=m_t0, name='ä¸å‘åˆ¸', marker_color=COLORS['danger']), row=1, col=1)

# M â†’ Y (åˆ†å±‚)
m_bins = pd.qcut(M, q=5, duplicates='drop')
y_by_m = pd.DataFrame({'M_bin': m_bins, 'Y': Y}).groupby('M_bin')['Y'].mean()

fig.add_trace(go.Bar(
    x=[str(b) for b in y_by_m.index],
    y=y_by_m.values,
    marker_color=COLORS['primary'],
    showlegend=False
), row=1, col=2)

# T â†’ Y
y_rate_t1 = Y[T==1].mean()
y_rate_t0 = Y[T==0].mean()

fig.add_trace(go.Bar(
    x=['å‘åˆ¸', 'ä¸å‘åˆ¸'],
    y=[y_rate_t1, y_rate_t0],
    marker_color=[COLORS['success'], COLORS['danger']],
    text=[f'{y_rate_t1:.1%}', f'{y_rate_t0:.1%}'],
    textposition='outside',
    showlegend=False
), row=1, col=3)

fig.update_layout(height=400, template='plotly_white', showlegend=False)
fig.show()

print(f"\\nğŸ“Š è§‚å¯Ÿ:")
print(f"1. å‘åˆ¸ç»„è®¿é—®æ¬¡æ•°æ›´å¤š: {m_t1.mean():.2f} vs {m_t0.mean():.2f}")
print(f"2. è®¿é—®è¶Šå¤šï¼Œè´­ä¹°ç‡è¶Šé«˜")
print(f"3. å‘åˆ¸ç»„è´­ä¹°ç‡æ›´é«˜: {y_rate_t1:.1%} vs {y_rate_t0:.1%}")
print(f"\\nâ“ é—®é¢˜: å‘åˆ¸çš„æ•ˆåº”ä¸­ï¼Œæœ‰å¤šå°‘æ˜¯é€šè¿‡å¢åŠ è®¿é—®æ¬¡æ•°å®ç°çš„ï¼Ÿ")""")

# ========== Baron-Kenny Method ==========
add_markdown("""## Part 4: Baron-Kenny æ–¹æ³•ï¼ˆä¼ ç»Ÿæ–¹æ³•ï¼‰

### æ–¹æ³•æ­¥éª¤

**Step 1**: å›å½’ Y ~ T (æ€»æ•ˆåº”)
$$Y = \\alpha_1 + \\tau \\cdot T + \\epsilon_1$$

**Step 2**: å›å½’ M ~ T (Tå¯¹Mçš„æ•ˆåº”)
$$M = \\alpha_2 + a \\cdot T + \\epsilon_2$$

**Step 3**: å›å½’ Y ~ T + M (ç›´æ¥æ•ˆåº”å’ŒMçš„æ•ˆåº”)
$$Y = \\alpha_3 + \\tau' \\cdot T + b \\cdot M + \\epsilon_3$$

**æ•ˆåº”åˆ†è§£**ï¼š
- é—´æ¥æ•ˆåº”: $IE = a \\times b$
- ç›´æ¥æ•ˆåº”: $DE = \\tau'$
- æ€»æ•ˆåº”: $TE = \\tau = \\tau' + a \\times b$

### å±€é™æ€§
- å‡è®¾çº¿æ€§å…³ç³»
- å‡è®¾æ— äº¤äº’ä½œç”¨
- å‡è®¾æ— æ··æ·†""")

add_code("""class BaronKennyMediation:
    \"\"\"Baron-Kenny ä¸­ä»‹åˆ†æ\"\"\"

    def __init__(self):
        self.model_total = None
        self.model_mediator = None
        self.model_direct = None

    def fit(self, T, M, Y, X=None):
        \"\"\"æ‹Ÿåˆä¸‰ä¸ªå›å½’æ¨¡å‹\"\"\"
        # å‡†å¤‡ç‰¹å¾
        if X is not None:
            T_X = np.column_stack([T, X])
            T_M_X = np.column_stack([T, M, X])
        else:
            T_X = T.reshape(-1, 1)
            T_M_X = np.column_stack([T, M])

        # Step 1: Y ~ T (+ X)
        self.model_total = LinearRegression()
        self.model_total.fit(T_X, Y)

        # Step 2: M ~ T (+ X)
        self.model_mediator = LinearRegression()
        self.model_mediator.fit(T_X, M)

        # Step 3: Y ~ T + M (+ X)
        self.model_direct = LinearRegression()
        self.model_direct.fit(T_M_X, Y)

        return self

    def get_effects(self):
        \"\"\"è®¡ç®—æ•ˆåº”\"\"\"
        # ç³»æ•°
        tau = self.model_total.coef_[0]  # æ€»æ•ˆåº”
        a = self.model_mediator.coef_[0]  # T â†’ M
        tau_prime = self.model_direct.coef_[0]  # ç›´æ¥æ•ˆåº”
        b = self.model_direct.coef_[1]  # M â†’ Y

        # é—´æ¥æ•ˆåº”
        indirect = a * b

        return {
            'total': tau,
            'direct': tau_prime,
            'indirect': indirect,
            'proportion_mediated': indirect / tau if tau != 0 else 0
        }

# åº”ç”¨ Baron-Kenny
bk = BaronKennyMediation()
bk.fit(T, M, Y, X)
bk_effects = bk.get_effects()

print("Baron-Kenny ä¸­ä»‹åˆ†æç»“æœ")
print("="*60)
for key, val in bk_effects.items():
    if key == 'proportion_mediated':
        print(f"{key}: {val:.1%}")
    else:
        print(f"{key}: {val:.4f}")

print(f"\\nä¸çœŸå®å€¼å¯¹æ¯”:")
print(f"  ç›´æ¥æ•ˆåº”: {bk_effects['direct']:.3f} vs {data['true_effects']['direct']:.3f}")
print(f"  é—´æ¥æ•ˆåº”: {bk_effects['indirect']:.3f} vs {data['true_effects']['indirect']:.3f}")""")

# ========== Mathematical Derivation ==========
add_markdown("""## Part 5: æ•°å­¦æ¨å¯¼

### ç›´æ¥æ•ˆåº”å’Œé—´æ¥æ•ˆåº”çš„å®šä¹‰

#### è‡ªç„¶ç›´æ¥æ•ˆåº” (Natural Direct Effect, NDE)

**å®šä¹‰**ï¼šå›ºå®šä¸­ä»‹å˜é‡åœ¨æ§åˆ¶ç»„çš„æ°´å¹³ï¼Œå¤„ç†å¯¹ç»“æœçš„æ•ˆåº”

$$NDE = E[Y(T=1, M(T=0)) - Y(T=0, M(T=0))]$$

**ç›´è§‰**ï¼šå¦‚æœç»™å¤„ç†ç»„ï¼Œä½†ä¿æŒä¸­ä»‹åœ¨æ§åˆ¶ç»„æ°´å¹³ï¼Œç»“æœä¼šå¦‚ä½•å˜åŒ–ï¼Ÿ

#### è‡ªç„¶é—´æ¥æ•ˆåº” (Natural Indirect Effect, NIE)

**å®šä¹‰**ï¼šå›ºå®šå¤„ç†åœ¨æ§åˆ¶ç»„ï¼Œä¸­ä»‹å˜åŒ–å¯¹ç»“æœçš„æ•ˆåº”

$$NIE = E[Y(T=0, M(T=1)) - Y(T=0, M(T=0))]$$

**ç›´è§‰**ï¼šå¦‚æœä¸ç»™å¤„ç†ï¼Œä½†ä¸­ä»‹å˜æˆå¤„ç†ç»„æ°´å¹³ï¼Œç»“æœä¼šå¦‚ä½•å˜åŒ–ï¼Ÿ

### è¯†åˆ«å…¬å¼ï¼ˆPearlæ¨å¯¼ï¼‰

åœ¨é¡ºåºå¿½ç•¥æ€§å‡è®¾ä¸‹ï¼š

**NDE**:
$$NDE = \\sum_m E[Y|T=1, M=m] \\cdot P(M=m|T=0) - E[Y|T=0]$$

**NIE**:
$$NIE = \\sum_m E[Y|T=0, M=m] \\cdot [P(M=m|T=1) - P(M=m|T=0)]$$

### çº¿æ€§æƒ…å†µä¸‹çš„ç®€åŒ–

å¦‚æœï¼š
- $M = \\alpha_M + a \\cdot T + \\epsilon_M$
- $Y = \\alpha_Y + \\tau' \\cdot T + b \\cdot M + \\epsilon_Y$

åˆ™ï¼š
- $DE = \\tau'$
- $IE = a \\times b$
- $TE = \\tau' + a \\times b$

---""")

# ========== Causal Mediation Analysis ==========
add_markdown("""## Part 6: å› æœä¸­ä»‹åˆ†æï¼ˆä»é›¶å®ç°ï¼‰

å®ç°å®Œæ•´çš„å› æœä¸­ä»‹æ¡†æ¶ï¼Œå¤„ç†éçº¿æ€§å…³ç³»å’Œäº¤äº’æ•ˆåº”ã€‚""")

add_code("""class CausalMediationAnalysis:
    \"\"\"
    å› æœä¸­ä»‹åˆ†æ

    å®ç° Imai, Keele, Tingley (2010) çš„æ¡†æ¶
    \"\"\"

    def __init__(self, mediator_model=None, outcome_model=None):
        self.mediator_model = mediator_model or LinearRegression()
        self.outcome_model = outcome_model or LinearRegression()

    def fit(self, T, M, Y, X=None):
        \"\"\"
        æ‹Ÿåˆä¸­ä»‹æ¨¡å‹å’Œç»“æœæ¨¡å‹

        M ~ T + X
        Y ~ T + M + T*M + X
        \"\"\"
        n = len(T)

        # å‡†å¤‡ç‰¹å¾
        if X is not None:
            X_with_T = np.column_stack([T, X])
            X_with_T_M = np.column_stack([T, M, T*M, X])  # åŒ…å«äº¤äº’é¡¹
        else:
            X_with_T = T.reshape(-1, 1)
            X_with_T_M = np.column_stack([T, M, T*M])

        # æ‹Ÿåˆ M ~ T + X
        self.mediator_model.fit(X_with_T, M)

        # æ‹Ÿåˆ Y ~ T + M + T*M + X
        self.outcome_model.fit(X_with_T_M, Y)

        self.T = T
        self.M = M
        self.Y = Y
        self.X = X

        return self

    def predict_mediator(self, T, X=None):
        \"\"\"é¢„æµ‹ä¸­ä»‹å˜é‡\"\"\"
        if X is not None:
            X_pred = np.column_stack([T, X])
        else:
            X_pred = T.reshape(-1, 1)
        return self.mediator_model.predict(X_pred)

    def predict_outcome(self, T, M, X=None):
        \"\"\"é¢„æµ‹ç»“æœå˜é‡\"\"\"
        if X is not None:
            X_pred = np.column_stack([T, M, T*M, X])
        else:
            X_pred = np.column_stack([T, M, T*M])
        return self.outcome_model.predict(X_pred)

    def estimate_effects(self, n_samples=None):
        \"\"\"
        ä¼°è®¡å› æœä¸­ä»‹æ•ˆåº”

        ä½¿ç”¨æ¨¡æ‹Ÿæ–¹æ³•ï¼ˆå‚æ•°åŒ–g-formulaï¼‰
        \"\"\"
        if n_samples is None:
            n_samples = len(self.T)

        # ä½¿ç”¨è§‚æµ‹æ•°æ®çš„åå˜é‡
        if self.X is not None:
            X_sim = self.X
        else:
            X_sim = None

        n = len(X_sim) if X_sim is not None else n_samples

        # Y(1, M(1))
        T1 = np.ones(n)
        M1 = self.predict_mediator(T1, X_sim)
        Y_1_M1 = self.predict_outcome(T1, M1, X_sim)

        # Y(0, M(0))
        T0 = np.zeros(n)
        M0 = self.predict_mediator(T0, X_sim)
        Y_0_M0 = self.predict_outcome(T0, M0, X_sim)

        # Y(1, M(0)) - NDE
        Y_1_M0 = self.predict_outcome(T1, M0, X_sim)

        # Y(0, M(1)) - NIE
        Y_0_M1 = self.predict_outcome(T0, M1, X_sim)

        # è®¡ç®—æ•ˆåº”
        total_effect = np.mean(Y_1_M1 - Y_0_M0)
        nde = np.mean(Y_1_M0 - Y_0_M0)
        nie = np.mean(Y_0_M1 - Y_0_M0)

        return {
            'total': total_effect,
            'direct': nde,
            'indirect': nie,
            'proportion_mediated': nie / total_effect if total_effect != 0 else 0
        }

# åº”ç”¨å› æœä¸­ä»‹åˆ†æ
cma = CausalMediationAnalysis()
cma.fit(T, M, Y, X)
cma_effects = cma.estimate_effects()

print("å› æœä¸­ä»‹åˆ†æç»“æœ")
print("="*60)
for key, val in cma_effects.items():
    if key == 'proportion_mediated':
        print(f"{key}: {val:.1%}")
    else:
        print(f"{key}: {val:.4f}")

print(f"\\nä¸çœŸå®å€¼å¯¹æ¯”:")
print(f"  ç›´æ¥æ•ˆåº”: {cma_effects['direct']:.3f} vs {data['true_effects']['direct']:.3f}")
print(f"  é—´æ¥æ•ˆåº”: {cma_effects['indirect']:.3f} vs {data['true_effects']['indirect']:.3f}")""")

# ========== TODO and Interview Questions ==========
add_markdown("""## æ€è€ƒé¢˜ä¸ç»ƒä¹ 

### åŸºç¡€ç†è§£

1. **ç›´æ¥æ•ˆåº”å’Œé—´æ¥æ•ˆåº”çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿç”¨ç”Ÿæ´»ä¾‹å­è§£é‡Šã€‚**

2. **ä¸ºä»€ä¹ˆè¯´Baron-Kennyæ–¹æ³•æœ‰å±€é™æ€§ï¼Ÿä»€ä¹ˆæƒ…å†µä¸‹ä¼šå¤±æ•ˆï¼Ÿ**

3. **å› æœä¸­ä»‹åˆ†æéœ€è¦å“ªäº›è¯†åˆ«å‡è®¾ï¼Ÿå“ªä¸ªæœ€éš¾éªŒè¯ï¼Ÿ**

### æ·±å…¥åˆ†æ

4. **å¦‚æœä¸­ä»‹å˜é‡Må’Œç»“æœå˜é‡Yéƒ½æ˜¯äºŒå…ƒçš„ï¼Œåº”è¯¥å¦‚ä½•ä¿®æ”¹æ¨¡å‹ï¼Ÿ**

5. **å¦‚æœå­˜åœ¨å¤šä¸ªä¸­ä»‹å˜é‡ï¼Œå¦‚ä½•åˆ†æï¼Ÿ**

6. **ä¸­ä»‹æ•ˆåº”çš„ç½®ä¿¡åŒºé—´å¦‚ä½•è®¡ç®—ï¼Ÿï¼ˆæç¤ºï¼šBootstrapï¼‰**

### é¢è¯•é¢˜

**é¢˜ç›®1**ï¼šæŸå…¬å¸æµ‹è¯•æ–°UIè®¾è®¡å¯¹ç”¨æˆ·ç•™å­˜çš„å½±å“ã€‚å‘ç°æ–°UIæå‡äº†15%ç•™å­˜ç‡ã€‚

è¿½é—®ï¼š
- å¦‚ä½•åˆ¤æ–­è¿™ä¸ªæ•ˆåº”æ˜¯å¦é€šè¿‡ã€Œç”¨æˆ·æ»¡æ„åº¦ã€ä¸­ä»‹ï¼Ÿ
- éœ€è¦æ”¶é›†ä»€ä¹ˆæ•°æ®ï¼Ÿ
- å¦‚ä½•è®¾è®¡åˆ†ææµç¨‹ï¼Ÿ

**é¢˜ç›®2**ï¼šç¼–ç é¢˜ - å®ç°Bootstrapç½®ä¿¡åŒºé—´

```python
def bootstrap_mediation_ci(T, M, Y, X=None, n_bootstrap=1000, alpha=0.05):
    \"\"\"
    è®¡ç®—ä¸­ä»‹æ•ˆåº”çš„Bootstrapç½®ä¿¡åŒºé—´

    å‚æ•°:
        T, M, Y, X: æ•°æ®
        n_bootstrap: Bootstrapæ¬¡æ•°
        alpha: æ˜¾è‘—æ€§æ°´å¹³

    è¿”å›:
        å„æ•ˆåº”çš„ç½®ä¿¡åŒºé—´
    \"\"\"
    # TODO: å®ç°è¿™ä¸ªå‡½æ•°
    pass
```

---""")

# ========== Summary ==========
add_markdown("""## æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

| æ¦‚å¿µ | å®šä¹‰ | å…¬å¼ |
|------|------|------|
| **æ€»æ•ˆåº”** | å¤„ç†å¯¹ç»“æœçš„æ€»å½±å“ | $TE = E[Y(1) - Y(0)]$ |
| **ç›´æ¥æ•ˆåº”** | ä¸ç»è¿‡ä¸­ä»‹çš„æ•ˆåº” | $NDE = E[Y(1,M(0)) - Y(0,M(0))]$ |
| **é—´æ¥æ•ˆåº”** | é€šè¿‡ä¸­ä»‹çš„æ•ˆåº” | $NIE = E[Y(0,M(1)) - Y(0,M(0))]$ |
| **ä¸­ä»‹æ¯”ä¾‹** | é—´æ¥æ•ˆåº”å æ€»æ•ˆåº”çš„æ¯”ä¾‹ | $PM = NIE / TE$ |

### æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| **Baron-Kenny** | ç®€å•ç›´è§‚ | çº¿æ€§å‡è®¾å¼º | è¿ç»­çº¿æ€§å…³ç³» |
| **å› æœä¸­ä»‹åˆ†æ** | çµæ´»ï¼Œå…è®¸éçº¿æ€§å’Œäº¤äº’ | éœ€è¦æ›´å¤šå‡è®¾ | ä¸€èˆ¬åœºæ™¯ |
| **æ•æ„Ÿæ€§åˆ†æ** | è¯„ä¼°æœªè§‚æµ‹æ··æ·†å½±å“ | è®¡ç®—å¤æ‚ | é«˜é£é™©å†³ç­– |

### å®è·µå»ºè®®

1. **ç”»å› æœå›¾**ï¼šæ˜ç¡®Tâ†’Mâ†’Yçš„è·¯å¾„
2. **æ£€æŸ¥å‡è®¾**ï¼šé¡ºåºå¿½ç•¥æ€§æœ€å…³é”®
3. **æ•æ„Ÿæ€§åˆ†æ**ï¼šæµ‹è¯•æœªè§‚æµ‹æ··æ·†çš„å½±å“
4. **ä¸šåŠ¡è§£é‡Š**ï¼šå°†ç»Ÿè®¡ç»“æœè½¬åŒ–ä¸ºå¯æ“ä½œå»ºè®®

### å»¶ä¼¸é˜…è¯»

- **ç»å…¸è®ºæ–‡**ï¼š
  - Baron & Kenny (1986): "The Moderator-Mediator Variable Distinction"
  - Imai, Keele & Tingley (2010): "A General Approach to Causal Mediation Analysis"
  - Pearl (2001): "Direct and Indirect Effects"

- **Pythonå·¥å…·**ï¼š
  - `mediation` package
  - `causalml` ä¸­çš„ä¸­ä»‹åˆ†ææ¨¡å—

---

**æ­å–œå®Œæˆä¸­ä»‹åˆ†æçš„å­¦ä¹ ï¼** ğŸ‰

ä½ ç°åœ¨å¯ä»¥ï¼š
- âœ… åˆ†è§£å› æœæ•ˆåº”ä¸ºç›´æ¥å’Œé—´æ¥éƒ¨åˆ†
- âœ… ç†è§£\"æ€ä¹ˆèµ·æ•ˆ\"è€Œä¸ä»…æ˜¯\"æœ‰æ²¡æœ‰æ•ˆ\"
- âœ… åº”ç”¨äºçœŸå®ä¸šåŠ¡åœºæ™¯åšæœºåˆ¶åˆ†æ
""")

# ä¿å­˜notebook
output_path = "/Users/zhangjunmengyang/PycharmProjects/awesome-casual-inference/notebooks/part7_advanced/part7_4_mediation_analysis.ipynb"
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(notebook, f, ensure_ascii=False, indent=2)

print(f"âœ… Notebook created: {output_path}")
