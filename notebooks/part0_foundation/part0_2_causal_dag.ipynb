{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ•¸ï¸ ç¬¬ä¸€ç«  ç»ƒä¹  2: å› æœå›¾ä¸ DAG\n",
    "\n",
    "---\n",
    "\n",
    "## ä»ã€Œçœ‹å›¾è¯´è¯ã€åˆ°ã€Œçœ‹å›¾æ–­å› æœã€\n",
    "\n",
    "åœ¨ä¸Šä¸€ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†æ½œåœ¨ç»“æœæ¡†æ¶ã€‚ä½†æ˜¯ï¼Œå½“ä½ é‡åˆ°è¿™æ ·çš„é—®é¢˜æ—¶ï¼š\n",
    "\n",
    "> \"è¿™ä¸ªå˜é‡åº”è¯¥æ§åˆ¶å—ï¼Ÿæ§åˆ¶äº†ä¼šæ€æ ·ï¼Ÿä¸æ§åˆ¶åˆä¼šæ€æ ·ï¼Ÿ\"\n",
    "\n",
    "å•çº¯é æ•°å­¦å…¬å¼å°±ä¸å¤Ÿç›´è§‚äº†ã€‚è¿™æ—¶å€™ï¼Œ**å› æœå›¾ (Causal Graph)** å°±æ´¾ä¸Šç”¨åœºäº†ï¼\n",
    "\n",
    "### ä¸€ä¸ªæœ‰è¶£çš„ä¾‹å­ ğŸ¥\n",
    "\n",
    "ä½ æ˜¯ä¸€åæµè¡Œç—…å­¦å®¶ï¼Œåœ¨ç ”ç©¶ã€Œè¿åŠ¨ã€å¯¹ã€Œå¥åº·ã€çš„å½±å“ã€‚ä½ å‘ç°ï¼š\n",
    "\n",
    "- ç»å¸¸è¿åŠ¨çš„äººæ›´å¥åº· âœ“\n",
    "- ä½†ç»å¸¸è¿åŠ¨çš„äººæ”¶å…¥ä¹Ÿæ›´é«˜...\n",
    "- è€Œé«˜æ”¶å…¥çš„äººæœ¬æ¥å°±æ›´å¥åº·ï¼ˆæ›´å¥½çš„åŒ»ç–—ã€é¥®é£Ÿï¼‰...\n",
    "\n",
    "æ‰€ä»¥è¿åŠ¨åˆ°åº•æœ‰æ²¡æœ‰ç”¨ï¼Ÿæ”¶å…¥æ˜¯æ€ä¹ˆå›äº‹ï¼Ÿåº”è¯¥æ€ä¹ˆåˆ†æï¼Ÿ\n",
    "\n",
    "ç”¨å› æœå›¾ï¼Œè¿™ä¸ªé—®é¢˜ä¸€ç”»å°±æ¸…æ¥šäº†ï¼\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š æœ¬èŠ‚å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "1. ç†è§£å› æœå›¾çš„åŸºæœ¬æ¦‚å¿µ\n",
    "2. è¯†åˆ«ä¸‰ç§æ ¸å¿ƒç»“æ„ï¼šæ··æ·†ã€ä¸­ä»‹ã€ç¢°æ’\n",
    "3. ç†è§£åé—¨è·¯å¾„å’Œ d-åˆ†ç¦»\n",
    "4. æŒæ¡ã€Œåº”è¯¥æ§åˆ¶å“ªäº›å˜é‡ã€çš„å†³ç­–æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Set, Tuple\n",
    "\n",
    "# è®¾ç½®\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæ¯•ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸŒŸ Part 1: ä»€ä¹ˆæ˜¯å› æœå›¾ (DAG)ï¼Ÿ\n",
    "\n",
    "### DAG = Directed Acyclic Graphï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰\n",
    "\n",
    "- **æœ‰å‘ (Directed)**: ç®­å¤´æŒ‡å‘å› æœçš„æ–¹å‘ï¼ˆåŸå›  â†’ ç»“æœï¼‰\n",
    "- **æ— ç¯ (Acyclic)**: ä¸èƒ½æœ‰å¾ªç¯ï¼ˆA â†’ B â†’ C â†’ A æ˜¯ä¸å…è®¸çš„ï¼‰\n",
    "- **å›¾ (Graph)**: ç”¨èŠ‚ç‚¹å’Œè¾¹è¡¨ç¤ºå˜é‡ä¹‹é—´çš„å…³ç³»\n",
    "\n",
    "### æœ€ç®€å•çš„å› æœå›¾\n",
    "\n",
    "```\n",
    "T â†’ Y\n",
    "```\n",
    "\n",
    "è¿™è¡¨ç¤ºï¼šT **å¯¼è‡´** Yï¼ˆT æ˜¯åŸå› ï¼ŒY æ˜¯ç»“æœï¼‰\n",
    "\n",
    "### ç»å…¸çš„æ··æ·†ç»“æ„\n",
    "\n",
    "```\n",
    "    X\n",
    "   â†™ â†˜\n",
    "  T   Y\n",
    "   â†˜ â†—\n",
    "```\n",
    "\n",
    "ç­‰ä»·äºï¼š\n",
    "- X â†’ Tï¼ˆX å½±å“ Tï¼‰\n",
    "- X â†’ Yï¼ˆX å½±å“ Yï¼‰  \n",
    "- T â†’ Yï¼ˆT å½±å“ Yï¼‰\n",
    "\n",
    "è¿™é‡Œ X å°±æ˜¯**æ··æ·†å˜é‡ (Confounder)**ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¨ ç”¨ä»£ç ç”»å› æœå›¾\n",
    "\n",
    "è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªç®€å•çš„å‡½æ•°æ¥å¯è§†åŒ–å› æœå›¾ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_dag(edges, title=\"å› æœå›¾ (DAG)\", highlight_path=None):\n",
    "    \"\"\"\n",
    "    ç”»ä¸€ä¸ªç®€å•çš„å› æœå›¾\n",
    "    \n",
    "    Args:\n",
    "        edges: è¾¹çš„åˆ—è¡¨ï¼Œå¦‚ [(\"X\", \"T\"), (\"X\", \"Y\"), (\"T\", \"Y\")]\n",
    "        title: å›¾çš„æ ‡é¢˜\n",
    "        highlight_path: è¦é«˜äº®çš„è·¯å¾„\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import networkx as nx\n",
    "        \n",
    "        G = nx.DiGraph()\n",
    "        G.add_edges_from(edges)\n",
    "        \n",
    "        # è®¾ç½®èŠ‚ç‚¹ä½ç½®\n",
    "        pos = nx.spring_layout(G, seed=42)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        \n",
    "        # ç”»è¾¹\n",
    "        nx.draw_networkx_edges(G, pos, edge_color='gray', \n",
    "                               arrows=True, arrowsize=20,\n",
    "                               connectionstyle=\"arc3,rad=0.1\")\n",
    "        \n",
    "        # å¦‚æœæœ‰é«˜äº®è·¯å¾„\n",
    "        if highlight_path:\n",
    "            highlight_edges = [(highlight_path[i], highlight_path[i+1]) \n",
    "                              for i in range(len(highlight_path)-1)]\n",
    "            nx.draw_networkx_edges(G, pos, edgelist=highlight_edges,\n",
    "                                   edge_color='red', width=2,\n",
    "                                   arrows=True, arrowsize=25)\n",
    "        \n",
    "        # ç”»èŠ‚ç‚¹\n",
    "        nx.draw_networkx_nodes(G, pos, node_color='lightblue', \n",
    "                               node_size=2000, alpha=0.9)\n",
    "        nx.draw_networkx_labels(G, pos, font_size=14, font_weight='bold')\n",
    "        \n",
    "        plt.title(title, fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"éœ€è¦å®‰è£… networkx: pip install networkx\")\n",
    "        print(f\"\\nè¾¹: {edges}\")\n",
    "\n",
    "# ç”»ä¸€ä¸ªç®€å•çš„æ··æ·†ç»“æ„\n",
    "confounding_edges = [(\"X\", \"T\"), (\"X\", \"Y\"), (\"T\", \"Y\")]\n",
    "draw_dag(confounding_edges, \"ç»å…¸æ··æ·†ç»“æ„: X æ˜¯æ··æ·†å˜é‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ” Part 2: ä¸‰ç§æ ¸å¿ƒå› æœç»“æ„\n",
    "\n",
    "å› æœå›¾ä¸­æœ‰ä¸‰ç§æœ€åŸºæœ¬çš„ç»“æ„ï¼Œç†è§£å®ƒä»¬æ˜¯æŒæ¡å› æœæ¨æ–­çš„å…³é”®ï¼\n",
    "\n",
    "### ç»“æ„ 1: å‰å­ (Fork) - æ··æ·†\n",
    "\n",
    "```\n",
    "T â† X â†’ Y\n",
    "```\n",
    "\n",
    "**ç‰¹ç‚¹**: X åŒæ—¶å½±å“ T å’Œ Y\n",
    "\n",
    "**ä¾‹å­**: \n",
    "- X = å¹´é¾„\n",
    "- T = æ˜¯å¦å–å’–å•¡\n",
    "- Y = æ˜¯å¦æœ‰å¿ƒè„ç—…\n",
    "\n",
    "å¹´è½»äººå–å’–å•¡æ›´å¤šï¼Œä½†å¹´è½»äººå¿ƒè„ç—…ä¹Ÿæ›´å°‘ã€‚å¦‚æœä¸æ§åˆ¶å¹´é¾„ï¼Œä¼šé”™è¯¯åœ°è®¤ä¸ºå’–å•¡é¢„é˜²å¿ƒè„ç—…ï¼\n",
    "\n",
    "**è§„åˆ™**: éœ€è¦æ§åˆ¶ X æ¥é˜»æ–­æ··æ·†\n",
    "\n",
    "---\n",
    "\n",
    "### ç»“æ„ 2: é“¾æ¡ (Chain) - ä¸­ä»‹\n",
    "\n",
    "```\n",
    "T â†’ M â†’ Y\n",
    "```\n",
    "\n",
    "**ç‰¹ç‚¹**: T é€šè¿‡ M å½±å“ Y\n",
    "\n",
    "**ä¾‹å­**:\n",
    "- T = å—æ•™è‚²ç¨‹åº¦\n",
    "- M = æ”¶å…¥\n",
    "- Y = å¥åº·çŠ¶å†µ\n",
    "\n",
    "æ•™è‚²é€šè¿‡æé«˜æ”¶å…¥æ¥æ”¹å–„å¥åº·ã€‚M æ˜¯ä¸­ä»‹å˜é‡ã€‚\n",
    "\n",
    "**è§„åˆ™**: \n",
    "- å¦‚æœæƒ³ä¼°è®¡ T çš„**æ€»æ•ˆåº”**ï¼Œä¸è¦æ§åˆ¶ M\n",
    "- å¦‚æœæƒ³ä¼°è®¡ T çš„**ç›´æ¥æ•ˆåº”**ï¼Œéœ€è¦æ§åˆ¶ M\n",
    "\n",
    "---\n",
    "\n",
    "### ç»“æ„ 3: ç¢°æ’ (Collider) - ç¢°æ’å˜é‡\n",
    "\n",
    "```\n",
    "T â†’ C â† Y\n",
    "```\n",
    "\n",
    "**ç‰¹ç‚¹**: T å’Œ Y éƒ½å½±å“ C\n",
    "\n",
    "**ä¾‹å­** (ç»å…¸ï¼):\n",
    "- T = æ¼”æŠ€å¥½\n",
    "- Y = é¢œå€¼é«˜\n",
    "- C = æˆä¸ºæ˜æ˜Ÿ\n",
    "\n",
    "æˆä¸ºæ˜æ˜Ÿéœ€è¦æ¼”æŠ€**æˆ–**é¢œå€¼ï¼ˆè‡³å°‘ä¸€ä¸ªï¼‰ã€‚åœ¨æ˜æ˜Ÿç¾¤ä½“ä¸­ï¼Œæ¼”æŠ€å¥½å’Œé¢œå€¼é«˜ä¼šå‘ˆç°è´Ÿç›¸å…³â€”â€”å› ä¸ºåªé é¢œå€¼çš„äººæ¼”æŠ€å¯èƒ½ä¸å¥½ï¼Œåªé æ¼”æŠ€çš„äººå¯èƒ½ä¸æ˜¯é è„¸åƒé¥­ã€‚\n",
    "\n",
    "**è§„åˆ™**: åƒä¸‡ä¸è¦æ§åˆ¶ç¢°æ’å˜é‡ Cï¼å¦åˆ™ä¼šåˆ›é€ è™šå‡å…³è”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”»å‡ºä¸‰ç§ç»“æ„\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "structures = [\n",
    "    ([(\"X\", \"T\"), (\"X\", \"Y\")], \"Fork (å‰å­/æ··æ·†)\\nT â† X â†’ Y\\næ§åˆ¶ X âœ“\"),\n",
    "    ([(\"T\", \"M\"), (\"M\", \"Y\")], \"Chain (é“¾æ¡/ä¸­ä»‹)\\nT â†’ M â†’ Y\\né€šå¸¸ä¸æ§åˆ¶ M\"),\n",
    "    ([(\"T\", \"C\"), (\"Y\", \"C\")], \"Collider (ç¢°æ’)\\nT â†’ C â† Y\\nç»å¯¹ä¸æ§åˆ¶ C âœ—\")\n",
    "]\n",
    "\n",
    "for idx, (edges, title) in enumerate(structures):\n",
    "    ax = axes[idx]\n",
    "    try:\n",
    "        import networkx as nx\n",
    "        G = nx.DiGraph()\n",
    "        G.add_edges_from(edges)\n",
    "        pos = nx.spring_layout(G, seed=42)\n",
    "        \n",
    "        nx.draw_networkx_edges(G, pos, ax=ax, edge_color='gray', \n",
    "                               arrows=True, arrowsize=20)\n",
    "        nx.draw_networkx_nodes(G, pos, ax=ax, node_color='lightblue', \n",
    "                               node_size=1500, alpha=0.9)\n",
    "        nx.draw_networkx_labels(G, pos, ax=ax, font_size=12, font_weight='bold')\n",
    "        ax.set_title(title, fontsize=11)\n",
    "        ax.axis('off')\n",
    "    except:\n",
    "        ax.text(0.5, 0.5, f\"è¾¹: {edges}\\n{title}\", ha='center', va='center')\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ§ª ç»ƒä¹ : è¯†åˆ«å› æœç»“æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def identify_structure(edges: List[Tuple[str, str]], node: str) -> str:\n    \"\"\"\n    æ ¹æ® DAG è¾¹ï¼Œè¯†åˆ«ç»™å®šèŠ‚ç‚¹çš„å› æœç»“æ„ç±»å‹\n    \n    ç»“æ„ç±»å‹:\n    - \"confounder\": æ··æ·†å˜é‡ (å‡ºåº¦ >= 2ï¼Œåƒå‰å­çš„ä¸­å¿ƒ)\n    - \"mediator\": ä¸­ä»‹å˜é‡ (å…¥åº¦ >= 1 ä¸” å‡ºåº¦ >= 1ï¼Œåœ¨é“¾æ¡ä¸­é—´)\n    - \"collider\": ç¢°æ’å˜é‡ (å…¥åº¦ >= 2ï¼Œåƒç¢°æ’çš„ä¸­å¿ƒ)\n    \n    Args:\n        edges: è¾¹åˆ—è¡¨ï¼Œå¦‚ [(\"X\", \"T\"), (\"X\", \"Y\"), (\"T\", \"Y\")]\n        node: è¦è¯†åˆ«çš„èŠ‚ç‚¹\n    \n    Returns:\n        ç»“æ„ç±»å‹å­—ç¬¦ä¸²\n    \"\"\"\n    # === ä½ çš„ä»£ç å¼€å§‹ ===\n    # æç¤º 1: è®¡ç®—å…¥åº¦ (æœ‰å¤šå°‘æ¡è¾¹æŒ‡å‘è¿™ä¸ªèŠ‚ç‚¹)\n    in_degree = None  # ä½ çš„ä»£ç \n    \n    # æç¤º 2: è®¡ç®—å‡ºåº¦ (è¿™ä¸ªèŠ‚ç‚¹æœ‰å¤šå°‘æ¡è¾¹æŒ‡å‡ºå»)\n    out_degree = None  # ä½ çš„ä»£ç \n    \n    # æç¤º 3: æ ¹æ®å…¥åº¦å’Œå‡ºåº¦åˆ¤æ–­ç»“æ„ç±»å‹\n    # - ç¢°æ’å˜é‡ (collider): å…¥åº¦ >= 2, å‡ºåº¦ = 0 (å¤šä¸ªç®­å¤´æŒ‡å‘å®ƒ)\n    # - æ··æ·†å˜é‡ (confounder): å‡ºåº¦ >= 2 (å®ƒæŒ‡å‘å¤šä¸ªèŠ‚ç‚¹)\n    # - ä¸­ä»‹å˜é‡ (mediator): å…¥åº¦ >= 1 ä¸” å‡ºåº¦ >= 1 (åœ¨é“¾æ¡ä¸­é—´)\n    \n    pass  # åˆ é™¤æ­¤è¡Œï¼Œå¡«å…¥ä½ çš„ä»£ç \n    # === ä½ çš„ä»£ç ç»“æŸ ==="
  },
  {
   "cell_type": "markdown",
   "source": "<details>\n<summary>ğŸ“ å‚è€ƒç­”æ¡ˆï¼ˆç‚¹å‡»å±•å¼€ï¼‰</summary>\n\n```python\ndef identify_structure(edges: List[Tuple[str, str]], node: str) -> str:\n    \"\"\"æ ¹æ® DAG è¾¹ï¼Œè¯†åˆ«ç»™å®šèŠ‚ç‚¹çš„å› æœç»“æ„ç±»å‹\"\"\"\n    # è®¡ç®—å…¥åº¦å’Œå‡ºåº¦\n    in_degree = sum(1 for edge in edges if edge[1] == node)\n    out_degree = sum(1 for edge in edges if edge[0] == node)\n    \n    # æ ¹æ®å…¥åº¦å’Œå‡ºåº¦åˆ¤æ–­ç»“æ„ç±»å‹\n    if in_degree >= 2 and out_degree == 0:\n        return \"collider\"  # ç¢°æ’å˜é‡ï¼šå¤šä¸ªç®­å¤´æŒ‡å‘å®ƒ\n    elif out_degree >= 2:\n        return \"confounder\"  # æ··æ·†å˜é‡ï¼šå®ƒæŒ‡å‘å¤šä¸ªèŠ‚ç‚¹\n    elif in_degree >= 1 and out_degree >= 1:\n        return \"mediator\"  # ä¸­ä»‹å˜é‡ï¼šåœ¨é“¾æ¡ä¸­é—´\n    else:\n        return \"other\"\n```\n\n**è§£é‡Š**ï¼š\n- **Colliderï¼ˆç¢°æ’ï¼‰**: in_degree â‰¥ 2 ä¸” out_degree = 0ï¼Œå¦‚ T â†’ C â† Y\n  - ç‰¹ç‚¹ï¼šå¤šä¸ªç®­å¤´æŒ‡å‘å®ƒï¼Œåƒç¢°æ’ç‚¹\n  - è§„åˆ™ï¼šä¸èƒ½æ§åˆ¶ï¼Œå¦åˆ™ä¼šæ‰“å¼€è·¯å¾„\n  \n- **Confounderï¼ˆæ··æ·†ï¼‰**: out_degree â‰¥ 2ï¼Œå¦‚ X â†’ T å’Œ X â†’ Y\n  - ç‰¹ç‚¹ï¼šå®ƒæŒ‡å‘å¤šä¸ªèŠ‚ç‚¹ï¼Œæ˜¯ã€Œå‰å­ã€çš„ä¸­å¿ƒ\n  - è§„åˆ™ï¼šå¿…é¡»æ§åˆ¶ï¼Œé˜»æ–­åé—¨è·¯å¾„\n  \n- **Mediatorï¼ˆä¸­ä»‹ï¼‰**: in_degree â‰¥ 1 ä¸” out_degree â‰¥ 1ï¼Œå¦‚ T â†’ M â†’ Y\n  - ç‰¹ç‚¹ï¼šåœ¨å› æœé“¾æ¡ä¸­é—´\n  - è§„åˆ™ï¼šä¼°è®¡æ€»æ•ˆåº”æ—¶ä¸æ§åˆ¶ï¼Œä¼°è®¡ç›´æ¥æ•ˆåº”æ—¶æ§åˆ¶\n</details>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•ä½ çš„ä»£ç \n",
    "test_edges = [(\"X\", \"T\"), (\"X\", \"Y\"), (\"T\", \"Y\")]\n",
    "\n",
    "print(\"DAG: X â†’ T, X â†’ Y, T â†’ Y\")\n",
    "print(\"\\nè¯†åˆ«æ¯ä¸ªèŠ‚ç‚¹çš„è§’è‰²:\")\n",
    "\n",
    "for node in [\"X\", \"T\", \"Y\"]:\n",
    "    structure = identify_structure(test_edges, node)\n",
    "    if structure:\n",
    "        print(f\"   èŠ‚ç‚¹ {node}: {structure}\")\n",
    "    else:\n",
    "        print(f\"   èŠ‚ç‚¹ {node}: [æœªå®Œæˆ]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ›¤ï¸ Part 3: è·¯å¾„ä¸åé—¨å‡†åˆ™\n",
    "\n",
    "### ä»€ä¹ˆæ˜¯ã€Œè·¯å¾„ã€ï¼Ÿ\n",
    "\n",
    "åœ¨å› æœå›¾ä¸­ï¼Œä» T åˆ° Y å¯èƒ½æœ‰å¤šæ¡è·¯å¾„ï¼š\n",
    "\n",
    "```\n",
    "    X\n",
    "   â†™ â†˜\n",
    "  T â†’ Y\n",
    "```\n",
    "\n",
    "ä» T åˆ° Y æœ‰ä¸¤æ¡è·¯å¾„ï¼š\n",
    "1. **ç›´æ¥è·¯å¾„ (å› æœè·¯å¾„)**: T â†’ Y âœ…\n",
    "2. **åé—¨è·¯å¾„**: T â† X â†’ Y âš ï¸\n",
    "\n",
    "### ä»€ä¹ˆæ˜¯ã€Œåé—¨è·¯å¾„ã€ï¼Ÿ\n",
    "\n",
    "åé—¨è·¯å¾„æ˜¯ä» T åˆ° Y çš„è·¯å¾„ä¸­ï¼Œç¬¬ä¸€ä¸ªç®­å¤´**æŒ‡å‘ T** çš„è·¯å¾„ã€‚\n",
    "\n",
    "- T â†’ Y ä¸æ˜¯åé—¨ï¼ˆç®­å¤´ä» T å‡ºå‘ï¼‰\n",
    "- T â† X â†’ Y æ˜¯åé—¨ï¼ˆç¬¬ä¸€ä¸ªç®­å¤´æŒ‡å‘ Tï¼‰\n",
    "\n",
    "**åé—¨è·¯å¾„ä¼šé€ æˆæ··æ·†åå·®ï¼æˆ‘ä»¬éœ€è¦æŠŠå®ƒé˜»æ–­ã€‚**\n",
    "\n",
    "### åé—¨å‡†åˆ™ (Backdoor Criterion)\n",
    "\n",
    "è¦æ— ååœ°ä¼°è®¡ T å¯¹ Y çš„å› æœæ•ˆåº”ï¼Œéœ€è¦æ‰¾åˆ°ä¸€ç»„å˜é‡ Z æ»¡è¶³ï¼š\n",
    "\n",
    "1. Z é˜»æ–­äº†æ‰€æœ‰ä» T åˆ° Y çš„åé—¨è·¯å¾„\n",
    "2. Z ä¸åŒ…å« T çš„ä»»ä½•åä»£"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ğŸ“– ç¤ºèŒƒä»£ç : æ‰¾å‡º DAG ä¸­çš„æ‰€æœ‰è·¯å¾„\n\ndef find_all_paths(edges: List[Tuple[str, str]], \n                   start: str, \n                   end: str,\n                   ignore_direction: bool = True) -> List[List[str]]:\n    \"\"\"\n    æ‰¾å‡º DAG ä¸­ä» start åˆ° end çš„æ‰€æœ‰è·¯å¾„\n    \n    Args:\n        edges: è¾¹åˆ—è¡¨\n        start: èµ·å§‹èŠ‚ç‚¹\n        end: ç»ˆæ­¢èŠ‚ç‚¹\n        ignore_direction: æ˜¯å¦å¿½ç•¥è¾¹çš„æ–¹å‘ï¼ˆæ‰¾åé—¨è·¯å¾„æ—¶éœ€è¦å¿½ç•¥ï¼‰\n    \n    Returns:\n        è·¯å¾„åˆ—è¡¨ï¼Œæ¯æ¡è·¯å¾„æ˜¯èŠ‚ç‚¹åºåˆ—\n    \"\"\"\n    # æ„å»ºé‚»æ¥è¡¨\n    adj = {}\n    for u, v in edges:\n        if u not in adj:\n            adj[u] = []\n        adj[u].append(v)\n        \n        if ignore_direction:  # å¦‚æœå¿½ç•¥æ–¹å‘ï¼Œä¹Ÿæ·»åŠ åå‘è¾¹\n            if v not in adj:\n                adj[v] = []\n            adj[v].append(u)\n    \n    paths = []\n    \n    # ä½¿ç”¨ DFS æ‰¾å‡ºæ‰€æœ‰è·¯å¾„\n    def dfs(current, path, visited):\n        \"\"\"\n        æ·±åº¦ä¼˜å…ˆæœç´¢æ‰¾è·¯å¾„\n        \n        current: å½“å‰èŠ‚ç‚¹\n        path: å½“å‰è·¯å¾„\n        visited: å·²è®¿é—®èŠ‚ç‚¹é›†åˆ\n        \"\"\"\n        # å¦‚æœåˆ°è¾¾ç»ˆç‚¹ï¼Œä¿å­˜è·¯å¾„\n        if current == end:\n            paths.append(path.copy())\n            return\n        \n        # éå†é‚»å±…\n        for neighbor in adj.get(current, []):\n            if neighbor not in visited:\n                # å°†é‚»å±…åŠ å…¥å·²è®¿é—®ï¼Œé€’å½’è°ƒç”¨ï¼Œç„¶åç§»é™¤ï¼ˆå›æº¯ï¼‰\n                visited.add(neighbor)\n                path.append(neighbor)\n                dfs(neighbor, path, visited)\n                path.pop()\n                visited.remove(neighbor)\n    \n    dfs(start, [start], {start})\n    return paths",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<details>\n<summary>ğŸ“ å‚è€ƒç­”æ¡ˆï¼ˆç‚¹å‡»å±•å¼€ï¼‰</summary>\n\n```python\ndef identify_backdoor_paths(edges: List[Tuple[str, str]], \n                            treatment: str, \n                            outcome: str) -> List[List[str]]:\n    \"\"\"è¯†åˆ«ä» treatment åˆ° outcome çš„åé—¨è·¯å¾„\"\"\"\n    all_paths = find_all_paths(edges, treatment, outcome, ignore_direction=True)\n    \n    backdoor_paths = []\n    for path in all_paths:\n        if len(path) < 2:\n            continue\n        \n        # æ£€æŸ¥æ˜¯å¦æ˜¯åé—¨è·¯å¾„\n        # åé—¨è·¯å¾„çš„ç¬¬ä¸€æ¡è¾¹æŒ‡å‘ treatment\n        first_step = path[1]  # è·¯å¾„ä¸Šçš„ç¬¬äºŒä¸ªèŠ‚ç‚¹\n        \n        # æ£€æŸ¥è¾¹ first_step â†’ treatment æ˜¯å¦å­˜åœ¨\n        is_backdoor = (first_step, treatment) in edges\n        \n        if is_backdoor:\n            backdoor_paths.append(path)\n    \n    return backdoor_paths\n```\n\n**è§£é‡Š**ï¼š\n- **åé—¨è·¯å¾„å®šä¹‰**: ä» T åˆ° Y çš„è·¯å¾„ï¼Œç¬¬ä¸€æ¡è¾¹æŒ‡å‘ Tï¼ˆç®­å¤´æœå‘ Tï¼‰\n  \n- **è¯†åˆ«æ–¹æ³•**:\n  1. æ‰¾åˆ°æ‰€æœ‰ä» T åˆ° Y çš„è·¯å¾„ï¼ˆå¿½ç•¥æ–¹å‘ï¼‰\n  2. å¯¹æ¯æ¡è·¯å¾„ï¼Œæ£€æŸ¥ç¬¬ä¸€æ­¥\n  3. å¦‚æœç¬¬ä¸€æ­¥æ˜¯ path[1] â†’ Tï¼ˆå³ (path[1], T) åœ¨è¾¹é›†ä¸­ï¼‰ï¼Œåˆ™æ˜¯åé—¨è·¯å¾„\n  \n- **ä¾‹å­**: \n  ```\n  DAG: X â†’ T, X â†’ Y, T â†’ Y\n  è·¯å¾„: T â† X â†’ Y (å³ [T, X, Y])\n  ç¬¬ä¸€æ­¥: X â†’ T (åœ¨è¾¹é›†ä¸­) âœ“ æ˜¯åé—¨è·¯å¾„\n  ```\n  \n- **ä¸ºä»€ä¹ˆé‡è¦**: åé—¨è·¯å¾„ä¼šå¼•å…¥æ··æ·†åå·®ï¼Œå¿…é¡»é˜»æ–­å®ƒä»¬\n</details>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ“– ç¤ºèŒƒä»£ç : è¯†åˆ«åé—¨è·¯å¾„\n\ndef identify_backdoor_paths(edges: List[Tuple[str, str]], \n                            treatment: str, \n                            outcome: str) -> List[List[str]]:\n    \"\"\"\n    è¯†åˆ«ä» treatment åˆ° outcome çš„åé—¨è·¯å¾„\n    \n    åé—¨è·¯å¾„: ä» T åˆ° Y çš„è·¯å¾„ï¼Œå…¶ä¸­ç¬¬ä¸€æ¡è¾¹æŒ‡å‘ T\n    \n    Returns:\n        åé—¨è·¯å¾„åˆ—è¡¨\n    \"\"\"\n    all_paths = find_all_paths(edges, treatment, outcome, ignore_direction=True)\n    \n    backdoor_paths = []\n    for path in all_paths:\n        if len(path) < 2:\n            continue\n        \n        # æ£€æŸ¥æ˜¯å¦æ˜¯åé—¨è·¯å¾„\n        # åé—¨è·¯å¾„çš„ç¬¬ä¸€æ¡è¾¹æŒ‡å‘ treatment\n        # å³æ£€æŸ¥ (path[1], treatment) æ˜¯å¦åœ¨ edges ä¸­\n        \n        first_step = path[1]  # è·¯å¾„ä¸Šçš„ç¬¬äºŒä¸ªèŠ‚ç‚¹\n        \n        # æ£€æŸ¥è¾¹ first_step â†’ treatment æ˜¯å¦å­˜åœ¨\n        is_backdoor = (first_step, treatment) in edges\n        \n        if is_backdoor:\n            backdoor_paths.append(path)\n    \n    return backdoor_paths"
  },
  {
   "cell_type": "markdown",
   "source": "<details>\n<summary>ğŸ“ å‚è€ƒç­”æ¡ˆï¼ˆç‚¹å‡»å±•å¼€ï¼‰</summary>\n\n```python\ndef is_valid_adjustment_set(edges: List[Tuple[str, str]], \n                            treatment: str, \n                            outcome: str,\n                            adjustment_set: Set[str]) -> bool:\n    \"\"\"æ£€æŸ¥ç»™å®šçš„è°ƒæ•´é›†æ˜¯å¦æœ‰æ•ˆï¼ˆæ»¡è¶³åé—¨å‡†åˆ™ï¼‰\"\"\"\n    # æ­¥éª¤ 1: æ‰¾å‡º treatment çš„æ‰€æœ‰åä»£\n    def find_descendants(node):\n        descendants = set()\n        to_visit = [n for (s, n) in edges if s == node]\n        while to_visit:\n            current = to_visit.pop()\n            if current not in descendants:\n                descendants.add(current)\n                to_visit.extend([n for (s, n) in edges if s == current])\n        return descendants\n    \n    descendants_of_T = find_descendants(treatment)\n    \n    # æ£€æŸ¥è°ƒæ•´é›†æ˜¯å¦åŒ…å« treatment çš„åä»£\n    contains_descendant = bool(adjustment_set & descendants_of_T)\n    \n    if contains_descendant:\n        return False  # è¿åæ¡ä»¶ 2\n    \n    # æ­¥éª¤ 2: æ‰¾å‡ºæ‰€æœ‰åé—¨è·¯å¾„\n    backdoor_paths = identify_backdoor_paths(edges, treatment, outcome)\n    \n    # æ£€æŸ¥è°ƒæ•´é›†æ˜¯å¦é˜»æ–­æ‰€æœ‰åé—¨è·¯å¾„\n    for path in backdoor_paths:\n        path_nodes = set(path) - {treatment, outcome}\n        # æ£€æŸ¥ adjustment_set æ˜¯å¦ä¸ path_nodes æœ‰äº¤é›†\n        is_blocked = bool(adjustment_set & path_nodes)\n        \n        if not is_blocked:\n            return False  # æœ‰åé—¨è·¯å¾„æ²¡è¢«é˜»æ–­\n    \n    return True\n```\n\n**è§£é‡Š**ï¼š\n- **åé—¨å‡†åˆ™ä¸¤ä¸ªæ¡ä»¶**:\n  1. è°ƒæ•´é›†é˜»æ–­æ‰€æœ‰åé—¨è·¯å¾„\n  2. è°ƒæ•´é›†ä¸åŒ…å« treatment çš„åä»£\n  \n- **æ¡ä»¶ 1 éªŒè¯**:\n  - å¯¹æ¯æ¡åé—¨è·¯å¾„ï¼Œæ£€æŸ¥è°ƒæ•´é›†æ˜¯å¦åŒ…å«è·¯å¾„ä¸Šè‡³å°‘ä¸€ä¸ªèŠ‚ç‚¹\n  - ä½¿ç”¨é›†åˆäº¤é›†è¿ç®—ï¼š`adjustment_set & path_nodes`\n  - å¦‚æœäº¤é›†éç©ºï¼Œè¯´æ˜è·¯å¾„è¢«é˜»æ–­\n  \n- **æ¡ä»¶ 2 éªŒè¯**:\n  - æ‰¾å‡º T çš„æ‰€æœ‰åä»£ï¼ˆé€’å½’æœç´¢ï¼‰\n  - æ£€æŸ¥è°ƒæ•´é›†æ˜¯å¦ä¸åä»£é›†åˆæœ‰äº¤é›†\n  - å¦‚æœæœ‰äº¤é›†ï¼Œè¿åæ¡ä»¶ï¼ˆå¯èƒ½é˜»æ–­å› æœè·¯å¾„ï¼‰\n  \n- **ä¸ºä»€ä¹ˆä¸èƒ½æ§åˆ¶åä»£**: \n  - T â†’ M â†’ Y ä¸­ï¼Œæ§åˆ¶ M ä¼šé˜»æ–­å› æœè·¯å¾„\n  - æˆ‘ä»¬æƒ³ä¼°è®¡ T çš„æ€»æ•ˆåº”ï¼Œä¸èƒ½é˜»æ–­ T çš„ä½œç”¨æœºåˆ¶\n</details>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•åé—¨è·¯å¾„è¯†åˆ«\n",
    "test_edges = [(\"X\", \"T\"), (\"X\", \"Y\"), (\"T\", \"Y\")]\n",
    "\n",
    "print(\"DAG: X â†’ T, X â†’ Y, T â†’ Y\")\n",
    "print(\"\\nå¯»æ‰¾ä» T åˆ° Y çš„è·¯å¾„...\")\n",
    "\n",
    "all_paths = find_all_paths(test_edges, \"T\", \"Y\", ignore_direction=True)\n",
    "print(f\"\\næ‰€æœ‰è·¯å¾„: {all_paths}\")\n",
    "\n",
    "backdoor = identify_backdoor_paths(test_edges, \"T\", \"Y\")\n",
    "print(f\"åé—¨è·¯å¾„: {backdoor}\")\n",
    "\n",
    "if backdoor:\n",
    "    print(f\"\\nâœ… éœ€è¦æ§åˆ¶çš„å˜é‡: {set(sum(backdoor, [])) - {'T', 'Y'}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<details>\n<summary>ğŸ“ å‚è€ƒç­”æ¡ˆï¼ˆç‚¹å‡»å±•å¼€ï¼‰</summary>\n\n```python\ndef simulate_confounding_dag(n: int = 2000, seed: int = 42):\n    \"\"\"æ¨¡æ‹Ÿç»å…¸æ··æ·† DAG çš„æ•°æ®\"\"\"\n    np.random.seed(seed)\n    \n    # ç”Ÿæˆæ··æ·†å˜é‡ X\n    X = np.random.randn(n)\n    \n    # ç”Ÿæˆå¤„ç† Tï¼ˆå— X å½±å“ï¼‰\n    T = (X + np.random.randn(n) > 0).astype(int)\n    \n    # ç”Ÿæˆç»“æœ Yï¼ˆå— T å’Œ X å½±å“ï¼‰\n    Y = 1 + 2 * T + 1.5 * X + np.random.randn(n) * 0.5\n    \n    df = pd.DataFrame({'X': X, 'T': T, 'Y': Y})\n    return df\n```\n\n**è§£é‡Š**ï¼š\n- **DAG ç»“æ„**: X â†’ T, X â†’ Y, T â†’ Yï¼ˆç»å…¸æ··æ·†ï¼‰\n  \n- **æ•°æ®ç”Ÿæˆè¿‡ç¨‹**:\n  - X ~ N(0, 1): æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„æ··æ·†å˜é‡\n  - T = 1[X + Îµ > 0]: X è¶Šå¤§ï¼ŒT=1 çš„æ¦‚ç‡è¶Šé«˜\n  - Y = 1 + 2T + 1.5X + Îµ: çœŸå® ATE = 2\n  \n- **æ··æ·†æœºåˆ¶**:\n  - X åŒæ—¶å½±å“ Tï¼ˆç³»æ•°éšå«åœ¨ P(T=1|X) ä¸­ï¼‰\n  - X åŒæ—¶å½±å“ Yï¼ˆç³»æ•° = 1.5ï¼‰\n  - ä¸æ§åˆ¶ X ä¼šå¯¼è‡´åå·®\n  \n- **éªŒè¯**: \n  - æœ´ç´ ä¼°è®¡ä¼šåé«˜ï¼ˆå› ä¸º T=1 çš„äºº X æ›´å¤§ï¼ŒY ä¹Ÿæ›´å¤§ï¼‰\n  - æ§åˆ¶ X åä¼°è®¡åº”è¯¥æ¥è¿‘ 2\n</details>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ“– ç¤ºèŒƒä»£ç : æ£€æŸ¥è°ƒæ•´é›†æ˜¯å¦æ»¡è¶³åé—¨å‡†åˆ™\n\ndef is_valid_adjustment_set(edges: List[Tuple[str, str]], \n                            treatment: str, \n                            outcome: str,\n                            adjustment_set: Set[str]) -> bool:\n    \"\"\"\n    æ£€æŸ¥ç»™å®šçš„è°ƒæ•´é›†æ˜¯å¦æœ‰æ•ˆï¼ˆæ»¡è¶³åé—¨å‡†åˆ™ï¼‰\n    \n    åé—¨å‡†åˆ™è¦æ±‚è°ƒæ•´é›†:\n    1. é˜»æ–­æ‰€æœ‰åé—¨è·¯å¾„\n    2. ä¸åŒ…å« treatment çš„åä»£\n    \n    Returns:\n        True å¦‚æœè°ƒæ•´é›†æœ‰æ•ˆ\n    \"\"\"\n    # æ­¥éª¤ 1: æ‰¾å‡º treatment çš„æ‰€æœ‰åä»£\n    def find_descendants(node):\n        \"\"\"æ‰¾å‡ºä¸€ä¸ªèŠ‚ç‚¹çš„æ‰€æœ‰åä»£\"\"\"\n        descendants = set()\n        to_visit = [n for (s, n) in edges if s == node]\n        while to_visit:\n            current = to_visit.pop()\n            if current not in descendants:\n                descendants.add(current)\n                to_visit.extend([n for (s, n) in edges if s == current])\n        return descendants\n    \n    descendants_of_T = find_descendants(treatment)\n    \n    # æ£€æŸ¥è°ƒæ•´é›†æ˜¯å¦åŒ…å« treatment çš„åä»£\n    contains_descendant = bool(adjustment_set & descendants_of_T)\n    \n    if contains_descendant:\n        return False  # è¿åæ¡ä»¶ 2\n    \n    # æ­¥éª¤ 2: æ‰¾å‡ºæ‰€æœ‰åé—¨è·¯å¾„\n    backdoor_paths = identify_backdoor_paths(edges, treatment, outcome)\n    \n    # æ£€æŸ¥è°ƒæ•´é›†æ˜¯å¦é˜»æ–­æ‰€æœ‰åé—¨è·¯å¾„\n    # ä¸€æ¡è·¯å¾„è¢«é˜»æ–­å½“ä¸”ä»…å½“è°ƒæ•´é›†åŒ…å«è·¯å¾„ä¸Šçš„è‡³å°‘ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆé™¤äº† T å’Œ Yï¼‰\n    for path in backdoor_paths:\n        path_nodes = set(path) - {treatment, outcome}\n        # æ£€æŸ¥ adjustment_set æ˜¯å¦ä¸ path_nodes æœ‰äº¤é›†\n        is_blocked = bool(adjustment_set & path_nodes)\n        \n        if not is_blocked:\n            return False  # æœ‰åé—¨è·¯å¾„æ²¡è¢«é˜»æ–­\n    \n    return True"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•è°ƒæ•´é›†\n",
    "test_edges = [(\"X\", \"T\"), (\"X\", \"Y\"), (\"T\", \"Y\")]\n",
    "\n",
    "print(\"DAG: X â†’ T, X â†’ Y, T â†’ Y\")\n",
    "print(\"\\næ£€éªŒä¸åŒçš„è°ƒæ•´é›†:\")\n",
    "\n",
    "adjustment_sets = [set(), {\"X\"}, {\"Y\"}]\n",
    "for adj_set in adjustment_sets:\n",
    "    result = is_valid_adjustment_set(test_edges, \"T\", \"Y\", adj_set)\n",
    "    status = \"âœ… æœ‰æ•ˆ\" if result else \"âŒ æ— æ•ˆ\"\n",
    "    print(f\"   è°ƒæ•´é›† {adj_set if adj_set else '{}'}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<details>\n<summary>ğŸ“ å‚è€ƒç­”æ¡ˆï¼ˆç‚¹å‡»å±•å¼€ï¼‰</summary>\n\n```python\ndef simulate_collider_bias(n: int = 2000, seed: int = 42):\n    \"\"\"æ¨¡æ‹Ÿç¢°æ’åå·®\"\"\"\n    np.random.seed(seed)\n    \n    # ç”Ÿæˆæ¼”æŠ€ Tï¼ˆç‹¬ç«‹ï¼‰\n    T = np.random.uniform(0, 10, n)\n    \n    # ç”Ÿæˆé¢œå€¼ Yï¼ˆç‹¬ç«‹ï¼‰\n    Y = np.random.uniform(0, 10, n)\n    \n    # ç”Ÿæˆç¢°æ’å˜é‡ Cï¼ˆæ˜¯å¦æˆä¸ºæ˜æ˜Ÿï¼‰\n    C = (T + Y > 12).astype(int)\n    \n    df = pd.DataFrame({'æ¼”æŠ€': T, 'é¢œå€¼': Y, 'æ˜æ˜Ÿ': C})\n    \n    # è®¡ç®—ç›¸å…³æ€§\n    overall_corr = np.corrcoef(T, Y)[0, 1]\n    \n    # åªçœ‹æ˜æ˜Ÿçš„ç›¸å…³æ€§\n    stars = df[df['æ˜æ˜Ÿ'] == 1]\n    conditional_corr = np.corrcoef(stars['æ¼”æŠ€'], stars['é¢œå€¼'])[0, 1] if len(stars) > 10 else 0\n    \n    return df, overall_corr, conditional_corr\n```\n\n**è§£é‡Š**ï¼š\n- **DAG ç»“æ„**: T â†’ C â† Yï¼ˆç¢°æ’ç»“æ„ï¼‰\n  - Tï¼ˆæ¼”æŠ€ï¼‰å’Œ Yï¼ˆé¢œå€¼ï¼‰æœ¬æ¥æ˜¯**ç‹¬ç«‹çš„**\n  - Cï¼ˆæ˜¯å¦æˆä¸ºæ˜æ˜Ÿï¼‰æ˜¯ç¢°æ’å˜é‡\n  \n- **ç¢°æ’æ¡ä»¶**: T + Y > 12\n  - éœ€è¦æ¼”æŠ€å’Œé¢œå€¼çš„æ€»å’Œè¶³å¤Ÿé«˜æ‰èƒ½æˆä¸ºæ˜æ˜Ÿ\n  - å¯ä»¥æ¼”æŠ€å¾ˆé«˜é¢œå€¼ä¸€èˆ¬ï¼Œæˆ–é¢œå€¼å¾ˆé«˜æ¼”æŠ€ä¸€èˆ¬\n  - è¿™åˆ›é€ äº†ã€Œæ›¿ä»£ã€å…³ç³»\n  \n- **å¥½è±åæ‚–è®º**:\n  - æ€»äººå£ï¼šæ¼”æŠ€å’Œé¢œå€¼ç›¸å…³æ€§ â‰ˆ 0ï¼ˆç‹¬ç«‹ï¼‰\n  - æ˜æ˜Ÿç¾¤ä½“ï¼šæ¼”æŠ€å’Œé¢œå€¼å‘ˆç°**è´Ÿç›¸å…³**\n  - åŸå› ï¼šåœ¨æ˜æ˜Ÿä¸­ï¼Œé«˜æ¼”æŠ€çš„äººå¯èƒ½é¢œå€¼ä¸€èˆ¬ï¼ˆé æ¼”æŠ€è¿›æ¥çš„ï¼‰\n  \n- **å¯ç¤º**: æ§åˆ¶ç¢°æ’å˜é‡ä¼šåˆ›é€ è™šå‡å…³è”ï¼\n</details>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ“– ç¤ºèŒƒä»£ç : æ¨¡æ‹Ÿç»å…¸æ··æ·† DAG\n\ndef simulate_confounding_dag(n: int = 2000, seed: int = 42):\n    \"\"\"\n    æ¨¡æ‹Ÿç»å…¸æ··æ·† DAG çš„æ•°æ®\n    \n    DAG: X â†’ T, X â†’ Y, T â†’ Y\n    \n    æ•°æ®ç”Ÿæˆè¿‡ç¨‹:\n    - X ~ N(0, 1)\n    - T = 1 if X + noise > 0 else 0\n    - Y = 1 + 2*T + 1.5*X + noise\n    \n    çœŸå® ATE = 2\n    \"\"\"\n    np.random.seed(seed)\n    \n    # ç”Ÿæˆæ··æ·†å˜é‡ X\n    X = np.random.randn(n)\n    \n    # ç”Ÿæˆå¤„ç† Tï¼ˆå— X å½±å“ï¼‰\n    # T = 1 å½“ X + noise > 0\n    T = (X + np.random.randn(n) > 0).astype(int)\n    \n    # ç”Ÿæˆç»“æœ Yï¼ˆå— T å’Œ X å½±å“ï¼‰\n    # Y = 1 + 2*T + 1.5*X + noise\n    Y = 1 + 2 * T + 1.5 * X + np.random.randn(n) * 0.5\n    \n    df = pd.DataFrame({'X': X, 'T': T, 'Y': Y})\n    \n    return df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_ate_with_adjustment(df: pd.DataFrame, \n",
    "                                  adjustment_vars: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨çº¿æ€§å›å½’è¿›è¡Œè°ƒæ•´ä¼°è®¡\n",
    "    \n",
    "    Y = b0 + b1*T + b2*X1 + b3*X2 + ...\n",
    "    b1 å°±æ˜¯è°ƒæ•´åçš„ ATE ä¼°è®¡\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    # æ„å»ºç‰¹å¾çŸ©é˜µ\n",
    "    features = ['T'] + adjustment_vars\n",
    "    X = df[features].values\n",
    "    y = df['Y'].values\n",
    "    \n",
    "    # æ‹Ÿåˆçº¿æ€§å›å½’\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # T çš„ç³»æ•°å°±æ˜¯è°ƒæ•´åçš„ ATE\n",
    "    return model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œæ¨¡æ‹Ÿ\n",
    "df = simulate_confounding_dag(n=5000)\n",
    "\n",
    "if df is not None and df['X'] is not None:\n",
    "    true_ate = 2.0\n",
    "    \n",
    "    # æœ´ç´ ä¼°è®¡ï¼ˆä¸æ§åˆ¶ä»»ä½•å˜é‡ï¼‰\n",
    "    naive_ate = df[df['T']==1]['Y'].mean() - df[df['T']==0]['Y'].mean()\n",
    "    \n",
    "    # è°ƒæ•´ä¼°è®¡ï¼ˆæ§åˆ¶ Xï¼‰\n",
    "    adjusted_ate = estimate_ate_with_adjustment(df, ['X'])\n",
    "    \n",
    "    print(\"ğŸ”¬ æ··æ·† DAG æ¨¡æ‹Ÿç»“æœ:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"çœŸå® ATE: {true_ate:.4f}\")\n",
    "    print(f\"\\næœ´ç´ ä¼°è®¡ï¼ˆä¸æ§åˆ¶ Xï¼‰: {naive_ate:.4f}\")\n",
    "    print(f\"   åå·®: {naive_ate - true_ate:+.4f} {'âš ï¸ æœ‰åï¼' if abs(naive_ate - true_ate) > 0.1 else ''}\")\n",
    "    print(f\"\\nè°ƒæ•´ä¼°è®¡ï¼ˆæ§åˆ¶ Xï¼‰: {adjusted_ate:.4f}\")\n",
    "    print(f\"   åå·®: {adjusted_ate - true_ate:+.4f} {'âœ… å¾ˆå‡†ï¼' if abs(adjusted_ate - true_ate) < 0.1 else ''}\")\n",
    "else:\n",
    "    print(\"âŒ è¯·å®Œæˆ simulate_confounding_dag å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ“– ç¤ºèŒƒä»£ç : æ¨¡æ‹Ÿç¢°æ’åå·®ï¼ˆå¥½è±åæ‚–è®ºï¼‰\n\ndef simulate_collider_bias(n: int = 2000, seed: int = 42):\n    \"\"\"\n    æ¨¡æ‹Ÿç¢°æ’åå·®\n    \n    DAG: T â†’ C â† Yï¼ˆT å’Œ Y æœ¬æ¥æ˜¯ç‹¬ç«‹çš„ï¼ï¼‰\n    \n    åœºæ™¯: å¥½è±åæ‚–è®º\n    - T = æ¼”æŠ€ï¼ˆ0åˆ°10åˆ†ï¼‰\n    - Y = é¢œå€¼ï¼ˆ0åˆ°10åˆ†ï¼‰\n    - C = æ˜¯å¦æˆä¸ºæ˜æ˜Ÿï¼ˆéœ€è¦æ¼”æŠ€+é¢œå€¼ > 12ï¼‰\n    \n    æ¼”æŠ€å’Œé¢œå€¼æ˜¯ç‹¬ç«‹çš„ï¼ä½†åœ¨æ˜æ˜Ÿç¾¤ä½“ä¸­ä¼šå‘ˆç°è´Ÿç›¸å…³ã€‚\n    \"\"\"\n    np.random.seed(seed)\n    \n    # ç”Ÿæˆæ¼”æŠ€ Tï¼ˆç‹¬ç«‹ï¼‰\n    T = np.random.uniform(0, 10, n)\n    \n    # ç”Ÿæˆé¢œå€¼ Yï¼ˆç‹¬ç«‹ï¼‰\n    Y = np.random.uniform(0, 10, n)\n    \n    # ç”Ÿæˆç¢°æ’å˜é‡ Cï¼ˆæ˜¯å¦æˆä¸ºæ˜æ˜Ÿï¼‰\n    # å½“ T + Y > 12 æ—¶æˆä¸ºæ˜æ˜Ÿ\n    C = (T + Y > 12).astype(int)\n    \n    df = pd.DataFrame({'æ¼”æŠ€': T, 'é¢œå€¼': Y, 'æ˜æ˜Ÿ': C})\n    \n    # è®¡ç®—ç›¸å…³æ€§\n    overall_corr = np.corrcoef(T, Y)[0, 1]\n    \n    # åªçœ‹æ˜æ˜Ÿçš„ç›¸å…³æ€§\n    stars = df[df['æ˜æ˜Ÿ'] == 1]\n    conditional_corr = np.corrcoef(stars['æ¼”æŠ€'], stars['é¢œå€¼'])[0, 1] if len(stars) > 10 else 0\n    \n    return df, overall_corr, conditional_corr"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œç¢°æ’åå·®æ¨¡æ‹Ÿ\n",
    "df_collider, overall, conditional = simulate_collider_bias(n=5000)\n",
    "\n",
    "if overall is not None:\n",
    "    print(\"ğŸ¬ å¥½è±åæ‚–è®ºæ¨¡æ‹Ÿ:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"æ€»äººå£ä¸­æ¼”æŠ€å’Œé¢œå€¼çš„ç›¸å…³æ€§: {overall:.4f}\")\n",
    "    print(f\"   è§£è¯»: {'å‡ ä¹ä¸ç›¸å…³ âœ…' if abs(overall) < 0.1 else 'æœ‰ç›¸å…³æ€§'}\")\n",
    "    print(f\"\\nåªçœ‹æ˜æ˜Ÿæ—¶æ¼”æŠ€å’Œé¢œå€¼çš„ç›¸å…³æ€§: {conditional:.4f}\")\n",
    "    print(f\"   è§£è¯»: {'å¼ºè´Ÿç›¸å…³ âš ï¸' if conditional < -0.3 else 'æœ‰è´Ÿç›¸å…³'}\")\n",
    "    \n",
    "    print(f\"\\næ˜æ˜Ÿå æ€»äººå£: {df_collider['æ˜æ˜Ÿ'].mean()*100:.1f}%\")\n",
    "else:\n",
    "    print(\"âŒ è¯·å®Œæˆ simulate_collider_bias å‡½æ•°ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## ğŸ¯ é¢è¯•é¢˜æ¨¡æ‹Ÿ\n\n### æ¦‚å¿µé¢˜\n\n**Q1: ä»€ä¹ˆæ˜¯å› æœå›¾ï¼ˆDAGï¼‰ï¼Ÿå®ƒä¸ä¼ ç»Ÿçš„ç»Ÿè®¡å›¾ï¼ˆå¦‚ç›¸å…³ç³»æ•°çŸ©é˜µï¼‰æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ**\n\n<details>\n<summary>ç­”æ¡ˆ</summary>\n\n**å› æœå›¾ï¼ˆDAGï¼‰**:\n- Directed Acyclic Graphï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰\n- èŠ‚ç‚¹è¡¨ç¤ºå˜é‡ï¼Œè¾¹è¡¨ç¤ºå› æœå…³ç³»ï¼ˆç®­å¤´æ–¹å‘è¡¨ç¤ºå› æœæ–¹å‘ï¼‰\n- ç¼–ç äº†å˜é‡ä¹‹é—´çš„å› æœå‡è®¾ï¼Œè€Œéä»…ä»…æ˜¯ç»Ÿè®¡å…³è”\n\n**ä¸ç›¸å…³ç³»æ•°çŸ©é˜µçš„åŒºåˆ«**:\n\n| ç‰¹æ€§ | å› æœå›¾ | ç›¸å…³ç³»æ•°çŸ©é˜µ |\n|-----|--------|------------|\n| æ–¹å‘æ€§ | æœ‰æ–¹å‘ï¼ˆA â†’ B â‰  B â†’ Aï¼‰ | æ— æ–¹å‘ï¼ˆå¯¹ç§°ï¼‰ |\n| å› æœæ€§ | ç¼–ç å› æœå…³ç³» | ä»…ç¼–ç ç›¸å…³æ€§ |\n| æ¡ä»¶ç‹¬ç«‹ | d-åˆ†ç¦»â†’æ¡ä»¶ç‹¬ç«‹ | æ— æ³•æ¨æ–­ |\n| å¹²é¢„ | å¯é¢„æµ‹å¹²é¢„æ•ˆæœ | æ— æ³•é¢„æµ‹ |\n\n**ä¾‹å­**:\n- ç›¸å…³ç³»æ•°ï¼šå†°æ·‡æ·‹é”€é‡å’Œæººæ°´äººæ•°æ­£ç›¸å…³ï¼ˆr = 0.7ï¼‰\n- å› æœå›¾ï¼šæ¸©åº¦ â†’ å†°æ·‡æ·‹é”€é‡ï¼Œæ¸©åº¦ â†’ æ¸¸æ³³äººæ•° â†’ æººæ°´\n- ç»“è®ºï¼šç¦å”®å†°æ·‡æ·‹ä¸ä¼šå‡å°‘æººæ°´ï¼ˆå› æœå›¾æ­£ç¡®ï¼Œç›¸å…³æ€§è¯¯å¯¼ï¼‰\n\n</details>\n\n---\n\n**Q2: è§£é‡Šåé—¨å‡†åˆ™ï¼ˆBackdoor Criterionï¼‰çš„å«ä¹‰ï¼Œå¹¶ä¸¾ä¾‹è¯´æ˜ä»€ä¹ˆæ ·çš„å˜é‡é›†åˆæ»¡è¶³åé—¨å‡†åˆ™ã€‚**\n\n<details>\n<summary>ç­”æ¡ˆ</summary>\n\n**åé—¨å‡†åˆ™å®šä¹‰**:\n\nå˜é‡é›†åˆ Z æ»¡è¶³ç›¸å¯¹äº (T, Y) çš„åé—¨å‡†åˆ™ï¼Œéœ€æ»¡è¶³ï¼š\n1. Z é˜»æ–­æ‰€æœ‰ä» T åˆ° Y çš„åé—¨è·¯å¾„\n2. Z ä¸åŒ…å« T çš„ä»»ä½•åä»£\n\n**ç›´è§‰**: Z å…³é—­äº†ã€Œæ··æ·†çš„é—¨ã€ï¼Œä½†ä¿ç•™äº†ã€Œå› æœçš„è·¯å¾„ã€ã€‚\n\n**ä¾‹å­ 1: ç®€å•æ··æ·†**\n```\nDAG: X â†’ T, X â†’ Y, T â†’ Y\nåé—¨è·¯å¾„: T â† X â†’ Y\nè°ƒæ•´é›†: {X} âœ“ æ»¡è¶³\n- X é˜»æ–­å”¯ä¸€åé—¨è·¯å¾„\n- X ä¸æ˜¯ T çš„åä»£\n```\n\n**ä¾‹å­ 2: ä¸­ä»‹å˜é‡**\n```\nDAG: T â†’ M â†’ Y, X â†’ T, X â†’ Y\nåé—¨è·¯å¾„: T â† X â†’ Y\nè°ƒæ•´é›†: {M} âœ— ä¸æ»¡è¶³\n- M æ˜¯ T çš„åä»£ï¼ˆè¿åæ¡ä»¶2ï¼‰\n- æ§åˆ¶ M ä¼šé˜»æ–­å› æœè·¯å¾„ T â†’ M â†’ Y\næ­£ç¡®è°ƒæ•´é›†: {X}\n```\n\n**ä¾‹å­ 3: ç¢°æ’å˜é‡**\n```\nDAG: T â†’ C â† Y, T â†’ Y\nè°ƒæ•´é›†: {C} âœ— ä¸æ»¡è¶³\n- C æ˜¯ç¢°æ’å˜é‡ï¼Œæœ¬æ¥é˜»æ–­ï¼Œæ§åˆ¶ååè€Œæ‰“å¼€è·¯å¾„\n- ä¼šå¼•å…¥è™šå‡å…³è”\næ­£ç¡®è°ƒæ•´é›†: {} (ç©ºé›†ï¼Œä¸éœ€è¦æ§åˆ¶ä»»ä½•å˜é‡)\n```\n\n**å®è·µæ„ä¹‰**: åé—¨å‡†åˆ™å‘Šè¯‰æˆ‘ä»¬ã€Œåº”è¯¥æ§åˆ¶å“ªäº›å˜é‡ã€æ¥è¯†åˆ«å› æœæ•ˆåº”ã€‚\n\n</details>\n\n---\n\n**Q3: ä¸ºä»€ä¹ˆæ§åˆ¶ç¢°æ’å˜é‡ä¼šå¼•å…¥åå·®ï¼Ÿç”¨å¥½è±åæ‚–è®ºæˆ–ä¼¯å…‹åˆ©æ€§åˆ«æ­§è§†æ¡ˆè§£é‡Šã€‚**\n\n<details>\n<summary>ç­”æ¡ˆ</summary>\n\n**ç¢°æ’å˜é‡çš„ç‰¹æ€§**:\n- ç»“æ„ï¼šT â†’ C â† Y\n- T å’Œ Y æœ¬æ¥ç‹¬ç«‹ï¼Œä½†éƒ½å½±å“ C\n- æ§åˆ¶ Cï¼ˆæ¡ä»¶äº C=æŸå€¼ï¼‰ä¼šæ‰“å¼€ T å’Œ Y ä¹‹é—´çš„è™šå‡å…³è”\n\n**å¥½è±åæ‚–è®ºä¾‹å­**:\n\nDAG: æ¼”æŠ€ â†’ æˆä¸ºæ˜æ˜Ÿ â† é¢œå€¼\n\n1. **æ€»äººå£**: æ¼”æŠ€å’Œé¢œå€¼ç‹¬ç«‹ï¼ˆç›¸å…³æ€§â‰ˆ0ï¼‰\n2. **åªçœ‹æ˜æ˜Ÿ**: æ¼”æŠ€å’Œé¢œå€¼è´Ÿç›¸å…³ï¼ˆç›¸å…³æ€§<0ï¼‰\n3. **åŸå› **: \n   - æˆä¸ºæ˜æ˜Ÿéœ€è¦æ¼”æŠ€+é¢œå€¼è¶³å¤Ÿé«˜\n   - åœ¨æ˜æ˜Ÿä¸­ï¼Œé«˜æ¼”æŠ€çš„äººå¯èƒ½é¢œå€¼ä¸€èˆ¬ï¼ˆé æ¼”æŠ€è¿›æ¥ï¼‰\n   - åœ¨æ˜æ˜Ÿä¸­ï¼Œé«˜é¢œå€¼çš„äººå¯èƒ½æ¼”æŠ€ä¸€èˆ¬ï¼ˆé è„¸è¿›æ¥ï¼‰\n   - è¿™æ˜¯ã€Œæ›¿ä»£æ•ˆåº”ã€\n\n**æ•°å­¦ç›´è§‰**:\n\næ¡ä»¶æ¦‚ç‡çš„è´å¶æ–¯å…¬å¼ï¼š\n$$P(T=1 \\mid C=1, Y=0) > P(T=1 \\mid C=1, Y=1)$$\n\nè§£é‡Šï¼š\n- å¦‚æœå·²çŸ¥æŸäººæ˜¯æ˜æ˜Ÿï¼ˆC=1ï¼‰ä¸”é¢œå€¼ä¸é«˜ï¼ˆY=0ï¼‰\n- é‚£ä¹ˆä»–æ¼”æŠ€é«˜ï¼ˆT=1ï¼‰çš„æ¦‚ç‡æ›´å¤§ï¼ˆå¦åˆ™æ€ä¹ˆæˆä¸ºæ˜æ˜Ÿï¼Ÿï¼‰\n- è¿™å°±æ˜¯è´Ÿç›¸å…³\n\n**å®è·µè­¦ç¤º**:\n- ä¸è¦æ§åˆ¶ç¢°æ’å˜é‡ï¼ˆå¦‚ã€Œåªçœ‹æˆåŠŸè€…ã€ã€Œåªçœ‹å­˜æ´»è€…ã€ï¼‰\n- å­˜æ´»è€…åå·®ï¼ˆSurvivorship Biasï¼‰å°±æ˜¯ç¢°æ’åå·®çš„ä¸€ç§\n\n</details>\n\n---\n\n### ç¼–ç¨‹é¢˜\n\n**Q4: ç»™å®šä¸€ä¸ª DAGï¼Œè¯·å®ç°å‡½æ•°æ‰¾å‡ºæ‰€æœ‰æ»¡è¶³åé—¨å‡†åˆ™çš„æœ€å°è°ƒæ•´é›†ã€‚**\n\n<details>\n<summary>å‚è€ƒä»£ç </summary>\n\n```python\nfrom itertools import combinations\n\ndef find_all_valid_adjustment_sets(edges, treatment, outcome):\n    \"\"\"\n    æ‰¾å‡ºæ‰€æœ‰æ»¡è¶³åé—¨å‡†åˆ™çš„è°ƒæ•´é›†\n    \n    ç­–ç•¥ï¼š\n    1. åˆ—ä¸¾æ‰€æœ‰å¯èƒ½çš„å˜é‡å­é›†\n    2. å¯¹æ¯ä¸ªå­é›†æ£€éªŒæ˜¯å¦æ»¡è¶³åé—¨å‡†åˆ™\n    3. æ‰¾å‡ºæœ€å°çš„ï¼ˆèŠ‚ç‚¹æ•°æœ€å°‘ï¼‰\n    \"\"\"\n    # è·å–æ‰€æœ‰èŠ‚ç‚¹\n    all_nodes = set()\n    for u, v in edges:\n        all_nodes.add(u)\n        all_nodes.add(v)\n    \n    # æ’é™¤ T å’Œ Y\n    candidates = all_nodes - {treatment, outcome}\n    \n    # æ‰¾å‡º T çš„åä»£ï¼ˆä¸èƒ½æ§åˆ¶ï¼‰\n    descendants = find_descendants(edges, treatment)\n    candidates = candidates - descendants\n    \n    # æšä¸¾æ‰€æœ‰å­é›†ï¼Œä»å°åˆ°å¤§\n    valid_sets = []\n    for size in range(len(candidates) + 1):\n        for subset in combinations(candidates, size):\n            adj_set = set(subset)\n            if is_valid_adjustment_set(edges, treatment, outcome, adj_set):\n                valid_sets.append(adj_set)\n    \n    # æ‰¾å‡ºæœ€å°çš„\n    if not valid_sets:\n        return []\n    \n    min_size = min(len(s) for s in valid_sets)\n    minimal_sets = [s for s in valid_sets if len(s) == min_size]\n    \n    return minimal_sets\n\ndef find_descendants(edges, node):\n    \"\"\"æ‰¾å‡ºä¸€ä¸ªèŠ‚ç‚¹çš„æ‰€æœ‰åä»£\"\"\"\n    descendants = set()\n    to_visit = [v for (u, v) in edges if u == node]\n    \n    while to_visit:\n        current = to_visit.pop()\n        if current not in descendants:\n            descendants.add(current)\n            to_visit.extend([v for (u, v) in edges if u == current])\n    \n    return descendants\n\n# æµ‹è¯•\nedges = [\n    (\"X1\", \"T\"), (\"X1\", \"Y\"),  # X1 æ˜¯æ··æ·†\n    (\"X2\", \"T\"), (\"X2\", \"Y\"),  # X2 æ˜¯æ··æ·†\n    (\"T\", \"M\"), (\"M\", \"Y\"),     # M æ˜¯ä¸­ä»‹\n    (\"T\", \"C\"), (\"Y\", \"C\")      # C æ˜¯ç¢°æ’\n]\n\nminimal = find_all_valid_adjustment_sets(edges, \"T\", \"Y\")\nprint(\"æœ€å°è°ƒæ•´é›†:\")\nfor s in minimal:\n    print(f\"  {s if s else '{}'}\")\n\n# è¾“å‡º: {X1, X2}, {X1}, {X2} éƒ½å¯èƒ½æ˜¯æœ€å°è°ƒæ•´é›†\n# å…·ä½“å–å†³äºæ˜¯å¦ä¸¤ä¸ªéƒ½éœ€è¦é˜»æ–­æ‰€æœ‰åé—¨è·¯å¾„\n```\n\n**å…³é”®ç‚¹**:\n- å¿…é¡»é˜»æ–­æ‰€æœ‰åé—¨è·¯å¾„\n- ä¸èƒ½åŒ…å« T çš„åä»£ï¼ˆå¦‚ Mï¼‰\n- ä¸åº”åŒ…å«ç¢°æ’å˜é‡ï¼ˆå¦‚ Cï¼‰\n- æœ€å°è°ƒæ•´é›†å¯èƒ½ä¸å”¯ä¸€\n\n</details>\n\n---\n\n**Q5: å®ç°ä¸€ä¸ªå‡½æ•°ï¼Œæ¨¡æ‹Ÿä¸‰ç§å› æœç»“æ„ï¼ˆFork, Chain, Colliderï¼‰ï¼ŒéªŒè¯æ§åˆ¶ä¸­é—´èŠ‚ç‚¹çš„ä¸åŒæ•ˆæœã€‚**\n\n<details>\n<summary>å‚è€ƒä»£ç </summary>\n\n```python\ndef simulate_three_structures(n=2000, seed=42):\n    \"\"\"\n    æ¨¡æ‹Ÿå¹¶å¯¹æ¯”ä¸‰ç§å› æœç»“æ„\n    \n    1. Fork: T â† X â†’ Y (æ··æ·†)\n    2. Chain: T â†’ M â†’ Y (ä¸­ä»‹)\n    3. Collider: T â†’ C â† Y (ç¢°æ’)\n    \"\"\"\n    np.random.seed(seed)\n    results = {}\n    \n    # ===== Structure 1: Fork (æ··æ·†) =====\n    X = np.random.randn(n)\n    T_fork = (X + np.random.randn(n) > 0).astype(int)\n    Y_fork = X + np.random.randn(n) * 0.5  # Y ä¸å— T å½±å“ï¼Œåªå— X å½±å“\n    \n    # ä¸æ§åˆ¶ X: T å’Œ Y çœ‹èµ·æ¥ç›¸å…³\n    corr_unconditional_fork = np.corrcoef(T_fork, Y_fork)[0, 1]\n    \n    # æ§åˆ¶ X: T å’Œ Y ç‹¬ç«‹\n    from sklearn.linear_model import LinearRegression\n    model = LinearRegression().fit(np.column_stack([T_fork, X]), Y_fork)\n    residual_Y = Y_fork - model.predict(np.column_stack([T_fork, X]))\n    residual_T = T_fork - LinearRegression().fit(X.reshape(-1, 1), T_fork).predict(X.reshape(-1, 1))\n    corr_conditional_fork = np.corrcoef(residual_T, residual_Y)[0, 1]\n    \n    results['Fork'] = {\n        'ä¸æ§åˆ¶X': corr_unconditional_fork,\n        'æ§åˆ¶X': corr_conditional_fork\n    }\n    \n    # ===== Structure 2: Chain (ä¸­ä»‹) =====\n    T_chain = np.random.randn(n)\n    M = T_chain + np.random.randn(n) * 0.5\n    Y_chain = M + np.random.randn(n) * 0.5  # Y é€šè¿‡ M å— T å½±å“\n    \n    # ä¸æ§åˆ¶ M: T å’Œ Y ç›¸å…³ï¼ˆæ€»æ•ˆåº”ï¼‰\n    corr_unconditional_chain = np.corrcoef(T_chain, Y_chain)[0, 1]\n    \n    # æ§åˆ¶ M: T å’Œ Y ç‹¬ç«‹ï¼ˆç›´æ¥æ•ˆåº”=0ï¼‰\n    model = LinearRegression().fit(np.column_stack([T_chain, M]), Y_chain)\n    residual_Y = Y_chain - model.predict(np.column_stack([T_chain, M]))\n    residual_T = T_chain - LinearRegression().fit(M.reshape(-1, 1), T_chain).predict(M.reshape(-1, 1))\n    corr_conditional_chain = np.corrcoef(residual_T, residual_Y)[0, 1]\n    \n    results['Chain'] = {\n        'ä¸æ§åˆ¶M': corr_unconditional_chain,\n        'æ§åˆ¶M': corr_conditional_chain\n    }\n    \n    # ===== Structure 3: Collider (ç¢°æ’) =====\n    T_collider = np.random.randn(n)\n    Y_collider = np.random.randn(n)  # T å’Œ Y ç‹¬ç«‹\n    C = T_collider + Y_collider + np.random.randn(n) * 0.5\n    \n    # ä¸æ§åˆ¶ C: T å’Œ Y ç‹¬ç«‹\n    corr_unconditional_collider = np.corrcoef(T_collider, Y_collider)[0, 1]\n    \n    # æ§åˆ¶ C: T å’Œ Y ç›¸å…³ï¼ˆè™šå‡å…³è”ï¼‰\n    model = LinearRegression().fit(np.column_stack([T_collider, C]), Y_collider)\n    residual_Y = Y_collider - model.predict(np.column_stack([T_collider, C]))\n    residual_T = T_collider - LinearRegression().fit(C.reshape(-1, 1), T_collider).predict(C.reshape(-1, 1))\n    corr_conditional_collider = np.corrcoef(residual_T, residual_Y)[0, 1]\n    \n    results['Collider'] = {\n        'ä¸æ§åˆ¶C': corr_unconditional_collider,\n        'æ§åˆ¶C': corr_conditional_collider\n    }\n    \n    return results\n\n# è¿è¡Œå¹¶å±•ç¤º\nresults = simulate_three_structures()\nfor structure, corrs in results.items():\n    print(f\"\\n{structure}:\")\n    for condition, corr in corrs.items():\n        print(f\"  {condition}: {corr:.4f}\")\n\n# é¢„æœŸè¾“å‡º:\n# Fork: ä¸æ§åˆ¶X é«˜ç›¸å…³ï¼Œæ§åˆ¶X ä½ç›¸å…³ (é˜»æ–­æ··æ·†)\n# Chain: ä¸æ§åˆ¶M é«˜ç›¸å…³ï¼Œæ§åˆ¶M ä½ç›¸å…³ (é˜»æ–­å› æœé“¾)\n# Collider: ä¸æ§åˆ¶C ä½ç›¸å…³ï¼Œæ§åˆ¶C é«˜ç›¸å…³ (æ‰“å¼€è·¯å¾„!)\n```\n\n**å…³é”®å‘ç°**:\n1. Fork å’Œ Chain: æ§åˆ¶ä¸­é—´èŠ‚ç‚¹**é˜»æ–­**å…³è”\n2. Collider: æ§åˆ¶ä¸­é—´èŠ‚ç‚¹**æ‰“å¼€**å…³è”ï¼ˆç›¸åï¼ï¼‰\n3. è¿™éªŒè¯äº† d-åˆ†ç¦»çš„ä¸‰ç§è§„åˆ™\n\n</details>\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## ğŸ“ æ•°å­¦æ¨å¯¼\n\n### 1. d-åˆ†ç¦»çš„å½¢å¼åŒ–å®šä¹‰\n\n**å®šä¹‰**: åœ¨ DAG G ä¸­ï¼Œç»™å®šèŠ‚ç‚¹é›†åˆ Zï¼Œå¦‚æœ Z é˜»æ–­äº† X å’Œ Y ä¹‹é—´çš„æ‰€æœ‰è·¯å¾„ï¼Œåˆ™ç§° X å’Œ Y è¢« Z d-åˆ†ç¦»ã€‚\n\næ•°å­¦è¡¨è¾¾ï¼š$(X \\perp\\!\\!\\!\\perp Y \\mid Z)_G$\n\n**é˜»æ–­è§„åˆ™** (Pearl, 1988):\n\nä¸€æ¡è·¯å¾„ P è¢«é›†åˆ Z é˜»æ–­ï¼Œå½“ä¸”ä»…å½“ï¼š\n\n1. **Fork (å‰å­)**: $A \\leftarrow B \\rightarrow C$\n   - å¦‚æœ B âˆˆ Zï¼Œè·¯å¾„è¢«é˜»æ–­\n   - ç›´è§‰ï¼šæ§åˆ¶ä¸­é—´èŠ‚ç‚¹é˜»æ–­å…³è”\n\n2. **Chain (é“¾æ¡)**: $A \\rightarrow B \\rightarrow C$\n   - å¦‚æœ B âˆˆ Zï¼Œè·¯å¾„è¢«é˜»æ–­\n   - ç›´è§‰ï¼šæ§åˆ¶ä¸­é—´èŠ‚ç‚¹é˜»æ–­ä¼ é€’\n\n3. **Collider (ç¢°æ’)**: $A \\rightarrow B \\leftarrow C$\n   - å¦‚æœ B âˆ‰ Z **ä¸”** B çš„æ‰€æœ‰åä»£éƒ½ âˆ‰ Zï¼Œè·¯å¾„è¢«é˜»æ–­\n   - å¦‚æœ B âˆˆ Z **æˆ–** B çš„æŸä¸ªåä»£ âˆˆ Zï¼Œè·¯å¾„è¢«**æ‰“å¼€**\n   - ç›´è§‰ï¼šç¢°æ’é»˜è®¤é˜»æ–­ï¼Œæ§åˆ¶ååè€Œæ‰“å¼€\n\n**d-åˆ†ç¦»å®šç†** (Pearl):\n$$P(X, Y \\mid Z) = P(X \\mid Z) \\cdot P(Y \\mid Z) \\iff (X \\perp\\!\\!\\!\\perp Y \\mid Z)_G$$\n\nå³ï¼šå›¾ä¸­çš„ d-åˆ†ç¦»å¯¹åº”æ¦‚ç‡åˆ†å¸ƒä¸­çš„æ¡ä»¶ç‹¬ç«‹ã€‚\n\n---\n\n### 2. åé—¨å‡†åˆ™çš„å½¢å¼åŒ–è¯æ˜\n\n**åé—¨å‡†åˆ™** (Pearl, 1993): \n\nç»™å®š DAG Gï¼Œå˜é‡é›†åˆ Z æ»¡è¶³ç›¸å¯¹äº (T, Y) çš„åé—¨å‡†åˆ™ï¼Œå½“ä¸”ä»…å½“ï¼š\n\n1. Z ä¸­æ²¡æœ‰ T çš„åä»£\n2. Z é˜»æ–­æ‰€æœ‰ä» T åˆ° Y çš„åŒ…å«æŒ‡å‘ T çš„ç®­å¤´çš„è·¯å¾„\n\n**å®šç†**: å¦‚æœ Z æ»¡è¶³åé—¨å‡†åˆ™ï¼Œåˆ™ï¼š\n\n$$P(Y(t)) = \\sum_z P(Y \\mid T=t, Z=z) \\cdot P(Z=z)$$\n\n**è¯æ˜æ€è·¯**:\n\n1. **å› æœæ•ˆåº”å®šä¹‰**: \n   $$P(Y(t)) = \\sum_x P(Y(t) \\mid X=x) \\cdot P(X=x)$$\n   å…¶ä¸­ X æ˜¯æ‰€æœ‰å˜é‡ã€‚\n\n2. **do-calculus è§„åˆ™**: \n   å¦‚æœ Z é˜»æ–­æ‰€æœ‰åé—¨è·¯å¾„ï¼Œåˆ™ï¼š\n   $$P(Y \\mid do(T=t), Z=z) = P(Y \\mid T=t, Z=z)$$\n   \n3. **è¾¹é™…åŒ–**: \n   $$P(Y \\mid do(T=t)) = \\sum_z P(Y \\mid do(T=t), Z=z) \\cdot P(Z=z)$$\n   \n4. **æ›¿æ¢**: \n   $$= \\sum_z P(Y \\mid T=t, Z=z) \\cdot P(Z=z)$$\n\n**ç›´è§‰**: æ§åˆ¶ Z åï¼ŒT å¯¹ Y çš„æ•ˆåº”æ˜¯å› æœçš„ï¼ˆä¸å†æœ‰æ··æ·†ï¼‰ã€‚\n\n---\n\n### 3. ç¢°æ’åå·®çš„æ•°å­¦è¯´æ˜\n\n**è®¾å®š**: T â†’ C â† Yï¼ŒT å’Œ Y æœ¬æ¥ç‹¬ç«‹\n\n**å‘½é¢˜**: åœ¨æ€»äººå£ä¸­ $T \\perp\\!\\!\\!\\perp Y$ï¼Œä½†æ¡ä»¶äº C åï¼ŒT å’Œ Y ä¸ç‹¬ç«‹ã€‚\n\n**è¯æ˜**:\n\nå‡è®¾ï¼š\n- P(T = 1) = P(T = 0) = 0.5\n- P(Y = 1) = P(Y = 0) = 0.5\n- P(C = 1 | T, Y) = (T + Y) / 2\n\nå³ï¼šC = 1 éœ€è¦ T æˆ– Y è‡³å°‘æœ‰ä¸€ä¸ªä¸º 1ã€‚\n\n**æ€»äººå£**: \n$$P(T = 1, Y = 1) = P(T = 1) \\cdot P(Y = 1) = 0.25$$\n$$P(T = 1) \\cdot P(Y = 1) = 0.5 \\times 0.5 = 0.25$$\n\nå› æ­¤ $T \\perp\\!\\!\\!\\perp Y$ âœ“\n\n**æ¡ä»¶äº C = 1**: \n$$P(T = 1, Y = 1 \\mid C = 1) = \\frac{P(C = 1 \\mid T = 1, Y = 1) \\cdot P(T = 1, Y = 1)}{P(C = 1)}$$\n\nè®¡ç®—ï¼š\n- $P(C = 1 \\mid T = 1, Y = 1) = 1$\n- $P(C = 1 \\mid T = 1, Y = 0) = 0.5$\n- $P(C = 1 \\mid T = 0, Y = 1) = 0.5$\n- $P(C = 1 \\mid T = 0, Y = 0) = 0$\n\n$$P(C = 1) = 1 \\times 0.25 + 0.5 \\times 0.25 + 0.5 \\times 0.25 + 0 \\times 0.25 = 0.5$$\n\n$$P(T = 1, Y = 1 \\mid C = 1) = \\frac{1 \\times 0.25}{0.5} = 0.5$$\n\nè€Œï¼š\n$$P(T = 1 \\mid C = 1) \\cdot P(Y = 1 \\mid C = 1) = 0.5 \\times 0.5 = 0.25 \\neq 0.5$$\n\nå› æ­¤ $T \\not\\perp\\!\\!\\!\\perp Y \\mid C$ âœ—\n\n**ç»“è®º**: æ§åˆ¶ç¢°æ’å˜é‡ä¼šå¼•å…¥ä¾èµ–å…³ç³»ï¼ˆè™šå‡å…³è”ï¼‰ã€‚\n\n---\n\n### 4. å‰é—¨å‡†åˆ™ï¼ˆé¢å¤–çŸ¥è¯†ï¼‰\n\nå½“å­˜åœ¨æœªè§‚æµ‹æ··æ·† U ä½†æœ‰ä¸­ä»‹å˜é‡ M æ—¶ï¼š\n\n**DAG**: $T \\rightarrow M \\rightarrow Y, U \\rightarrow T, U \\rightarrow Y$\n\n**å‰é—¨å‡†åˆ™**: å¦‚æœï¼š\n1. M é˜»æ–­æ‰€æœ‰ä» T åˆ° Y çš„æœ‰å‘è·¯å¾„\n2. ä¸å­˜åœ¨ä» T åˆ° M çš„åé—¨è·¯å¾„\n3. T é˜»æ–­æ‰€æœ‰ä» M åˆ° Y çš„åé—¨è·¯å¾„\n\nåˆ™ï¼š\n$$P(Y(t)) = \\sum_m P(M = m \\mid T = t) \\sum_{t'} P(Y \\mid M = m, T = t') \\cdot P(T = t')$$\n\n**åº”ç”¨**: å½“æ— æ³•æ§åˆ¶æ··æ·† Uï¼Œä½†å¯ä»¥æµ‹é‡ä¸­ä»‹ M æ—¶ä½¿ç”¨ã€‚\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ç¢°æ’åå·®\n",
    "if overall is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # å›¾1: æ€»äººå£\n",
    "    ax1 = axes[0]\n",
    "    stars = df_collider[df_collider['æ˜æ˜Ÿ'] == 1]\n",
    "    non_stars = df_collider[df_collider['æ˜æ˜Ÿ'] == 0]\n",
    "    \n",
    "    ax1.scatter(non_stars['æ¼”æŠ€'], non_stars['é¢œå€¼'], \n",
    "                alpha=0.3, c='gray', label='æ™®é€šäºº', s=20)\n",
    "    ax1.scatter(stars['æ¼”æŠ€'], stars['é¢œå€¼'], \n",
    "                alpha=0.7, c='gold', label='æ˜æ˜Ÿ', s=50, edgecolors='black')\n",
    "    ax1.set_xlabel('æ¼”æŠ€')\n",
    "    ax1.set_ylabel('é¢œå€¼')\n",
    "    ax1.set_title(f'æ€»äººå£\\nç›¸å…³æ€§ = {overall:.3f}')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # å›¾2: åªçœ‹æ˜æ˜Ÿ\n",
    "    ax2 = axes[1]\n",
    "    ax2.scatter(stars['æ¼”æŠ€'], stars['é¢œå€¼'], \n",
    "                alpha=0.7, c='gold', s=50, edgecolors='black')\n",
    "    \n",
    "    # æ·»åŠ è¶‹åŠ¿çº¿\n",
    "    z = np.polyfit(stars['æ¼”æŠ€'], stars['é¢œå€¼'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_line = np.linspace(stars['æ¼”æŠ€'].min(), stars['æ¼”æŠ€'].max(), 100)\n",
    "    ax2.plot(x_line, p(x_line), 'r--', linewidth=2, label='è¶‹åŠ¿çº¿')\n",
    "    \n",
    "    ax2.set_xlabel('æ¼”æŠ€')\n",
    "    ax2.set_ylabel('é¢œå€¼')\n",
    "    ax2.set_title(f'åªçœ‹æ˜æ˜Ÿç¾¤ä½“\\nç›¸å…³æ€§ = {conditional:.3f} (è™šå‡è´Ÿç›¸å…³ï¼)')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nğŸ’¡ å¯ç¤º: æ§åˆ¶ç¢°æ’å˜é‡ä¼šåˆ›é€ è™šå‡å…³è”ï¼\")\n",
    "    print(\"   åœ¨å› æœæ¨æ–­ä¸­ï¼Œç»å¯¹ä¸èƒ½æ§åˆ¶ç¢°æ’å˜é‡ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Part 7: æ€è€ƒé¢˜\n",
    "\n",
    "### é—®é¢˜ 1: DAG åˆ†æ\n",
    "\n",
    "ç»™å®šä»¥ä¸‹ DAG:\n",
    "\n",
    "```\n",
    "X â†’ T â†’ Y â† U â†’ X\n",
    "```\n",
    "\n",
    "å›ç­”:\n",
    "- T å’Œ Y ä¹‹é—´æœ‰å“ªäº›è·¯å¾„ï¼Ÿ\n",
    "- å“ªäº›æ˜¯åé—¨è·¯å¾„ï¼Ÿ\n",
    "- æœ€å°è°ƒæ•´é›†æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„åˆ†æ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 2: ä¸ºä»€ä¹ˆæ§åˆ¶ç¢°æ’å˜é‡ä¼šå¼•å…¥åå·®ï¼Ÿ\n",
    "\n",
    "**æç¤º:** æƒ³æƒ³å¥½è±åæ‚–è®ºçš„ä¾‹å­...\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 3: ä¸­ä»‹å˜é‡åº”è¯¥æ§åˆ¶å—ï¼Ÿ\n",
    "\n",
    "åœ¨ä»¥ä¸‹ DAG ä¸­ï¼šT â†’ M â†’ Y\n",
    "\n",
    "- ä»€ä¹ˆæ—¶å€™åº”è¯¥æ§åˆ¶ Mï¼Ÿ\n",
    "- ä»€ä¹ˆæ—¶å€™ä¸åº”è¯¥æ§åˆ¶ Mï¼Ÿ\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é—®é¢˜ 4: æœªè§‚æµ‹æ··æ·†\n",
    "\n",
    "å¦‚æœå­˜åœ¨æœªè§‚æµ‹çš„æ··æ·†å˜é‡ Uï¼ˆæˆ‘ä»¬æ²¡æœ‰æ•°æ®ï¼‰ï¼Œæœ‰ä»€ä¹ˆæ–¹æ³•å¯ä»¥è¯†åˆ«å› æœæ•ˆåº”ï¼Ÿ\n",
    "\n",
    "**æç¤º:** æƒ³æƒ³å·¥å…·å˜é‡ã€æ–­ç‚¹å›å½’ã€åŒé‡å·®åˆ†...\n",
    "\n",
    "**ä½ çš„ç­”æ¡ˆ:**\n",
    "\n",
    "*ï¼ˆåœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ€è€ƒ...ï¼‰*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ‰ æ€»ç»“\n",
    "\n",
    "### æ ¸å¿ƒçŸ¥è¯†ç‚¹\n",
    "\n",
    "| æ¦‚å¿µ | å®šä¹‰ | è§„åˆ™ |\n",
    "|-----|------|------|\n",
    "| æ··æ·†å˜é‡ | T â† X â†’ Y | å¿…é¡»æ§åˆ¶ |\n",
    "| ä¸­ä»‹å˜é‡ | T â†’ M â†’ Y | ä¼°è®¡æ€»æ•ˆåº”æ—¶ä¸æ§åˆ¶ |\n",
    "| ç¢°æ’å˜é‡ | T â†’ C â† Y | ç»å¯¹ä¸èƒ½æ§åˆ¶ |\n",
    "\n",
    "### åé—¨å‡†åˆ™\n",
    "\n",
    "è¦æ— åä¼°è®¡ T å¯¹ Y çš„æ•ˆåº”ï¼š\n",
    "1. æ‰¾å‡ºæ‰€æœ‰åé—¨è·¯å¾„\n",
    "2. é€‰æ‹©ä¸€ç»„å˜é‡é˜»æ–­æ‰€æœ‰åé—¨è·¯å¾„\n",
    "3. ç¡®ä¿è¿™ç»„å˜é‡ä¸åŒ…å« T çš„åä»£\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬çŸ¥é“äº†ã€Œåº”è¯¥æ§åˆ¶ä»€ä¹ˆã€ï¼Œä¸‹ä¸€ä¸ªç»ƒä¹ æˆ‘ä»¬å°†æ·±å…¥å­¦ä¹ **æ··æ·†åå·®**â€”â€”å®ƒæœ‰å¤šå¤§ï¼Ÿæ€ä¹ˆé‡åŒ–ï¼Ÿæ€ä¹ˆé¿å…ï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "**ã€Œç”»å›¾å…ˆè¡Œï¼Œåˆ†æåè¡Œã€æ˜¯å› æœæ¨æ–­çš„ç¬¬ä¸€åŸåˆ™ã€‚**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}