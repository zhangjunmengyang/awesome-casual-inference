{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 Exercise 2: TARNet ä¸ DragonNet - æ·±åº¦å› æœæ¨æ–­çš„æ¼”è¿›\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "1. ç†è§£ TARNet çš„æ¶æ„è®¾è®¡å’Œ Factual Loss\n",
    "2. æŒæ¡ DragonNet çš„ä¸‰å¤´æ¶æ„å’Œå€¾å‘å¾—åˆ†æ­£åˆ™åŒ–\n",
    "3. ç†è§£ Targeted Regularization çš„åŸç†\n",
    "4. é€šè¿‡å¯¹æ¯”å®éªŒç†è§£ä¸¤è€…çš„åŒºåˆ«\n",
    "5. å­¦ä¼šåœ¨å®è·µä¸­é€‰æ‹©åˆé€‚çš„æ¨¡å‹\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å…±åŒèƒŒæ™¯ï¼šæ·±åº¦å­¦ä¹ ç”¨äºå› æœæ¨æ–­\n",
    "\n",
    "### ä¸ºä»€ä¹ˆéœ€è¦æ·±åº¦å­¦ä¹ ï¼Ÿ\n",
    "\n",
    "ä¼ ç»Ÿå› æœæ¨æ–­æ–¹æ³•ï¼ˆå¦‚ IPW, Matchingï¼‰é¢ä¸´çš„æŒ‘æˆ˜ï¼š\n",
    "- **é«˜ç»´ç‰¹å¾**: ç°ä»£åº”ç”¨ä¸­ç‰¹å¾ç»´åº¦å¯èƒ½å¾ˆé«˜ï¼ˆå›¾åƒã€æ–‡æœ¬ã€ç”¨æˆ·è¡Œä¸ºï¼‰\n",
    "- **éçº¿æ€§å…³ç³»**: ç‰¹å¾ä¸ç»“æœä¹‹é—´çš„å…³ç³»å¯èƒ½é«˜åº¦éçº¿æ€§\n",
    "- **è¡¨ç¤ºå­¦ä¹ **: éœ€è¦è‡ªåŠ¨å­¦ä¹ æœ‰æ•ˆçš„ç‰¹å¾è¡¨ç¤º\n",
    "\n",
    "### æ ¸å¿ƒé—®é¢˜ï¼šåäº‹å®æ— æ³•è§‚æµ‹\n",
    "\n",
    "å¯¹äºæ¯ä¸ªæ ·æœ¬ $i$:\n",
    "- å¦‚æœ $T_i=1$ï¼Œæˆ‘ä»¬åªè§‚æµ‹åˆ° $Y_i(1)$ï¼Œ$Y_i(0)$ æ˜¯åäº‹å®\n",
    "- å¦‚æœ $T_i=0$ï¼Œæˆ‘ä»¬åªè§‚æµ‹åˆ° $Y_i(0)$ï¼Œ$Y_i(1)$ æ˜¯åäº‹å®\n",
    "\n",
    "è¿™å°±æ˜¯**å› æœæ¨æ–­çš„æ ¹æœ¬æŒ‘æˆ˜**ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from typing import Tuple, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# ç»˜å›¾è®¾ç½®\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(\"ç¯å¢ƒå‡†å¤‡å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: TARNet - å¼€å±±ä¹‹ä½œ\n",
    "\n",
    "## TARNet: Treatment-Agnostic Representation Network\n",
    "\n",
    "TARNet æ˜¯ 2017 å¹´æå‡ºçš„å¼€åˆ›æ€§å·¥ä½œï¼Œé¦–æ¬¡å°†æ·±åº¦å­¦ä¹ ç³»ç»Ÿåœ°åº”ç”¨äºå› æœæ•ˆåº”ä¼°è®¡ã€‚\n",
    "\n",
    "### æ ¸å¿ƒè®¾è®¡\n",
    "\n",
    "1. **å…±äº«è¡¨ç¤ºå±‚**ï¼šå­¦ä¹ å¯¹å¤„ç†ç»„å’Œæ§åˆ¶ç»„éƒ½æœ‰ç”¨çš„ç‰¹å¾è¡¨ç¤º\n",
    "2. **åŒå¤´è¾“å‡º**ï¼šåˆ†åˆ«é¢„æµ‹ Y(0) å’Œ Y(1)\n",
    "\n",
    "$$X \\xrightarrow{\\Phi} \\text{Representation} \\xrightarrow{\\begin{cases} h_0 \\to \\hat{Y}(0) \\\\ h_1 \\to \\hat{Y}(1) \\end{cases}}$$\n",
    "\n",
    "### ç”Ÿæ´»åŒ–ç±»æ¯”ï¼šåŒè¯­ç¿»è¯‘å®˜\n",
    "\n",
    "æƒ³è±¡ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘å®˜ï¼Œéœ€è¦ç¿»è¯‘ä¸­æ–‡æ–‡ç« ç»™ä¸¤ç±»è¯»è€…ï¼š\n",
    "- **è‹±è¯­è¯»è€…** (å¤„ç†ç»„)\n",
    "- **æ³•è¯­è¯»è€…** (æ§åˆ¶ç»„)\n",
    "\n",
    "**ä¼ ç»Ÿæ–¹æ³• (T-Learner)**ï¼š\n",
    "- é›‡ä½£ä¸¤ä¸ªç‹¬ç«‹çš„ç¿»è¯‘å®˜\n",
    "- æ¯ä¸ªç¿»è¯‘å®˜åªæ‡‚ä¸€ç§è¯­è¨€\n",
    "- æ•ˆç‡ä½ï¼Œä¸”æ— æ³•åˆ©ç”¨å…±åŒçŸ¥è¯†\n",
    "\n",
    "**TARNet æ–¹æ³•**ï¼š\n",
    "- ä¸€ä¸ªç¿»è¯‘å®˜å…ˆç†è§£æ–‡ç« æ ¸å¿ƒå«ä¹‰ (å…±äº«è¡¨ç¤º)\n",
    "- ç„¶ååˆ†åˆ«ç¿»è¯‘æˆè‹±è¯­å’Œæ³•è¯­ (åŒå¤´è¾“å‡º)\n",
    "- æ•ˆç‡é«˜ï¼Œä¸”èƒ½åˆ©ç”¨è¯­è¨€é—´çš„å…±åŒç»“æ„\n",
    "\n",
    "### TARNet æ¶æ„å›¾\n",
    "\n",
    "```\n",
    "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "        â”‚         å…±äº«è¡¨ç¤ºå±‚ (Shared Repr)          â”‚\n",
    "        â”‚  X â†’ [Hidden] â†’ [Hidden] â†’ Î¦(X)         â”‚\n",
    "        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                          â”‚\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â–¼                           â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚    Head 0     â”‚           â”‚    Head 1     â”‚\n",
    "    â”‚ Î¦(X) â†’ Å¶(0)  â”‚           â”‚ Î¦(X) â†’ Å¶(1)  â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "            â”‚                           â”‚\n",
    "            â–¼                           â–¼\n",
    "      æ§åˆ¶ç»„é¢„æµ‹                    å¤„ç†ç»„é¢„æµ‹\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factual Loss: å…³é”®è®­ç»ƒç­–ç•¥\n",
    "\n",
    "### æ ¸å¿ƒæŒ‘æˆ˜ï¼šåäº‹å®æ— æ³•è§‚æµ‹\n",
    "\n",
    "å¯¹äºæ¯ä¸ªæ ·æœ¬ï¼Œæˆ‘ä»¬åªèƒ½è§‚æµ‹åˆ°ä¸€ä¸ªç»“æœï¼š\n",
    "- å¦‚æœ T=1ï¼Œæˆ‘ä»¬åªè§‚æµ‹åˆ° Y(1)\n",
    "- å¦‚æœ T=0ï¼Œæˆ‘ä»¬åªè§‚æµ‹åˆ° Y(0)\n",
    "\n",
    "æ‰€ä»¥æˆ‘ä»¬åªèƒ½åœ¨ **è§‚æµ‹åˆ°çš„ç»“æœ** ä¸Šè®¡ç®—æŸå¤±ï¼\n",
    "\n",
    "### Factual Loss å…¬å¼\n",
    "\n",
    "$$L_{factual} = \\frac{1}{n}\\sum_{i=1}^{n} (Y_i - \\hat{Y}_i^{factual})^2$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "$$\\hat{Y}_i^{factual} = \\begin{cases} \\hat{Y}_i(1) & \\text{if } T_i = 1 \\\\ \\hat{Y}_i(0) & \\text{if } T_i = 0 \\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹  1.1: ç†è§£ TARNet æ¶æ„\n",
    "\n",
    "class SimpleTARNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ç®€åŒ–ç‰ˆ TARNet\n",
    "    \n",
    "    æ¶æ„:\n",
    "    X -> [Shared Representation] -> Phi(X)\n",
    "                                      |\n",
    "                    +----------------+----------------+\n",
    "                    |                                 |\n",
    "                [Head 0]                         [Head 1]\n",
    "                    |                                 |\n",
    "                  Y(0)                              Y(1)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int = 50,\n",
    "        repr_dim: int = 25\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # å…±äº«è¡¨ç¤ºå±‚\n",
    "        self.representation = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, repr_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # æ§åˆ¶ç»„è¾“å‡ºå¤´ (Y0)\n",
    "        self.head0 = nn.Sequential(\n",
    "            nn.Linear(repr_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "        )\n",
    "        \n",
    "        # å¤„ç†ç»„è¾“å‡ºå¤´ (Y1)\n",
    "        self.head1 = nn.Sequential(\n",
    "            nn.Linear(repr_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­\n",
    "        \n",
    "        Returns:\n",
    "            (y0_pred, y1_pred, representation)\n",
    "        \"\"\"\n",
    "        phi = self.representation(x)\n",
    "        y0 = self.head0(phi)\n",
    "        y1 = self.head1(phi)\n",
    "        \n",
    "        return y0, y1, phi\n",
    "    \n",
    "    def predict_ite(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"é¢„æµ‹ä¸ªä½“å¤„ç†æ•ˆåº” ITE = Y(1) - Y(0)\"\"\"\n",
    "        y0, y1, _ = self.forward(x)\n",
    "        return y1 - y0\n",
    "\n",
    "# æµ‹è¯•æ¶æ„\n",
    "model = SimpleTARNet(input_dim=5)\n",
    "X_sample = torch.randn(10, 5)\n",
    "y0, y1, phi = model(X_sample)\n",
    "print(f\"TARNet è¾“å‡ºå½¢çŠ¶: Y0={y0.shape}, Y1={y1.shape}, Phi={phi.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹  1.2: Factual Loss\n",
    "\n",
    "def compute_factual_loss(\n",
    "    y_true: torch.Tensor,\n",
    "    t_true: torch.Tensor,\n",
    "    y0_pred: torch.Tensor,\n",
    "    y1_pred: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    è®¡ç®— Factual Loss\n",
    "    \n",
    "    å…³é”®æ€æƒ³: åªåœ¨è§‚æµ‹åˆ°çš„ç»“æœä¸Šè®¡ç®—æŸå¤±\n",
    "    - å¦‚æœ T=1, æŸå¤± = (Y - Y1_pred)^2\n",
    "    - å¦‚æœ T=0, æŸå¤± = (Y - Y0_pred)^2\n",
    "    \"\"\"\n",
    "    # æ ¹æ®å¤„ç†çŠ¶æ€é€‰æ‹©é¢„æµ‹å€¼\n",
    "    t_expanded = t_true.unsqueeze(1) if len(t_true.shape) == 1 else t_true\n",
    "    y_pred = torch.where(t_expanded == 1, y1_pred, y0_pred)\n",
    "    \n",
    "    # è®¡ç®— MSE\n",
    "    y_true_expanded = y_true.unsqueeze(1) if len(y_true.shape) == 1 else y_true\n",
    "    loss = torch.mean((y_true_expanded - y_pred)**2)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# æµ‹è¯•\n",
    "y_true = torch.FloatTensor([1.0, 2.0, 3.0])\n",
    "t_true = torch.FloatTensor([1.0, 0.0, 1.0])\n",
    "y0_pred = torch.FloatTensor([[1.5], [2.0], [2.5]])\n",
    "y1_pred = torch.FloatTensor([[1.0], [2.5], [3.0]])\n",
    "\n",
    "loss = compute_factual_loss(y_true, t_true, y0_pred, y1_pred)\n",
    "print(f\"Factual Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: DragonNet - ä¸‰å¤´é¾™çš„è¿›åŒ–\n",
    "\n",
    "## ä» TARNet åˆ° DragonNet: ä¸€ä¸ªå·§å¦™çš„å‡çº§\n",
    "\n",
    "å¦‚æœç¿»è¯‘å®˜åŒæ—¶è¿˜èƒ½**åˆ¤æ–­å®¢æˆ·æ¥è‡ªå“ªä¸ªå›½å®¶**ï¼ˆå€¾å‘å¾—åˆ†ï¼‰ï¼Œç¿»è¯‘æ•ˆæœä¼šä¸ä¼šæ›´å¥½å‘¢ï¼Ÿ\n",
    "\n",
    "è¿™å°±æ˜¯ **DragonNet** çš„æ ¸å¿ƒæ€æƒ³ï¼\n",
    "\n",
    "## DragonNet çš„ç›´è§‰: ä¸‰å¤´é¾™çš„æ•…äº‹\n",
    "\n",
    "### é—®é¢˜å›é¡¾\n",
    "\n",
    "åœ¨å› æœæ¨æ–­ä¸­ï¼Œ**æ··æ·†**æ˜¯æœ€å¤§çš„æ•Œäººã€‚æƒ³è±¡ä½ åœ¨ç ”ç©¶ã€Œå¹¿å‘Šæ˜¯å¦å¢åŠ ç”¨æˆ·è´­ä¹°ã€ï¼š\n",
    "\n",
    "- ç»å¸¸è´­ç‰©çš„ç”¨æˆ·**æ›´å®¹æ˜“çœ‹åˆ°å¹¿å‘Š**ï¼ˆç®—æ³•æ¨èï¼‰\n",
    "- ç»å¸¸è´­ç‰©çš„ç”¨æˆ·**æœ¬æ¥å°±ä¼šä¹°æ›´å¤š**\n",
    "\n",
    "è¿™å°±æ˜¯**é€‰æ‹©åå·®**ï¼šå¤„ç†åˆ†é…ä¸æ˜¯éšæœºçš„ï¼Œè€Œæ˜¯ä¾èµ–äºæ··æ·†å› å­ã€‚\n",
    "\n",
    "### TARNet çš„å±€é™\n",
    "\n",
    "TARNet åªå­¦ä¹ ã€Œé¢„æµ‹ç»“æœã€ï¼Œä½†ä¸æ˜¾å¼åœ°ç†è§£ã€Œè°ä¼šè¢«å¤„ç†ã€ã€‚\n",
    "\n",
    "### DragonNet çš„è§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "DragonNet æ·»åŠ äº†**ç¬¬ä¸‰ä¸ªå¤´**â€”â€”å€¾å‘å¾—åˆ†å¤´ï¼\n",
    "\n",
    "```\n",
    "                       ğŸ§  å…±äº«è¡¨ç¤ºå±‚\n",
    "                           |                    \n",
    "       +------------------+-------------------+\n",
    "       |                  |                   |\n",
    "    ğŸ¯ Y(0)å¤´         ğŸ¯ Y(1)å¤´          ğŸ“Š å€¾å‘å¾—åˆ†å¤´\n",
    "       |                  |                   |\n",
    "  æ§åˆ¶ç»„ç»“æœé¢„æµ‹    å¤„ç†ç»„ç»“æœé¢„æµ‹      \"è°ä¼šè¢«å¤„ç†?\"\n",
    "```\n",
    "\n",
    "ä¸ºä»€ä¹ˆå«ã€Œé¾™ç½‘ã€ï¼ˆDragonNetï¼‰ï¼Ÿå› ä¸ºè¿™ä¸‰ä¸ªå¤´å°±åƒä¼ è¯´ä¸­çš„**ä¸‰å¤´é¾™**ï¼\n",
    "\n",
    "### å…³é”®æ´å¯Ÿ\n",
    "\n",
    "æ·»åŠ å€¾å‘å¾—åˆ†å¤´æœ‰ä»€ä¹ˆå¥½å¤„ï¼Ÿ\n",
    "\n",
    "1. **æ­£åˆ™åŒ–ä½œç”¨**: å¼ºè¿«è¡¨ç¤ºå±‚åŒæ—¶å­¦ä¼šã€Œé¢„æµ‹ç»“æœã€å’Œã€Œé¢„æµ‹å¤„ç†ã€\n",
    "2. **å¹³è¡¡è¡¨ç¤º**: è®©è¡¨ç¤ºå±‚æ•è·ä¸**å¤„ç†åˆ†é…ç›¸å…³çš„ä¿¡æ¯**ï¼Œè¿™æ­£æ˜¯æ··æ·†å› å­ï¼\n",
    "3. **Targeted Regularization**: ç”¨å€¾å‘å¾—åˆ†æ¥è°ƒæ•´æŸå¤±å‡½æ•°ï¼Œå‡å°‘åå·®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DragonNet æ ¸å¿ƒå…¬å¼\n",
    "\n",
    "### æ¶æ„\n",
    "\n",
    "$$\\Phi(X) = f_{\\text{repr}}(X) \\quad \\text{(å…±äº«è¡¨ç¤º)}$$\n",
    "\n",
    "$$\\hat{Y}(0) = h_0(\\Phi(X)), \\quad \\hat{Y}(1) = h_1(\\Phi(X)) \\quad \\text{(ç»“æœå¤´)}$$\n",
    "\n",
    "$$\\hat{e}(X) = h_e(\\Phi(X)) \\quad \\text{(å€¾å‘å¾—åˆ†å¤´)}$$\n",
    "\n",
    "### å¤åˆæŸå¤±å‡½æ•°\n",
    "\n",
    "$$\\mathcal{L}_{\\text{DragonNet}} = \\mathcal{L}_{\\text{factual}} + \\alpha \\cdot \\mathcal{L}_{\\text{propensity}} + \\beta \\cdot \\mathcal{L}_{\\text{targeted}}$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "\n",
    "1. **Factual Loss** (å’Œ TARNet ä¸€æ ·):\n",
    "$$\\mathcal{L}_{\\text{factual}} = \\frac{1}{N}\\sum_{i=1}^{N} (Y_i - [T_i \\cdot \\hat{Y}_i(1) + (1-T_i) \\cdot \\hat{Y}_i(0)])^2$$\n",
    "\n",
    "2. **Propensity Loss** (äºŒåˆ†ç±»äº¤å‰ç†µ):\n",
    "$$\\mathcal{L}_{\\text{propensity}} = -\\frac{1}{N}\\sum_{i=1}^{N} [T_i \\log \\hat{e}_i + (1-T_i) \\log (1-\\hat{e}_i)]$$\n",
    "\n",
    "3. **Targeted Regularization** (DragonNet çš„åˆ›æ–°):\n",
    "$$\\mathcal{L}_{\\text{targeted}} = \\frac{1}{N}\\sum_{i=1}^{N} \\left(Y_i - \\hat{Y}_i - \\epsilon \\cdot h_i\\right)^2$$\n",
    "\n",
    "å…¶ä¸­ $h_i = \\frac{T_i}{\\hat{e}(X_i)} - \\frac{1-T_i}{1-\\hat{e}(X_i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeted Regularization: é­”æ³•å…¬å¼çš„ç›´è§‰\n",
    "\n",
    "### é‚£ä¸ªç¥ç§˜çš„ h æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "$$h = \\frac{T}{e(X)} - \\frac{1-T}{1-e(X)}$$\n",
    "\n",
    "è¿™ä¸ªå…¬å¼æ¥è‡ªäº**åŠå‚æ•°æ•ˆç‡ç†è®º**å’Œ **TMLEï¼ˆTargeted Maximum Likelihood Estimationï¼‰**ã€‚\n",
    "\n",
    "### ä¸€ä¸ªç›´è§‰è§£é‡Š\n",
    "\n",
    "æƒ³è±¡ä½ åœ¨åšæ°‘æ„è°ƒæŸ¥ï¼Œä½†æœ‰äº›äººç¾¤æ›´éš¾æ¥è§¦åˆ°ï¼ˆæ¯”å¦‚å¹´è½»äººä¸çˆ±æ¥ç”µè¯ï¼‰ï¼š\n",
    "\n",
    "- **e(X)** = æŸäººè¢«è°ƒæŸ¥åˆ°çš„æ¦‚ç‡ï¼ˆå€¾å‘å¾—åˆ†ï¼‰\n",
    "- **T/e(X)**: å¦‚æœè¢«è°ƒæŸ¥åˆ°ï¼ˆT=1ï¼‰ï¼Œç”¨ 1/e(X) åŠ æƒï¼Œç›¸å½“äºã€Œå°‘è§çš„äººæ›´é‡è¦ã€\n",
    "- **-(1-T)/(1-e(X))**: å¦‚æœæ²¡è¢«è°ƒæŸ¥åˆ°ï¼ˆT=0ï¼‰ï¼Œç”¨åå‘æƒé‡\n",
    "\n",
    "è¿™ä¸ª **h** æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ª**åŒé‡é²æ£’æ€§**çš„è°ƒæ•´é¡¹ï¼\n",
    "\n",
    "### epsilon çš„ä½œç”¨\n",
    "\n",
    "**epsilon (Îµ)** æ˜¯ä¸€ä¸ª**å¯å­¦ä¹ çš„æ ‡é‡å‚æ•°**ï¼š\n",
    "\n",
    "- å®ƒè®©æ¨¡å‹è‡ªåŠ¨å­¦ä¹ ã€Œéœ€è¦å¤šå°‘è°ƒæ•´ã€\n",
    "- å¦‚æœæ¨¡å‹å·²ç»å¾ˆå‡†ï¼Œepsilon ä¼šè¶‹è¿‘äº 0\n",
    "- å¦‚æœæœ‰åå·®ï¼Œepsilon ä¼šå­¦åˆ°ä¸€ä¸ªéé›¶å€¼æ¥ä¿®æ­£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹  2.1: DragonNet æ¶æ„\n",
    "\n",
    "class SimpleDragonNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ç®€åŒ–ç‰ˆ DragonNet - ä¸‰å¤´é¾™ç½‘ç»œ\n",
    "    \n",
    "    ä¸ TARNet çš„åŒºåˆ«:\n",
    "    1. å¤šäº†ä¸€ä¸ªå€¾å‘å¾—åˆ†å¤´\n",
    "    2. æœ‰ä¸€ä¸ªå¯å­¦ä¹ çš„ epsilon å‚æ•°\n",
    "    3. ä½¿ç”¨ ELU æ¿€æ´»å‡½æ•°ï¼ˆåŸè®ºæ–‡æ¨èï¼‰\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int = 50,\n",
    "        repr_dim: int = 25\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # å…±äº«è¡¨ç¤ºå±‚ (ä½¿ç”¨ ELU)\n",
    "        self.representation = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim, repr_dim),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "        # æ§åˆ¶ç»„è¾“å‡ºå¤´ (Y0)\n",
    "        self.head0 = nn.Sequential(\n",
    "            nn.Linear(repr_dim, hidden_dim // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "        )\n",
    "        \n",
    "        # å¤„ç†ç»„è¾“å‡ºå¤´ (Y1)\n",
    "        self.head1 = nn.Sequential(\n",
    "            nn.Linear(repr_dim, hidden_dim // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "        )\n",
    "        \n",
    "        # å€¾å‘å¾—åˆ†å¤´ (è¿™æ˜¯å…³é”®ï¼)\n",
    "        self.propensity_head = nn.Sequential(\n",
    "            nn.Linear(repr_dim, hidden_dim // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()  # è¾“å‡ºé™åˆ¶åœ¨ [0, 1]\n",
    "        )\n",
    "        \n",
    "        # epsilon å‚æ•° (å¯å­¦ä¹ çš„æ ‡é‡)\n",
    "        self.epsilon = nn.Parameter(torch.tensor(0.0))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple:\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­\n",
    "        \n",
    "        Returns:\n",
    "            (y0_pred, y1_pred, propensity, epsilon, representation)\n",
    "        \"\"\"\n",
    "        phi = self.representation(x)\n",
    "        y0 = self.head0(phi)\n",
    "        y1 = self.head1(phi)\n",
    "        propensity = self.propensity_head(phi)\n",
    "        \n",
    "        return y0, y1, propensity, self.epsilon, phi\n",
    "    \n",
    "    def predict_ite(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"é¢„æµ‹ä¸ªä½“å¤„ç†æ•ˆåº”\"\"\"\n",
    "        y0, y1, _, _, _ = self.forward(x)\n",
    "        return y1 - y0\n",
    "\n",
    "# æµ‹è¯• DragonNet æ¶æ„\n",
    "dragon_model = SimpleDragonNet(input_dim=5)\n",
    "X_sample = torch.randn(10, 5)\n",
    "y0, y1, prop, eps, phi = dragon_model(X_sample)\n",
    "\n",
    "print(\"DragonNet æ¶æ„æµ‹è¯•é€šè¿‡! ğŸ‰\")\n",
    "print(f\"\\nè¾“å‡ºå½¢çŠ¶:\")\n",
    "print(f\"  Y0 é¢„æµ‹: {y0.shape}\")\n",
    "print(f\"  Y1 é¢„æµ‹: {y1.shape}\")\n",
    "print(f\"  å€¾å‘å¾—åˆ†: {prop.shape}\")\n",
    "print(f\"  è¡¨ç¤ºå‘é‡: {phi.shape}\")\n",
    "print(f\"\\nå…³é”®å‚æ•°:\")\n",
    "print(f\"  Epsilon: {eps}\")\n",
    "print(f\"  å€¾å‘å¾—åˆ†èŒƒå›´: [{prop.min():.4f}, {prop.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹  2.2: DragonNet å¤åˆæŸå¤±å‡½æ•°\n",
    "\n",
    "def dragonnet_loss(\n",
    "    y_true: torch.Tensor,\n",
    "    t_true: torch.Tensor,\n",
    "    y0_pred: torch.Tensor,\n",
    "    y1_pred: torch.Tensor,\n",
    "    propensity: torch.Tensor,\n",
    "    epsilon: torch.Tensor,\n",
    "    alpha: float = 1.0,\n",
    "    beta: float = 1.0\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    DragonNet å¤åˆæŸå¤±å‡½æ•°\n",
    "    \n",
    "    L = L_factual + alpha * L_propensity + beta * L_targeted\n",
    "    \"\"\"\n",
    "    # ç¡®ä¿å½¢çŠ¶æ­£ç¡®\n",
    "    y0_pred = y0_pred.squeeze()\n",
    "    y1_pred = y1_pred.squeeze()\n",
    "    propensity = propensity.squeeze()\n",
    "    \n",
    "    # 1. Factual Loss\n",
    "    y_pred = t_true * y1_pred + (1 - t_true) * y0_pred\n",
    "    factual_loss = torch.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "    # 2. Propensity Loss (äºŒåˆ†ç±»äº¤å‰ç†µ)\n",
    "    eps = 1e-8\n",
    "    propensity_loss = -torch.mean(\n",
    "        t_true * torch.log(propensity + eps) + \n",
    "        (1 - t_true) * torch.log(1 - propensity + eps)\n",
    "    )\n",
    "    \n",
    "    # 3. Targeted Regularization\n",
    "    h = t_true / (propensity + eps) - (1 - t_true) / (1 - propensity + eps)\n",
    "    targeted_reg = torch.mean((y_true - y_pred - epsilon * h) ** 2)\n",
    "    \n",
    "    # æ€»æŸå¤±\n",
    "    total_loss = factual_loss + alpha * propensity_loss + beta * targeted_reg\n",
    "    \n",
    "    return {\n",
    "        'total': total_loss,\n",
    "        'factual': factual_loss,\n",
    "        'propensity': propensity_loss,\n",
    "        'targeted': targeted_reg\n",
    "    }\n",
    "\n",
    "# æµ‹è¯•æŸå¤±å‡½æ•°\n",
    "y_true = torch.FloatTensor([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "t_true = torch.FloatTensor([1.0, 0.0, 1.0, 0.0, 1.0])\n",
    "y0_pred = torch.FloatTensor([1.5, 2.0, 2.5, 4.5, 4.0])\n",
    "y1_pred = torch.FloatTensor([2.0, 2.5, 3.0, 5.0, 5.5])\n",
    "propensity = torch.FloatTensor([0.7, 0.3, 0.6, 0.4, 0.8])\n",
    "epsilon = torch.tensor(0.1)\n",
    "\n",
    "losses = dragonnet_loss(\n",
    "    y_true, t_true, y0_pred, y1_pred,\n",
    "    propensity, epsilon, alpha=1.0, beta=1.0\n",
    ")\n",
    "\n",
    "print(\"æŸå¤±å‡½æ•°æµ‹è¯•é€šè¿‡! ğŸ‰\")\n",
    "print(f\"\\nå„æŸå¤±é¡¹:\")\n",
    "print(f\"  Factual Loss: {losses['factual'].item():.4f}\")\n",
    "print(f\"  Propensity Loss: {losses['propensity'].item():.4f}\")\n",
    "print(f\"  Targeted Reg: {losses['targeted'].item():.4f}\")\n",
    "print(f\"  Total Loss: {losses['total'].item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: æ•°æ®ç”Ÿæˆä¸å®éªŒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹  3.1: ç”Ÿæˆå¼ºæ··æ·†æ•°æ®\n",
    "\n",
    "def generate_confounded_data(\n",
    "    n: int = 2000,\n",
    "    seed: int = 42\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆæœ‰å¼ºæ··æ·†çš„æ•°æ®\n",
    "    \n",
    "    åœºæ™¯: å¹¿å‘ŠæŠ•æ”¾æ•ˆæœè¯„ä¼°\n",
    "    - X: ç”¨æˆ·ç‰¹å¾ï¼ˆè´­ç‰©é¢‘ç‡ã€å¹³å°æ´»è·ƒåº¦ã€æ¶ˆè´¹èƒ½åŠ›ç­‰ï¼‰\n",
    "    - T: æ˜¯å¦çœ‹åˆ°å¹¿å‘Šï¼ˆä¸æ˜¯éšæœºåˆ†é…ï¼é«˜ä»·å€¼ç”¨æˆ·æ›´å®¹æ˜“çœ‹åˆ°ï¼‰\n",
    "    - Y: æ˜¯å¦è´­ä¹°\n",
    "    \n",
    "    å¼ºæ··æ·†: ç”¨æˆ·ç‰¹å¾åŒæ—¶å½±å“ã€Œæ˜¯å¦çœ‹å¹¿å‘Šã€å’Œã€Œæ˜¯å¦è´­ä¹°ã€\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # ç”¨æˆ·ç‰¹å¾ (5ç»´)\n",
    "    X = np.random.randn(n, 5)\n",
    "    # X[:, 0]: è´­ç‰©é¢‘ç‡\n",
    "    # X[:, 1]: å¹³å°æ´»è·ƒåº¦\n",
    "    # X[:, 2]: æ¶ˆè´¹èƒ½åŠ›\n",
    "    # X[:, 3]: æµè§ˆå†å²\n",
    "    # X[:, 4]: ç‚¹å‡»ç‡\n",
    "    \n",
    "    # å¼ºæ··æ·†çš„å¤„ç†åˆ†é…ï¼ˆé«˜ä»·å€¼ç”¨æˆ·æ›´å®¹æ˜“çœ‹åˆ°å¹¿å‘Šï¼‰\n",
    "    propensity = 1 / (1 + np.exp(-(\n",
    "        1.0 * X[:, 0] +   # è´­ç‰©é¢‘ç‡é«˜ -> æ›´å¯èƒ½çœ‹å¹¿å‘Š\n",
    "        0.8 * X[:, 1] +   # æ´»è·ƒåº¦é«˜ -> æ›´å¯èƒ½çœ‹å¹¿å‘Š\n",
    "        0.6 * X[:, 2]     # æ¶ˆè´¹èƒ½åŠ›é«˜ -> æ›´å¯èƒ½çœ‹å¹¿å‘Š\n",
    "    )))\n",
    "    \n",
    "    T = np.random.binomial(1, propensity, n)\n",
    "    \n",
    "    # ç”Ÿæˆæ½œåœ¨ç»“æœï¼ˆç»“æœä¹Ÿä¾èµ–äº X - è¿™æ˜¯æ··æ·†ï¼ï¼‰\n",
    "    noise = np.random.randn(n) * 0.5\n",
    "    Y0 = 2.0 + X[:, 0] + 0.5 * X[:, 1] + noise\n",
    "    \n",
    "    # å¼‚è´¨æ€§å¤„ç†æ•ˆåº”\n",
    "    treatment_effect = 2.0 + 0.5 * X[:, 0]  # åŸºç¡€æ•ˆåº” 2, åŠ ä¸Šä¸ç‰¹å¾ç›¸å…³çš„éƒ¨åˆ†\n",
    "    Y1 = Y0 + treatment_effect\n",
    "    \n",
    "    # è§‚æµ‹ç»“æœ\n",
    "    Y = np.where(T == 1, Y1, Y0)\n",
    "    \n",
    "    return X, T, Y, Y0, Y1\n",
    "\n",
    "# ç”Ÿæˆæ•°æ®\n",
    "X, T, Y, Y0, Y1 = generate_confounded_data(n=2000)\n",
    "\n",
    "print(\"æ•°æ®ç”ŸæˆæˆåŠŸ! ğŸ‰\")\n",
    "print(f\"æ•°æ®å½¢çŠ¶: X={X.shape}\")\n",
    "print(f\"å¤„ç†ç»„æ¯”ä¾‹: {T.mean():.2%}\")\n",
    "print(f\"\\nçœŸå®å› æœæ•ˆåº”:\")\n",
    "print(f\"  çœŸå® ATE: {np.mean(Y1 - Y0):.4f}\")\n",
    "print(f\"  çœŸå® ATT: {np.mean((Y1 - Y0)[T == 1]):.4f}\")\n",
    "print(f\"\\næœ´ç´ ä¼°è®¡ï¼ˆæœ‰åï¼ï¼‰:\")\n",
    "naive_ate = Y[T == 1].mean() - Y[T == 0].mean()\n",
    "print(f\"  æœ´ç´  ATE: {naive_ate:.4f}\")\n",
    "print(f\"  åå·®: {naive_ate - np.mean(Y1 - Y0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: å¯¹æ¯”å®éªŒ - TARNet vs DragonNet\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬è®­ç»ƒå¹¶å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„æ€§èƒ½ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹  4.1: ç»Ÿä¸€è®­ç»ƒå‡½æ•°\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    X: np.ndarray,\n",
    "    T: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    model_type: str = 'tarnet',  # 'tarnet' or 'dragonnet'\n",
    "    n_epochs: int = 200,\n",
    "    batch_size: int = 64,\n",
    "    learning_rate: float = 1e-3,\n",
    "    alpha: float = 1.0,\n",
    "    beta: float = 1.0,\n",
    "    verbose: bool = True\n",
    ") -> Tuple[nn.Module, dict]:\n",
    "    \"\"\"\n",
    "    ç»Ÿä¸€çš„æ¨¡å‹è®­ç»ƒå‡½æ•°\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_type: 'tarnet' (åªç”¨ factual loss) æˆ– 'dragonnet' (å®Œæ•´æŸå¤±)\n",
    "    alpha: å€¾å‘å¾—åˆ†æŸå¤±æƒé‡ (ä»… dragonnet)\n",
    "    beta: targeted regularization æƒé‡ (ä»… dragonnet)\n",
    "    \"\"\"\n",
    "    # æ•°æ®å‡†å¤‡\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    T_tensor = torch.FloatTensor(T)\n",
    "    Y_tensor = torch.FloatTensor(Y)\n",
    "    \n",
    "    dataset = TensorDataset(X_tensor, T_tensor, Y_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # ä¼˜åŒ–å™¨\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # è®­ç»ƒå†å²\n",
    "    history = {\n",
    "        'total_loss': [],\n",
    "        'factual_loss': [],\n",
    "        'propensity_loss': [],\n",
    "        'targeted_loss': [],\n",
    "        'epsilon': []\n",
    "    }\n",
    "    \n",
    "    # è®­ç»ƒå¾ªç¯\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_losses = {k: 0 for k in ['total_loss', 'factual_loss', 'propensity_loss', 'targeted_loss']}\n",
    "        n_batches = 0\n",
    "        \n",
    "        for batch_x, batch_t, batch_y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # å‰å‘ä¼ æ’­\n",
    "            if model_type == 'dragonnet':\n",
    "                y0_pred, y1_pred, propensity, epsilon, _ = model(batch_x)\n",
    "                \n",
    "                # DragonNet å®Œæ•´æŸå¤±\n",
    "                losses = dragonnet_loss(\n",
    "                    batch_y, batch_t, y0_pred, y1_pred,\n",
    "                    propensity, epsilon, alpha=alpha, beta=beta\n",
    "                )\n",
    "                loss = losses['total']\n",
    "                \n",
    "                # è®°å½•å„é¡¹æŸå¤±\n",
    "                epoch_losses['total_loss'] += loss.item()\n",
    "                epoch_losses['factual_loss'] += losses['factual'].item()\n",
    "                epoch_losses['propensity_loss'] += losses['propensity'].item()\n",
    "                epoch_losses['targeted_loss'] += losses['targeted'].item()\n",
    "            else:\n",
    "                # TARNet åªç”¨ factual loss\n",
    "                y0_pred, y1_pred, _ = model(batch_x)\n",
    "                loss = compute_factual_loss(batch_y, batch_t, y0_pred, y1_pred)\n",
    "                \n",
    "                epoch_losses['total_loss'] += loss.item()\n",
    "                epoch_losses['factual_loss'] += loss.item()\n",
    "            \n",
    "            # åå‘ä¼ æ’­\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            n_batches += 1\n",
    "        \n",
    "        # è®°å½•å¹³å‡æŸå¤±\n",
    "        for k in epoch_losses.keys():\n",
    "            history[k].append(epoch_losses[k] / n_batches)\n",
    "        \n",
    "        # è®°å½• epsilon (ä»… dragonnet)\n",
    "        if model_type == 'dragonnet':\n",
    "            history['epsilon'].append(model.epsilon.item())\n",
    "        \n",
    "        if verbose and (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {history['total_loss'][-1]:.4f}\")\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹  4.2: è®­ç»ƒ TARNet\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"è®­ç»ƒ TARNet (åªç”¨ Factual Loss)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tarnet_model = SimpleTARNet(input_dim=X.shape[1])\n",
    "tarnet_model, tarnet_history = train_model(\n",
    "    tarnet_model, X, T, Y,\n",
    "    model_type='tarnet',\n",
    "    n_epochs=200,\n",
    "    batch_size=64,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nTARNet è®­ç»ƒå®Œæˆ! æœ€ç»ˆæŸå¤±: {tarnet_history['total_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹  4.3: è®­ç»ƒ DragonNet\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"è®­ç»ƒ DragonNet (å®Œæ•´æŸå¤±)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dragonnet_model = SimpleDragonNet(input_dim=X.shape[1])\n",
    "dragonnet_model, dragonnet_history = train_model(\n",
    "    dragonnet_model, X, T, Y,\n",
    "    model_type='dragonnet',\n",
    "    n_epochs=200,\n",
    "    batch_size=64,\n",
    "    alpha=1.0,\n",
    "    beta=1.0,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nDragonNet è®­ç»ƒå®Œæˆ! æœ€ç»ˆæŸå¤±: {dragonnet_history['total_loss'][-1]:.4f}\")\n",
    "print(f\"æœ€ç»ˆ Epsilon: {dragonnet_history['epsilon'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹  4.4: è¯„ä¼°å‡½æ•°\n",
    "\n",
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    X: np.ndarray,\n",
    "    Y0: np.ndarray,\n",
    "    Y1: np.ndarray,\n",
    "    model_type: str = 'tarnet'\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    è¯„ä¼°æ¨¡å‹æ€§èƒ½\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_tensor = torch.FloatTensor(X)\n",
    "        \n",
    "        if model_type == 'dragonnet':\n",
    "            y0_pred, y1_pred, _, _, _ = model(X_tensor)\n",
    "        else:\n",
    "            y0_pred, y1_pred, _ = model(X_tensor)\n",
    "        \n",
    "        y0_pred = y0_pred.numpy().squeeze()\n",
    "        y1_pred = y1_pred.numpy().squeeze()\n",
    "    \n",
    "    # çœŸå® ITE\n",
    "    ite_true = Y1 - Y0\n",
    "    ite_pred = y1_pred - y0_pred\n",
    "    \n",
    "    # PEHE (Precision in Estimation of Heterogeneous Effect)\n",
    "    pehe = np.sqrt(np.mean((ite_true - ite_pred) ** 2))\n",
    "    \n",
    "    # ATE è¯¯å·®\n",
    "    ate_true = np.mean(ite_true)\n",
    "    ate_pred = np.mean(ite_pred)\n",
    "    ate_error = np.abs(ate_true - ate_pred)\n",
    "    \n",
    "    # ITE ç›¸å…³æ€§\n",
    "    ite_corr = np.corrcoef(ite_true.flatten(), ite_pred.flatten())[0, 1]\n",
    "    \n",
    "    return {\n",
    "        'pehe': pehe,\n",
    "        'ate_true': ate_true,\n",
    "        'ate_pred': ate_pred,\n",
    "        'ate_error': ate_error,\n",
    "        'ite_corr': ite_corr,\n",
    "        'ite_true': ite_true,\n",
    "        'ite_pred': ite_pred,\n",
    "        'y0_pred': y0_pred,\n",
    "        'y1_pred': y1_pred\n",
    "    }\n",
    "\n",
    "# è¯„ä¼°ä¸¤ä¸ªæ¨¡å‹\n",
    "tarnet_metrics = evaluate_model(tarnet_model, X, Y0, Y1, model_type='tarnet')\n",
    "dragonnet_metrics = evaluate_model(dragonnet_model, X, Y0, Y1, model_type='dragonnet')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TARNet vs DragonNet æ€§èƒ½å¯¹æ¯”\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n{'æ¨¡å‹':<15} {'PEHE':<15} {'ATE è¯¯å·®':<15} {'ITE ç›¸å…³æ€§':<15}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'TARNet':<15} {tarnet_metrics['pehe']:<15.4f} {tarnet_metrics['ate_error']:<15.4f} {tarnet_metrics['ite_corr']:<15.4f}\")\n",
    "print(f\"{'DragonNet':<15} {dragonnet_metrics['pehe']:<15.4f} {dragonnet_metrics['ate_error']:<15.4f} {dragonnet_metrics['ite_corr']:<15.4f}\")\n",
    "\n",
    "# è®¡ç®—æ”¹è¿›\n",
    "pehe_improve = (tarnet_metrics['pehe'] - dragonnet_metrics['pehe']) / tarnet_metrics['pehe'] * 100\n",
    "ate_improve = (tarnet_metrics['ate_error'] - dragonnet_metrics['ate_error']) / tarnet_metrics['ate_error'] * 100\n",
    "\n",
    "print(f\"\\næ”¹è¿›:\")\n",
    "print(f\"  PEHE: {pehe_improve:+.1f}%\")\n",
    "print(f\"  ATE è¯¯å·®: {ate_improve:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å¯¹æ¯”ç»“æœ\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# ç¬¬ä¸€è¡Œ: TARNet ç»“æœ\n",
    "# ITE æ•£ç‚¹å›¾\n",
    "axes[0, 0].scatter(tarnet_metrics['ite_true'], tarnet_metrics['ite_pred'], alpha=0.3, s=10, c='#3498db')\n",
    "min_val = min(tarnet_metrics['ite_true'].min(), tarnet_metrics['ite_pred'].min())\n",
    "max_val = max(tarnet_metrics['ite_true'].max(), tarnet_metrics['ite_pred'].max())\n",
    "axes[0, 0].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
    "axes[0, 0].set_xlabel('True ITE')\n",
    "axes[0, 0].set_ylabel('Predicted ITE')\n",
    "axes[0, 0].set_title(f'TARNet: ITE Prediction (r={tarnet_metrics[\"ite_corr\"]:.3f})')\n",
    "\n",
    "# ITE è¯¯å·®åˆ†å¸ƒ\n",
    "ite_error_tarnet = tarnet_metrics['ite_pred'] - tarnet_metrics['ite_true']\n",
    "axes[0, 1].hist(ite_error_tarnet, bins=50, alpha=0.7, color='#3498db', edgecolor='black')\n",
    "axes[0, 1].axvline(x=0, color='red', linestyle='--', label='Zero Error')\n",
    "axes[0, 1].axvline(x=ite_error_tarnet.mean(), color='orange', linestyle='-', label=f'Mean: {ite_error_tarnet.mean():.3f}')\n",
    "axes[0, 1].set_xlabel('ITE Prediction Error')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title(f'TARNet: ITE Error Distribution (PEHE={tarnet_metrics[\"pehe\"]:.3f})')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# è®­ç»ƒæ›²çº¿\n",
    "axes[0, 2].plot(tarnet_history['total_loss'], 'b-', linewidth=2)\n",
    "axes[0, 2].set_xlabel('Epoch')\n",
    "axes[0, 2].set_ylabel('Loss')\n",
    "axes[0, 2].set_title('TARNet: Training Loss')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# ç¬¬äºŒè¡Œ: DragonNet ç»“æœ\n",
    "# ITE æ•£ç‚¹å›¾\n",
    "axes[1, 0].scatter(dragonnet_metrics['ite_true'], dragonnet_metrics['ite_pred'], alpha=0.3, s=10, c='#e74c3c')\n",
    "min_val = min(dragonnet_metrics['ite_true'].min(), dragonnet_metrics['ite_pred'].min())\n",
    "max_val = max(dragonnet_metrics['ite_true'].max(), dragonnet_metrics['ite_pred'].max())\n",
    "axes[1, 0].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
    "axes[1, 0].set_xlabel('True ITE')\n",
    "axes[1, 0].set_ylabel('Predicted ITE')\n",
    "axes[1, 0].set_title(f'DragonNet: ITE Prediction (r={dragonnet_metrics[\"ite_corr\"]:.3f})')\n",
    "\n",
    "# ITE è¯¯å·®åˆ†å¸ƒ\n",
    "ite_error_dragon = dragonnet_metrics['ite_pred'] - dragonnet_metrics['ite_true']\n",
    "axes[1, 1].hist(ite_error_dragon, bins=50, alpha=0.7, color='#e74c3c', edgecolor='black')\n",
    "axes[1, 1].axvline(x=0, color='red', linestyle='--', label='Zero Error')\n",
    "axes[1, 1].axvline(x=ite_error_dragon.mean(), color='orange', linestyle='-', label=f'Mean: {ite_error_dragon.mean():.3f}')\n",
    "axes[1, 1].set_xlabel('ITE Prediction Error')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title(f'DragonNet: ITE Error Distribution (PEHE={dragonnet_metrics[\"pehe\"]:.3f})')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# æŸå¤±ç»„æˆ\n",
    "axes[1, 2].plot(dragonnet_history['factual_loss'], 'g-', label='Factual', linewidth=2)\n",
    "axes[1, 2].plot(dragonnet_history['propensity_loss'], 'r-', label='Propensity', linewidth=2)\n",
    "if len(dragonnet_history['targeted_loss']) > 0:\n",
    "    axes[1, 2].plot(dragonnet_history['targeted_loss'], 'purple', label='Targeted', linewidth=2)\n",
    "axes[1, 2].set_xlabel('Epoch')\n",
    "axes[1, 2].set_ylabel('Loss')\n",
    "axes[1, 2].set_title('DragonNet: Loss Components')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹æ¯”æŸ±çŠ¶å›¾\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# PEHE å¯¹æ¯”\n",
    "models = ['TARNet', 'DragonNet']\n",
    "pehe_values = [tarnet_metrics['pehe'], dragonnet_metrics['pehe']]\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "\n",
    "bars1 = axes[0].bar(models, pehe_values, color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[0].set_ylabel('PEHE')\n",
    "axes[0].set_title('PEHE å¯¹æ¯” (è¶Šä½è¶Šå¥½)')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "for bar, val in zip(bars1, pehe_values):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "                f'{val:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# ATE Error å¯¹æ¯”\n",
    "ate_errors = [tarnet_metrics['ate_error'], dragonnet_metrics['ate_error']]\n",
    "\n",
    "bars2 = axes[1].bar(models, ate_errors, color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[1].set_ylabel('ATE Error')\n",
    "axes[1].set_title('ATE è¯¯å·®å¯¹æ¯” (è¶Šä½è¶Šå¥½)')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "for bar, val in zip(bars2, ate_errors):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
    "                f'{val:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: ä½•æ—¶é€‰æ‹©å“ªä¸ªæ¨¡å‹ï¼Ÿ\n",
    "\n",
    "## å†³ç­–æ ‘\n",
    "\n",
    "```\n",
    "å¼€å§‹\n",
    "  |\n",
    "  v\n",
    "æ˜¯å¦å­˜åœ¨å¼ºæ··æ·†ï¼Ÿ\n",
    "  |\n",
    "  +-- å¦ (RCTæˆ–å¼±æ··æ·†) --> TARNet\n",
    "  |                        - æ›´ç®€å•\n",
    "  |                        - æ›´å¿«è®­ç»ƒ\n",
    "  |                        - è¶³å¤Ÿå‡†ç¡®\n",
    "  |\n",
    "  +-- æ˜¯ (å¼ºæ··æ·†) --> å¤„ç†åˆ†é…æ˜¯å¦é«˜åº¦ä¸å¹³è¡¡ï¼Ÿ\n",
    "                        |\n",
    "                        +-- å¦ --> TARNet æˆ– DragonNet éƒ½å¯\n",
    "                        |          (DragonNet ç•¥å¥½)\n",
    "                        |\n",
    "                        +-- æ˜¯ --> DragonNet\n",
    "                                   - å€¾å‘å¾—åˆ†å¤´æœ‰å¸®åŠ©\n",
    "                                   - Targeted Reg å‡å°‘åå·®\n",
    "```\n",
    "\n",
    "## é€‰æ‹©æŒ‡å—è¡¨\n",
    "\n",
    "| åœºæ™¯ | æ¨èæ¨¡å‹ | åŸå›  |\n",
    "|------|----------|------|\n",
    "| **éšæœºå¯¹ç…§è¯•éªŒ (RCT)** | TARNet | æ— æ··æ·†ï¼Œæ— éœ€å€¾å‘å¾—åˆ† |\n",
    "| **è§‚å¯Ÿæ€§æ•°æ® + å¼±æ··æ·†** | TARNet | ç®€å•æœ‰æ•ˆï¼Œè®­ç»ƒå¿« |\n",
    "| **è§‚å¯Ÿæ€§æ•°æ® + å¼ºæ··æ·†** | DragonNet | å€¾å‘å¾—åˆ†æ­£åˆ™åŒ–æœ‰å¸®åŠ© |\n",
    "| **å¤„ç†åˆ†é…é«˜åº¦ä¸å¹³è¡¡** | DragonNet | Targeted Reg æ›´ç¨³å¥ |\n",
    "| **æ•°æ®é‡å¾ˆå° (< 500)** | TARNet | é¿å…è¿‡æ‹Ÿåˆ |\n",
    "| **é«˜ç»´ç‰¹å¾ (å›¾åƒ/æ–‡æœ¬)** | DragonNet | æ›´å¥½çš„è¡¨ç¤ºå­¦ä¹  |\n",
    "\n",
    "## è¶…å‚æ•°è°ƒä¼˜å»ºè®®\n",
    "\n",
    "### TARNet\n",
    "- `hidden_dim`: 50-200\n",
    "- `repr_dim`: 25-100\n",
    "- `learning_rate`: 1e-4 ~ 1e-2\n",
    "- `batch_size`: 32-128\n",
    "\n",
    "### DragonNet\n",
    "- åŸºç¡€å‚æ•°åŒ TARNet\n",
    "- `alpha` (å€¾å‘å¾—åˆ†æƒé‡): 0.5-2.0\n",
    "  - æ··æ·†è¶Šå¼ºï¼Œalpha è¶Šå¤§\n",
    "  - å»ºè®®ä» 1.0 å¼€å§‹\n",
    "- `beta` (targeted reg æƒé‡): 0.5-2.0\n",
    "  - å¤„ç†åˆ†é…è¶Šä¸å¹³è¡¡ï¼Œbeta è¶Šå¤§\n",
    "  - å»ºè®®ä» 1.0 å¼€å§‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# æ€è€ƒé¢˜\n",
    "\n",
    "è¯·åœ¨ä¸‹é¢çš„å•å…ƒæ ¼ä¸­å†™ä¸‹ä½ çš„ç­”æ¡ˆï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æ€è€ƒé¢˜ 1: ä¸ºä»€ä¹ˆ TARNet éœ€è¦å…±äº«è¡¨ç¤ºå±‚ï¼Ÿä¸ºä»€ä¹ˆä¸ç»™ä¸¤ä¸ªå¤´åˆ†åˆ«çš„ç‰¹å¾æå–å™¨ï¼Ÿ\n\nanswer_1 = \"\"\"\nå‚è€ƒç­”æ¡ˆ:\n\nå…±äº«è¡¨ç¤ºå±‚çš„ä¸‰å¤§ä¼˜åŠ¿:\n\n1. **æ ·æœ¬æ•ˆç‡æå‡**:\n   - T=1çš„æ ·æœ¬åªèƒ½è®­ç»ƒY(1)å¤´ï¼ŒT=0çš„æ ·æœ¬åªèƒ½è®­ç»ƒY(0)å¤´\n   - ä½†å…±äº«å±‚Î¦(X)å¯ä»¥ä»æ‰€æœ‰æ ·æœ¬ä¸­å­¦ä¹ \n   - ç›¸å½“äºå˜ç›¸å¢åŠ äº†è®­ç»ƒæ•°æ®\n\n2. **çŸ¥è¯†è¿ç§»**:\n   - Y(0)å’ŒY(1)å¾€å¾€æœ‰å…±åŒçš„é¢„æµ‹å› å­ï¼ˆæ¯”å¦‚ç”¨æˆ·åŸºç¡€ç‰¹å¾ï¼‰\n   - å…±äº«è¡¨ç¤ºå…è®¸ä¸¤ä¸ªå¤´ä¹‹é—´çŸ¥è¯†è¿ç§»\n   - ç±»ä¼¼Multi-Task Learningçš„ç¡¬å‚æ•°å…±äº«\n\n3. **æ­£åˆ™åŒ–ä½œç”¨**:\n   - å¼ºè¿«æ¨¡å‹å­¦ä¹ å¯¹ä¸¤ç»„éƒ½æœ‰ç”¨çš„é€šç”¨ç‰¹å¾\n   - é˜²æ­¢è¿‡æ‹Ÿåˆåˆ°æŸä¸€ç»„çš„å™ªå£°\n\nå¦‚æœåˆ†åˆ«ä½¿ç”¨ç‰¹å¾æå–å™¨ï¼ˆT-Learnerï¼‰:\n- æ•°æ®åˆ©ç”¨ç‡ä½ï¼ˆæ¯ä¸ªæ¨¡å‹åªç”¨ä¸€åŠæ•°æ®ï¼‰\n- å®¹æ˜“è¿‡æ‹Ÿåˆ\n- ä½†å¼‚è´¨æ€§å»ºæ¨¡æ›´çµæ´»ï¼ˆä¸¤ä¸ªå®Œå…¨ç‹¬ç«‹çš„æ¨¡å‹ï¼‰\n\nå†³ç­–: æ•°æ®é‡å°/ç‰¹å¾å¤š â†’ TARNet; æ•°æ®é‡å¤§/å¼‚è´¨æ€§æå¼º â†’ T-Learner\n\"\"\"\nprint(answer_1)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æ€è€ƒé¢˜ 2: Factual Loss å’Œæ™®é€šçš„ç›‘ç£å­¦ä¹ æŸå¤±æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ\n\nanswer_2 = \"\"\"\nå‚è€ƒç­”æ¡ˆ:\n\næ ¸å¿ƒåŒºåˆ«åœ¨äº**å“ªäº›æ ·æœ¬å‚ä¸æŸå¤±è®¡ç®—**:\n\n**æ™®é€šç›‘ç£å­¦ä¹ **:\n- æ‰€æœ‰æ ·æœ¬éƒ½æœ‰æ ‡ç­¾Y\n- æŸå¤± = MSE(Y_pred, Y_true)ï¼Œå¯¹æ‰€æœ‰æ ·æœ¬\n\n**Factual Loss**:\n- æ¯ä¸ªæ ·æœ¬åªæœ‰ä¸€ä¸ªè§‚æµ‹ç»“æœï¼ˆfactualï¼‰\n- T=1çš„æ ·æœ¬: åªåœ¨Y(1)å¤´è®¡ç®—æŸå¤±\n- T=0çš„æ ·æœ¬: åªåœ¨Y(0)å¤´è®¡ç®—æŸå¤±\n- æŸå¤±æ˜¯\"æ¡ä»¶æ€§çš„\"\n\næ•°å­¦å½¢å¼å¯¹æ¯”:\n\næ™®é€šç›‘ç£:\nL = 1/N Î£ (Y_i - f(X_i, T_i))Â²\n\nFactual Loss:\nL = 1/N Î£ (Y_i - [T_iÂ·Î¼â‚(X_i) + (1-T_i)Â·Î¼â‚€(X_i)])Â²\n\nå…³é”®æ´å¯Ÿ:\n- Factual Losså®é™…ä¸Šæ˜¯**åŠç›‘ç£å­¦ä¹ **\n- Y(0)å¯¹äºT=1çš„æ ·æœ¬æ˜¯\"ç¼ºå¤±\"çš„\n- Y(1)å¯¹äºT=0çš„æ ·æœ¬æ˜¯\"ç¼ºå¤±\"çš„\n- å…±äº«è¡¨ç¤ºÎ¦(X)èµ·åˆ°äº†çŸ¥è¯†è¿ç§»çš„ä½œç”¨\n\nä¸ºä»€ä¹ˆä¸èƒ½ç”¨æ™®é€šç›‘ç£å­¦ä¹ ?\n- å› ä¸ºæˆ‘ä»¬æƒ³ä¼°è®¡Y(0)å’ŒY(1)çš„å·®å¼‚ï¼ˆITEï¼‰\n- æ™®é€šå›å½’åªç»™å‡ºY = f(X, T)ï¼Œæ— æ³•åˆ†ç¦»åäº‹å®\n\"\"\"\nprint(answer_2)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æ€è€ƒé¢˜ 3: DragonNet çš„å€¾å‘å¾—åˆ†å¤´åœ¨æ¨¡å‹ä¸­èµ·ä»€ä¹ˆä½œç”¨ï¼Ÿä¸ºä»€ä¹ˆä¸å•ç‹¬è®­ç»ƒä¸€ä¸ªå€¾å‘å¾—åˆ†æ¨¡å‹ï¼Ÿ\n\nanswer_3 = \"\"\"\nå‚è€ƒç­”æ¡ˆ:\n\nå€¾å‘å¾—åˆ†å¤´çš„ä¸‰å¤§ä½œç”¨:\n\n1. **æ­£åˆ™åŒ–å…±äº«è¡¨ç¤º**:\n   - å¼ºè¿«Î¦(X)åŒæ—¶å­¦ä¹ \"é¢„æµ‹Y\"å’Œ\"é¢„æµ‹T\"\n   - è¿™æ„å‘³ç€è¡¨ç¤ºå±‚å¿…é¡»æ•è·å½±å“å¤„ç†åˆ†é…çš„å› ç´ \n   - è¿™äº›å› ç´ å¾€å¾€ä¹Ÿæ˜¯æ··æ·†å› å­!\n\n2. **ä¿¡æ¯å…±äº«ä¸ååŒè®­ç»ƒ**:\n   - è”åˆè®­ç»ƒè®©ä¸‰ä¸ªä»»åŠ¡ç›¸äº’å¢å¼º\n   - å€¾å‘å¾—åˆ†å¤´çš„æ¢¯åº¦ä¹Ÿä¼šæ›´æ–°å…±äº«è¡¨ç¤º\n   - ç±»ä¼¼Multi-Task Learningçš„æ•ˆæœ\n\n3. **Targeted Regularizationçš„åŸºç¡€**:\n   - DragonNetçš„ç¬¬ä¸‰é¡¹æŸå¤±éœ€è¦å€¾å‘å¾—åˆ†e(X)\n   - å¦‚æœå•ç‹¬è®­ç»ƒï¼Œæ¢¯åº¦æ— æ³•åå‘ä¼ æ’­\n   - è”åˆè®­ç»ƒå®ç°ç«¯åˆ°ç«¯ä¼˜åŒ–\n\nä¸ºä»€ä¹ˆä¸å•ç‹¬è®­ç»ƒå€¾å‘å¾—åˆ†æ¨¡å‹?\n\n**åˆ†ç¦»è®­ç»ƒçš„é—®é¢˜**:\n- å€¾å‘å¾—åˆ†æ¨¡å‹å’Œç»“æœæ¨¡å‹å„è‡ªä¼˜åŒ–ï¼Œå¯èƒ½ä¸ä¸€è‡´\n- æ— æ³•ç«¯åˆ°ç«¯ä¼˜åŒ–Targeted Regularization\n- å¤±å»äº†å¤šä»»åŠ¡å­¦ä¹ çš„æ­£åˆ™åŒ–benefit\n\n**è”åˆè®­ç»ƒçš„ä¼˜åŠ¿**:\n- å…±äº«è¡¨ç¤ºÎ¦(X)è¢«å¤šä¸ªç›®æ ‡çº¦æŸ\n- å€¾å‘å¾—åˆ†å¤´èµ·åˆ°\"æŒ‡å¯¼\"ä½œç”¨ï¼Œå‘Šè¯‰è¡¨ç¤ºå±‚ä»€ä¹ˆæ˜¯é‡è¦ç‰¹å¾\n- ç†è®ºä¸Šæ›´æ¥è¿‘åŒé‡é²æ£’æ€§ä¼°è®¡å™¨\n\nç±»æ¯”: åƒæ˜¯åœ¨å­¦ä¹ æ—¶åŒæ—¶åš\"ä¹ é¢˜\"(é¢„æµ‹Y)å’Œ\"çŸ¥è¯†ç‚¹æ¢³ç†\"(ç†è§£Tçš„åˆ†é…æœºåˆ¶)ï¼Œæ•ˆæœæ¯”å•ç‹¬åšä¹ é¢˜æ›´å¥½\n\"\"\"\nprint(answer_3)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æ€è€ƒé¢˜ 4: Targeted Regularization ä¸­çš„ h = T/e(X) - (1-T)/(1-e(X)) çš„ç›´è§‰æ˜¯ä»€ä¹ˆï¼Ÿ\n\nanswer_4 = \"\"\"\nå‚è€ƒç­”æ¡ˆ:\n\nè¿™ä¸ªå…¬å¼æ¥è‡ª**é€†å€¾å‘åŠ æƒ(IPW)**å’Œ**åŒé‡é²æ£’æ€§**ç†è®ºã€‚\n\nç›´è§‰è§£é‡Š - æ°‘æ„è°ƒæŸ¥çš„ç±»æ¯”:\n\næƒ³è±¡ä½ åœ¨åšæ°‘æ„è°ƒæŸ¥ï¼Œä½†ä¸åŒäººç¾¤è¢«è°ƒæŸ¥åˆ°çš„æ¦‚ç‡ä¸åŒ:\n\nh = T/e(X) - (1-T)/(1-e(X))\n\n**ç¬¬ä¸€é¡¹ T/e(X)** (è¢«å¤„ç†ç»„):\n- e(X)å°çš„äºº â†’ æƒé‡å¤§\n- æ„æ€: \"æœ¬æ¥ä¸å¤ªå¯èƒ½è¢«å¤„ç†ï¼Œä½†å®é™…è¢«å¤„ç†äº†\"çš„æ ·æœ¬æ›´é‡è¦\n- ç±»æ¯”: ä¸çˆ±æ¥ç”µè¯çš„å¹´è½»äººå¦‚æœæ¥äº†ç”µè¯ï¼Œä»–ä»¬çš„æ„è§è¦åŠ æƒ\n\n**ç¬¬äºŒé¡¹ -(1-T)/(1-e(X))** (æ§åˆ¶ç»„):\n- e(X)å¤§çš„äºº â†’ æƒé‡å¤§ï¼ˆå–è´Ÿå·ï¼‰\n- æ„æ€: \"æœ¬æ¥å¾ˆå¯èƒ½è¢«å¤„ç†ï¼Œä½†å®é™…æ²¡è¢«å¤„ç†\"çš„æ ·æœ¬æ›´é‡è¦\n- ç±»æ¯”: çˆ±æ¥ç”µè¯çš„è€å¹´äººå¦‚æœæ²¡æ¥ç”µè¯ï¼Œè¿™ä¸ªç¼ºå¤±æ›´éœ€è¦è¡¥å¿\n\n**hçš„ä½œç”¨**:\n1. å¹³è¡¡å¤„ç†ç»„å’Œæ§åˆ¶ç»„çš„åˆ†å¸ƒå·®å¼‚\n2. ç»™\"åå¸¸\"æ ·æœ¬æ›´å¤§æƒé‡ï¼ˆé«˜e(X)ä½†T=0ï¼Œæˆ–ä½e(X)ä½†T=1ï¼‰\n3. æœ¬è´¨æ˜¯IPWçš„è°ƒæ•´å› å­\n\n**ä¸ºä»€ä¹ˆåœ¨Targeted Regä¸­ä½¿ç”¨**:\n\nL_TR = E[(Y - Å¶ - ÎµÂ·h)Â²]\n\n- å¦‚æœæ¨¡å‹é¢„æµ‹Å¶å·²ç»å¾ˆå‡†ï¼ŒÎµä¼šå­¦åˆ°0\n- å¦‚æœæœ‰ç³»ç»Ÿæ€§åå·®ï¼ŒÎµÂ·hæä¾›\"å€¾å‘å¾—åˆ†æ–¹å‘\"çš„ä¿®æ­£\n- è¿™å®ç°äº†åŒé‡é²æ£’æ€§: ç»“æœæ¨¡å‹å‡† or å€¾å‘å¾—åˆ†æ¨¡å‹å‡†ï¼Œä»»ä¸€ä¸ªå¯¹ï¼Œä¼°è®¡å°±æ— å\n\næ•°å­¦æ¥æº:\nè¿™æ¥è‡ªåŠå‚æ•°æ•ˆç‡ç†è®ºä¸­çš„Efficient Influence Function (EIF)ã€‚\n\"\"\"\nprint(answer_4)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æ€è€ƒé¢˜ 5: epsilon å‚æ•°çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆå®ƒæ˜¯å¯å­¦ä¹ çš„ï¼Ÿ\n\nanswer_5 = \"\"\"\nå‚è€ƒç­”æ¡ˆ:\n\nepsilon (Îµ) æ˜¯Targeted Regularizationä¸­çš„**å¯å­¦ä¹ æ ‡é‡å‚æ•°**ã€‚\n\nä½œç”¨:\n\n1. **è‡ªé€‚åº”ä¿®æ­£å¹…åº¦**:\n   - Îµæ§åˆ¶å€¾å‘å¾—åˆ†è°ƒæ•´é¡¹hçš„å¼ºåº¦\n   - L_TR = E[(Y - Å¶ - ÎµÂ·h)Â²]\n   - Îµå¤§ â†’ æ›´ä¾èµ–å€¾å‘å¾—åˆ†ä¿®æ­£\n   - Îµå° â†’ æ›´ä¾èµ–ç»“æœæ¨¡å‹é¢„æµ‹\n\n2. **åŒé‡é²æ£’æ€§çš„æ¡¥æ¢**:\n   - å¦‚æœç»“æœæ¨¡å‹Å¶å·²ç»å¾ˆå‡† â†’ Îµä¼šå­¦åˆ°â‰ˆ0\n   - å¦‚æœç»“æœæ¨¡å‹æœ‰åå·® â†’ Îµå­¦åˆ°éé›¶å€¼ï¼Œç”¨hæ¥è¡¥å¿\n   - è‡ªåŠ¨å¹³è¡¡ä¸¤ç§ç­–ç•¥\n\n3. **æ¨¡å‹é€‰æ‹©æŒ‡æ ‡**:\n   - è®­ç»ƒåÎµçš„å€¼åæ˜ æ¨¡å‹è´¨é‡\n   - Îµâ‰ˆ0: ç»“æœæ¨¡å‹å·²ç»è¶³å¤Ÿå‡†\n   - Îµè¾ƒå¤§: éœ€è¦å€¾å‘å¾—åˆ†ä¿®æ­£\n\nä¸ºä»€ä¹ˆæ˜¯å¯å­¦ä¹ çš„?\n\n**å›ºå®šÎµçš„é—®é¢˜**:\n- ä¸åŒæ•°æ®é›†æœ€ä¼˜çš„Îµä¸åŒ\n- æ··æ·†ç¨‹åº¦å¼º â†’ éœ€è¦å¤§Îµ\n- æ··æ·†ç¨‹åº¦å¼± â†’ éœ€è¦å°Îµ\n\n**å¯å­¦ä¹ Îµçš„ä¼˜åŠ¿**:\n- ç«¯åˆ°ç«¯ä¼˜åŒ–ï¼Œè‡ªåŠ¨æ‰¾åˆ°æœ€ä¼˜ä¿®æ­£å¼ºåº¦\n- é€‚åº”ä¸åŒçš„æ•°æ®åˆ†å¸ƒ\n- é¿å…æ‰‹åŠ¨è°ƒå‚\n\nå®ç°ç»†èŠ‚:\n```python\nclass DragonNet(nn.Module):\n    def __init__(self):\n        self.epsilon = nn.Parameter(torch.tensor(0.0))  # åˆå§‹åŒ–ä¸º0\n```\n\nè®­ç»ƒè¿‡ç¨‹:\n- åˆå§‹é˜¶æ®µ: Îµâ‰ˆ0ï¼Œä¸»è¦é ç»“æœæ¨¡å‹\n- ä¸­æœŸ: Îµå¼€å§‹å­¦ä¹ ï¼Œå¼•å…¥å€¾å‘å¾—åˆ†ä¿®æ­£\n- åæœŸ: Îµæ”¶æ•›åˆ°æŸä¸ªå€¼ï¼Œåæ˜ æœ€ä¼˜å¹³è¡¡ç‚¹\n\nç›‘æ§Îµçš„å˜åŒ–å¯ä»¥ç†è§£æ¨¡å‹çš„å­¦ä¹ è¿‡ç¨‹!\n\"\"\"\nprint(answer_5)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æ€è€ƒé¢˜ 6: åœ¨ä½ çš„å®éªŒä¸­ï¼ŒDragonNet æ¯” TARNet æ•ˆæœå¥½å—ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n\nanswer_6 = \"\"\"\nå‚è€ƒç­”æ¡ˆ:\n\nä»å®éªŒç»“æœçœ‹ï¼ˆè¿è¡Œä½ è‡ªå·±çš„å®éªŒåå¡«å†™ï¼‰:\n\nPEHEå¯¹æ¯”: TARNet = ____, DragonNet = ____\nATEè¯¯å·®å¯¹æ¯”: TARNet = ____, DragonNet = ____\n\n**å¦‚æœDragonNetæ›´å¥½**:\n\nåŸå› åˆ†æ:\n1. æ•°æ®æœ‰å¼ºæ··æ·† - æˆ‘ä»¬ç”Ÿæˆæ•°æ®æ—¶ç‰¹æ„è®¾è®¡äº†æ··æ·†\n2. å€¾å‘å¾—åˆ†å¤´æ•è·äº†å¤„ç†åˆ†é…æœºåˆ¶\n3. Targeted Regularizationæä¾›äº†é¢å¤–çš„æ­£åˆ™åŒ–\n\n**å¦‚æœå·®ä¸å¤š**:\n\nå¯èƒ½åŸå› :\n1. æ•°æ®é‡ä¸å¤Ÿå¤§ï¼ŒDragonNetçš„ä¼˜åŠ¿æ²¡ä½“ç°å‡ºæ¥\n2. æ··æ·†ä¸å¤Ÿå¼ºï¼ŒTARNetå·²ç»è¶³å¤Ÿ\n3. è¶…å‚æ•°Î±å’ŒÎ²æ²¡è°ƒå¥½\n\n**å¦‚æœTARNetæ›´å¥½** (è¾ƒå°‘è§):\n\nå¯èƒ½åŸå› :\n1. DragonNetè¿‡æ‹Ÿåˆï¼ˆå‚æ•°æ›´å¤šï¼‰\n2. å€¾å‘å¾—åˆ†å¤´å­¦ä¹ å¤±è´¥ï¼ˆæ£€æŸ¥propensity_lossæ˜¯å¦æ”¶æ•›ï¼‰\n3. alphaå’Œbetaè®¾ç½®ä¸åˆç†\n\n**å®éªŒè®¾è®¡çš„æ´å¯Ÿ**:\n\næˆ‘ä»¬çš„æ•°æ®ç”Ÿæˆè¿‡ç¨‹:\n```python\n# å¼ºæ··æ·†: Xå½±å“Tçš„åˆ†é…\npropensity = sigmoid(1.0*X[:,0] + 0.8*X[:,1] + 0.6*X[:,2])\n\n# Xä¹Ÿå½±å“Y\nY0 = 2.0 + X[:,0] + 0.5*X[:,1] + noise\n```\n\nè¿™æ˜¯å…¸å‹çš„\"Xæ—¢æ˜¯æ··æ·†å› å­åˆæ˜¯é¢„æµ‹å› å­\"åœºæ™¯ â†’ DragonNetåº”è¯¥æ›´å¥½\n\n**è¿›ä¸€æ­¥å®éªŒ**:\nå¯ä»¥å°è¯•è°ƒæ•´:\n- å¢å¤§alphaï¼ˆå¦‚2.0ï¼‰â†’ æ›´å¼ºçš„å€¾å‘å¾—åˆ†çº¦æŸ\n- å¢å¤§betaï¼ˆå¦‚2.0ï¼‰â†’ æ›´å¼ºçš„targeted reg\n- è§‚å¯Ÿepsilonçš„å˜åŒ–è½¨è¿¹\n\"\"\"\nprint(answer_6)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æ€è€ƒé¢˜ 7: å¦‚æœå¤„ç†åˆ†é…æ˜¯å®Œå…¨éšæœºçš„ï¼ˆRCTï¼‰ï¼ŒDragonNet è¿˜æœ‰ä¼˜åŠ¿å—ï¼Ÿ\n\nanswer_7 = \"\"\"\nå‚è€ƒç­”æ¡ˆ:\n\nåœ¨RCTï¼ˆéšæœºå¯¹ç…§è¯•éªŒï¼‰ä¸­ï¼Œ**DragonNetçš„ä¼˜åŠ¿ä¼šå¤§å¹…å‡å¼±ï¼Œä½†ä¸ä¼šå®Œå…¨æ¶ˆå¤±**ã€‚\n\n**ç†è®ºåˆ†æ**:\n\nRCTæ„å‘³ç€: T âŠ¥ X (å¤„ç†åˆ†é…ä¸ç‰¹å¾ç‹¬ç«‹)\n\næ­¤æ—¶:\n1. **æ— æ··æ·†** â†’ ä¸éœ€è¦å€¾å‘å¾—åˆ†è°ƒæ•´\n2. **e(X) = å¸¸æ•°** (æ¯”å¦‚0.5) â†’ å€¾å‘å¾—åˆ†å¤´å­¦åˆ°çš„æ˜¯å¸¸æ•°\n3. **Targeted Regä¸­çš„h â‰ˆ 0** â†’ ç¬¬ä¸‰é¡¹æŸå¤±å‡ ä¹ä¸èµ·ä½œç”¨\n\nDragonNeté€€åŒ–ä¸º:\nL = L_factual + Î±Â·L_propensity\n\nè€ŒL_propensityåœ¨RCTä¸­åªæ˜¯åœ¨æ‹Ÿåˆä¸€ä¸ªå¸¸æ•°å‡½æ•°ã€‚\n\n**å¯èƒ½çš„å°ä¼˜åŠ¿**:\n\n1. **æ­£åˆ™åŒ–æ•ˆæœ**:\n   - å³ä½¿åœ¨RCTï¼Œå¤šä»»åŠ¡å­¦ä¹ çš„æ­£åˆ™åŒ–ä»ç„¶æœ‰ç”¨\n   - å€¾å‘å¾—åˆ†å¤´å¯èƒ½å¸®åŠ©è¡¨ç¤ºå±‚å­¦ä¹ æ›´é²æ£’çš„ç‰¹å¾\n\n2. **å¹³è¡¡æ£€éªŒ**:\n   - å¦‚æœå€¾å‘å¾—åˆ†å¤´å­¦åˆ°e(X) â‰  å¸¸æ•°ï¼Œè¯´æ˜å¯èƒ½æœ‰é—®é¢˜\n   - å¯ä»¥ç”¨æ¥æ£€éªŒéšæœºåŒ–æ˜¯å¦æˆåŠŸ\n\n**å®éªŒéªŒè¯**:\n\nç”ŸæˆRCTæ•°æ®:\n```python\nT = np.random.binomial(1, 0.5, n)  # å®Œå…¨éšæœº\n```\n\né¢„æœŸç»“æœ:\n- TARNetå’ŒDragonNetæ€§èƒ½æ¥è¿‘\n- DragonNetçš„epsilon â‰ˆ 0\n- propensity_headå­¦åˆ°â‰ˆ0.5çš„å¸¸æ•°\n\n**å®è·µå»ºè®®**:\n\nRCTåœºæ™¯:\n- ä¼˜å…ˆç”¨TARNetï¼ˆæ›´ç®€å•ï¼‰\n- å¦‚æœç”¨DragonNetï¼Œè®¾ç½®è¾ƒå°çš„alphaå’Œbeta\n- å…³æ³¨epsilonçš„å€¼ï¼ˆåº”è¯¥æ¥è¿‘0ï¼‰\n\nè§‚å¯Ÿæ€§ç ”ç©¶:\n- DragonNetæ›´æœ‰ä¼˜åŠ¿\n- å€¾å‘å¾—åˆ†å¤´æ•è·é€‰æ‹©åå·®\n- Targeted Regå‡å°‘åå·®\n\nç»“è®º: DragonNetæ˜¯ä¸º**æ··æ·†/é€‰æ‹©åå·®**è®¾è®¡çš„ï¼ŒRCTä¸­å…¶ä¼˜åŠ¿ä¸æ˜æ˜¾ã€‚\n\"\"\"\nprint(answer_7)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# é¢è¯•é¢˜æ¨¡æ‹Ÿä¸æ·±åº¦å‰–æ\n\n## é«˜é¢‘é¢è¯•é¢˜é›†é”¦\n\n### é¢˜ç›® 1: TARNet å’Œæ™®é€šç¥ç»ç½‘ç»œå›å½’æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ\n\n**æ ‡å‡†ç­”æ¡ˆ**:\n\nTARNet ä¸æ™®é€šç¥ç»ç½‘ç»œå›å½’çš„æ ¸å¿ƒåŒºåˆ«åœ¨äº:\n\n1. **æ¶æ„è®¾è®¡**:\n   - æ™®é€šå›å½’: X â†’ NN â†’ Y\n   - TARNet: X â†’ å…±äº«è¡¨ç¤ºÎ¦(X) â†’ åŒå¤´[Î¼â‚€, Î¼â‚]\n\n2. **è®­ç»ƒç­–ç•¥**:\n   - æ™®é€šå›å½’: ç›´æ¥ç”¨æ‰€æœ‰æ ·æœ¬è®­ç»ƒY = f(X, T)\n   - TARNet: Factual Loss - åªåœ¨è§‚æµ‹åˆ°çš„ç»“æœä¸Šè®¡ç®—æŸå¤±\n\n3. **åäº‹å®æ¨æ–­**:\n   - æ™®é€šå›å½’: æ— æ³•ç›´æ¥ç»™å‡ºåäº‹å®\n   - TARNet: åŒæ—¶é¢„æµ‹Y(0)å’ŒY(1)\n\n4. **æ ·æœ¬æ•ˆç‡**:\n   - æ™®é€šå›å½’: ä¸¤ç»„æ ·æœ¬ç‹¬ç«‹è®­ç»ƒ\n   - TARNet: å…±äº«è¡¨ç¤ºï¼Œæé«˜æ ·æœ¬æ•ˆç‡\n\n**è¿›é˜¶å›ç­”** (åŠ åˆ†é¡¹):\n\nTARNetçš„Factual Losså®é™…ä¸Šæ˜¯åœ¨åš**åŠç›‘ç£å­¦ä¹ **:\n- å¯¹äºT=1çš„æ ·æœ¬ï¼Œæˆ‘ä»¬åªè§‚æµ‹åˆ°Y(1)ï¼ŒY(0)æ˜¯\"ç¼ºå¤±\"çš„\n- å…±äº«è¡¨ç¤ºÎ¦(X)å…è®¸ä¸¤ç»„ä¹‹é—´çš„çŸ¥è¯†è¿ç§»\n- è¿™ç±»ä¼¼äºMulti-Task Learningä¸­çš„ç¡¬å‚æ•°å…±äº«\n\n---\n\n### é¢˜ç›® 2: DragonNet ä¸ºä»€ä¹ˆè¦è”åˆé¢„æµ‹å€¾å‘å¾—åˆ†ï¼Ÿ\n\n**æ ‡å‡†ç­”æ¡ˆ**:\n\nDragonNetæ·»åŠ å€¾å‘å¾—åˆ†å¤´çš„ä¸‰å¤§åŸå› :\n\n1. **æ­£åˆ™åŒ–ä½œç”¨**:\n   - å¼ºè¿«è¡¨ç¤ºå±‚Î¦(X)åŒæ—¶å­¦ä¹ \"é¢„æµ‹Y\"å’Œ\"é¢„æµ‹T\"\n   - é˜²æ­¢è¡¨ç¤ºå±‚åªä¼˜åŒ–ç»“æœé¢„æµ‹è€Œå¿½ç•¥æ··æ·†å› å­\n\n2. **æ•è·æ··æ·†**:\n   - å€¾å‘å¾—åˆ†e(X) = P(T=1|X)åæ˜ äº†Xä¸­å“ªäº›å› ç´ å½±å“å¤„ç†åˆ†é…\n   - è¿™äº›å› ç´ å¾€å¾€ä¹Ÿæ˜¯æ··æ·†å› å­\n\n3. **Targeted Regularization**:\n   - åˆ©ç”¨å€¾å‘å¾—åˆ†æ„é€ åŒé‡é²æ£’æ€§çš„è°ƒæ•´é¡¹\n   - ç†è®ºä¸Šå¯ä»¥å‡å°‘åå·®(æ¥è‡ªTMLEç†è®º)\n\n**æ•°å­¦æ¨å¯¼**:\n\næ ¹æ®åŒé‡é²æ£’æ€§ç†è®º:\n\n$$\\tau = \\mathbb{E}\\left[\\frac{T \\cdot Y}{e(X)} - \\frac{(1-T) \\cdot Y}{1-e(X)}\\right]$$\n\nDragonNetçš„Targeted Regularizationæ­£æ˜¯åˆ©ç”¨è¿™ä¸ªåŸç†:\n\n$$h_i = \\frac{T_i}{\\hat{e}(X_i)} - \\frac{1-T_i}{1-\\hat{e}(X_i)}$$\n\nå½“ç»“æœæ¨¡å‹Î¼â‚€, Î¼â‚å‡†ç¡®æˆ–å€¾å‘å¾—åˆ†æ¨¡å‹e(X)å‡†ç¡®æ—¶ï¼Œä¼°è®¡éƒ½æ˜¯æ— åçš„ã€‚\n\n**é¢è¯•åŠ åˆ†ç‚¹**:\n- æåˆ°TMLE (Targeted Maximum Likelihood Estimation)\n- æåˆ°åŒé‡é²æ£’æ€§\n- èƒ½ç”»å‡ºDragonNetçš„ä¸‰å¤´æ¶æ„å›¾\n\n---\n\n### é¢˜ç›® 3: CEVAE çš„æ ¸å¿ƒå‡è®¾æ˜¯ä»€ä¹ˆï¼Ÿ\n\n**æ ‡å‡†ç­”æ¡ˆ**:\n\nCEVAEä¾èµ–äº**ä»£ç†å˜é‡å‡è®¾** (Proxy Variable Assumption):\n\n1. **å‡è®¾å†…å®¹**:\n   - å­˜åœ¨éšå˜é‡Zå½±å“Xã€Tã€Y\n   - è§‚æµ‹åˆ°çš„XåŒ…å«å…³äºZçš„\"è¶³å¤Ÿä¿¡æ¯\"\n   - å½¢å¼åŒ–: $p(Y(t) | X, Z) = p(Y(t) | X)$\n\n2. **è¯†åˆ«æ¡ä»¶**:\n   ```\n   Z â†’ X (Xæ˜¯Zçš„ä»£ç†)\n   Z â†’ T (Zå½±å“å¤„ç†åˆ†é…)\n   Z â†’ Y (Zå½±å“ç»“æœ)\n   ```\n\n3. **ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”**:\n   - IPW/PSMå‡è®¾: æ‰€æœ‰æ··æ·†éƒ½è¢«è§‚æµ‹ (Unconfoundedness)\n   - IVå‡è®¾: Z âŠ¥ Y | T (Zä¸ç›´æ¥å½±å“Y)\n   - CEVAEå‡è®¾: Zéƒ¨åˆ†è§‚æµ‹(é€šè¿‡X)\n\n**ä¸ºä»€ä¹ˆè¿™ä¸ªå‡è®¾é‡è¦**:\n\nå¦‚æœXå®Œå…¨ä¸åŒ…å«Zçš„ä¿¡æ¯ï¼ŒCEVAEä¼šå¤±è´¥ï¼Œå› ä¸º:\n- åéªŒæ¨æ–­q(Z|X,T,Y)æ— æ³•ä»Xä¸­\"è¿˜åŸ\"Z\n- è¿™æ—¶CEVAEé€€åŒ–ä¸ºç›²ç›®çŒœæµ‹\n\n**é¢è¯•å®˜è¿½é—®**: \"å¦‚ä½•éªŒè¯è¿™ä¸ªå‡è®¾ï¼Ÿ\"\n\nç­”: \n1. é¢†åŸŸçŸ¥è¯†: ç¡®ä¿XåŒ…å«ç›¸å…³çš„ä»£ç†æŒ‡æ ‡\n2. æ•æ„Ÿæ€§åˆ†æ: æµ‹è¯•ä¸åŒçš„éšå˜é‡ç»´åº¦\n3. é¢„æµ‹æ£€éªŒ: æ£€æŸ¥Xçš„é‡æ„è´¨é‡\n\n---\n\n### é¢˜ç›® 4: æ·±åº¦å­¦ä¹ å› æœæ¨¡å‹çš„ä¸»è¦æŒ‘æˆ˜æ˜¯ä»€ä¹ˆï¼Ÿ\n\n**æ ‡å‡†ç­”æ¡ˆ** (å¤šç»´åº¦å›ç­”):\n\n#### 1. ç†è®ºæŒ‘æˆ˜\n\n- **è¯†åˆ«æ€§**: æ·±åº¦æ¨¡å‹çš„éå‡¸ä¼˜åŒ–ä½¿å¾—è¯†åˆ«æ¡ä»¶éš¾ä»¥éªŒè¯\n- **è¿‡æ‹Ÿåˆ**: å‚æ•°å¤šï¼Œå®¹æ˜“è®°ä½å™ªå£°è€Œéå› æœå…³ç³»\n- **å¯è§£é‡Šæ€§**: é»‘ç›’æ¨¡å‹ï¼Œéš¾ä»¥ç†è§£å­¦åˆ°äº†ä»€ä¹ˆ\n\n#### 2. å®è·µæŒ‘æˆ˜\n\n- **è¶…å‚æ•°æ•æ„Ÿ**: ç½‘ç»œæ·±åº¦ã€å®½åº¦ã€å­¦ä¹ ç‡éƒ½ä¼šå½±å“ç»“æœ\n- **è®­ç»ƒä¸ç¨³å®š**: GAN-basedæ–¹æ³•(å¦‚GANITE)å®¹æ˜“æ¨¡å¼å´©æºƒ\n- **è®¡ç®—æˆæœ¬**: æ¯”ä¼ ç»Ÿæ–¹æ³•æ…¢å¾ˆå¤š\n\n#### 3. æ•°æ®æŒ‘æˆ˜\n\n- **æ ·æœ¬éœ€æ±‚**: æ·±åº¦æ¨¡å‹é€šå¸¸éœ€è¦æ›´å¤šæ•°æ®\n- **æ ‡ç­¾å™ªå£°**: å¯¹Yçš„æµ‹é‡è¯¯å·®æ›´æ•æ„Ÿ\n- **åˆ†å¸ƒåç§»**: æµ‹è¯•é›†å’Œè®­ç»ƒé›†åˆ†å¸ƒä¸åŒæ—¶è¡¨ç°å·®\n\n#### 4. æ–¹æ³•è®ºæŒ‘æˆ˜\n\n- **è¯„ä¼°å›°éš¾**: çœŸå®ITEæ— æ³•è§‚æµ‹ï¼Œåªèƒ½ç”¨PEHEç­‰æ¨¡æ‹ŸæŒ‡æ ‡\n- **åŸºå‡†ç¼ºå¤±**: æ²¡æœ‰ç»Ÿä¸€çš„benchmark\n- **è°ƒå‚é»‘ç®±**: ä¸åŒä»»åŠ¡éœ€è¦é‡æ–°è°ƒå‚\n\n**æœ€ä½³å®è·µå»ºè®®**:\n\n1. ä»ç®€å•æ¨¡å‹å¼€å§‹(å¦‚TARNet)\n2. ä½¿ç”¨äº¤å‰éªŒè¯é€‰æ‹©è¶…å‚æ•°\n3. è¿›è¡Œæ¶ˆèå®éªŒéªŒè¯æ¯ä¸ªç»„ä»¶çš„ä½œç”¨\n4. æ•æ„Ÿæ€§åˆ†ææµ‹è¯•é²æ£’æ€§\n\n---\n\n## è¿›é˜¶é¢è¯•é¢˜\n\n### é¢˜ç›® 5: å¦‚æœä½ è¦è®¾è®¡ä¸€ä¸ªæ–°çš„æ·±åº¦å› æœæ¨¡å‹ï¼Œä½ ä¼šè€ƒè™‘ä»€ä¹ˆï¼Ÿ\n\n**ç­”é¢˜æ€è·¯** (å±•ç¤ºæ€ç»´è¿‡ç¨‹):\n\n#### Step 1: æ˜ç¡®é—®é¢˜è®¾å®š\n\n- äºŒå€¼å¤„ç† vs è¿ç»­å¤„ç† vs å¤šå€¼å¤„ç†ï¼Ÿ\n- è§‚æµ‹æ•°æ® vs RCTï¼Ÿ\n- æ˜¯å¦å­˜åœ¨æœªè§‚æµ‹æ··æ·†ï¼Ÿ\n\n#### Step 2: é€‰æ‹©åŸºç¡€æ¶æ„\n\n- å…±äº«è¡¨ç¤º + å¤šå¤´ (ç±»ä¼¼TARNet)\n- VAEæ¡†æ¶ (ç±»ä¼¼CEVAE)\n- GANæ¡†æ¶ (ç±»ä¼¼GANITE)\n\n#### Step 3: è®¾è®¡æŸå¤±å‡½æ•°\n\næ ¸å¿ƒæƒè¡¡:\n```\nL_total = L_prediction + Î±Â·L_balance + Î²Â·L_regularization\n```\n\n- L_prediction: Factual loss\n- L_balance: IPM (MMD/Wasserstein)\n- L_regularization: é¢†åŸŸçŸ¥è¯†çº¦æŸ\n\n#### Step 4: åˆ›æ–°ç‚¹\n\nå¯èƒ½çš„æ–¹å‘:\n1. **æ³¨æ„åŠ›æœºåˆ¶**: è‡ªåŠ¨å­¦ä¹ å“ªäº›ç‰¹å¾æ˜¯æ··æ·†å› å­\n2. **å…ƒå­¦ä¹ **: å¿«é€Ÿé€‚åº”æ–°çš„å› æœä»»åŠ¡\n3. **ä¸ç¡®å®šæ€§é‡åŒ–**: è´å¶æ–¯æ·±åº¦å­¦ä¹ \n4. **å› æœå›¾å‘ç°**: è”åˆå­¦ä¹ ç»“æ„å’Œå‚æ•°\n\n**é¢è¯•åŠ åˆ†ç‚¹**:\n- å¼•ç”¨æœ€æ–°è®ºæ–‡ (ICML/NeurIPS)\n- æåˆ°å…·ä½“åº”ç”¨åœºæ™¯\n- è®¨è®ºtrade-offs\n\n---\n\n### é¢˜ç›® 6: TARNetå’ŒT-Learneræœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿä»€ä¹ˆæ—¶å€™ç”¨å“ªä¸ªï¼Ÿ\n\n**å¯¹æ¯”åˆ†æ**:\n\n| ç»´åº¦ | T-Learner | TARNet |\n|------|-----------|--------|\n| å‚æ•°å…±äº« | æ—  (ä¸¤ä¸ªç‹¬ç«‹æ¨¡å‹) | æœ‰ (å…±äº«è¡¨ç¤ºå±‚) |\n| æ ·æœ¬æ•ˆç‡ | ä½ (å„ç”¨ä¸€åŠæ•°æ®) | é«˜ (å…±äº«çŸ¥è¯†) |\n| è¿‡æ‹Ÿåˆé£é™© | é«˜ | ä¸­ç­‰ |\n| å®ç°å¤æ‚åº¦ | ç®€å• | ä¸­ç­‰ |\n| å¼‚è´¨æ€§å»ºæ¨¡ | çµæ´» | å—å…±äº«è¡¨ç¤ºçº¦æŸ |\n\n**å†³ç­–æ ‘**:\n\n```\næ•°æ®é‡å¤§ (>10k) ?\nâ”œâ”€ æ˜¯ â†’ å¼‚è´¨æ€§å¾ˆå¼ºï¼Ÿ\nâ”‚       â”œâ”€ æ˜¯ â†’ T-Learner\nâ”‚       â””â”€ å¦ â†’ TARNet\nâ””â”€ å¦ â†’ ç‰¹å¾ç»´åº¦é«˜ï¼Ÿ\n        â”œâ”€ æ˜¯ â†’ TARNet (éœ€è¦æ­£åˆ™åŒ–)\n        â””â”€ å¦ â†’ T-Learner æˆ– TARNetéƒ½å¯\n```\n\n---\n\n## æ ¸å¿ƒæ•°å­¦æ¨å¯¼\n\n### æ¨å¯¼ 1: TARNet çš„ Factual Loss\n\n**ç›®æ ‡**: æœ€å°åŒ–é¢„æµ‹è¯¯å·®\n\n$$\\mathcal{L} = \\mathbb{E}[(Y - \\hat{Y})^2]$$\n\n**å…³é”®ç‚¹**: æˆ‘ä»¬åªè§‚æµ‹åˆ°factual outcome\n\n$$\\hat{Y}^{factual} = \\begin{cases} \n\\mu_1(\\Phi(X)) & \\text{if } T = 1 \\\\\n\\mu_0(\\Phi(X)) & \\text{if } T = 0\n\\end{cases}$$\n\n**å±•å¼€**:\n\n$$\\begin{align}\n\\mathcal{L} &= \\mathbb{E}_{T=1}[(Y - \\mu_1(\\Phi(X)))^2] \\cdot P(T=1) \\\\\n&\\quad + \\mathbb{E}_{T=0}[(Y - \\mu_0(\\Phi(X)))^2] \\cdot P(T=0)\n\\end{align}$$\n\n**å®ç°**:\n\n```python\nloss = torch.where(T == 1, \n                   (Y - mu1)**2, \n                   (Y - mu0)**2).mean()\n```\n\n---\n\n### æ¨å¯¼ 2: DragonNet çš„ Targeted Regularization\n\n**æ¥æº**: TMLEç†è®º\n\n**æ ¸å¿ƒæ€æƒ³**: åˆ©ç”¨å€¾å‘å¾—åˆ†æ„é€ ä¸€é˜¶æ— åä¼°è®¡\n\n**æ¨å¯¼**:\n\n1. çœŸå®ATEçš„efficient influence function (EIF):\n\n$$\\psi(X, T, Y) = \\frac{T \\cdot (Y - \\mu_1(X))}{e(X)} - \\frac{(1-T) \\cdot (Y - \\mu_0(X))}{1 - e(X)} + \\mu_1(X) - \\mu_0(X)$$\n\n2. ä¸€é˜¶æ¡ä»¶ (first-order condition):\n\n$$\\mathbb{E}[\\psi(X, T, Y)] = \\tau_{ATE}$$\n\n3. Targeted Regularizationæƒ©ç½šEIFçš„æ–¹å·®:\n\n$$\\mathcal{L}_{TR} = \\mathbb{E}\\left[\\left(Y - \\hat{\\mu} - \\epsilon \\cdot h(X, T)\\right)^2\\right]$$\n\nå…¶ä¸­:\n$$h(X, T) = \\frac{T}{e(X)} - \\frac{1-T}{1-e(X)}$$\n\n**ç›´è§‰**: \n- h(X,T)æ˜¯å€¾å‘å¾—åˆ†çš„\"ä¿®æ­£é¡¹\"\n- Îµæ˜¯å¯å­¦ä¹ çš„ä¿®æ­£å¹…åº¦\n- è¿™ä¸ªæŸå¤±é¼“åŠ±æ¨¡å‹åœ¨å€¾å‘å¾—åˆ†è¾¹ç•Œé™„è¿‘æ›´å‡†ç¡®\n\n---\n\n### æ¨å¯¼ 3: CEVAE çš„ ELBO\n\n**ç›®æ ‡**: æœ€å¤§åŒ–è¾¹é™…å¯¹æ•°ä¼¼ç„¶\n\n$$\\log p_\\theta(X, T, Y) = \\log \\int p_\\theta(X, T, Y, Z) dZ$$\n\n**é—®é¢˜**: ç§¯åˆ†intractable\n\n**è§£å†³**: å˜åˆ†æ¨æ–­ï¼Œå¼•å…¥q_Ï†(Z|X,T,Y)\n\n**Jensenä¸ç­‰å¼**:\n\n$$\\begin{align}\n\\log p_\\theta(X, T, Y) &= \\log \\mathbb{E}_{q_\\phi} \\left[\\frac{p_\\theta(X, T, Y, Z)}{q_\\phi(Z|X,T,Y)}\\right] \\\\\n&\\geq \\mathbb{E}_{q_\\phi} \\left[\\log \\frac{p_\\theta(X, T, Y, Z)}{q_\\phi(Z|X,T,Y)}\\right] \\\\\n&= \\mathbb{E}_{q_\\phi}[\\log p_\\theta(X|Z)] + \\mathbb{E}_{q_\\phi}[\\log p_\\theta(T|X,Z)] \\\\\n&\\quad + \\mathbb{E}_{q_\\phi}[\\log p_\\theta(Y|T,X,Z)] - KL(q_\\phi || p(Z))\n\\end{align}$$\n\n**ELBO**:\n\n$$\\mathcal{L}_{ELBO} = \\mathbb{E}_{q_\\phi}[\\log p(X,T,Y|Z)] - KL(q_\\phi(Z|X,T,Y) || p(Z))$$\n\n**å„é¡¹è§£é‡Š**:\n\n1. $\\log p(X|Z)$: Xçš„é‡æ„æŸå¤±\n2. $\\log p(T|X,Z)$: Tçš„åˆ†ç±»æŸå¤±\n3. $\\log p(Y|T,X,Z)$: Yçš„é¢„æµ‹æŸå¤±\n4. KLæ•£åº¦: æ­£åˆ™åŒ–é¡¹ï¼Œé˜²æ­¢åéªŒå´©æºƒ\n\n---\n\n### æ¨å¯¼ 4: GANITE çš„å¯¹æŠ—æŸå¤±\n\n**Block 1: åäº‹å®ç”Ÿæˆ**\n\n**ç”Ÿæˆå™¨ç›®æ ‡**:\n\n$$\\min_{G_{cf}} \\mathbb{E}_{X,T,Y,Z}\\left[D_{cf}(X, T, Y, G_{cf}(X, T, Y, Z))\\right]$$\n\n**åˆ¤åˆ«å™¨ç›®æ ‡**:\n\n$$\\max_{D_{cf}} \\mathbb{E}[D_{cf}(X, T, Y, Y_{cf}^{true})] + \\mathbb{E}[\\log(1 - D_{cf}(X, T, Y, Y_{cf}^{fake}))]$$\n\n**ç›‘ç£çº¦æŸ** (å…³é”®!):\n\n$$\\mathcal{L}_{sup} = \\mathbb{E}[(Y - G_{cf}(X, T, Y, Z))^2] \\quad \\text{when generating factual}$$\n\n**æ€»æŸå¤±**:\n\n$$\\mathcal{L}_{G_{cf}} = -\\mathbb{E}[\\log D_{cf}] + \\lambda \\cdot \\mathcal{L}_{sup}$$\n\n**Block 2: ITEä¼°è®¡**\n\nä½¿ç”¨Block 1å¡«è¡¥çš„å®Œæ•´æ½œåœ¨ç»“æœè®­ç»ƒITEç”Ÿæˆå™¨:\n\n$$\\hat{\\tau}(X) = G_{ITE}(X)$$\n\nçº¦æŸ: $\\hat{Y}(1) - \\hat{Y}(0) = \\hat{\\tau}(X)$\n\n---\n\n## å®æˆ˜æŠ€å·§æ€»ç»“\n\n### è°ƒå‚ç»éªŒ\n\n| è¶…å‚æ•° | TARNet | DragonNet | CEVAE | GANITE |\n|--------|--------|-----------|-------|--------|\n| å­¦ä¹ ç‡ | 1e-3 | 1e-3 | 1e-4 | 1e-4 (G), 1e-3 (D) |\n| æ‰¹å¤§å° | 64-256 | 128-512 | 64-128 | 128-256 |\n| éšè—å±‚ç»´åº¦ | 100-300 | 200-400 | 200-500 | 64-128 |\n| æ­£åˆ™åŒ–æƒé‡Î± | - | 0.5-2.0 | - | - |\n| KLæƒé‡Î² | - | 0.5-2.0 | 0.1-1.0 | - |\n\n### è®­ç»ƒç›‘æ§æŒ‡æ ‡\n\n1. **æ”¶æ•›æ€§**:\n   - Train/Val lossæ›²çº¿\n   - æ¢¯åº¦èŒƒæ•°\n\n2. **å¹³è¡¡æ€§**:\n   - MMDæˆ–Wassersteinè·ç¦»\n   - SMD (æ¯ä¸ªç‰¹å¾ç»´åº¦)\n\n3. **é¢„æµ‹è´¨é‡**:\n   - Factualé¢„æµ‹çš„MSE\n   - å€¾å‘å¾—åˆ†çš„AUC (DragonNet)\n\n4. **åäº‹å®åˆç†æ€§** (å¦‚æœ‰çœŸå€¼):\n   - PEHE\n   - ATEè¯¯å·®\n\n---\n\n*æ­å–œä½ å®Œæˆäº†æ·±åº¦å› æœæ¨¡å‹çš„é¢è¯•é¢˜å’Œæ•°å­¦æ¨å¯¼ï¼* ğŸ“"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}