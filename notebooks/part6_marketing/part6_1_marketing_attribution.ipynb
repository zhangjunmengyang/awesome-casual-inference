{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è¥é”€å½’å›  - è°ã€ŒçœŸæ­£ã€å¸¦æ¥äº†è½¬åŒ–ï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "## æ¬¢è¿æ¥åˆ°è¥é”€å½’å› çš„ä¸–ç•Œï¼\n",
    "\n",
    "æƒ³è±¡ä¸€ä¸‹è¿™ä¸ªåœºæ™¯ï¼š\n",
    "\n",
    "> ä½ æ˜¯ä¸€å®¶ç”µå•†å…¬å¸çš„è¥é”€æ€»ç›‘ã€‚ä¸Šä¸ªæœˆï¼Œå¸‚åœºéƒ¨åœ¨ 5 ä¸ªæ¸ é“æŠ•æ”¾äº†å¹¿å‘Šï¼š\n",
    "> - ğŸ’» Google æœç´¢å¹¿å‘Š\n",
    "> - ğŸ“± æœ‹å‹åœˆå¹¿å‘Š\n",
    "> - ğŸ“§ EDM é‚®ä»¶è¥é”€\n",
    "> - ğŸ¥ æŠ–éŸ³çŸ­è§†é¢‘\n",
    "> - ğŸ›ï¸ ç”µå•†è”ç›Ÿ\n",
    ">\n",
    "> ä¸€ä¸ªç”¨æˆ·çš„è´­ä¹°è·¯å¾„æ˜¯è¿™æ ·çš„ï¼š\n",
    "> ```\n",
    "> æœ‹å‹åœˆå¹¿å‘Š â†’ æœç´¢å¹¿å‘Š â†’ EDM â†’ æœç´¢å¹¿å‘Š â†’ è´­ä¹°ï¼ğŸ’°\n",
    "> ```\n",
    ">\n",
    "> ç°åœ¨ CFO é—®ä½ ï¼š\"è¿™ç¬”è®¢å•åº”è¯¥ç®—è°çš„åŠŸåŠ³ï¼Ÿæˆ‘ä»¬æ˜å¹´çš„é¢„ç®—è¦æ€ä¹ˆåˆ†é…ï¼Ÿ\"\n",
    "\n",
    "ä½ å¯èƒ½ä¼šæƒ³ï¼šè¿™è¿˜ä¸ç®€å•ï¼Ÿ\n",
    "\n",
    "- **é”€å”®è¯´**ï¼š\"ç®—æœ€åä¸€æ¬¡æœç´¢å¹¿å‘Šçš„ï¼ä¸´é—¨ä¸€è„šæœ€é‡è¦ï¼\"\n",
    "- **å“ç‰Œè¯´**ï¼š\"ç®—æœ‹å‹åœˆå¹¿å‘Šçš„ï¼ç¬¬ä¸€å°è±¡æ‰æ˜¯è½¬åŒ–çš„èµ·ç‚¹ï¼\"\n",
    "- **å¢é•¿è¯´**ï¼š\"éƒ½é‡è¦ï¼Œå¹³å‡åˆ†é…è´¡çŒ®ï¼\"\n",
    "- **CFO è¯´**ï¼š\"æˆ‘åªå…³å¿ƒè°å¸¦æ¥äº†å¢é‡æ”¶å…¥ï¼\"\n",
    "\n",
    "æ¯ä¸ªäººè¯´çš„å¥½åƒéƒ½æœ‰é“ç†... ğŸ¤”\n",
    "\n",
    "è¿™å°±æ˜¯**è¥é”€å½’å›  (Marketing Attribution)** è¦è§£å†³çš„é—®é¢˜ï¼\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š æœ¬èŠ‚å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "1. ç†è§£å½’å› é—®é¢˜çš„æœ¬è´¨ï¼ˆå¤šè§¦ç‚¹å½’å›  vs å•è§¦ç‚¹å½’å› ï¼‰\n",
    "2. æŒæ¡è§„åˆ™å½’å› æ–¹æ³•ï¼ˆLast-touch, First-touch, Linear, Time-decay, Position-basedï¼‰\n",
    "3. ç†è§£ Shapley Value å½’å› çš„åŸç†å’Œè®¡ç®—\n",
    "4. æŒæ¡ Markov Chain å½’å› çš„å»ºæ¨¡\n",
    "5. **åŒºåˆ†è§¦è¾¾å½’å›  vs å¢é‡å½’å› **ï¼ˆæ ¸å¿ƒï¼ï¼‰\n",
    "6. å°†å½’å› ç»“æœåº”ç”¨äºé¢„ç®—ä¼˜åŒ–å†³ç­–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations, permutations\n",
    "from typing import List, Dict, Tuple, Set\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡æ˜¾ç¤ºå’Œç»˜å›¾é£æ ¼\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæ¯•ï¼è®©æˆ‘ä»¬å¼€å§‹å§ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸŒŸ Part 1: å½’å› é—®é¢˜çš„æœ¬è´¨\n",
    "\n",
    "### ä»€ä¹ˆæ˜¯è¥é”€å½’å› ï¼Ÿ\n",
    "\n",
    "è¥é”€å½’å› å›ç­”çš„æ ¸å¿ƒé—®é¢˜æ˜¯ï¼š\n",
    "\n",
    "> **åœ¨ä¸€æ¬¡è½¬åŒ–ï¼ˆè´­ä¹°ã€æ³¨å†Œç­‰ï¼‰ä¸­ï¼Œå¤šä¸ªè¥é”€è§¦ç‚¹å„è‡ªçš„è´¡çŒ®æ˜¯å¤šå°‘ï¼Ÿ**\n",
    "\n",
    "### ä¸€ä¸ªçœŸå®çš„ç”¨æˆ·æ—…ç¨‹\n",
    "\n",
    "è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªçœŸå®çš„ä¾‹å­ï¼ˆæŸç”µå•†ç”¨æˆ·çš„ 30 å¤©è´­ä¹°è·¯å¾„ï¼‰ï¼š\n",
    "\n",
    "```\n",
    "Day 1:  æœ‹å‹åœˆå¹¿å‘Šï¼ˆé¦–æ¬¡æ¥è§¦ï¼‰\n",
    "Day 5:  Google æœç´¢å¹¿å‘Šï¼ˆä¸»åŠ¨æœç´¢ï¼‰\n",
    "Day 10: EDM é‚®ä»¶ï¼ˆæ”¶åˆ°ä¿ƒé”€ä¿¡æ¯ï¼‰\n",
    "Day 15: Google æœç´¢å¹¿å‘Šï¼ˆå†æ¬¡æœç´¢ï¼‰\n",
    "Day 18: æŠ–éŸ³å¹¿å‘Šï¼ˆçœ‹åˆ°ç§è‰è§†é¢‘ï¼‰\n",
    "Day 20: Google æœç´¢å¹¿å‘Šï¼ˆæœ€ç»ˆè´­ä¹°ï¼‰âœ…\n",
    "```\n",
    "\n",
    "è¿™ä¸ªè·¯å¾„ä¸­ï¼Œç”¨æˆ·åœ¨ 20 å¤©å†…æ¥è§¦äº† **6 æ¬¡è¥é”€è§¦ç‚¹**ï¼Œæ¶‰åŠ **4 ä¸ªæ¸ é“**ã€‚\n",
    "\n",
    "### å½’å›  vs å› æœæ¨æ–­\n",
    "\n",
    "| ç»´åº¦ | å½’å›  (Attribution) | å› æœæ¨æ–­ (Causal Inference) |\n",
    "|------|-------------------|----------------------------|\n",
    "| é—®é¢˜ | å·²è½¬åŒ–ç”¨æˆ·çš„è§¦ç‚¹å¦‚ä½•\"åˆ†åŠŸåŠ³\" | æ¸ é“æ˜¯å¦\"å¯¼è‡´\"äº†è½¬åŒ– |\n",
    "| æ ·æœ¬ | åªçœ‹è½¬åŒ–ç”¨æˆ· | éœ€è¦è½¬åŒ– + æœªè½¬åŒ–ç”¨æˆ· |\n",
    "| åäº‹å® | ä¸è€ƒè™‘ | æ ¸å¿ƒï¼ˆå¦‚æœæ²¡æœ‰è¿™ä¸ªæ¸ é“ä¼šæ€æ ·ï¼‰ |\n",
    "| å®éªŒéœ€æ±‚ | ä¸éœ€è¦ | éœ€è¦ï¼ˆæˆ–å¼ºå‡è®¾ï¼‰ |\n",
    "| å›ç­” | \"å‚ä¸äº†\"è½¬åŒ– | \"å¯¼è‡´äº†\"è½¬åŒ– |\n",
    "\n",
    "**å…³é”®åŒºåˆ«**ï¼š\n",
    "- **å½’å› **ï¼šåŸºäºå·²è½¬åŒ–ç”¨æˆ·çš„å†å²è§¦ç‚¹æ•°æ®ï¼Œåˆ†é…\"åŠŸåŠ³\"\n",
    "- **å¢é‡å½’å› **ï¼šåŸºäºå®éªŒæˆ–å‡†å®éªŒï¼Œä¼°è®¡æ¸ é“çš„\"å¢é‡æ•ˆåº”\"\n",
    "\n",
    "æˆ‘ä»¬ä»Šå¤©ä¸»è¦è®¨è®ºå‰è€…ï¼ˆè§¦è¾¾å½’å› ï¼‰ï¼Œæœ€åä¼šè®¨è®ºå¦‚ä½•åšå¢é‡å½’å› ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¬ ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®\n",
    "\n",
    "è®©æˆ‘ä»¬ç”Ÿæˆä¸€ä¸ªæ¨¡æ‹Ÿçš„ç”¨æˆ·è·¯å¾„æ•°æ®é›†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_journeys(n_users: int = 1000, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆç”¨æˆ·è½¬åŒ–è·¯å¾„æ•°æ®\n",
    "    \n",
    "    æ¯ä¸ªç”¨æˆ·å¯èƒ½ç»å†å¤šä¸ªè¥é”€è§¦ç‚¹ï¼Œæœ€ç»ˆè½¬åŒ–ï¼ˆæˆ–æœªè½¬åŒ–ï¼‰\n",
    "    \n",
    "    æ¸ é“ï¼š\n",
    "    - Search: æœç´¢å¹¿å‘Š\n",
    "    - Social: ç¤¾äº¤åª’ä½“\n",
    "    - Email: é‚®ä»¶è¥é”€\n",
    "    - Display: å±•ç¤ºå¹¿å‘Š\n",
    "    - Affiliate: ç”µå•†è”ç›Ÿ\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: user_id, path, converted, revenue\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    channels = ['Search', 'Social', 'Email', 'Display', 'Affiliate']\n",
    "    \n",
    "    # å¸¸è§è·¯å¾„æ¨¡å¼ï¼ˆæœ‰äº›è·¯å¾„æ›´å®¹æ˜“å¯¼è‡´è½¬åŒ–ï¼‰\n",
    "    common_paths = [\n",
    "        ['Social', 'Search'],                          # å“ç‰Œè®¤çŸ¥ â†’ ä¸»åŠ¨æœç´¢\n",
    "        ['Search'],                                    # ç›´æ¥æœç´¢\n",
    "        ['Social', 'Email', 'Search'],                 # å¤šæ¬¡è§¦è¾¾\n",
    "        ['Display', 'Search'],                         # å±•ç¤º â†’ æœç´¢\n",
    "        ['Email', 'Search'],                           # é‚®ä»¶ â†’ æœç´¢\n",
    "        ['Social', 'Search', 'Email', 'Search'],       # å¤æ‚è·¯å¾„\n",
    "        ['Affiliate', 'Search'],                       # è”ç›Ÿ â†’ æœç´¢\n",
    "        ['Display', 'Social', 'Search'],               # å¤šæ¸ é“\n",
    "    ]\n",
    "    \n",
    "    # æ¯ç§è·¯å¾„çš„è½¬åŒ–æ¦‚ç‡ï¼ˆåé¢çš„è·¯å¾„æ›´å¤æ‚ï¼Œä½†è½¬åŒ–ç‡æ›´é«˜ï¼‰\n",
    "    conversion_probs = [0.05, 0.03, 0.15, 0.08, 0.10, 0.25, 0.12, 0.18]\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for user_id in range(n_users):\n",
    "        # éšæœºé€‰æ‹©ä¸€ä¸ªè·¯å¾„æ¨¡å¼\n",
    "        path_idx = np.random.choice(len(common_paths), p=[0.15, 0.20, 0.10, 0.12, 0.13, 0.08, 0.10, 0.12])\n",
    "        path = common_paths[path_idx].copy()\n",
    "        \n",
    "        # éšæœºæ·»åŠ ä¸€äº›å™ªå£°ï¼ˆé‡å¤è§¦ç‚¹ï¼‰\n",
    "        if np.random.rand() < 0.3:\n",
    "            path.append(np.random.choice(channels))\n",
    "        \n",
    "        # åˆ¤æ–­æ˜¯å¦è½¬åŒ–\n",
    "        converted = np.random.rand() < conversion_probs[path_idx]\n",
    "        \n",
    "        # è½¬åŒ–é‡‘é¢ï¼ˆå¦‚æœè½¬åŒ–ï¼‰\n",
    "        revenue = np.random.lognormal(4.5, 0.5) if converted else 0\n",
    "        \n",
    "        data.append({\n",
    "            'user_id': user_id,\n",
    "            'path': ' > '.join(path),\n",
    "            'path_list': path,\n",
    "            'converted': converted,\n",
    "            'revenue': revenue,\n",
    "            'touchpoints': len(path)\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # åªä¿ç•™è½¬åŒ–ç”¨æˆ·ï¼ˆå½’å› åªé’ˆå¯¹è½¬åŒ–ç”¨æˆ·ï¼‰\n",
    "    df_converted = df[df['converted']].reset_index(drop=True)\n",
    "    \n",
    "    return df_converted\n",
    "\n",
    "# ç”Ÿæˆæ•°æ®\n",
    "df_journeys = generate_user_journeys(n_users=5000)\n",
    "\n",
    "print(f\"ğŸ¯ ç”Ÿæˆäº† {len(df_journeys)} ä¸ªè½¬åŒ–ç”¨æˆ·çš„è·¯å¾„æ•°æ®\")\n",
    "print(f\"\\næ•°æ®é¢„è§ˆ:\")\n",
    "display(df_journeys.head(10))\n",
    "\n",
    "# ç»Ÿè®¡ä¿¡æ¯\n",
    "print(f\"\\nğŸ“Š åŸºæœ¬ç»Ÿè®¡:\")\n",
    "print(f\"   æ€»è½¬åŒ–æ•°: {len(df_journeys)}\")\n",
    "print(f\"   æ€»æ”¶å…¥: ${df_journeys['revenue'].sum():,.2f}\")\n",
    "print(f\"   å¹³å‡å®¢å•ä»·: ${df_journeys['revenue'].mean():.2f}\")\n",
    "print(f\"   å¹³å‡è§¦ç‚¹æ•°: {df_journeys['touchpoints'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–è·¯å¾„é•¿åº¦åˆ†å¸ƒ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# è§¦ç‚¹æ•°åˆ†å¸ƒ\n",
    "ax1 = axes[0]\n",
    "df_journeys['touchpoints'].value_counts().sort_index().plot(kind='bar', ax=ax1, color='steelblue', edgecolor='black')\n",
    "ax1.set_xlabel('è·¯å¾„é•¿åº¦ï¼ˆè§¦ç‚¹æ•°ï¼‰')\n",
    "ax1.set_ylabel('ç”¨æˆ·æ•°')\n",
    "ax1.set_title('ç”¨æˆ·è·¯å¾„é•¿åº¦åˆ†å¸ƒ')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# æ¸ é“å‡ºç°é¢‘æ¬¡\n",
    "ax2 = axes[1]\n",
    "channel_counts = defaultdict(int)\n",
    "for path_list in df_journeys['path_list']:\n",
    "    for channel in path_list:\n",
    "        channel_counts[channel] += 1\n",
    "\n",
    "channel_df = pd.DataFrame(list(channel_counts.items()), columns=['Channel', 'Count']).sort_values('Count', ascending=True)\n",
    "channel_df.plot(kind='barh', x='Channel', y='Count', ax=ax2, color='coral', edgecolor='black', legend=False)\n",
    "ax2.set_xlabel('å‡ºç°æ¬¡æ•°')\n",
    "ax2.set_ylabel('æ¸ é“')\n",
    "ax2.set_title('å„æ¸ é“åœ¨è½¬åŒ–è·¯å¾„ä¸­çš„å‡ºç°é¢‘æ¬¡')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Part 2: è§„åˆ™å½’å› æ–¹æ³•\n",
    "\n",
    "è§„åˆ™å½’å› æ˜¯æœ€ç®€å•ç›´æ¥çš„æ–¹æ³•ï¼ŒåŸºäºé¢„å®šä¹‰çš„è§„åˆ™æ¥åˆ†é…åŠŸåŠ³ã€‚\n",
    "\n",
    "### 2.1 å¸¸è§è§„åˆ™å½’å› æ¨¡å‹\n",
    "\n",
    "| æ¨¡å‹ | è§„åˆ™ | é€‚ç”¨åœºæ™¯ | ä¼˜ç‚¹ | ç¼ºç‚¹ |\n",
    "|------|------|---------|------|------|\n",
    "| **Last-touch** | 100% å½’å› ç»™æœ€åä¸€ä¸ªè§¦ç‚¹ | çŸ­å‘¨æœŸã€å†²åŠ¨æ¶ˆè´¹ | ç®€å•ï¼›é”€å”®å¯¼å‘ | å¿½ç•¥å‰æœŸåŸ¹è‚² |\n",
    "| **First-touch** | 100% å½’å› ç»™ç¬¬ä¸€ä¸ªè§¦ç‚¹ | å“ç‰Œè¥é”€ | å¼ºè°ƒè®¤çŸ¥ä»·å€¼ | å¿½ç•¥åç»­è½¬åŒ–åŠªåŠ› |\n",
    "| **Linear** | å¹³å‡åˆ†é… | æ‰€æœ‰è§¦ç‚¹åŒç­‰é‡è¦ | å…¬å¹³ï¼›ç®€å• | ä¸ç¬¦åˆç›´è§‰ |\n",
    "| **Time-decay** | è¶Šæ¥è¿‘è½¬åŒ–æƒé‡è¶Šé«˜ | é•¿å‘¨æœŸå†³ç­– | ç¬¦åˆ\"ä¸´é—¨ä¸€è„š\"ç›´è§‰ | å‚æ•°æ•æ„Ÿ |\n",
    "| **Position-based** | é¦–æœ«å„ 40%ï¼Œä¸­é—´ 20% | è®¤çŸ¥+è½¬åŒ–éƒ½é‡è¦ | å¹³è¡¡é¦–æœ« | ä¸­é—´è§¦ç‚¹è¢«ä½ä¼° |\n",
    "\n",
    "### 2.2 æ•°å­¦å®šä¹‰\n",
    "\n",
    "å‡è®¾ä¸€ä¸ªç”¨æˆ·çš„è½¬åŒ–è·¯å¾„ä¸º $P = [c_1, c_2, ..., c_n]$ï¼Œå…¶ä¸­ $c_i$ æ˜¯ç¬¬ $i$ ä¸ªè§¦ç‚¹ã€‚\n",
    "\n",
    "**Last-touch Attribution:**\n",
    "$$\n",
    "w_i = \\begin{cases}\n",
    "1 & i = n \\\\\n",
    "0 & i \\neq n\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**First-touch Attribution:**\n",
    "$$\n",
    "w_i = \\begin{cases}\n",
    "1 & i = 1 \\\\\n",
    "0 & i \\neq 1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Linear Attribution:**\n",
    "$$\n",
    "w_i = \\frac{1}{n} \\quad \\forall i\n",
    "$$\n",
    "\n",
    "**Time-decay Attribution:**\n",
    "$$\n",
    "w_i = \\frac{e^{-\\lambda(n-i)}}{\\sum_{j=1}^{n} e^{-\\lambda(n-j)}}\n",
    "$$\n",
    "å…¶ä¸­ $\\lambda$ æ˜¯è¡°å‡ç‡å‚æ•°ï¼ˆé€šå¸¸å– 0.5-2ï¼‰ã€‚\n",
    "\n",
    "**Position-based Attribution (40-20-40):**\n",
    "$$\n",
    "w_i = \\begin{cases}\n",
    "0.4 & i = 1 \\\\\n",
    "0.4 & i = n \\\\\n",
    "\\frac{0.2}{n-2} & 1 < i < n\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class RuleBasedAttribution:\n    \"\"\"\n    è§„åˆ™å½’å› æ¨¡å‹\n    \"\"\"\n    \n    @staticmethod\n    def last_touch(path: List[str]) -> Dict[str, float]:\n        \"\"\"\n        Last-touch å½’å› ï¼š100% å½’ç»™æœ€åä¸€ä¸ªè§¦ç‚¹\n        \"\"\"\n        attribution = {}\n        for channel in set(path):\n            attribution[channel] = 1.0 if channel == path[-1] else 0.0\n        return attribution\n    \n    @staticmethod\n    def first_touch(path: List[str]) -> Dict[str, float]:\n        \"\"\"\n        First-touch å½’å› ï¼š100% å½’ç»™ç¬¬ä¸€ä¸ªè§¦ç‚¹\n        \"\"\"\n        attribution = {}\n        for channel in set(path):\n            attribution[channel] = 1.0 if channel == path[0] else 0.0\n        return attribution\n    \n    @staticmethod\n    def linear(path: List[str]) -> Dict[str, float]:\n        \"\"\"\n        Linear å½’å› ï¼šå¹³å‡åˆ†é…æƒé‡\n        \"\"\"\n        attribution = defaultdict(float)\n        weight_per_touch = 1.0 / len(path)\n        for channel in path:\n            attribution[channel] += weight_per_touch\n        return dict(attribution)\n    \n    @staticmethod\n    def time_decay(path: List[str], decay_rate: float = 0.7) -> Dict[str, float]:\n        \"\"\"\n        Time-decay å½’å› ï¼šè¶Šæ¥è¿‘è½¬åŒ–ï¼Œæƒé‡è¶Šé«˜\n        \n        Args:\n            decay_rate: è¡°å‡ç‡ï¼Œè¶Šå¤§åˆ™æœ€åè§¦ç‚¹æƒé‡è¶Šå¤§\n        \"\"\"\n        n = len(path)\n        attribution = defaultdict(float)\n        \n        weights = []\n        for i in range(n):\n            weight = np.exp(-decay_rate * (n - 1 - i))\n            weights.append(weight)\n        \n        # å½’ä¸€åŒ–\n        total = sum(weights)\n        weights = [w / total for w in weights]\n        \n        # ç´¯åŠ åŒä¸€æ¸ é“çš„æƒé‡\n        for i, channel in enumerate(path):\n            attribution[channel] += weights[i]\n        \n        return dict(attribution)\n    \n    @staticmethod\n    def position_based(path: List[str], first_weight: float = 0.4, last_weight: float = 0.4) -> Dict[str, float]:\n        \"\"\"\n        Position-based å½’å› ï¼šé¦–æœ«å„å å›ºå®šæ¯”ä¾‹ï¼Œä¸­é—´å¹³åˆ†å‰©ä½™\n        \n        Args:\n            first_weight: ç¬¬ä¸€ä¸ªè§¦ç‚¹çš„æƒé‡ï¼ˆé»˜è®¤ 0.4ï¼‰\n            last_weight: æœ€åä¸€ä¸ªè§¦ç‚¹çš„æƒé‡ï¼ˆé»˜è®¤ 0.4ï¼‰\n        \"\"\"\n        n = len(path)\n        attribution = defaultdict(float)\n        \n        if n == 1:\n            attribution[path[0]] = 1.0\n        elif n == 2:\n            attribution[path[0]] = 0.5\n            attribution[path[1]] = 0.5\n        else:\n            # ç¬¬ä¸€ä¸ªè§¦ç‚¹\n            attribution[path[0]] += first_weight\n            # æœ€åä¸€ä¸ªè§¦ç‚¹\n            attribution[path[-1]] += last_weight\n            # ä¸­é—´è§¦ç‚¹å¹³åˆ†å‰©ä½™æƒé‡\n            middle_weight = (1.0 - first_weight - last_weight) / (n - 2)\n            for i in range(1, n - 1):\n                attribution[path[i]] += middle_weight\n        \n        return dict(attribution)\n\n# æµ‹è¯•\ntest_path = ['Social', 'Search', 'Email', 'Search']\nprint(\"ğŸ§ª æµ‹è¯•è·¯å¾„:\", ' > '.join(test_path))\nprint(\"\\nå„ç§å½’å› ç»“æœ:\")\nprint(f\"Last-touch:     {RuleBasedAttribution.last_touch(test_path)}\")\nprint(f\"First-touch:    {RuleBasedAttribution.first_touch(test_path)}\")\nprint(f\"Linear:         {RuleBasedAttribution.linear(test_path)}\")\nprint(f\"Time-decay:     {RuleBasedAttribution.time_decay(test_path)}\")\nprint(f\"Position-based: {RuleBasedAttribution.position_based(test_path)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_attribution(df: pd.DataFrame, method: str = 'last_touch') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    å¯¹æ‰€æœ‰ç”¨æˆ·è·¯å¾„åº”ç”¨å½’å› æ–¹æ³•\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with channel-level attribution results\n",
    "    \"\"\"\n",
    "    channel_attribution = defaultdict(float)\n",
    "    channel_revenue = defaultdict(float)\n",
    "    channel_conversions = defaultdict(int)\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        path = row['path_list']\n",
    "        revenue = row['revenue']\n",
    "        \n",
    "        # é€‰æ‹©å½’å› æ–¹æ³•\n",
    "        if method == 'last_touch':\n",
    "            weights = RuleBasedAttribution.last_touch(path)\n",
    "        elif method == 'first_touch':\n",
    "            weights = RuleBasedAttribution.first_touch(path)\n",
    "        elif method == 'linear':\n",
    "            weights = RuleBasedAttribution.linear(path)\n",
    "        elif method == 'time_decay':\n",
    "            weights = RuleBasedAttribution.time_decay(path)\n",
    "        elif method == 'position_based':\n",
    "            weights = RuleBasedAttribution.position_based(path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "        \n",
    "        # åˆ†é…æ”¶å…¥\n",
    "        for channel, weight in weights.items():\n",
    "            channel_revenue[channel] += revenue * weight\n",
    "            channel_attribution[channel] += weight\n",
    "            if weight > 0:\n",
    "                channel_conversions[channel] += 1\n",
    "    \n",
    "    # åˆ›å»ºç»“æœ DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        'Channel': list(channel_revenue.keys()),\n",
    "        'Attributed_Revenue': list(channel_revenue.values()),\n",
    "        'Attributed_Conversions': [channel_attribution[ch] for ch in channel_revenue.keys()],\n",
    "        'Touch_Count': [channel_conversions[ch] for ch in channel_revenue.keys()]\n",
    "    }).sort_values('Attributed_Revenue', ascending=False)\n",
    "    \n",
    "    result_df['Revenue_Share'] = result_df['Attributed_Revenue'] / result_df['Attributed_Revenue'].sum()\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# å¯¹æ¯”ä¸åŒå½’å› æ–¹æ³•\n",
    "methods = ['last_touch', 'first_touch', 'linear', 'time_decay', 'position_based']\n",
    "results = {}\n",
    "\n",
    "for method in methods:\n",
    "    results[method] = apply_attribution(df_journeys, method)\n",
    "\n",
    "# å¯è§†åŒ–å¯¹æ¯”\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, method in enumerate(methods):\n",
    "    ax = axes[idx]\n",
    "    data = results[method].sort_values('Attributed_Revenue', ascending=True)\n",
    "    data.plot(kind='barh', x='Channel', y='Attributed_Revenue', ax=ax, color='skyblue', edgecolor='black', legend=False)\n",
    "    ax.set_xlabel('å½’å› æ”¶å…¥ ($)')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_title(f'{method.replace(\"_\", \"-\").title()} Attribution')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # æ·»åŠ ç™¾åˆ†æ¯”æ ‡ç­¾\n",
    "    for i, (channel, revenue) in enumerate(zip(data['Channel'], data['Attributed_Revenue'])):\n",
    "        share = revenue / data['Attributed_Revenue'].sum() * 100\n",
    "        ax.text(revenue, i, f' {share:.1f}%', va='center', fontsize=9)\n",
    "\n",
    "# ç§»é™¤å¤šä½™çš„å­å›¾\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š ä¸åŒå½’å› æ–¹æ³•çš„å¯¹æ¯”ï¼ˆæ”¶å…¥å æ¯”ï¼‰:\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    method: results[method].set_index('Channel')['Revenue_Share'] * 100\n",
    "    for method in methods\n",
    "})\n",
    "display(comparison_df.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¤” è§„åˆ™å½’å› çš„é—®é¢˜\n",
    "\n",
    "ä»ä¸Šé¢çš„ç»“æœå¯ä»¥çœ‹å‡ºï¼Œ**ä¸åŒçš„å½’å› æ–¹æ³•ä¼šå¾—åˆ°æˆªç„¶ä¸åŒçš„ç»“è®º**ï¼\n",
    "\n",
    "- **Last-touch**: Search å æ¯”æœ€é«˜ï¼ˆå› ä¸ºç»å¸¸æ˜¯æœ€åè§¦ç‚¹ï¼‰\n",
    "- **First-touch**: Social å æ¯”æå‡ï¼ˆå› ä¸ºå¸¸ä½œä¸ºé¦–æ¬¡æ¥è§¦ï¼‰\n",
    "- **Linear**: ç›¸å¯¹å¹³å‡\n",
    "\n",
    "**æ ¸å¿ƒé—®é¢˜**ï¼šè§„åˆ™å½’å› æ˜¯**ä¸»è§‚çš„ã€æ­¦æ–­çš„**ï¼Œç¼ºä¹ç†è®ºåŸºç¡€ã€‚\n",
    "\n",
    "é‚£æœ‰æ²¡æœ‰æ›´\"å…¬å¹³\"ã€æ›´æœ‰ç†è®ºåŸºç¡€çš„æ–¹æ³•å‘¢ï¼Ÿ\n",
    "\n",
    "æœ‰ï¼**Shapley Value** å½’å› ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ² Part 3: Shapley Value å½’å› \n",
    "\n",
    "### 3.1 åˆä½œåšå¼ˆè®ºåŸºç¡€\n",
    "\n",
    "**Shapley Value** æ¥è‡ªåˆä½œåšå¼ˆè®ºï¼Œç”± Lloyd Shapley äº 1953 å¹´æå‡ºï¼ˆä»–å› æ­¤è·å¾—äº† 2012 å¹´è¯ºè´å°”ç»æµå­¦å¥–ï¼‰ã€‚\n",
    "\n",
    "#### ä¸€ä¸ªç”ŸåŠ¨çš„ä¾‹å­ï¼šä¸‰ä¸ªäººåˆä½œå¼€åº—\n",
    "\n",
    "å‡è®¾æœ‰ä¸‰ä¸ªäººåˆä½œå¼€äº†ä¸€å®¶å¥¶èŒ¶åº—ï¼š\n",
    "- **Alice**ï¼šæä¾›èµ„é‡‘ ğŸ’°\n",
    "- **Bob**ï¼šæä¾›åœºåœ° ğŸ \n",
    "- **Carol**ï¼šæä¾›æŠ€æœ¯ï¼ˆä¼šåšå¥¶èŒ¶ï¼‰ğŸ§‹\n",
    "\n",
    "åº—é“ºæœ€ç»ˆèµšäº† **100 ä¸‡**ã€‚é—®é¢˜ï¼šå¦‚ä½•\"å…¬å¹³\"åœ°åˆ†é’±ï¼Ÿ\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥è®¡ç®—æ¯ç§ç»„åˆçš„æ”¶ç›Šï¼š\n",
    "\n",
    "| ç»„åˆ | èƒ½å¼€åº—å—ï¼Ÿ | æ”¶ç›Š |\n",
    "|------|-----------|------|\n",
    "| {} | âŒ | 0 |\n",
    "| {Alice} | âŒï¼ˆæ²¡åœºåœ°å’ŒæŠ€æœ¯ï¼‰ | 0 |\n",
    "| {Bob} | âŒï¼ˆæ²¡é’±å’ŒæŠ€æœ¯ï¼‰ | 0 |\n",
    "| {Carol} | âŒï¼ˆæ²¡é’±å’Œåœºåœ°ï¼‰ | 0 |\n",
    "| {Alice, Bob} | âŒï¼ˆæ²¡äººä¼šåšï¼‰ | 0 |\n",
    "| {Alice, Carol} | ğŸ”ºï¼ˆå¯ä»¥ç§Ÿåœºåœ°ï¼‰| 50 ä¸‡ |\n",
    "| {Bob, Carol} | ğŸ”ºï¼ˆå¯ä»¥å€Ÿé’±ï¼‰| 60 ä¸‡ |\n",
    "| {Alice, Bob, Carol} | âœ… | 100 ä¸‡ |\n",
    "\n",
    "**Shapley Value çš„æ€æƒ³**ï¼š\n",
    "> ä¸€ä¸ªäººçš„è´¡çŒ® = å¹³å‡è€Œè¨€ï¼ŒTA åŠ å…¥åå¸¦æ¥çš„å¢é‡æ”¶ç›Š\n",
    "\n",
    "### 3.2 Shapley Value çš„å®šä¹‰\n",
    "\n",
    "å¯¹äºåˆä½œåšå¼ˆ $(N, v)$ï¼Œå…¶ä¸­ï¼š\n",
    "- $N$ æ˜¯ç©å®¶é›†åˆï¼ˆåœ¨è¥é”€å½’å› ä¸­æ˜¯æ¸ é“é›†åˆï¼‰\n",
    "- $v(S)$ æ˜¯å­é›† $S$ çš„ä»·å€¼å‡½æ•°ï¼ˆè½¬åŒ–ä»·å€¼ï¼‰\n",
    "\n",
    "ç©å®¶ $i$ çš„ Shapley Value å®šä¹‰ä¸ºï¼š\n",
    "\n",
    "$$\n",
    "\\phi_i(v) = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|! \\cdot (|N| - |S| - 1)!}{|N|!} \\cdot [v(S \\cup \\{i\\}) - v(S)]\n",
    "$$\n",
    "\n",
    "**äººè¯ç¿»è¯‘**ï¼š\n",
    "- éå†æ‰€æœ‰ä¸åŒ…å« $i$ çš„å­é›† $S$\n",
    "- è®¡ç®— $i$ åŠ å…¥ $S$ åçš„å¢é‡ï¼š$v(S \\cup \\{i\\}) - v(S)$\n",
    "- å¯¹æ‰€æœ‰å¯èƒ½çš„åŠ å…¥é¡ºåºå–å¹³å‡ï¼ˆæƒé‡æ˜¯ $\\frac{|S|! \\cdot (|N| - |S| - 1)!}{|N|!}$ï¼‰\n",
    "\n",
    "### 3.3 Shapley Value çš„å…¬ç†æ€§\n",
    "\n",
    "Shapley Value æ˜¯**å”¯ä¸€**æ»¡è¶³ä»¥ä¸‹å…¬ç†çš„åˆ†é…æ–¹æ¡ˆï¼š\n",
    "\n",
    "1. **æ•ˆç‡æ€§ (Efficiency)**: $\\sum_{i \\in N} \\phi_i(v) = v(N)$ ï¼ˆæ‰€æœ‰ä»·å€¼è¢«å®Œå…¨åˆ†é…ï¼‰\n",
    "2. **å¯¹ç§°æ€§ (Symmetry)**: å¦‚æœ $i, j$ å¯äº’æ¢ï¼Œåˆ™ $\\phi_i(v) = \\phi_j(v)$\n",
    "3. **è™šæ‹Ÿæ€§ (Null player)**: å¦‚æœ $v(S \\cup \\{i\\}) = v(S)$ å¯¹æ‰€æœ‰ $S$ æˆç«‹ï¼Œåˆ™ $\\phi_i(v) = 0$\n",
    "4. **å¯åŠ æ€§ (Additivity)**: $\\phi_i(v + w) = \\phi_i(v) + \\phi_i(w)$\n",
    "\n",
    "è¿™äº›å…¬ç†ä¿è¯äº† Shapley Value çš„\"å…¬å¹³æ€§\"ã€‚\n",
    "\n",
    "### 3.4 åœ¨è¥é”€å½’å› ä¸­çš„åº”ç”¨\n",
    "\n",
    "å°†ç”¨æˆ·è½¬åŒ–è·¯å¾„è§†ä¸ºåˆä½œåšå¼ˆï¼š\n",
    "- **ç©å®¶**: è·¯å¾„ä¸­çš„å„ä¸ªæ¸ é“\n",
    "- **ä»·å€¼å‡½æ•°** $v(S)$: åŒ…å«å­é›† $S$ ä¸­æ¸ é“çš„è·¯å¾„çš„å¹³å‡è½¬åŒ–ç‡ï¼ˆæˆ–æ”¶å…¥ï¼‰\n",
    "\n",
    "ä¾‹å¦‚ï¼Œè·¯å¾„ `Social > Search > Email > Search`ï¼š\n",
    "- $N = \\{\\text{Social}, \\text{Search}, \\text{Email}\\}$\n",
    "- $v(\\{\\text{Search}\\})$ = åŒ…å« Search çš„è·¯å¾„çš„å¹³å‡è½¬åŒ–ä»·å€¼\n",
    "- $v(\\{\\text{Social}, \\text{Search}\\})$ = åŒ…å« Social å’Œ Search çš„è·¯å¾„çš„å¹³å‡è½¬åŒ–ä»·å€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class ShapleyAttribution:\n    \"\"\"\n    Shapley Value å½’å› \n    \"\"\"\n    \n    def __init__(self, df: pd.DataFrame):\n        \"\"\"\n        Args:\n            df: åŒ…å« 'path_list' å’Œ 'revenue' åˆ—çš„ DataFrame\n        \"\"\"\n        self.df = df\n        self.all_channels = set()\n        for path in df['path_list']:\n            self.all_channels.update(path)\n        \n        # æ„å»ºä»·å€¼å‡½æ•°ï¼šæ¯ä¸ªæ¸ é“å­é›†å¯¹åº”çš„å¹³å‡æ”¶å…¥\n        self.value_function = self._build_value_function()\n    \n    def _build_value_function(self) -> Dict[frozenset, float]:\n        \"\"\"\n        æ„å»ºä»·å€¼å‡½æ•° v(S)\n        \n        v(S) = åŒ…å«å­é›† S ä¸­æ‰€æœ‰æ¸ é“çš„è·¯å¾„çš„å¹³å‡æ”¶å…¥\n        \"\"\"\n        value_func = {}\n        \n        # æšä¸¾æ‰€æœ‰å¯èƒ½çš„æ¸ é“å­é›†\n        from itertools import chain, combinations\n        \n        def powerset(iterable):\n            \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n            s = list(iterable)\n            return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n        \n        for subset in powerset(self.all_channels):\n            subset_set = frozenset(subset)\n            \n            if len(subset_set) == 0:\n                value_func[subset_set] = 0.0\n                continue\n            \n            # æ‰¾åˆ°åŒ…å«è¿™ä¸ªå­é›†æ‰€æœ‰æ¸ é“çš„è·¯å¾„\n            matching_revenues = []\n            for idx, row in self.df.iterrows():\n                path_channels = set(row['path_list'])\n                if subset_set.issubset(path_channels):\n                    matching_revenues.append(row['revenue'])\n            \n            # è®¡ç®—å¹³å‡æ”¶å…¥ï¼ˆå¦‚æœæ²¡æœ‰åŒ¹é…çš„è·¯å¾„ï¼Œå€¼ä¸º 0ï¼‰\n            value_func[subset_set] = np.mean(matching_revenues) if matching_revenues else 0.0\n        \n        return value_func\n    \n    def compute_shapley(self, channel: str) -> float:\n        \"\"\"\n        è®¡ç®—å•ä¸ªæ¸ é“çš„ Shapley Value\n        \n        å…¬å¼: Ï†_i = Î£_{S âŠ† N\\{i}} [|S|!(|N|-|S|-1)! / |N|!] * [v(Sâˆª{i}) - v(S)]\n        \"\"\"\n        n = len(self.all_channels)\n        other_channels = self.all_channels - {channel}\n        \n        shapley_value = 0.0\n        \n        # æšä¸¾æ‰€æœ‰ä¸åŒ…å«å½“å‰æ¸ é“çš„å­é›†\n        from itertools import chain, combinations\n        \n        def powerset(iterable):\n            s = list(iterable)\n            return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n        \n        for subset in powerset(other_channels):\n            subset_set = frozenset(subset)\n            s_size = len(subset_set)\n            \n            # è®¡ç®—æƒé‡: |S|! * (|N| - |S| - 1)! / |N|!\n            from math import factorial\n            weight = factorial(s_size) * factorial(n - s_size - 1) / factorial(n)\n            \n            # è®¡ç®—è¾¹é™…è´¡çŒ®: v(S âˆª {i}) - v(S)\n            v_with = self.value_function.get(subset_set | {channel}, 0.0)\n            v_without = self.value_function.get(subset_set, 0.0)\n            marginal_contribution = v_with - v_without\n            \n            shapley_value += weight * marginal_contribution\n        \n        return shapley_value\n    \n    def compute_all_shapley(self) -> Dict[str, float]:\n        \"\"\"\n        è®¡ç®—æ‰€æœ‰æ¸ é“çš„ Shapley Value\n        \"\"\"\n        shapley_values = {}\n        for channel in self.all_channels:\n            shapley_values[channel] = self.compute_shapley(channel)\n        return shapley_values\n\n# è®¡ç®— Shapley å½’å› \nprint(\"ğŸ² è®¡ç®— Shapley Value å½’å› ...ï¼ˆå¯èƒ½éœ€è¦å‡ ç§’é’Ÿï¼‰\")\nshapley_model = ShapleyAttribution(df_journeys)\nshapley_values = shapley_model.compute_all_shapley()\n\nprint(\"\\nâœ… Shapley Value å½’å› ç»“æœ:\")\nshapley_df = pd.DataFrame(list(shapley_values.items()), columns=['Channel', 'Shapley_Value']).sort_values('Shapley_Value', ascending=False)\nshapley_df['Value_Share'] = shapley_df['Shapley_Value'] / shapley_df['Shapley_Value'].sum()\ndisplay(shapley_df)\n\n# å°† Shapley è½¬æ¢ä¸ºæ”¶å…¥å½’å› \ntotal_revenue = df_journeys['revenue'].sum()\nshapley_df['Attributed_Revenue'] = shapley_df['Shapley_Value'] / shapley_df['Shapley_Value'].sum() * total_revenue\n\nprint(f\"\\næ€»æ”¶å…¥: ${total_revenue:,.2f}\")\nprint(f\"Shapley å½’å› æ€»å’Œ: ${shapley_df['Attributed_Revenue'].sum():,.2f} (åº”è¯¥ç›¸ç­‰)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹æ¯” Shapley ä¸è§„åˆ™å½’å› \n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "all_methods = methods + ['shapley']\n",
    "all_results = results.copy()\n",
    "all_results['shapley'] = shapley_df.rename(columns={'Shapley_Value': 'Attributed_Revenue'})[['Channel', 'Attributed_Revenue']]\n",
    "\n",
    "for idx, method in enumerate(all_methods):\n",
    "    ax = axes[idx]\n",
    "    data = all_results[method].sort_values('Attributed_Revenue', ascending=True)\n",
    "    \n",
    "    color = 'gold' if method == 'shapley' else 'skyblue'\n",
    "    data.plot(kind='barh', x='Channel', y='Attributed_Revenue', ax=ax, color=color, edgecolor='black', legend=False)\n",
    "    ax.set_xlabel('å½’å› å€¼')\n",
    "    ax.set_ylabel('')\n",
    "    \n",
    "    title = 'Shapley Value â­' if method == 'shapley' else f'{method.replace(\"_\", \"-\").title()}'\n",
    "    ax.set_title(title, fontweight='bold' if method == 'shapley' else 'normal')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# æ•°å€¼å¯¹æ¯”\n",
    "print(\"\\nğŸ“Š æ‰€æœ‰æ–¹æ³•çš„å¯¹æ¯”ï¼ˆæ”¶å…¥å æ¯” %ï¼‰:\")\n",
    "comparison_df = pd.DataFrame()\n",
    "for method in all_methods:\n",
    "    df_method = all_results[method].copy()\n",
    "    df_method['Share'] = df_method['Attributed_Revenue'] / df_method['Attributed_Revenue'].sum() * 100\n",
    "    comparison_df[method] = df_method.set_index('Channel')['Share']\n",
    "\n",
    "display(comparison_df.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ Shapley Value çš„ä¼˜åŠ¿\n",
    "\n",
    "1. **ç†è®ºåŸºç¡€**: åŸºäºåˆä½œåšå¼ˆè®ºï¼Œæœ‰ä¸¥æ ¼çš„å…¬ç†åŒ–åŸºç¡€\n",
    "2. **å…¬å¹³æ€§**: å”¯ä¸€æ»¡è¶³ 4 ä¸ªå…¬ç†çš„åˆ†é…æ–¹æ¡ˆ\n",
    "3. **è€ƒè™‘äº¤äº’**: è€ƒè™‘äº†æ¸ é“ä¹‹é—´çš„ååŒæ•ˆåº”\n",
    "\n",
    "### âš ï¸ Shapley Value çš„å±€é™\n",
    "\n",
    "1. **è®¡ç®—å¤æ‚åº¦**: $O(2^n)$ æŒ‡æ•°å¤æ‚åº¦ï¼Œæ¸ é“å¤šæ—¶å¾ˆæ…¢\n",
    "2. **æ•°æ®éœ€æ±‚**: éœ€è¦è¶³å¤Ÿçš„æ•°æ®æ¥ä¼°è®¡æ‰€æœ‰å­é›†çš„ä»·å€¼\n",
    "3. **ä»æ˜¯è§¦è¾¾å½’å› **: æ²¡æœ‰è€ƒè™‘åäº‹å®ï¼ˆ\"å¦‚æœæ²¡æœ‰è¿™ä¸ªæ¸ é“ä¼šæ€æ ·\"ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”— Part 4: Markov Chain å½’å› \n",
    "\n",
    "### 4.1 é©¬å°”å¯å¤«é“¾çš„æ€æƒ³\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³**: å°†ç”¨æˆ·æ—…ç¨‹å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«é“¾ï¼Œæ¸ é“çš„ä»·å€¼ = ç§»é™¤è¯¥æ¸ é“åè½¬åŒ–ç‡çš„ä¸‹é™ã€‚\n",
    "\n",
    "### 4.2 å»ºæ¨¡æ­¥éª¤\n",
    "\n",
    "1. **æ„å»ºè½¬ç§»æ¦‚ç‡çŸ©é˜µ**: ä»ä¸€ä¸ªæ¸ é“åˆ°å¦ä¸€ä¸ªæ¸ é“çš„æ¦‚ç‡\n",
    "2. **è®¡ç®—è½¬åŒ–æ¦‚ç‡**: ä»èµ·ç‚¹åˆ°è½¬åŒ–çš„æ¦‚ç‡\n",
    "3. **ç§»é™¤æ•ˆåº”**: ç§»é™¤æŸä¸ªæ¸ é“åï¼Œè½¬åŒ–æ¦‚ç‡ä¸‹é™å¤šå°‘\n",
    "\n",
    "### 4.3 è½¬ç§»æ¦‚ç‡çŸ©é˜µ\n",
    "\n",
    "$$\n",
    "P_{ij} = P(\\text{ä¸‹ä¸€ä¸ªçŠ¶æ€æ˜¯ } j | \\text{å½“å‰çŠ¶æ€æ˜¯ } i)\n",
    "$$\n",
    "\n",
    "ä¾‹å¦‚ï¼š\n",
    "```\n",
    "         Social  Search  Email  Conversion\n",
    "Social     0      0.7    0.2      0.1\n",
    "Search    0.1     0.3    0.4      0.2\n",
    "Email     0.2     0.5     0       0.3\n",
    "```\n",
    "\n",
    "### 4.4 ç§»é™¤æ•ˆåº”\n",
    "\n",
    "æ¸ é“ $c$ çš„è´¡çŒ®ï¼š\n",
    "\n",
    "$$\n",
    "\\text{Removal Effect}_c = \\frac{P(\\text{Conversion}) - P(\\text{Conversion | remove } c)}{P(\\text{Conversion})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovAttribution:\n",
    "    \"\"\"\n",
    "    Markov Chain å½’å› æ¨¡å‹\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "        self.channels = set()\n",
    "        for path in df['path_list']:\n",
    "            self.channels.update(path)\n",
    "        \n",
    "        # æ„å»ºè½¬ç§»çŸ©é˜µ\n",
    "        self.transition_matrix = self._build_transition_matrix()\n",
    "    \n",
    "    def _build_transition_matrix(self, excluded_channel: str = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        æ„å»ºè½¬ç§»æ¦‚ç‡çŸ©é˜µ\n",
    "        \n",
    "        Args:\n",
    "            excluded_channel: è¦æ’é™¤çš„æ¸ é“ï¼ˆç”¨äºè®¡ç®—ç§»é™¤æ•ˆåº”ï¼‰\n",
    "        \"\"\"\n",
    "        # ç»Ÿè®¡è½¬ç§»æ¬¡æ•°\n",
    "        transitions = defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        for idx, row in self.df.iterrows():\n",
    "            path = row['path_list']\n",
    "            \n",
    "            # è¿‡æ»¤æ‰è¢«æ’é™¤çš„æ¸ é“\n",
    "            if excluded_channel:\n",
    "                path = [ch for ch in path if ch != excluded_channel]\n",
    "            \n",
    "            if len(path) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Start -> ç¬¬ä¸€ä¸ªæ¸ é“\n",
    "            transitions['Start'][path[0]] += 1\n",
    "            \n",
    "            # æ¸ é“ä¹‹é—´çš„è½¬ç§»\n",
    "            for i in range(len(path) - 1):\n",
    "                transitions[path[i]][path[i+1]] += 1\n",
    "            \n",
    "            # æœ€åä¸€ä¸ªæ¸ é“ -> Conversion\n",
    "            transitions[path[-1]]['Conversion'] += 1\n",
    "        \n",
    "        # è½¬æ¢ä¸ºæ¦‚ç‡ï¼ˆå½’ä¸€åŒ–ï¼‰\n",
    "        transition_probs = {}\n",
    "        for from_state, to_states in transitions.items():\n",
    "            total = sum(to_states.values())\n",
    "            transition_probs[from_state] = {to_state: count / total for to_state, count in to_states.items()}\n",
    "        \n",
    "        return transition_probs\n",
    "    \n",
    "    def _conversion_probability(self, transition_matrix: dict, max_steps: int = 20) -> float:\n",
    "        \"\"\"\n",
    "        è®¡ç®—ä» Start åˆ° Conversion çš„æ¦‚ç‡ï¼ˆä½¿ç”¨è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼‰\n",
    "        \"\"\"\n",
    "        n_simulations = 10000\n",
    "        conversions = 0\n",
    "        \n",
    "        for _ in range(n_simulations):\n",
    "            state = 'Start'\n",
    "            for step in range(max_steps):\n",
    "                if state == 'Conversion':\n",
    "                    conversions += 1\n",
    "                    break\n",
    "                \n",
    "                if state not in transition_matrix or len(transition_matrix[state]) == 0:\n",
    "                    break\n",
    "                \n",
    "                # æ ¹æ®è½¬ç§»æ¦‚ç‡é€‰æ‹©ä¸‹ä¸€ä¸ªçŠ¶æ€\n",
    "                next_states = list(transition_matrix[state].keys())\n",
    "                probs = list(transition_matrix[state].values())\n",
    "                state = np.random.choice(next_states, p=probs)\n",
    "        \n",
    "        return conversions / n_simulations\n",
    "    \n",
    "    def compute_removal_effects(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        è®¡ç®—æ¯ä¸ªæ¸ é“çš„ç§»é™¤æ•ˆåº”\n",
    "        \"\"\"\n",
    "        # åŸºå‡†è½¬åŒ–ç‡ï¼ˆæ‰€æœ‰æ¸ é“éƒ½åœ¨ï¼‰\n",
    "        base_conversion_prob = self._conversion_probability(self.transition_matrix)\n",
    "        \n",
    "        removal_effects = {}\n",
    "        \n",
    "        for channel in self.channels:\n",
    "            # ç§»é™¤è¯¥æ¸ é“åé‡å»ºè½¬ç§»çŸ©é˜µ\n",
    "            transition_without = self._build_transition_matrix(excluded_channel=channel)\n",
    "            \n",
    "            # è®¡ç®—ç§»é™¤åçš„è½¬åŒ–ç‡\n",
    "            conversion_without = self._conversion_probability(transition_without)\n",
    "            \n",
    "            # ç§»é™¤æ•ˆåº” = è½¬åŒ–ç‡çš„ä¸‹é™æ¯”ä¾‹\n",
    "            if base_conversion_prob > 0:\n",
    "                removal_effect = (base_conversion_prob - conversion_without) / base_conversion_prob\n",
    "            else:\n",
    "                removal_effect = 0.0\n",
    "            \n",
    "            removal_effects[channel] = max(removal_effect, 0.0)  # é¿å…è´Ÿå€¼\n",
    "        \n",
    "        return removal_effects\n",
    "\n",
    "# è®¡ç®— Markov å½’å› \n",
    "print(\"ğŸ”— è®¡ç®— Markov Chain å½’å› ...ï¼ˆéœ€è¦è¿è¡Œè’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼‰\")\n",
    "markov_model = MarkovAttribution(df_journeys)\n",
    "removal_effects = markov_model.compute_removal_effects()\n",
    "\n",
    "# å½’ä¸€åŒ–ä¸ºå½’å› æƒé‡\n",
    "total_removal = sum(removal_effects.values())\n",
    "markov_attribution = {ch: effect / total_removal for ch, effect in removal_effects.items()}\n",
    "\n",
    "print(\"\\nâœ… Markov Chain å½’å› ç»“æœ:\")\n",
    "markov_df = pd.DataFrame(list(markov_attribution.items()), columns=['Channel', 'Markov_Attribution']).sort_values('Markov_Attribution', ascending=False)\n",
    "markov_df['Attributed_Revenue'] = markov_df['Markov_Attribution'] * total_revenue\n",
    "display(markov_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€ç»ˆå¯¹æ¯”ï¼šæ‰€æœ‰æ–¹æ³•\n",
    "final_comparison = pd.DataFrame()\n",
    "\n",
    "for method in ['last_touch', 'shapley']:\n",
    "    df_method = all_results[method].copy()\n",
    "    df_method['Share'] = df_method['Attributed_Revenue'] / df_method['Attributed_Revenue'].sum() * 100\n",
    "    final_comparison[method] = df_method.set_index('Channel')['Share']\n",
    "\n",
    "# æ·»åŠ  Markov\n",
    "final_comparison['markov'] = markov_df.set_index('Channel')['Markov_Attribution'] * 100\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "final_comparison.plot(kind='bar', ax=ax, width=0.8, edgecolor='black')\n",
    "ax.set_ylabel('å½’å› å æ¯” (%)')\n",
    "ax.set_xlabel('æ¸ é“')\n",
    "ax.set_title('ä¸‰ç§å½’å› æ–¹æ³•çš„å¯¹æ¯”', fontsize=14, fontweight='bold')\n",
    "ax.legend(['Last-touch', 'Shapley Value', 'Markov Chain'])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š æœ€ç»ˆå¯¹æ¯”ï¼ˆå½’å› å æ¯” %ï¼‰:\")\n",
    "display(final_comparison.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âš¡ Part 5: å¢é‡å½’å›  vs è§¦è¾¾å½’å› \n",
    "\n",
    "### 5.1 æœ¬è´¨åŒºåˆ«\n",
    "\n",
    "å‰é¢æ‰€æœ‰çš„æ–¹æ³•ï¼ˆè§„åˆ™å½’å› ã€Shapleyã€Markovï¼‰éƒ½æ˜¯**è§¦è¾¾å½’å›  (Touch Attribution)**ï¼š\n",
    "\n",
    "| ç»´åº¦ | è§¦è¾¾å½’å›  | å¢é‡å½’å›  |\n",
    "|------|---------|----------|\n",
    "| **é—®é¢˜** | è°\"å‚ä¸äº†\"è½¬åŒ–ï¼Ÿ | è°\"å¯¼è‡´äº†\"è½¬åŒ–ï¼Ÿ |\n",
    "| **æ•°æ®** | åªçœ‹è½¬åŒ–ç”¨æˆ·çš„è·¯å¾„ | éœ€è¦è½¬åŒ– + æœªè½¬åŒ–ç”¨æˆ· |\n",
    "| **åäº‹å®** | âŒ ä¸è€ƒè™‘ | âœ… æ ¸å¿ƒ |\n",
    "| **æ–¹æ³•** | è§„åˆ™ã€Shapleyã€Markov | RCTã€PSMã€DID ç­‰ |\n",
    "| **å›ç­”** | \"åœ¨è½¬åŒ–è·¯å¾„ä¸­ï¼Œè°å‡ºç°äº†\" | \"å¦‚æœæ²¡æœ‰è¿™ä¸ªæ¸ é“ï¼Œä¼šè½¬åŒ–å—\" |\n",
    "\n",
    "### 5.2 ä¸€ä¸ªé‡è¦çš„ä¾‹å­\n",
    "\n",
    "å‡è®¾æœ‰ä¸¤ä¸ªæ¸ é“ï¼š\n",
    "- **Brand Display**ï¼ˆå“ç‰Œå±•ç¤ºå¹¿å‘Šï¼‰ï¼šè¦†ç›–æ‰€æœ‰äººï¼Œä½†è½¬åŒ–ç‡ä½\n",
    "- **Retargeting**ï¼ˆé‡å®šå‘å¹¿å‘Šï¼‰ï¼šåªé’ˆå¯¹å·²è®¿é—®ç”¨æˆ·ï¼Œè½¬åŒ–ç‡é«˜\n",
    "\n",
    "**è§¦è¾¾å½’å› **ä¼šå‘ç°ï¼š\n",
    "- Retargeting åœ¨å¤§éƒ¨åˆ†è½¬åŒ–è·¯å¾„çš„æœ€å\n",
    "- â†’ Last-touch ä¼šç»™ Retargeting å¾ˆé«˜çš„æƒé‡\n",
    "\n",
    "**ä½†å®é™…æƒ…å†µå¯èƒ½æ˜¯**ï¼š\n",
    "- Retargeting åªæ˜¯\"é”¦ä¸Šæ·»èŠ±\"ï¼Œè¿™äº›ç”¨æˆ·æœ¬æ¥å°±ä¼šè½¬åŒ–\n",
    "- Brand Display æ‰æ˜¯\"é›ªä¸­é€ç‚­\"ï¼Œå¸¦æ¥äº†æ–°ç”¨æˆ·\n",
    "\n",
    "**å¢é‡å½’å› **ä¼šé€šè¿‡å®éªŒå‘ç°ï¼š\n",
    "- Retargeting çš„å¢é‡æ•ˆåº”ï¼š+2%\n",
    "- Brand Display çš„å¢é‡æ•ˆåº”ï¼š+15%\n",
    "\n",
    "### 5.3 å¦‚ä½•åšå¢é‡å½’å› ï¼Ÿ\n",
    "\n",
    "**æ–¹æ³• 1: éšæœºå®éªŒ (RCT)**\n",
    "- éšæœºåˆ†ä¸ºå®éªŒç»„ï¼ˆæŠ•æ”¾æ¸ é“ Aï¼‰å’Œå¯¹ç…§ç»„ï¼ˆä¸æŠ•æ”¾ï¼‰\n",
    "- æ¯”è¾ƒä¸¤ç»„çš„è½¬åŒ–ç‡å·®å¼‚ â†’ æ¸ é“ A çš„å¢é‡æ•ˆåº”\n",
    "- **é‡‘æ ‡å‡†**ï¼Œä½†æˆæœ¬é«˜ã€å‘¨æœŸé•¿\n",
    "\n",
    "**æ–¹æ³• 2: Geo-experiment**\n",
    "- åœ¨ä¸åŒåœ°åŒºéšæœºå¼€å…³æ¸ é“\n",
    "- é€‚åˆæ— æ³•åšç”¨æˆ·çº§éšæœºåŒ–çš„åœºæ™¯ï¼ˆå¦‚ç”µè§†å¹¿å‘Šï¼‰\n",
    "\n",
    "**æ–¹æ³• 3: PSM / DML**\n",
    "- å¦‚æœæ— æ³•åšå®éªŒï¼Œä½¿ç”¨è§‚æµ‹æ•°æ®çš„å› æœæ¨æ–­æ–¹æ³•\n",
    "- æ¯”è¾ƒ\"çœ‹åˆ°å¹¿å‘Šçš„ç”¨æˆ·\" vs \"å€¾å‘æ€§å¾—åˆ†åŒ¹é…çš„æœªçœ‹åˆ°å¹¿å‘Šçš„ç”¨æˆ·\"\n",
    "\n",
    "**æ–¹æ³• 4: Ghost Ads**\n",
    "- åœ¨å¹¿å‘Šç«ä»·ä¸­ï¼Œéšæœº\"æ”¾å¼ƒ\"ä¸€éƒ¨åˆ†æ›å…‰æœºä¼š\n",
    "- æ¯”è¾ƒ\"èµ¢å¾—æ›å…‰\" vs \"æ”¾å¼ƒæ›å…‰\"çš„ç”¨æˆ·çš„è½¬åŒ–ç‡\n",
    "- Facebookã€Google éƒ½åœ¨ç”¨\n",
    "\n",
    "### 5.4 ç®€å•æ¨¡æ‹Ÿï¼šå¢é‡ vs è§¦è¾¾\n",
    "\n",
    "è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªç®€åŒ–çš„ä¾‹å­è¯´æ˜å·®å¼‚ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_incremental_vs_touch():\n",
    "    \"\"\"\n",
    "    æ¨¡æ‹Ÿå¢é‡å½’å›  vs è§¦è¾¾å½’å› çš„å·®å¼‚\n",
    "    \n",
    "    åœºæ™¯ï¼š\n",
    "    - Channel A (Brand): è¦†ç›–æ‰€æœ‰äººï¼Œå¸¦æ¥è®¤çŸ¥ï¼Œå¢é‡æ•ˆåº” +10%\n",
    "    - Channel B (Retargeting): åªé’ˆå¯¹é«˜æ„å‘ç”¨æˆ·ï¼Œå‡ºç°åœ¨æœ€åï¼Œå¢é‡æ•ˆåº” +2%\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_users = 10000\n",
    "    \n",
    "    # ç”¨æˆ·çš„åŸºç¡€è½¬åŒ–å€¾å‘ï¼ˆ0-1ï¼‰\n",
    "    base_propensity = np.random.beta(2, 8, n_users)  # å¤§éƒ¨åˆ†ç”¨æˆ·åŸºç¡€è½¬åŒ–ç‡ä½\n",
    "    \n",
    "    # Channel A: è¦†ç›–æ‰€æœ‰äºº\n",
    "    exposed_to_A = np.ones(n_users, dtype=bool)\n",
    "    \n",
    "    # Channel B: åªé’ˆå¯¹é«˜å€¾å‘ç”¨æˆ·ï¼ˆtop 30%ï¼‰\n",
    "    threshold = np.percentile(base_propensity, 70)\n",
    "    exposed_to_B = base_propensity >= threshold\n",
    "    \n",
    "    # çœŸå®çš„å¢é‡æ•ˆåº”\n",
    "    # Channel A: è®©è½¬åŒ–æ¦‚ç‡ +10%\n",
    "    # Channel B: è®©è½¬åŒ–æ¦‚ç‡ +2%\n",
    "    conversion_prob = base_propensity.copy()\n",
    "    conversion_prob += 0.10 * exposed_to_A  # Channel A çš„å¢é‡\n",
    "    conversion_prob += 0.02 * exposed_to_B  # Channel B çš„å¢é‡\n",
    "    conversion_prob = np.clip(conversion_prob, 0, 1)\n",
    "    \n",
    "    # å®é™…è½¬åŒ–\n",
    "    converted = np.random.rand(n_users) < conversion_prob\n",
    "    \n",
    "    # ========== å¢é‡å½’å› ï¼ˆçœŸå®æ•ˆåº”ï¼‰==========\n",
    "    # è¿™æ˜¯æˆ‘ä»¬åœ¨æ¨¡æ‹Ÿä¸­è®¾å®šçš„çœŸå®å€¼\n",
    "    true_incremental = {\n",
    "        'Channel_A': 0.10,\n",
    "        'Channel_B': 0.02\n",
    "    }\n",
    "    \n",
    "    # ========== è§¦è¾¾å½’å› ï¼ˆLast-touchï¼‰==========\n",
    "    # åªçœ‹è½¬åŒ–ç”¨æˆ·çš„è·¯å¾„\n",
    "    converted_users = converted\n",
    "    \n",
    "    # æ„é€ è·¯å¾„ï¼šA -> Bï¼ˆå¦‚æœæš´éœ²äº Bï¼‰æˆ–è€…åªæœ‰ A\n",
    "    paths = []\n",
    "    for i in range(n_users):\n",
    "        if not converted[i]:\n",
    "            continue\n",
    "        \n",
    "        if exposed_to_B[i]:\n",
    "            paths.append(['Channel_A', 'Channel_B'])\n",
    "        else:\n",
    "            paths.append(['Channel_A'])\n",
    "    \n",
    "    # Last-touch å½’å› \n",
    "    last_touch_counts = Counter([path[-1] for path in paths])\n",
    "    total_conversions = sum(last_touch_counts.values())\n",
    "    last_touch_attribution = {ch: count / total_conversions for ch, count in last_touch_counts.items()}\n",
    "    \n",
    "    # ç»“æœ\n",
    "    print(\"ğŸ”¬ å¢é‡å½’å›  vs è§¦è¾¾å½’å› å¯¹æ¯”\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'æ¸ é“':<15} {'çœŸå®å¢é‡æ•ˆåº”':<20} {'Last-touch å½’å› ':<20}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for channel in ['Channel_A', 'Channel_B']:\n",
    "        incremental = true_incremental.get(channel, 0) * 100\n",
    "        touch = last_touch_attribution.get(channel, 0) * 100\n",
    "        print(f\"{channel:<15} {incremental:>6.1f}% (çœŸå®ä»·å€¼) {touch:>12.1f}% (å½’å› ç»“æœ)\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nâš ï¸ è§‚å¯Ÿ:\")\n",
    "    print(\"   - Channel A çš„çœŸå®å¢é‡æ•ˆåº”æ˜¯ 10%ï¼Œä½† Last-touch åªç»™äº†å®ƒå¾ˆå°‘çš„æƒé‡\")\n",
    "    print(\"   - Channel B çš„çœŸå®å¢é‡æ•ˆåº”åªæœ‰ 2%ï¼Œä½†å› ä¸ºå®ƒæ€»æ˜¯æœ€åè§¦ç‚¹ï¼Œå¾—åˆ°äº†å¤§éƒ¨åˆ†å½’å› \")\n",
    "    print(\"   - è¿™å°±æ˜¯è§¦è¾¾å½’å› çš„é—®é¢˜ï¼šæ··æ·†äº†'å‚ä¸'å’Œ'å¯¼è‡´'\")\n",
    "    \n",
    "    # å¯è§†åŒ–\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    channels = ['Channel A\\n(Brand)', 'Channel B\\n(Retargeting)']\n",
    "    incremental_values = [10, 2]\n",
    "    touch_values = [last_touch_attribution.get('Channel_A', 0) * 100, \n",
    "                    last_touch_attribution.get('Channel_B', 0) * 100]\n",
    "    \n",
    "    x = np.arange(len(channels))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, incremental_values, width, label='çœŸå®å¢é‡æ•ˆåº”', color='green', edgecolor='black', alpha=0.8)\n",
    "    ax.bar(x + width/2, touch_values, width, label='Last-touch å½’å› ', color='orange', edgecolor='black', alpha=0.8)\n",
    "    \n",
    "    ax.set_ylabel('ç™¾åˆ†æ¯” (%)', fontsize=12)\n",
    "    ax.set_title('å¢é‡å½’å›  vs è§¦è¾¾å½’å› çš„å·®å¼‚', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(channels)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "    for i, (inc, touch) in enumerate(zip(incremental_values, touch_values)):\n",
    "        ax.text(i - width/2, inc + 1, f'{inc:.1f}%', ha='center', fontsize=10, fontweight='bold')\n",
    "        ax.text(i + width/2, touch + 1, f'{touch:.1f}%', ha='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "simulate_incremental_vs_touch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ å…³é”®å¯ç¤º\n",
    "\n",
    "1. **è§¦è¾¾å½’å› å‘Šè¯‰ä½ \"è°å‚ä¸äº†\"ï¼Œå¢é‡å½’å› å‘Šè¯‰ä½ \"è°å¯¼è‡´äº†\"**\n",
    "2. **è§¦è¾¾å½’å› ä¼šé«˜ä¼°\"æœ€åè§¦ç‚¹\"çš„ä»·å€¼**ï¼ˆå› ä¸ºé«˜æ„å‘ç”¨æˆ·æ›´å®¹æ˜“è¢« retargetingï¼‰\n",
    "3. **è§¦è¾¾å½’å› ä¼šä½ä¼°\"ä¸Šæ¸¸æ¸ é“\"çš„ä»·å€¼**ï¼ˆå¦‚å“ç‰Œå¹¿å‘Šï¼‰\n",
    "4. **ä¸šåŠ¡å†³ç­–åº”åŸºäºå¢é‡å½’å› **ï¼ˆå¦åˆ™ä¼šé”™è¯¯åˆ†é…é¢„ç®—ï¼‰\n",
    "\n",
    "### ğŸ’¡ å®è·µå»ºè®®\n",
    "\n",
    "| åœºæ™¯ | ç”¨å“ªç§å½’å› ï¼Ÿ |\n",
    "|------|-------------|\n",
    "| å¿«é€Ÿäº†è§£ç”¨æˆ·è·¯å¾„ | è§¦è¾¾å½’å›  |\n",
    "| é¢„ç®—åˆ†é…å†³ç­– | å¢é‡å½’å›  |\n",
    "| æ¸ é“æ•ˆæœè¯„ä¼° | å¢é‡å½’å›  |\n",
    "| æ— æ³•åšå®éªŒ | è§¦è¾¾å½’å›  + ä¸šåŠ¡åˆ¤æ–­ |\n",
    "| æœ‰å®éªŒèƒ½åŠ› | å¢é‡å½’å› ï¼ˆRCTï¼‰ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¼ Part 6: ä¸šåŠ¡å®è·µ\n",
    "\n",
    "### 6.1 æ¡ˆä¾‹ï¼šå¤šæ¸ é“è¥é”€å½’å› \n",
    "\n",
    "å‡è®¾ä½ æ˜¯ä¸€å®¶ SaaS å…¬å¸çš„å¢é•¿è´Ÿè´£äººï¼Œç°åœ¨è¦å†³å®šæ˜å¹´çš„è¥é”€é¢„ç®—åˆ†é…ã€‚\n",
    "\n",
    "**ç°çŠ¶**ï¼š\n",
    "- 5 ä¸ªæ¸ é“ï¼Œæ€»é¢„ç®— 100 ä¸‡\n",
    "- ä»Šå¹´çš„åˆ†é…ï¼šSearch 30ä¸‡ã€Social 25ä¸‡ã€Email 20ä¸‡ã€Display 15ä¸‡ã€Affiliate 10ä¸‡\n",
    "\n",
    "**æ•°æ®**ï¼š\n",
    "- è§¦è¾¾å½’å› ç»“æœï¼ˆåŸºäºå†å²è½¬åŒ–è·¯å¾„ï¼‰\n",
    "- å¢é‡å®éªŒç»“æœï¼ˆåœ¨éƒ¨åˆ†åœ°åŒºåšçš„ Geo-experimentï¼‰\n",
    "\n",
    "**é—®é¢˜**ï¼šå¦‚ä½•è°ƒæ•´é¢„ç®—ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡æ‹Ÿä¸šåŠ¡åœºæ™¯\n",
    "budget_data = pd.DataFrame({\n",
    "    'Channel': ['Search', 'Social', 'Email', 'Display', 'Affiliate'],\n",
    "    'Current_Budget': [300000, 250000, 200000, 150000, 100000],\n",
    "    'Last_Touch_Attribution_%': [45, 15, 10, 20, 10],\n",
    "    'Shapley_Attribution_%': [30, 20, 15, 25, 10],\n",
    "    'Incremental_Lift_%': [5, 15, 8, 12, 3],  # æ¥è‡ªå®éªŒ\n",
    "    'Cost_per_Conversion': [50, 80, 30, 100, 40]\n",
    "})\n",
    "\n",
    "# è®¡ç®— ROI\n",
    "budget_data['Incremental_ROI'] = budget_data['Incremental_Lift_%'] / budget_data['Cost_per_Conversion']\n",
    "\n",
    "print(\"ğŸ“Š æ¸ é“åˆ†ææŠ¥å‘Š\\n\")\n",
    "display(budget_data)\n",
    "\n",
    "# å¯¹æ¯”ä¸åŒå½’å› æ–¹æ³•çš„å»ºè®®\n",
    "print(\"\\nğŸ’¡ ä¸åŒå½’å› æ–¹æ³•çš„é¢„ç®—å»ºè®®:\\n\")\n",
    "\n",
    "print(\"1ï¸âƒ£ åŸºäº Last-touch å½’å› :\")\n",
    "print(\"   â†’ å¢åŠ  Search é¢„ç®—ï¼ˆå æ¯” 45%ï¼‰\")\n",
    "print(\"   â†’ å‡å°‘ Email é¢„ç®—ï¼ˆå æ¯” 10%ï¼‰\")\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ åŸºäº Shapley å½’å› :\")\n",
    "print(\"   â†’ æ›´å¹³è¡¡ï¼ŒDisplay å’Œ Social åº”è·å¾—æ›´å¤šé¢„ç®—\")\n",
    "\n",
    "print(\"\\n3ï¸âƒ£ åŸºäºå¢é‡å½’å›  (æ¨è):\")\n",
    "print(\"   â†’ Social å¢é‡æœ€é«˜ï¼ˆ15%ï¼‰ï¼Œåº”å¢åŠ é¢„ç®—\")\n",
    "print(\"   â†’ Affiliate å¢é‡æœ€ä½ï¼ˆ3%ï¼‰ï¼Œè€ƒè™‘å‡å°‘\")\n",
    "print(\"   â†’ ç»“åˆ ROIï¼ŒEmail æ€§ä»·æ¯”æœ€é«˜\")\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# å­å›¾ 1: å½’å› å¯¹æ¯”\n",
    "ax1 = axes[0]\n",
    "budget_data_sorted = budget_data.sort_values('Channel')\n",
    "x = np.arange(len(budget_data_sorted))\n",
    "width = 0.25\n",
    "\n",
    "ax1.bar(x - width, budget_data_sorted['Last_Touch_Attribution_%'], width, label='Last-touch', alpha=0.8)\n",
    "ax1.bar(x, budget_data_sorted['Shapley_Attribution_%'], width, label='Shapley', alpha=0.8)\n",
    "ax1.bar(x + width, budget_data_sorted['Incremental_Lift_%'], width, label='Incremental', alpha=0.8)\n",
    "\n",
    "ax1.set_ylabel('ç™¾åˆ†æ¯” (%)')\n",
    "ax1.set_title('ä¸åŒå½’å› æ–¹æ³•çš„ç»“æœå¯¹æ¯”')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(budget_data_sorted['Channel'], rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# å­å›¾ 2: å¢é‡ ROI\n",
    "ax2 = axes[1]\n",
    "budget_data_sorted_roi = budget_data.sort_values('Incremental_ROI', ascending=True)\n",
    "budget_data_sorted_roi.plot(kind='barh', x='Channel', y='Incremental_ROI', ax=ax2, color='coral', edgecolor='black', legend=False)\n",
    "ax2.set_xlabel('å¢é‡ ROI (Lift % / Cost)')\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_title('å„æ¸ é“çš„å¢é‡ ROI')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 å¸¸è§é™·é˜±\n",
    "\n",
    "#### é™·é˜± 1: è¿‡åº¦ä¾èµ– Last-touch\n",
    "**é—®é¢˜**: ä¼šå¯¼è‡´è¿‡åº¦æŠ•èµ„ä¸‹æ¸¸æ¸ é“ï¼ˆå¦‚ Retargetingï¼‰ï¼Œå¿½è§†å“ç‰Œå»ºè®¾  \n",
    "**åæœ**: çŸ­æœŸ ROI çœ‹èµ·æ¥å¥½ï¼Œé•¿æœŸå¢é•¿ä¹åŠ›\n",
    "\n",
    "#### é™·é˜± 2: æ··æ·†ç›¸å…³ä¸å› æœ\n",
    "**é—®é¢˜**: é«˜æ„å‘ç”¨æˆ·æ›´å®¹æ˜“çœ‹åˆ° Retargeting å¹¿å‘Š  \n",
    "**åæœ**: è¯¯ä»¥ä¸º Retargeting æ•ˆæœå¥½ï¼Œå®é™…åªæ˜¯\"é¡ºæ°´æ¨èˆŸ\"\n",
    "\n",
    "#### é™·é˜± 3: å¿½è§†æ¸ é“ååŒ\n",
    "**é—®é¢˜**: å•ç‹¬è¯„ä¼°æ¯ä¸ªæ¸ é“ï¼Œå¿½è§†ç»„åˆæ•ˆåº”  \n",
    "**åæœ**: å¯èƒ½é”™è¯¯åœ°å…³é—­æŸä¸ª\"è¾…åŠ©\"æ¸ é“ï¼Œå¯¼è‡´æ•´ä½“æ•ˆæœä¸‹é™\n",
    "\n",
    "#### é™·é˜± 4: æ•°æ®åå·®\n",
    "**é—®é¢˜**: Cookie ä¸¢å¤±ã€è·¨è®¾å¤‡è¿½è¸ªä¸å…¨  \n",
    "**åæœ**: å½’å› æ•°æ®æœ¬èº«å°±ä¸å‡†ç¡®\n",
    "\n",
    "### 6.3 æœ€ä½³å®è·µ\n",
    "\n",
    "1. **ç”¨è§¦è¾¾å½’å› äº†è§£ç”¨æˆ·æ—…ç¨‹ï¼Œç”¨å¢é‡å½’å› åšå†³ç­–**\n",
    "2. **å®šæœŸåšå¢é‡å®éªŒï¼ˆè‡³å°‘æ¯å­£åº¦ä¸€æ¬¡ï¼‰**\n",
    "3. **å…³æ³¨ Holdout ç»„ï¼ˆä¸æŠ•æ”¾ä»»ä½•å¹¿å‘Šçš„å¯¹ç…§ç»„ï¼‰**\n",
    "4. **è­¦æƒ•\"å½’å› é€šè´§è†¨èƒ€\"**ï¼ˆæ‰€æœ‰æ¸ é“çš„å½’å› åŠ èµ·æ¥ > 100%ï¼‰\n",
    "5. **ç»“åˆä¸šåŠ¡å¸¸è¯†**ï¼ˆæ•°æ®æ˜¯å·¥å…·ï¼Œä¸æ˜¯ç­”æ¡ˆï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§  ç»ƒä¹ ä¸æ€è€ƒé¢˜\n",
    "\n",
    "### ç»ƒä¹  1: å®ç°è‡ªå·±çš„å½’å› æ¨¡å‹\n",
    "\n",
    "è¯·å®ç°ä¸€ä¸ªè‡ªå®šä¹‰çš„ Time-decay å½’å› ï¼Œè¡°å‡å‚æ•°å¯è°ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def custom_time_decay(path: List[str], half_life_days: int = 7) -> Dict[str, float]:\n    \"\"\"\n    å®ç°ä¸€ä¸ªåŸºäºåŠè¡°æœŸçš„ Time-decay å½’å› \n    \n    å‡è®¾è§¦ç‚¹ä¹‹é—´é—´éš” 1 å¤©ï¼Œæƒé‡æŒ‰åŠè¡°æœŸè¡°å‡ã€‚\n    \n    Args:\n        path: è½¬åŒ–è·¯å¾„\n        half_life_days: åŠè¡°æœŸï¼ˆå¤©ï¼‰\n    \n    Returns:\n        å„æ¸ é“çš„å½’å› æƒé‡\n    \n    æç¤º: \n    - æƒé‡ w_i = 2^(-(n-i)/half_life)\n    - è®°å¾—å½’ä¸€åŒ–\n    \"\"\"\n    n = len(path)\n    attribution = defaultdict(float)\n    \n    # è®¡ç®—æ¯ä¸ªè§¦ç‚¹çš„æƒé‡\n    weights = []\n    for i in range(n):\n        # è·ç¦»è½¬åŒ–çš„å¤©æ•°ï¼ˆç¬¬0ä¸ªè§¦ç‚¹è·ç¦»è½¬åŒ–n-1å¤©ï¼‰\n        days_to_conversion = n - 1 - i\n        # åŠè¡°æœŸè¡°å‡ï¼šw = 2^(-days/half_life)\n        weight = 2 ** (-days_to_conversion / half_life_days)\n        weights.append(weight)\n    \n    # å½’ä¸€åŒ–\n    total_weight = sum(weights)\n    weights = [w / total_weight for w in weights]\n    \n    # ç´¯åŠ åŒä¸€æ¸ é“çš„æƒé‡\n    for i, channel in enumerate(path):\n        attribution[channel] += weights[i]\n    \n    return dict(attribution)\n\n# æµ‹è¯•\ntest_path = ['Social', 'Search', 'Email', 'Search']\nresult = custom_time_decay(test_path, half_life_days=7)\nprint(f\"è‡ªå®šä¹‰ Time-decay ç»“æœ: {result}\")\n\n# éªŒè¯æ€»å’Œä¸º1\nprint(f\"æƒé‡æ€»å’Œ: {sum(result.values()):.4f} (åº”è¯¥ä¸º 1.0)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç»ƒä¹  2: Shapley å€¼çš„æ€§è´¨éªŒè¯\n",
    "\n",
    "éªŒè¯ Shapley å€¼çš„\"æ•ˆç‡æ€§\"å…¬ç†ï¼šæ‰€æœ‰æ¸ é“çš„ Shapley å€¼ä¹‹å’Œåº”è¯¥ç­‰äºæ€»ä»·å€¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# éªŒè¯ Shapley å€¼çš„\"æ•ˆç‡æ€§\"å…¬ç†\n\n# Shapley å€¼çš„æ•ˆç‡æ€§å…¬ç†ï¼šæ‰€æœ‰æ¸ é“çš„ Shapley å€¼ä¹‹å’Œåº”è¯¥ç­‰äºæ€»ä»·å€¼\nprint(\"ğŸ” éªŒè¯ Shapley Value çš„æ•ˆç‡æ€§å…¬ç†\")\nprint(\"=\"*60)\n\n# è®¡ç®—æ‰€æœ‰ Shapley å€¼çš„æ€»å’Œ\nshapley_sum = sum(shapley_values.values())\nprint(f\"\\nShapley å€¼æ€»å’Œ: {shapley_sum:.4f}\")\n\n# è®¡ç®—æ€»ä»·å€¼ï¼ˆæ‰€æœ‰æ¸ é“éƒ½å­˜åœ¨æ—¶çš„è½¬åŒ–ä»·å€¼ï¼‰\nall_channels_frozenset = frozenset(shapley_model.all_channels)\ntotal_value = shapley_model.value_function.get(all_channels_frozenset, 0.0)\nprint(f\"æ€»ä»·å€¼ v(N): {total_value:.4f}\")\n\n# æ£€æŸ¥æ˜¯å¦ç›¸ç­‰\ndifference = abs(shapley_sum - total_value)\nis_efficient = difference < 0.01  # å…è®¸å¾®å°çš„æ•°å€¼è¯¯å·®\n\nprint(f\"\\nå·®å¼‚: {difference:.6f}\")\nprint(f\"æ•ˆç‡æ€§å…¬ç†æ»¡è¶³: {'âœ… æ˜¯' if is_efficient else 'âŒ å¦'}\")\n\nprint(f\"\\nğŸ’¡ è§£é‡Š:\")\nprint(f\"  æ ¹æ® Shapley å€¼çš„æ•ˆç‡æ€§å…¬ç†ï¼Œæ‰€æœ‰ç©å®¶çš„ Shapley å€¼ä¹‹å’Œ\")\nprint(f\"  åº”è¯¥ç­‰äºå¤§è”ç›Ÿçš„æ€»ä»·å€¼ã€‚\")\nprint(f\"  \")\nprint(f\"  å…¬å¼: Î£ Ï†_i(v) = v(N)\")\nprint(f\"  \")\nprint(f\"  è¿™æ„å‘³ç€ï¼šShapley å½’å› ä¼šå°†æ€»æ”¶ç›Š\\\"å…¬å¹³\\\"åœ°å®Œå…¨åˆ†é…ç»™å„ä¸ªæ¸ é“ï¼Œ\")\nprint(f\"  ä¸ä¼šå¤šåˆ†ä¹Ÿä¸ä¼šå°‘åˆ†ã€‚\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<cell_type>markdown</cell_type>---\n\n## ğŸ§  ç»ƒä¹ ä¸æ€è€ƒé¢˜\n\n### ç»ƒä¹  1: å®ç°è‡ªå·±çš„å½’å› æ¨¡å‹\n\nè¯·å®ç°ä¸€ä¸ªè‡ªå®šä¹‰çš„ Time-decay å½’å› ï¼Œè¡°å‡å‚æ•°å¯è°ƒã€‚"
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## ğŸ“ æ€è€ƒé¢˜å‚è€ƒç­”æ¡ˆ\n\n### é—®é¢˜ 1: Last-touch å½’å› æœ‰ä»€ä¹ˆæ ¹æœ¬é—®é¢˜ï¼Ÿ\n\n**å‚è€ƒç­”æ¡ˆ**:\n\nLast-touch å½’å› çš„æ ¹æœ¬é—®é¢˜æ˜¯**æ··æ·†äº†\"å‚ä¸\"å’Œ\"å¯¼è‡´\"**ï¼Œå…·ä½“åŒ…æ‹¬ï¼š\n\n1. **å¿½ç•¥å‰æœŸåŸ¹è‚²**:\n   - ç”¨æˆ·å¯èƒ½å› ä¸ºå“ç‰Œå¹¿å‘Šäº§ç”Ÿè®¤çŸ¥ï¼Œä½†å½’å› å…¨ç»™æœ€åçš„æœç´¢å¹¿å‘Š\n   - ä¾‹å¦‚ï¼šç”¨æˆ·çœ‹åˆ°æœ‹å‹åœˆå¹¿å‘Š â†’ äº§ç”Ÿå…´è¶£ â†’ 1å‘¨åä¸»åŠ¨æœç´¢ â†’ è´­ä¹°\n   - Last-touch ä¼š100%å½’å› ç»™æœç´¢ï¼Œå¿½ç•¥æœ‹å‹åœˆå¹¿å‘Šçš„\"ç§è‰\"ä½œç”¨\n\n2. **Selection Biasï¼ˆé€‰æ‹©åå·®ï¼‰**:\n   - é«˜æ„å‘ç”¨æˆ·æ›´å®¹æ˜“è¢« Retargeting æ•è·\n   - Retargeting æ€»æ˜¯å‡ºç°åœ¨æœ€åï¼Œä½†å¯èƒ½åªæ˜¯\"é¡ºæ°´æ¨èˆŸ\"\n   - è¿™äº›ç”¨æˆ·å³ä½¿ä¸çœ‹ Retargeting ä¹Ÿä¼šè´­ä¹°ï¼ˆSure Thingsï¼‰\n\n3. **é¼“åŠ±çŸ­è§†è¡Œä¸º**:\n   - è¥é”€å›¢é˜Ÿä¼šè¿‡åº¦æŠ•èµ„\"ä¸´é—¨ä¸€è„š\"çš„æ¸ é“\n   - å¿½è§†é•¿æœŸå“ç‰Œå»ºè®¾å’Œä¸Šæ¸¸æ¸ é“\n\n4. **æ•°å­¦ä¸Šçš„ä¸åˆç†æ€§**:\n   - å¦‚æœè·¯å¾„æ˜¯ A â†’ B â†’ Cï¼ŒLast-touch ç»™ C å…¨éƒ¨æƒé‡\n   - ä½†å¦‚æœè·¯å¾„æ˜¯ A â†’ B â†’ C â†’ Cï¼ˆCé‡å¤ï¼‰ï¼ŒC ä»ç„¶æ˜¯100%\n   - æ²¡æœ‰è€ƒè™‘æ¸ é“çš„çœŸå®è¾¹é™…è´¡çŒ®\n\n**çœŸå®æ¡ˆä¾‹**:\næŸç”µå•†å¹³å°å‘ç°ï¼Œæœç´¢å¹¿å‘Šçš„ Last-touch å½’å› å æ¯”60%ï¼Œä½†é€šè¿‡ Geo-experimentï¼ˆå…³é—­æœç´¢å¹¿å‘Šï¼‰ï¼Œå‘ç°çœŸå®å¢é‡åªæœ‰15%ã€‚åŸå› æ˜¯å¤§éƒ¨åˆ†ç”¨æˆ·æœ¬æ¥å°±ä¼šä¸»åŠ¨æœç´¢å“ç‰Œè¯ã€‚\n\n---\n\n### é—®é¢˜ 2: Shapley Value å½’å› ä¸ºä»€ä¹ˆ\"å…¬å¹³\"ï¼Ÿå®ƒçš„å‡è®¾æ˜¯ä»€ä¹ˆï¼Ÿ\n\n**å‚è€ƒç­”æ¡ˆ**:\n\n**ä¸ºä»€ä¹ˆå…¬å¹³**:\n\nShapley Value æ˜¯**å”¯ä¸€**æ»¡è¶³ä»¥ä¸‹4ä¸ªå…¬ç†çš„åˆ†é…æ–¹æ¡ˆï¼š\n\n1. **æ•ˆç‡æ€§ (Efficiency)**: \n   $$\\sum_{i=1}^n \\phi_i(v) = v(N)$$\n   æ‰€æœ‰ä»·å€¼è¢«å®Œå…¨åˆ†é…ï¼Œä¸å¤šä¸å°‘\n\n2. **å¯¹ç§°æ€§ (Symmetry)**:\n   å¦‚æœæ¸ é“ $i$ å’Œ $j$ å¯äº’æ¢ï¼ˆå¯¹æ‰€æœ‰å­é›†è´¡çŒ®ç›¸åŒï¼‰ï¼Œåˆ™ $\\phi_i = \\phi_j$\n\n3. **è™šæ‹Ÿæ€§ (Null Player)**:\n   å¦‚æœæ¸ é“ $i$ å¯¹æ‰€æœ‰è”ç›Ÿéƒ½æ²¡æœ‰è´¡çŒ®ï¼Œåˆ™ $\\phi_i = 0$\n\n4. **å¯åŠ æ€§ (Additivity)**:\n   å¦‚æœæœ‰ä¸¤ä¸ªä»·å€¼å‡½æ•° $v$ å’Œ $w$ï¼Œåˆ™ $\\phi_i(v+w) = \\phi_i(v) + \\phi_i(w)$\n\n**æ ¸å¿ƒæ€æƒ³**:\nShapley Value è®¡ç®—çš„æ˜¯æ¸ é“åœ¨**æ‰€æœ‰å¯èƒ½çš„åŠ å…¥é¡ºåº**ä¸­çš„å¹³å‡è¾¹é™…è´¡çŒ®ã€‚\n\nä¾‹å¦‚ï¼Œ3ä¸ªæ¸ é“ A, B, Cï¼Œæœ‰6ç§åŠ å…¥é¡ºåºï¼š\n```\nA â†’ B â†’ C: A çš„è¾¹é™…è´¡çŒ® = v({A})\nB â†’ A â†’ C: A çš„è¾¹é™…è´¡çŒ® = v({A,B}) - v({B})\nC â†’ A â†’ B: A çš„è¾¹é™…è´¡çŒ® = v({A,C}) - v({C})\n... (å…±6ç§)\n```\n\nShapley å€¼ = è¿™6ç§æƒ…å†µçš„åŠ æƒå¹³å‡ï¼ˆæƒé‡ç”±ç»„åˆæ•°å†³å®šï¼‰\n\n**å‡è®¾**:\n\n1. **ä»·å€¼å¯åˆ†**: æ€»ä»·å€¼å¯ä»¥åˆ†è§£ä¸ºå„æ¸ é“çš„è´¡çŒ®ä¹‹å’Œ\n2. **ä»·å€¼å‡½æ•°å·²çŸ¥**: éœ€è¦èƒ½å¤Ÿä¼°è®¡æ‰€æœ‰å­é›† $v(S)$ çš„ä»·å€¼\n3. **æ¸ é“é—´æ— å¤–éƒ¨æ€§**: é™¤äº†ä»·å€¼å‡½æ•° $v(S)$ å·²ç»æ•è·çš„ï¼Œæ²¡æœ‰å…¶ä»–éšè—çš„äº¤äº’æ•ˆåº”\n4. **åˆä½œåšå¼ˆ**: æ‰€æœ‰æ¸ é“\"åˆä½œ\"äº§ç”Ÿè½¬åŒ–ï¼ˆå®é™…ä¸­å¯èƒ½æœ‰ç«äº‰å…³ç³»ï¼‰\n\n**å±€é™**:\n\n1. **ä»æ˜¯è§¦è¾¾å½’å› **: æ²¡æœ‰è€ƒè™‘åäº‹å®ï¼ˆå¦‚æœæ²¡æœ‰æŸæ¸ é“ä¼šæ€æ ·ï¼‰\n2. **è®¡ç®—å¤æ‚åº¦**: $O(2^n)$ï¼Œæ¸ é“å¤šæ—¶ä¸å¯è¡Œ\n3. **æ•°æ®éœ€æ±‚**: éœ€è¦æ‰€æœ‰æ¸ é“ç»„åˆçš„æ•°æ®ï¼ˆå®é™…ä¸­å¾ˆå¤šç»„åˆå¯èƒ½æ²¡æœ‰ï¼‰\n4. **é™æ€å‡è®¾**: å‡è®¾ä»·å€¼å‡½æ•°ä¸éšæ—¶é—´å˜åŒ–\n\n**ä¸å¢é‡å½’å› çš„å¯¹æ¯”**:\n- Shapley: \"åœ¨å·²è½¬åŒ–ç”¨æˆ·çš„è·¯å¾„ä¸­ï¼Œå¦‚ä½•å…¬å¹³åˆ†é…åŠŸåŠ³\"\n- å¢é‡å½’å› : \"æ¯ä¸ªæ¸ é“å¯¼è‡´äº†å¤šå°‘é¢å¤–è½¬åŒ–\"ï¼ˆéœ€è¦å®éªŒï¼‰\n\n---\n\n### é—®é¢˜ 3: å¦‚æœä¸€ä¸ªæ¸ é“åœ¨è½¬åŒ–è·¯å¾„ä¸­ä»æœªå‡ºç°è¿‡ï¼Œä½†å®ƒå½±å“äº†ç”¨æˆ·çš„çº¿ä¸‹è®¤çŸ¥ï¼Œè§¦è¾¾å½’å› èƒ½æ•æ‰åˆ°å—ï¼Ÿ\n\n**å‚è€ƒç­”æ¡ˆ**:\n\n**ä¸èƒ½ï¼** è¿™æ˜¯è§¦è¾¾å½’å› çš„æ ¹æœ¬å±€é™ã€‚\n\n**å…¸å‹æ¡ˆä¾‹**:\n\n1. **ç”µè§†å¹¿å‘Š**:\n   - ç”¨æˆ·çœ‹äº†ç”µè§†å¹¿å‘Šï¼Œäº§ç”Ÿå“ç‰Œè®¤çŸ¥\n   - 1å‘¨åä¸»åŠ¨æœç´¢å“ç‰Œè¯ï¼Œç‚¹å‡»æœç´¢å¹¿å‘Šè´­ä¹°\n   - è½¬åŒ–è·¯å¾„: `Search`ï¼ˆæ²¡æœ‰ TVï¼‰\n   - è§¦è¾¾å½’å› : TV è´¡çŒ® = 0%\n   - çœŸå®æƒ…å†µ: TV å¯èƒ½æ˜¯æœ€é‡è¦çš„æ¸ é“ï¼\n\n2. **çº¿ä¸‹æ´»åŠ¨**:\n   - ç”¨æˆ·å‚åŠ çº¿ä¸‹å“ç‰Œæ´»åŠ¨ï¼Œä½“éªŒäº§å“\n   - å›å®¶ååœ¨å®˜ç½‘è´­ä¹°ï¼ˆç›´æ¥è®¿é—®ï¼Œæ— ä»»ä½•å¹¿å‘Šè§¦è¾¾ï¼‰\n   - è½¬åŒ–è·¯å¾„: `Direct`\n   - è§¦è¾¾å½’å› : çº¿ä¸‹æ´»åŠ¨è´¡çŒ® = 0%\n\n3. **å£ç¢‘ä¼ æ’­**:\n   - ç”¨æˆ·å¬æœ‹å‹æ¨èäº§å“\n   - è‡ªå·±æœç´¢è´­ä¹°\n   - è½¬åŒ–è·¯å¾„: `Search`\n   - è§¦è¾¾å½’å› : å£ç¢‘è´¡çŒ® = 0%\n\n**å¦‚ä½•è§£å†³**:\n\n**æ–¹æ³• 1: Geo-based å®éªŒ**\n```python\n# ä¸åŒåŸå¸‚æŠ•æ”¾ä¸åŒçš„ç”µè§†å¹¿å‘Š\nåŸå¸‚A: æŠ•æ”¾ TV\nåŸå¸‚B: ä¸æŠ•æ”¾ TVï¼ˆå¯¹ç…§ç»„ï¼‰\n\n# å¯¹æ¯”ä¸¤ç»„çš„åœ¨çº¿è½¬åŒ–ç‡\nuplift = (åŸå¸‚Aè½¬åŒ–ç‡ - åŸå¸‚Bè½¬åŒ–ç‡) / åŸå¸‚Bè½¬åŒ–ç‡\n```\n\n**æ–¹æ³• 2: Brand Lift Study**\n```python\n# éšæœºæŠ½æ ·ç”¨æˆ·åšè°ƒç ”\nå®éªŒç»„: çœ‹è¿‡ç”µè§†å¹¿å‘Šçš„ç”¨æˆ·\nå¯¹ç…§ç»„: æœªçœ‹è¿‡çš„ç”¨æˆ·\n\n# å¯¹æ¯”å“ç‰Œè®¤çŸ¥åº¦ã€è´­ä¹°æ„å‘ã€å®é™…è½¬åŒ–ç‡\n```\n\n**æ–¹æ³• 3: Marketing Mix Modeling (MMM)**\n```R\n# å›å½’æ¨¡å‹\nsales_t = Î²â‚€ + Î²â‚Â·TV_GRP_t + Î²â‚‚Â·Search_Spend_t + Î²â‚ƒÂ·Social_Impressions_t + Îµ_t\n\n# Î²â‚ ä¼°è®¡çš„æ˜¯ TV çš„è¾¹é™…æ•ˆåº”\n# ä½¿ç”¨æ—¶é—´åºåˆ—æ•°æ®ï¼Œä¸éœ€è¦ç”¨æˆ·çº§è·¯å¾„\n```\n\n**æ–¹æ³• 4: Survey + å½’å› ç»“åˆ**\n```python\n# åœ¨è½¬åŒ–åé—®å·è°ƒæŸ¥\n\"æ‚¨æ˜¯å¦‚ä½•äº†è§£åˆ°æˆ‘ä»¬çš„äº§å“çš„ï¼Ÿ\"\né€‰é¡¹: æœ‹å‹æ¨è / ç”µè§†å¹¿å‘Š / æœç´¢ / å…¶ä»–\n\n# å°†è°ƒç ”æ•°æ®ä¸è§¦è¾¾å½’å› ç»“åˆ\n```\n\n**å…³é”®æ´å¯Ÿ**:\n- **è§¦è¾¾å½’å› åªèƒ½çœ‹åˆ°\"æ•°å­—è¶³è¿¹\"**\n- **çº¿ä¸‹å½±å“ã€å£ç¢‘ã€å“ç‰Œè®¤çŸ¥ç­‰æ— æ³•è¿½è¸ªçš„å› ç´ ä¼šè¢«ç³»ç»Ÿæ€§ä½ä¼°**\n- **è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå“ç‰Œå¹¿å‘Šå›¢é˜Ÿæ€»æ˜¯æŠ±æ€¨å½’å› ç»“æœä¸å…¬å¹³**\n\n**å®è·µå»ºè®®**:\n1. è§¦è¾¾å½’å›  + å¢é‡å½’å›  ç»“åˆä½¿ç”¨\n2. ä¸ºçº¿ä¸‹æ¸ é“è®¾ç½®å•ç‹¬çš„è¡¡é‡ä½“ç³»ï¼ˆMMM, Brand Liftï¼‰\n3. ä¸è¦åªçœ‹å½’å› æ•°æ®åšå†³ç­–ï¼Œç»“åˆä¸šåŠ¡å¸¸è¯†\n4. æ‰¿è®¤å½’å› çš„å±€é™ï¼Œä¿æŒè°¦å‘\n\n---\n\n### é—®é¢˜ 4: å¢é‡å½’å› éœ€è¦ä»€ä¹ˆæ•°æ®ï¼Ÿå¦‚æœæ— æ³•åš RCT æ€ä¹ˆåŠï¼Ÿ\n\n**å‚è€ƒç­”æ¡ˆ**:\n\n**å¢é‡å½’å› éœ€è¦çš„æ•°æ®**:\n\n**ç†æƒ³æƒ…å†µï¼ˆRCTï¼‰**:\n```python\næ•°æ®ç»“æ„:\nuser_id | treatment | outcome | covariates\n--------|-----------|---------|------------\n001     | 1         | 1       | age=25, ...\n002     | 0         | 0       | age=30, ...\n...\n\n# treatment: æ˜¯å¦æš´éœ²äºè¯¥æ¸ é“ï¼ˆéšæœºåˆ†é…ï¼‰\n# outcome: æ˜¯å¦è½¬åŒ–\n# covariates: åå˜é‡ï¼ˆç”¨äºæ–¹å·®ç¼©å‡ï¼‰\n```\n\næœ€ä½è¦æ±‚:\n- éšæœºåŒ–åˆ†ç»„ï¼ˆTreatment vs Controlï¼‰\n- è¶³å¤Ÿæ ·æœ¬é‡ï¼ˆæ£€éªŒåŠ› > 80%ï¼‰\n- æ¸…æ™°çš„å¤„ç†å®šä¹‰ï¼ˆä»€ä¹ˆç®—\"æš´éœ²\"ï¼‰\n- æ— å¹²æ‰°å‡è®¾ï¼ˆSUTVAï¼‰\n\n**å¦‚æœæ— æ³•åš RCTï¼Œæ›¿ä»£æ–¹æ¡ˆ**:\n\n**æ–¹æ³• 1: å‡†å®éªŒè®¾è®¡**\n\na) **Geo-Experimentï¼ˆåœ°ç†å®éªŒï¼‰**\n```python\n# é€‚ç”¨äºæ— æ³•ç”¨æˆ·çº§éšæœºåŒ–çš„åœºæ™¯ï¼ˆå¦‚ç”µè§†å¹¿å‘Šï¼‰\nå¤„ç†ç»„: åŸå¸‚ A, C, Eï¼ˆæŠ•æ”¾å¹¿å‘Šï¼‰\nå¯¹ç…§ç»„: åŸå¸‚ B, D, Fï¼ˆä¸æŠ•æ”¾ï¼‰\n\n# ä½¿ç”¨ DIDï¼ˆåŒé‡å·®åˆ†ï¼‰ä¼°è®¡\neffect = (Y_treat_post - Y_treat_pre) - (Y_control_post - Y_control_pre)\n```\n\nä¼˜ç‚¹: ä¸éœ€è¦ç”¨æˆ·çº§æ•°æ®  \nç¼ºç‚¹: éœ€è¦åŸå¸‚é—´å¯æ¯”ï¼ˆå¹³è¡Œè¶‹åŠ¿å‡è®¾ï¼‰\n\nb) **Regression Discontinuityï¼ˆæ–­ç‚¹å›å½’ï¼‰**\n```python\n# å¦‚æœå¤„ç†æœ‰æ˜ç¡®çš„åˆ†é…è§„åˆ™\nä¾‹å¦‚ï¼šç”¨æˆ·è¯„åˆ† >= 80 æ‰å‘åˆ¸\n\n# åœ¨æ–­ç‚¹é™„è¿‘æ¯”è¾ƒ\nuplift = lim(xâ†’80âº) E[Y|X=x] - lim(xâ†’80â») E[Y|X=x]\n```\n\nä¼˜ç‚¹: æ¥è¿‘éšæœºåŒ–  \nç¼ºç‚¹: åªèƒ½ä¼°è®¡å±€éƒ¨æ•ˆåº”ï¼ˆæ–­ç‚¹é™„è¿‘ï¼‰\n\n**æ–¹æ³• 2: è§‚æµ‹æ•°æ® + å› æœæ¨æ–­æ–¹æ³•**\n\na) **Propensity Score Matchingï¼ˆPSMï¼‰**\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import NearestNeighbors\n\n# 1. ä¼°è®¡å€¾å‘å¾—åˆ†\nps_model = LogisticRegression()\nps_model.fit(X, treatment)\npropensity_scores = ps_model.predict_proba(X)[:, 1]\n\n# 2. åŒ¹é…\n# ä¸ºæ¯ä¸ªå¤„ç†ç»„ç”¨æˆ·æ‰¾åˆ°å€¾å‘å¾—åˆ†æœ€æ¥è¿‘çš„å¯¹ç…§ç»„ç”¨æˆ·\nmatcher = NearestNeighbors(n_neighbors=1)\nmatcher.fit(propensity_scores[treatment==0].reshape(-1,1))\ndistances, indices = matcher.kneighbors(\n    propensity_scores[treatment==1].reshape(-1,1)\n)\n\n# 3. è®¡ç®— ATT\ntreated_outcomes = outcomes[treatment==1]\nmatched_control_outcomes = outcomes[treatment==0][indices.flatten()]\natt = (treated_outcomes - matched_control_outcomes).mean()\n```\n\nå‡è®¾: \n- Unconfoundedness: ç»™å®š Xï¼Œtreatment ä¸æ½œåœ¨ç»“æœç‹¬ç«‹\n- Overlap: 0 < P(T=1|X) < 1\n\nb) **Double Machine Learning (DML)**\n```python\nfrom econml.dml import DML\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n\n# ä½¿ç”¨æœºå™¨å­¦ä¹ ä¼°è®¡ nuisance functions\ndml = DML(\n    model_y=RandomForestRegressor(),\n    model_t=RandomForestClassifier(),\n    discrete_treatment=True\n)\ndml.fit(Y, T, X=X)\ntreatment_effect = dml.effect(X)\n```\n\nä¼˜ç‚¹: å…è®¸é«˜ç»´ Xï¼Œå‡å°‘æ¨¡å‹è¯¯è®¾åå·®  \nç¼ºç‚¹: ä»éœ€è¦ unconfoundedness\n\nc) **Instrumental Variableï¼ˆå·¥å…·å˜é‡ï¼‰**\n```python\n# å¯»æ‰¾æ»¡è¶³ä»¥ä¸‹æ¡ä»¶çš„å·¥å…·å˜é‡ Z:\n# 1. Relevance: Cov(Z, T) â‰  0\n# 2. Exclusion: Z åªé€šè¿‡ T å½±å“ Y\n# 3. Exogeneity: Z ä¸ Îµ ç‹¬ç«‹\n\n# ä¾‹å¦‚ï¼šéšæœºå¹¿å‘Šç«ä»·å¤±è´¥ä½œä¸ºå·¥å…·å˜é‡\nfrom statsmodels.sandbox.regression.gmm import IV2SLS\n\niv_model = IV2SLS(Y, X, T, Z).fit()\ntreatment_effect = iv_model.params['T']\n```\n\n**æ–¹æ³• 3: è‡ªç„¶å®éªŒ**\n\nå¯»æ‰¾\"æ„å¤–\"çš„éšæœºåŒ–æœºä¼šï¼š\n- ç³»ç»Ÿæ•…éšœå¯¼è‡´éƒ¨åˆ†ç”¨æˆ·æœªæ”¶åˆ°å¹¿å‘Š\n- æ”¿ç­–å˜åŒ–ï¼ˆå¦‚GDPRï¼‰å½±å“éƒ¨åˆ†åœ°åŒº\n- ä¾›ç»™é™åˆ¶å¯¼è‡´éšæœºrationing\n\n**æ–¹æ³• 4: Holdout + å¤–æ¨**\n```python\n# é•¿æœŸè®¾ç½® Holdout ç»„ï¼ˆå¦‚ 5% ç”¨æˆ·æ°¸ä¸æŠ•æ”¾ï¼‰\nholdout_conversion_rate = 2.5%\nfull_conversion_rate = 3.2%\n\nincremental_lift = (3.2% - 2.5%) / 2.5% = 28%\n\n# æ³¨æ„ï¼šHoldout ç»„å¯èƒ½ä¸representativeï¼ˆéœ€è¦å®šæœŸè½®æ¢ï¼‰\n```\n\n**æ— æ³•åš RCT æ—¶çš„å†³ç­–æ¡†æ¶**:\n\n```\nèƒ½åš Geo-Experiment? â†’ æ˜¯ â†’ ç”¨ DID\n        â†“\n        å¦\n        â†“\næœ‰æ˜ç¡®åˆ†é…è§„åˆ™? â†’ æ˜¯ â†’ ç”¨ RDD\n        â†“\n        å¦\n        â†“\næœ‰å·¥å…·å˜é‡? â†’ æ˜¯ â†’ ç”¨ IV\n        â†“\n        å¦\n        â†“\nè§‚æµ‹æ•°æ® + PSM/DMLï¼ˆæ³¨æ„å‡è®¾ï¼ï¼‰\n        +\næ•æ„Ÿæ€§åˆ†æ\n```\n\n**å…³é”®åŸåˆ™**:\n1. **RCT æ˜¯é‡‘æ ‡å‡†**ï¼Œå°½é‡åˆ›é€ å®éªŒæœºä¼š\n2. å¦‚æœç”¨è§‚æµ‹æ•°æ®ï¼Œ**ä¸€å®šè¦æ£€éªŒå‡è®¾**ï¼ˆå¹³è¡Œè¶‹åŠ¿ã€overlapã€balanceï¼‰\n3. **ä¸‰è§’éªŒè¯**ï¼šå¤šç§æ–¹æ³•äº¤å‰éªŒè¯\n4. **è¯šå®æ±‡æŠ¥**ï¼šè¯´æ˜æ–¹æ³•å±€é™ï¼Œä¸è¦è¿‡åº¦è‡ªä¿¡\n\n---\n\n### é—®é¢˜ 5: ä¸€ä¸ªå…¬å¸åŒæ—¶åšè§¦è¾¾å½’å› å’Œå¢é‡å½’å› ï¼Œå‘ç°ç»“æœå·®å¼‚å¾ˆå¤§ã€‚ä½ ä¼šç›¸ä¿¡å“ªä¸ªï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n\n**å‚è€ƒç­”æ¡ˆ**:\n\n**çŸ­ç­”æ¡ˆ: ç›¸ä¿¡å¢é‡å½’å› ï¼ˆå¦‚æœå®éªŒè®¾è®¡åˆç†ï¼‰ã€‚**\n\n**é•¿ç­”æ¡ˆ: ä¸¤è€…å›ç­”ä¸åŒé—®é¢˜ï¼Œéƒ½æœ‰ä»·å€¼ï¼Œä½†å†³ç­–æ—¶åº”ä»¥å¢é‡å½’å› ä¸ºä¸»ã€‚**\n\n**è¯¦ç»†åˆ†æ**:\n\n**æ¡ˆä¾‹: æœç´¢å¹¿å‘Šçš„å½’å› å·®å¼‚**\n\n```\nè§¦è¾¾å½’å› ï¼ˆLast-touchï¼‰: 50% çš„è½¬åŒ–å½’å› ç»™æœç´¢\nå¢é‡å½’å› ï¼ˆRCT å®éªŒï¼‰: å…³é—­æœç´¢å¹¿å‘Šï¼Œè½¬åŒ–ç‡ä»…ä¸‹é™ 10%\n\nå·®å¼‚: 50% vs 10%ï¼Œå·¨å¤§ï¼\n```\n\n**åŸå› åˆ†æ**:\n\n1. **Selection Biasï¼ˆæ ¸å¿ƒåŸå› ï¼‰**:\n   ```\n   ç”¨æˆ·ç±»å‹åˆ†å¸ƒ:\n   \n   è§¦è¾¾å½’å› çœ‹åˆ°çš„ç”¨æˆ·ï¼ˆå·²è½¬åŒ–ï¼‰:\n   - é«˜æ„å‘ç”¨æˆ·: 70%ï¼ˆè¿™äº›äººä¼šä¸»åŠ¨æœç´¢å“ç‰Œè¯ï¼‰\n   - ä½æ„å‘ç”¨æˆ·: 30%\n   \n   å…¨é‡ç”¨æˆ·:\n   - é«˜æ„å‘ç”¨æˆ·: 20%\n   - ä½æ„å‘ç”¨æˆ·: 80%\n   \n   â†’ æœç´¢å¹¿å‘Šä¸»è¦è§¦è¾¾çš„æ˜¯é«˜æ„å‘ç”¨æˆ·ï¼ˆSure Thingsï¼‰\n   â†’ è¿™äº›äººå³ä½¿ä¸æŠ•æœç´¢å¹¿å‘Šï¼Œä¹Ÿä¼šé€šè¿‡ç›´æ¥è®¿é—®è´­ä¹°\n   â†’ è§¦è¾¾å½’å› é«˜ä¼°äº†æœç´¢çš„çœŸå®å¢é‡\n   ```\n\n2. **è§¦è¾¾å½’å› çš„å‡è®¾**:\n   - å‡è®¾ï¼šç”¨æˆ·è·¯å¾„ä¸­çš„æ‰€æœ‰æ¸ é“éƒ½\"è´¡çŒ®\"äº†è½¬åŒ–\n   - ç°å®ï¼šå¾ˆå¤šæ¸ é“åªæ˜¯\"å‚ä¸\"äº†ï¼Œæ²¡æœ‰\"å¯¼è‡´\"è½¬åŒ–\n\n3. **å¢é‡å½’å› çš„ä¼˜åŠ¿**:\n   - ç›´æ¥å›ç­”ï¼š\"å¦‚æœæ²¡æœ‰æœç´¢å¹¿å‘Šï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ\"\n   - æœ‰å¯¹ç…§ç»„ï¼ˆåäº‹å®ï¼‰\n   - è€ƒè™‘äº†ç”¨æˆ·çš„ baseline conversion\n\n**ä»€ä¹ˆæ—¶å€™ä¸¤è€…ä¼šæ¥è¿‘ï¼Ÿ**\n\nå½“æ»¡è¶³ä»¥ä¸‹æ¡ä»¶æ—¶ï¼Œè§¦è¾¾å½’å›  â‰ˆ å¢é‡å½’å› ï¼š\n1. **æ¸ é“é—´ç‹¬ç«‹**: ç”¨æˆ·è¦ä¹ˆåªæ¥è§¦ä¸€ä¸ªæ¸ é“ï¼Œè¦ä¹ˆä¸æ¥è§¦\n2. **æ—  Selection Bias**: æ¸ é“è§¦è¾¾æ˜¯éšæœºçš„ï¼ˆå®é™…ä¸­å‡ ä¹ä¸å¯èƒ½ï¼‰\n3. **æ—  Sure Things**: æ‰€æœ‰è½¬åŒ–ç”¨æˆ·éƒ½æ˜¯å› ä¸ºè¥é”€æ‰è½¬åŒ–\n\n**å®é™…å»ºè®®**:\n\n**1. åˆ†å±‚ä½¿ç”¨**:\n```python\nå†³ç­–ç±»å‹           |  ä½¿ç”¨å“ªç§å½’å› ï¼Ÿ         | åŸå› \n-------------------|------------------------|------------------\né¢„ç®—åˆ†é…           | å¢é‡å½’å›                | éœ€è¦çœŸå® ROI\næ¸ é“æ•ˆæœè¯„ä¼°       | å¢é‡å½’å›                | éœ€è¦å› æœæ•ˆåº”\nç”¨æˆ·æ—…ç¨‹åˆ†æ       | è§¦è¾¾å½’å›                | äº†è§£è·¯å¾„æ¨¡å¼\næ¸ é“ååŒåˆ†æ       | è§¦è¾¾å½’å› ï¼ˆShapleyï¼‰    | åˆ†æäº¤äº’æ•ˆåº”\næˆ˜ç•¥è§„åˆ’           | å¢é‡å½’å›  + MMM         | é•¿æœŸå½±å“\n```\n\n**2. ç»“åˆä½¿ç”¨**:\n```python\n# ç”¨è§¦è¾¾å½’å› å‘ç°å¼‚å¸¸\nif Last_touch['æœç´¢å¹¿å‘Š'] > 50%:\n    # è®¾è®¡ RCT éªŒè¯\n    run_experiment('æœç´¢å¹¿å‘Šå…³åœå®éªŒ')\n    \n    if incremental_effect < 20%:\n        # ç¡®å®é«˜ä¼°äº†ï¼Œè°ƒæ•´é¢„ç®—\n        reduce_budget('æœç´¢å¹¿å‘Š')\n        increase_budget('å“ç‰Œå¹¿å‘Š')\n```\n\n**3. æ ¡å‡†è§¦è¾¾å½’å› **:\n```python\n# ä½¿ç”¨å¢é‡å½’å› ç»“æœæ ¡å‡†è§¦è¾¾å½’å› æƒé‡\ncalibration_factor = {\n    'æœç´¢å¹¿å‘Š': å¢é‡æ•ˆåº” / è§¦è¾¾å½’å› ,  # å¦‚ 10% / 50% = 0.2\n    'å“ç‰Œå¹¿å‘Š': ...\n}\n\ncalibrated_attribution = touch_attribution * calibration_factor\n```\n\n**è­¦ç¤ºæ¡ˆä¾‹**:\n\n```\næŸç”µå•†å¹³å°æ¡ˆä¾‹:\n\nè§¦è¾¾å½’å› ç»“æœ:\n- Retargeting: 60%\n- Brand Display: 10%\n- Search: 25%\n- Social: 5%\n\nåŸºäºæ­¤åˆ†é…é¢„ç®— â†’ 80% ç»™ Retargeting\n\nå¢é‡å®éªŒç»“æœ:\n- Retargeting: çœŸå®å¢é‡ 5%ï¼ˆå¤§éƒ¨åˆ†æ˜¯ Sure Thingsï¼‰\n- Brand Display: çœŸå®å¢é‡ 30%ï¼ˆå¸¦æ¥æ–°å®¢æˆ·ï¼‰\n- Search: çœŸå®å¢é‡ 15%\n- Social: çœŸå®å¢é‡ 12%\n\nå¦‚æœåªçœ‹è§¦è¾¾å½’å›  â†’ é”™è¯¯å†³ç­– â†’ ROI ä¸‹é™ 40%\n```\n\n**åˆ¤æ–­å®éªŒæ˜¯å¦å¯ä¿¡çš„æ ‡å‡†**:\n\nå¢é‡å½’å› ï¼ˆå®éªŒï¼‰å¯ä¿¡ï¼Œå½“ä¸”ä»…å½“ï¼š\n1. **éšæœºåŒ–æˆåŠŸ**: å®éªŒç»„ vs å¯¹ç…§ç»„ balanceï¼ˆæ£€éªŒåå˜é‡ï¼‰\n2. **æ ·æœ¬é‡å……è¶³**: Power â‰¥ 80%ï¼ŒMDE åˆç†\n3. **æ— å¹²æ‰°**: SUTVA æ»¡è¶³ï¼ˆå®éªŒç»„ä¸å½±å“å¯¹ç…§ç»„ï¼‰\n4. **å®éªŒæ‰§è¡Œæ— è¯¯**: æ— æ•°æ®æ³„éœ²ã€æ— æ—©åœåå·®\n5. **ç»“æœå¯å¤ç°**: å¤šæ¬¡å®éªŒç»“æœä¸€è‡´\n\n**æœ€ç»ˆç»“è®º**:\n\n| ç»´åº¦ | è§¦è¾¾å½’å›  | å¢é‡å½’å›  |\n|------|---------|---------|\n| **å›ç­”é—®é¢˜** | è°å‚ä¸äº†è½¬åŒ– | è°å¯¼è‡´äº†è½¬åŒ– |\n| **å› æœè§£é‡Š** | âŒ ä¸å¯ä¿¡ | âœ… å¯ä¿¡ï¼ˆå¦‚æœå®éªŒè®¾è®¡å¥½ï¼‰|\n| **å†³ç­–æŒ‡å¯¼** | âš ï¸ å‚è€ƒ | âœ… ä¸»è¦ä¾æ® |\n| **å®æ–½æˆæœ¬** | ä½ | é«˜ |\n| **é€‚ç”¨åœºæ™¯** | æ¢ç´¢åˆ†æ | æˆ˜ç•¥å†³ç­– |\n\n**ä¸€å¥è¯æ€»ç»“**:\n> è§¦è¾¾å½’å› å¸®ä½ \"çœ‹\"ï¼Œå¢é‡å½’å› å¸®ä½ \"å†³ç­–\"ã€‚å½“ä¸¤è€…å†²çªæ—¶ï¼Œç›¸ä¿¡å¢é‡å½’å› ï¼Œä½†ä¹Ÿè¦ç†è§£è§¦è¾¾å½’å› æ­ç¤ºçš„ç”¨æˆ·è¡Œä¸ºæ¨¡å¼ã€‚\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## ğŸ¯ é¢è¯•é¢˜æ¨¡æ‹Ÿ\n\n### æ¦‚å¿µé¢˜\n\n#### é—®é¢˜ 1: è§¦è¾¾å½’å›  vs å¢é‡å½’å› \n\n**é¢è¯•å®˜**: è¯·è§£é‡Šè§¦è¾¾å½’å› å’Œå¢é‡å½’å› çš„åŒºåˆ«ï¼Œä»¥åŠå„è‡ªçš„åº”ç”¨åœºæ™¯ã€‚\n\n**å‚è€ƒç­”æ¡ˆ**:\n\n**æ ¸å¿ƒåŒºåˆ«**ï¼š\n- **è§¦è¾¾å½’å›  (Touch Attribution)**: å›ç­”\"è°å‚ä¸äº†è½¬åŒ–\"\n  - æ•°æ®ï¼šåªçœ‹è½¬åŒ–ç”¨æˆ·çš„è§¦ç‚¹è·¯å¾„\n  - æ–¹æ³•ï¼šLast-touch, Shapley Value, Markov Chain\n  - é—®é¢˜ï¼šæ²¡æœ‰åäº‹å®ï¼Œæ— æ³•çŸ¥é“\"å¦‚æœæ²¡æœ‰è¿™ä¸ªæ¸ é“ä¼šæ€æ ·\"\n\n- **å¢é‡å½’å›  (Incremental Attribution)**: å›ç­”\"è°å¯¼è‡´äº†è½¬åŒ–\"\n  - æ•°æ®ï¼šéœ€è¦è½¬åŒ– + æœªè½¬åŒ–ç”¨æˆ·ï¼ˆå®éªŒ vs è§‚æµ‹ï¼‰\n  - æ–¹æ³•ï¼šRCT, Geo-experiment, PSM\n  - ä¼˜åŠ¿ï¼šä¼°è®¡å› æœæ•ˆåº”ï¼ˆçœŸå®å¢é‡ï¼‰\n\n**åº”ç”¨åœºæ™¯**ï¼š\n- **è§¦è¾¾å½’å› **: å¿«é€Ÿäº†è§£ç”¨æˆ·æ—…ç¨‹ã€æ¸ é“ç»„åˆåˆ†æ\n- **å¢é‡å½’å› **: é¢„ç®—åˆ†é…å†³ç­–ã€æ¸ é“æ•ˆæœè¯„ä¼°\n\n**å®é™…ä¾‹å­**ï¼š\n```\nåœºæ™¯ï¼šRetargeting å¹¿å‘Š\n\nè§¦è¾¾å½’å› ç»“æœï¼š\n- Last-touch å½’å›  60%ï¼ˆå› ä¸ºæ€»æ˜¯æœ€åè§¦ç‚¹ï¼‰\n- çœ‹èµ·æ¥æ•ˆæœå¾ˆå¥½\n\nå¢é‡å½’å› ç»“æœï¼ˆé€šè¿‡ Ghost Ads å®éªŒï¼‰ï¼š\n- çœŸå®å¢é‡åªæœ‰ +2%\n- å¤§éƒ¨åˆ†ç”¨æˆ·æœ¬æ¥å°±ä¼šè½¬åŒ–ï¼ˆSure Thingsï¼‰\n\nç»“è®ºï¼šè§¦è¾¾å½’å› é«˜ä¼°äº† Retargeting çš„ä»·å€¼\n```\n\n---\n\n#### é—®é¢˜ 2: Shapley Value çš„ä¼˜åŠ¿å’Œå±€é™\n\n**é¢è¯•å®˜**: ä¸ºä»€ä¹ˆè¯´ Shapley Value å½’å› æ¯”è§„åˆ™å½’å› æ›´\"å…¬å¹³\"ï¼Ÿå®ƒæœ‰ä»€ä¹ˆå±€é™æ€§ï¼Ÿ\n\n**å‚è€ƒç­”æ¡ˆ**:\n\n**Shapley Value çš„ä¼˜åŠ¿**ï¼š\n1. **å…¬ç†åŒ–åŸºç¡€**: å”¯ä¸€æ»¡è¶³ 4 ä¸ªå…¬ç†çš„åˆ†é…æ–¹æ¡ˆ\n   - æ•ˆç‡æ€§ï¼šÎ£Ï†áµ¢ = v(N)\n   - å¯¹ç§°æ€§ï¼šå¯äº’æ¢ç©å®¶è´¡çŒ®ç›¸ç­‰\n   - è™šæ‹Ÿæ€§ï¼šæ— è´¡çŒ®ç©å®¶å¾— 0\n   - å¯åŠ æ€§ï¼šçº¿æ€§\n\n2. **è€ƒè™‘æ‰€æœ‰å¯èƒ½çš„åŠ å…¥é¡ºåº**: ä¸åƒ Last-touch é‚£æ ·æ­¦æ–­\n\n3. **ç†è®ºä¿è¯**: åšå¼ˆè®ºè¯æ˜çš„\"å…¬å¹³åˆ†é…\"\n\n**å±€é™æ€§**ï¼š\n1. **è®¡ç®—å¤æ‚åº¦**: O(2â¿)ï¼Œæ¸ é“å¤šæ—¶ä¸å¯è¡Œ\n   - 5 ä¸ªæ¸ é“ï¼š32 ç§å­é›†\n   - 10 ä¸ªæ¸ é“ï¼š1024 ç§å­é›†\n\n2. **æ•°æ®éœ€æ±‚**: éœ€è¦ä¼°è®¡æ‰€æœ‰å­é›†çš„ä»·å€¼å‡½æ•° v(S)\n   - å®é™…ä¸­å¾ˆå¤šç»„åˆæ²¡æœ‰æ•°æ®\n\n3. **ä»æ˜¯è§¦è¾¾å½’å› **: æ²¡æœ‰å›ç­”\"å¦‚æœæ²¡æœ‰æŸæ¸ é“ä¼šæ€æ ·\"\n   - åªæ˜¯æ›´å…¬å¹³åœ°åˆ†é…\"åŠŸåŠ³\"\n   - ä¸ç­‰äºå› æœæ•ˆåº”\n\n4. **å‡è®¾ç‹¬ç«‹æ€§**: æ¸ é“é—´å¯èƒ½æœ‰ååŒ/æ›¿ä»£æ•ˆåº”\n\n**å·¥ç¨‹å®è·µ**ï¼š\n- Google çš„ Data-Driven Attribution ä½¿ç”¨è¿‘ä¼¼ç®—æ³•\n- é™åˆ¶æ¸ é“æ•°ï¼ˆèšåˆå°æ¸ é“ï¼‰\n- ä½¿ç”¨é‡‡æ ·ä¼°è®¡\n\n---\n\n### ç¼–ç¨‹é¢˜\n\n#### é—®é¢˜ 3: å®ç°ç®€åŒ–ç‰ˆ Shapley Value\n\n**é¢è¯•å®˜**: æ‰‹å†™ä¸€ä¸ªç®€åŒ–ç‰ˆçš„ Shapley Value è®¡ç®—å‡½æ•°ï¼ˆå‡è®¾åªæœ‰ 3 ä¸ªæ¸ é“ï¼‰ã€‚\n\n**å‚è€ƒç­”æ¡ˆ**:\n\n```python\ndef shapley_value_simple(conversion_data, channels):\n    \"\"\"\n    ç®€åŒ–ç‰ˆ Shapley Value è®¡ç®—\n    \n    Args:\n        conversion_data: List[Tuple[Set[str], float]]\n            [(æ¸ é“é›†åˆ, è½¬åŒ–ä»·å€¼), ...]\n        channels: List[str]\n            æ¸ é“åˆ—è¡¨\n    \n    Returns:\n        Dict[str, float]: å„æ¸ é“çš„ Shapley å€¼\n    \"\"\"\n    from itertools import combinations\n    \n    # æ„å»ºä»·å€¼å‡½æ•°\n    def v(channel_set):\n        \\\"\\\"\\\"è®¡ç®—åŒ…å« channel_set ä¸­æ‰€æœ‰æ¸ é“çš„è·¯å¾„çš„å¹³å‡ä»·å€¼\\\"\\\"\\\"\n        matching_values = [\n            value for path_channels, value in conversion_data\n            if channel_set.issubset(path_channels)\n        ]\n        return np.mean(matching_values) if matching_values else 0.0\n    \n    shapley = {}\n    n = len(channels)\n    \n    for channel in channels:\n        channel_value = 0.0\n        other_channels = [c for c in channels if c != channel]\n        \n        # éå†æ‰€æœ‰ä¸åŒ…å«å½“å‰æ¸ é“çš„å­é›†\n        for size in range(n):\n            for subset in combinations(other_channels, size):\n                subset_set = set(subset)\n                \n                # è¾¹é™…è´¡çŒ®\n                marginal = v(subset_set | {channel}) - v(subset_set)\n                \n                # Shapley æƒé‡\n                from math import factorial\n                weight = factorial(size) * factorial(n - size - 1) / factorial(n)\n                \n                channel_value += weight * marginal\n        \n        shapley[channel] = channel_value\n    \n    return shapley\n\n# æµ‹è¯•\ndata = [\n    ({'Search'}, 100),\n    ({'Social', 'Search'}, 150),\n    ({'Email', 'Search'}, 120),\n    ({'Social', 'Email', 'Search'}, 200),\n]\nchannels = ['Search', 'Social', 'Email']\nresult = shapley_value_simple(data, channels)\nprint(\"Shapley Values:\", result)\n```\n\n**å…³é”®ç‚¹**ï¼š\n1. ç†è§£ Shapley å…¬å¼çš„ç»„åˆä¼˜åŒ–æœ¬è´¨\n2. æ­£ç¡®è®¡ç®—æƒé‡ï¼ˆæ’åˆ—ç»„åˆï¼‰\n3. å¤„ç†è¾¹ç•Œæƒ…å†µï¼ˆç©ºé›†ã€å…¨é›†ï¼‰\n\n---\n\n#### é—®é¢˜ 4: Markov Chain å½’å› çš„è½¬ç§»çŸ©é˜µ\n\n**é¢è¯•å®˜**: ç»™å®šç”¨æˆ·è·¯å¾„æ•°æ®ï¼Œå¦‚ä½•æ„å»º Markov Chain çš„è½¬ç§»çŸ©é˜µï¼Ÿ\n\n**å‚è€ƒç­”æ¡ˆ**:\n\n```python\ndef build_transition_matrix(paths):\n    \"\"\"\n    æ„å»º Markov Chain è½¬ç§»çŸ©é˜µ\n    \n    Args:\n        paths: List[List[str]]\n            ç”¨æˆ·è·¯å¾„åˆ—è¡¨\n    \n    Returns:\n        pd.DataFrame: è½¬ç§»æ¦‚ç‡çŸ©é˜µ\n    \"\"\"\n    from collections import defaultdict\n    \n    # ç»Ÿè®¡è½¬ç§»æ¬¡æ•°\n    transitions = defaultdict(lambda: defaultdict(int))\n    \n    for path in paths:\n        # Start -> ç¬¬ä¸€ä¸ªè§¦ç‚¹\n        transitions['Start'][path[0]] += 1\n        \n        # è§¦ç‚¹ä¹‹é—´çš„è½¬ç§»\n        for i in range(len(path) - 1):\n            transitions[path[i]][path[i+1]] += 1\n        \n        # æœ€åä¸€ä¸ªè§¦ç‚¹ -> Conversion\n        transitions[path[-1]]['Conversion'] += 1\n    \n    # è½¬æ¢ä¸ºæ¦‚ç‡ï¼ˆå½’ä¸€åŒ–ï¼‰\n    transition_probs = {}\n    for from_state, to_states in transitions.items():\n        total = sum(to_states.values())\n        transition_probs[from_state] = {\n            to_state: count / total\n            for to_state, count in to_states.items()\n        }\n    \n    # è½¬æ¢ä¸º DataFrame\n    all_states = set(['Start', 'Conversion'])\n    for path in paths:\n        all_states.update(path)\n    \n    matrix = pd.DataFrame(0.0, index=all_states, columns=all_states)\n    for from_state, to_dict in transition_probs.items():\n        for to_state, prob in to_dict.items():\n            matrix.loc[from_state, to_state] = prob\n    \n    return matrix\n\n# æµ‹è¯•\npaths = [\n    ['Social', 'Search'],\n    ['Search'],\n    ['Social', 'Email', 'Search'],\n    ['Display', 'Search'],\n]\nmatrix = build_transition_matrix(paths)\nprint(\"è½¬ç§»çŸ©é˜µ:\")\nprint(matrix)\n```\n\n**å…³é”®ç‚¹**ï¼š\n1. ç†è§£é©¬å°”å¯å¤«é“¾çš„çŠ¶æ€è½¬ç§»\n2. æ­£ç¡®å½’ä¸€åŒ–ï¼ˆæ¯è¡Œå’Œä¸º 1ï¼‰\n3. å¤„ç† Start å’Œ Conversion ç‰¹æ®ŠçŠ¶æ€\n\n---\n\n### åœºæ™¯é¢˜\n\n#### é—®é¢˜ 5: å®é™…ä¸šåŠ¡é—®é¢˜\n\n**é¢è¯•å®˜**: ä½ ä»¬å…¬å¸çš„ Last-touch å½’å› æ˜¾ç¤ºæœç´¢å¹¿å‘Šè´¡çŒ®äº† 50% çš„è½¬åŒ–ï¼Œä½† CMO æ€€ç–‘è¿™ä¸ªæ•°å­—ã€‚å¦‚ä½•éªŒè¯ï¼Ÿ\n\n**å‚è€ƒç­”æ¡ˆ**:\n\n**åˆ†ææ€è·¯**ï¼š\n\n1. **è¯†åˆ«é—®é¢˜**ï¼š\n   - Last-touch å€¾å‘äºé«˜ä¼°\"æœ€åè§¦ç‚¹\"\n   - æœç´¢å¹¿å‘Šç»å¸¸å‡ºç°åœ¨è·¯å¾„æœ«ç«¯ï¼ˆç”¨æˆ·ä¸»åŠ¨æœç´¢ï¼‰\n   - å¯èƒ½æ˜¯ã€Œé¡ºæ°´æ¨èˆŸã€è€Œéã€Œé›ªä¸­é€ç‚­ã€\n\n2. **éªŒè¯æ–¹æ³•**ï¼š\n\n   **æ–¹æ³• 1: å¯¹æ¯”å¤šç§å½’å› æ–¹æ³•**\n   ```\n   - Last-touch: 50%\n   - First-touch: 20%\n   - Linear: 35%\n   - Shapley: 30%\n   \n   â†’ è¯´æ˜ Last-touch ç¡®å®é«˜ä¼°äº†\n   ```\n\n   **æ–¹æ³• 2: åˆ†æç”¨æˆ·è·¯å¾„**\n   ```python\n   # æ£€æŸ¥æœç´¢å¹¿å‘Šå‡ºç°çš„ä½ç½®\n   search_positions = []\n   for path in paths:\n       if 'Search' in path:\n           pos = path.index('Search') / len(path)\n           search_positions.append(pos)\n   \n   # å¦‚æœå¹³å‡ä½ç½® > 0.7ï¼Œè¯´æ˜ç»å¸¸åœ¨æœ«å°¾\n   avg_position = np.mean(search_positions)\n   print(f\"æœç´¢å¹¿å‘Šå¹³å‡ä½ç½®: {avg_position:.2f} (1.0=æœ€å)\")\n   ```\n\n   **æ–¹æ³• 3: å¢é‡å®éªŒï¼ˆæ¨èï¼‰**\n   ```\n   è®¾è®¡ Geo-experiment:\n   - é€‰æ‹©ç›¸ä¼¼çš„åœ°åŒº\n   - å®éªŒç»„ï¼šæ­£å¸¸æŠ•æ”¾æœç´¢å¹¿å‘Š\n   - å¯¹ç…§ç»„ï¼šå…³é—­æœç´¢å¹¿å‘Š\n   - å¯¹æ¯”è½¬åŒ–ç‡å·®å¼‚\n   \n   å¦‚æœå®é™…å¢é‡åªæœ‰ 10%ï¼Œè¯´æ˜ Last-touch çš„ 50% ä¸¥é‡é«˜ä¼°\n   ```\n\n3. **å»ºè®®æ–¹æ¡ˆ**ï¼š\n   - çŸ­æœŸï¼šæ”¹ç”¨ Shapley æˆ– Position-based å½’å› \n   - ä¸­æœŸï¼šå®æ–½å¢é‡å®éªŒ\n   - é•¿æœŸï¼šå»ºç«‹ MMMï¼ˆMarketing Mix Modelingï¼‰\n\n**é¢è¯•åŠ åˆ†ç‚¹**ï¼š\n- æåˆ°å…·ä½“çš„å®éªŒè®¾è®¡\n- è®¨è®ºæ•°æ®åå·®ï¼ˆCookie ä¸¢å¤±ã€è·¨è®¾å¤‡ï¼‰\n- è€ƒè™‘ä¸šåŠ¡å½±å“ï¼ˆé¢„ç®—é‡åˆ†é…ï¼‰\n\n---\n\n### æ€ç»´æ‹“å±•é¢˜\n\n#### é—®é¢˜ 6: çº¿ä¸‹æ¸ é“çš„å½’å› \n\n**é¢è¯•å®˜**: ç”µè§†å¹¿å‘Šã€çº¿ä¸‹æ´»åŠ¨è¿™äº›æ¸ é“æ— æ³•ç²¾å‡†è¿½è¸ªï¼Œå¦‚ä½•åšå½’å› ï¼Ÿ\n\n**å‚è€ƒç­”æ¡ˆ**:\n\n**æŒ‘æˆ˜**ï¼š\n- æ— æ³•è¿½è¸ªä¸ªä½“çº§è§¦è¾¾\n- æ— æ³•è®°å½•åœ¨è½¬åŒ–è·¯å¾„ä¸­\n- è§¦è¾¾å½’å› å¤±æ•ˆ\n\n**è§£å†³æ–¹æ¡ˆ**ï¼š\n\n1. **Geo-based å®éªŒ**ï¼š\n   ```\n   - ä¸åŒåŸå¸‚æŠ•æ”¾ä¸åŒçš„ç”µè§†å¹¿å‘Š\n   - å¯¹æ¯”å„åŸå¸‚çš„åœ¨çº¿è½¬åŒ–ç‡\n   - è¯†åˆ«ç”µè§†å¹¿å‘Šçš„å¢é‡æ•ˆåº”\n   ```\n\n2. **æ—¶é—´åºåˆ—åˆ†æ**ï¼š\n   ```python\n   # æ£€æŸ¥ç”µè§†å¹¿å‘Šæ’­å‡ºæ—¶æ®µå‰åçš„æœç´¢é‡å˜åŒ–\n   tv_schedule = [...]  # å¹¿å‘Šæ’­å‡ºæ—¶é—´\n   search_volume = [...]  # æœç´¢é‡\n   \n   # DID åˆ†æ\n   before = search_volume[två‰]\n   after = search_volume[två]\n   uplift = (after - before) / before\n   ```\n\n3. **Brand Lift Study**ï¼š\n   ```\n   - éšæœºé€‰æ‹©ç”¨æˆ·åšå“ç‰Œè®¤çŸ¥è°ƒç ”\n   - å®éªŒç»„ï¼šçœ‹è¿‡ç”µè§†å¹¿å‘Š\n   - å¯¹ç…§ç»„ï¼šæœªçœ‹è¿‡\n   - å¯¹æ¯”åç»­è½¬åŒ–ç‡\n   ```\n\n4. **MMM (Marketing Mix Modeling)**ï¼š\n   ```R\n   # ä½¿ç”¨å›å½’æ¨¡å‹\n   sales ~ TV_GRP + Search_Spend + Social_Impressions + ...\n   \n   # ä¼°è®¡å„æ¸ é“çš„å¼¹æ€§ç³»æ•°\n   # TV_GRP çš„ç³»æ•° = ç”µè§†å¹¿å‘Šçš„è¾¹é™…æ•ˆåº”\n   ```\n\n**å…³é”®æ´å¯Ÿ**ï¼š\n- çº¿ä¸‹æ¸ é“æ›´é€‚åˆå¢é‡å½’å› \n- éœ€è¦å®è§‚å±‚é¢çš„å› æœæ¨æ–­ï¼ˆGeo, MMMï¼‰\n- ä¸èƒ½åªçœ‹è§¦è¾¾å½’å› \n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š æ€»ç»“\n",
    "\n",
    "### æ ¸å¿ƒçŸ¥è¯†ç‚¹\n",
    "\n",
    "| æ¦‚å¿µ | è¦ç‚¹ | é€‚ç”¨åœºæ™¯ |\n",
    "|------|------|----------|\n",
    "| **è§¦è¾¾å½’å› ** | åŸºäºè½¬åŒ–è·¯å¾„åˆ†é…\"åŠŸåŠ³\" | äº†è§£ç”¨æˆ·æ—…ç¨‹ã€æ¸ é“ç»„åˆ |\n",
    "| **Last-touch** | 100% ç»™æœ€åè§¦ç‚¹ | çŸ­å‘¨æœŸã€ç›´æ¥è½¬åŒ– |\n",
    "| **Shapley Value** | åŸºäºåˆä½œåšå¼ˆè®ºï¼Œæ»¡è¶³å…¬ç†æ€§ | éœ€è¦\"å…¬å¹³\"åˆ†é… |\n",
    "| **Markov Chain** | åŸºäºè½¬ç§»æ¦‚ç‡ï¼Œç§»é™¤æ•ˆåº” | è€ƒè™‘è·¯å¾„åŠ¨æ€ |\n",
    "| **å¢é‡å½’å› ** | åŸºäºåäº‹å®ï¼Œä¼°è®¡å› æœæ•ˆåº” | **é¢„ç®—å†³ç­–ã€æ•ˆæœè¯„ä¼°** |\n",
    "\n",
    "### å…³é”®å…¬å¼\n",
    "\n",
    "**Shapley Value:**\n",
    "$$\n",
    "\\phi_i(v) = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|! \\cdot (|N| - |S| - 1)!}{|N|!} \\cdot [v(S \\cup \\{i\\}) - v(S)]\n",
    "$$\n",
    "\n",
    "**Removal Effect (Markov):**\n",
    "$$\n",
    "\\text{RE}_c = \\frac{P(\\text{Conv}) - P(\\text{Conv | remove } c)}{P(\\text{Conv})}\n",
    "$$\n",
    "\n",
    "### æœ€é‡è¦çš„å¯ç¤º\n",
    "\n",
    "> **\"å‚ä¸äº†è½¬åŒ–\" â‰  \"å¯¼è‡´äº†è½¬åŒ–\"**\n",
    ">\n",
    "> è§¦è¾¾å½’å› å‘Šè¯‰ä½ ç”¨æˆ·ç»å†äº†ä»€ä¹ˆï¼Œ  \n",
    "> å¢é‡å½’å› å‘Šè¯‰ä½ ä»€ä¹ˆçœŸæ­£èµ·äº†ä½œç”¨ã€‚\n",
    ">\n",
    "> ç”¨è§¦è¾¾å½’å› ç†è§£ï¼Œç”¨å¢é‡å½’å› å†³ç­–ã€‚\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "- åœ¨ `part6_2_coupon_optimization.ipynb` ä¸­ï¼Œæˆ‘ä»¬ä¼šå­¦ä¹ å¦‚ä½•ç”¨å› æœæ¨æ–­æ–¹æ³•åšä¼˜æƒ åˆ¸ä¼˜åŒ–\n",
    "- åœ¨ `part6_4_budget_allocation.ipynb` ä¸­ï¼Œæˆ‘ä»¬ä¼šå­¦ä¹ å¦‚ä½•ç»“åˆå½’å› ç»“æœè¿›è¡Œé¢„ç®—ä¼˜åŒ–\n",
    "\n",
    "---\n",
    "\n",
    "**æ­å–œä½ å®Œæˆäº†è¥é”€å½’å› çš„å­¦ä¹ ï¼** ğŸ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}